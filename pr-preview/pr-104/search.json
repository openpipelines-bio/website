[
  {
    "objectID": "user_guide/getting_started.html",
    "href": "user_guide/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "Depending on whether you plan to run the OpenPipelines workflows locally or in the cloud",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Getting started"
    ]
  },
  {
    "objectID": "user_guide/getting_started.html#starting-workflows-locally",
    "href": "user_guide/getting_started.html#starting-workflows-locally",
    "title": "Getting started",
    "section": "Starting workflows locally",
    "text": "Starting workflows locally\nIf you want to start workflows locally, you will need to install Nextflow.\n\nInstall Docker (optional)\nDocker is a containerization platform that allows you to package your application and all its dependencies into a single image. It is used to run the analysis pipelines.\nIf you are planning on running the workflows locally, you will need to install Docker. You do not need to install Docker if the workflows will be run in the cloud using AWS Batch, Azure Batch, Google Cloud Batch, or other cloud-based compute environments.\nTo install Docker, follow the instructions here.\n\n\nInstall Java\nNextflow requires Java 11 or later. To check if Java is installed on your system, run:\njava -version\nIf Java is not installed, you can download it from here.\n\n\nInstall Nextflow\nNextflow is distributed as a single executable file. To install it, run:\ncurl -s https://get.nextflow.io | bash\nThis command will download the latest version of Nextflow and store it in the current directory.\nTo install Nextflow system-wide, move the downloaded file to a directory in your $PATH, e.g.:\nmv nextflow /usr/local/bin\n\n\nTest the installation\nTo test the installation, run:\nnextflow run hello -with-docker",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Getting started"
    ]
  },
  {
    "objectID": "user_guide/getting_started.html#using-nextflow-tower",
    "href": "user_guide/getting_started.html#using-nextflow-tower",
    "title": "Getting started",
    "section": "Using Nextflow Tower",
    "text": "Using Nextflow Tower\nNextflow Tower is a web-based user interface for running and monitoring Nextflow pipelines. If you are planning on using Nextflow Tower, a compute environment will need to be set up.",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Getting started"
    ]
  },
  {
    "objectID": "user_guide/running_pipelines.html",
    "href": "user_guide/running_pipelines.html",
    "title": "Running pipelines",
    "section": "",
    "text": "Dependening on whether you want to run a workflow locally or on cloud infrastructure, using Nextflow Tower or not, you will need to use different commands.",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Running pipelines"
    ]
  },
  {
    "objectID": "user_guide/running_pipelines.html#run-locally-from-the-cli",
    "href": "user_guide/running_pipelines.html#run-locally-from-the-cli",
    "title": "Running pipelines",
    "section": "Run locally from the CLI",
    "text": "Run locally from the CLI\nYou can run a workflow from the command line using the following command:\nnextflow run openpipelines-bio/openpipeline \\\n  -main-script target/nextflow/workflows/integration/multimodal_integration/main.nf \\\n  -revision 0.12.1 \\\n  -latest \\\n  -profile docker \\\n  --publish_dir foo/ \\\n  --input \"bar\" \\\n  --output \"test.txt\"\nDoing so will run the workflow locally using a Docker container.",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Running pipelines"
    ]
  },
  {
    "objectID": "user_guide/running_pipelines.html#on-cloud-infrastructure",
    "href": "user_guide/running_pipelines.html#on-cloud-infrastructure",
    "title": "Running pipelines",
    "section": "On cloud infrastructure",
    "text": "On cloud infrastructure\nYou can use a similar command to run the workflow on cloud infrastructure, such as AWS Batch or Google Cloud Platform. However, this requires you to create a separate Nextflow config file for each cloud provider. See the Nextflow documentation for more information.\nnextflow run openpipelines-bio/openpipeline \\\n  -main-script target/nextflow/workflows/integration/multimodal_integration/main.nf \\\n  -revision 0.12.1 \\\n  -latest \\\n  --publish_dir foo/ \\\n  --input \"bar\" \\\n  --output \"test.txt\" \\\n  -c configs/my_hpc.config",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Running pipelines"
    ]
  },
  {
    "objectID": "user_guide/running_pipelines.html#using-the-nextflow-tower-cli",
    "href": "user_guide/running_pipelines.html#using-the-nextflow-tower-cli",
    "title": "Running pipelines",
    "section": "Using the Nextflow Tower CLI",
    "text": "Using the Nextflow Tower CLI\nIf you have access to a Nextflow Tower instance in which a Compute Environment has already been set up, you can run a workflow from the Tower CLI. The command is very similar to the command to run a workflow from the CLI, but you need to: * Use tw launch instead of nextflow run * Specify the workspace ID and compute environment ID * Rename arguments: -revision to --revision, -latest to --pull-latest, -main-script to --main-script, -c to --config * Store workflow arguments in a separate yaml file (if this was not already the case).\nExample:\ntw launch openpipelines-bio/openpipeline \\\n  --revision 0.12.1 \\\n  --pull-latest \\\n  --main-script target/nextflow/workflows/integration/multimodal_integration/main.nf \\\n  --workspace &lt;your workspace id&gt; \\\n  --compute-env &lt;your compute environment id&gt; \\\n  --params-file params.yaml \\\n  --config configs/my_hpc.config",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Running pipelines"
    ]
  },
  {
    "objectID": "user_guide/running_pipelines.html#using-the-nextflow-tower-web-ui",
    "href": "user_guide/running_pipelines.html#using-the-nextflow-tower-web-ui",
    "title": "Running pipelines",
    "section": "Using the Nextflow Tower Web UI",
    "text": "Using the Nextflow Tower Web UI\nIf you have access to a Nextflow Tower instance in which a Compute Environment has already been set up, you can run a workflow from the Tower UI. To do so, go to the “Launchpad” and click on the button “launch a run without configuration”.\n\nNext, fill in the required fields and click on “Launch run”.\n\nCompute environment: Select the compute environment you want to run the workflow on.\nPipeline to launch: Fill in openpipelines-bio/openpipeline.\nRevision number: The release number of the pipeline you want to run, e.g. 0.12.1. You can find the release number on the GitHub releases page.\nWork directory: The bucket path where the scratch data is stored.\nPipeline parameters: The YAML or JSON of the parameters that are passed to the pipeline. See the Components page for more information about the parameters of each pipeline.",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Running pipelines"
    ]
  },
  {
    "objectID": "team/index.html",
    "href": "team/index.html",
    "title": "Team",
    "section": "",
    "text": "Angela Oliveira Pisco\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Director of Computational Biology \n           at \n              \n              Insitro\n              \n          \n        \n      \n      \n      \n        \n          Core Member \n           at \n              \n              Open Problems\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Dorien Roosen\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Data Scientist \n           at \n              \n              Data Intuitive\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Dries De Maeyer\n      \n      Core Team Member\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Principal Scientist \n           at \n              \n              Janssen Pharmaceuticals\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Dries Schaumont\n      \n      Core Team Member\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Data Scientist \n           at \n              \n              Data Intuitive\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Elizabeth Mlynarski\n      \n      Contributor\n      \n      \n      \n      \n        \n          Principal Scientist Computational Genomics \n           at \n            \n              Janssen R&D US\n            \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Isabelle Bergiers\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Scientist OMICS Technology \n           at \n              \n              Janssen Pharmaceuticals\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Jakub Majercik\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Bioinformatics Engineer \n           at \n              \n              Data Intuitive\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Kai Waldrant\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Bioinformatician \n           at \n              \n              Data Intuitive\n              \n          \n        \n      \n      \n      \n        \n          Contributor \n           at \n              \n              Open Problems\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Malte D. Luecken\n      \n      Core Team Member\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Group Leader \n           at \n              \n              Helmholtz Munich\n              \n          \n        \n      \n      \n      \n        \n          Core Member \n           at \n              \n              Open Problems\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Marijke Van Moerbeke\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Statistical Consultant \n           at \n              \n              OpenAnalytics\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Matthias Beyens\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Principal Scientist \n           at \n              \n              Janssen Pharmaceuticals\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Mauro Saporita\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Lead Nextflow Developer \n           at \n              \n              Ardigen\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Povilas Gibas\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Bioinformatician \n           at \n              \n              Ardigen\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Robrecht Cannoodt\n      \n      Core Team Member\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Data Science Engineer \n           at \n              \n              Data Intuitive\n              \n          \n        \n      \n      \n      \n        \n          Core Member \n           at \n              \n              Open Problems\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Samuel D'Souza\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Data Engineer \n           at \n              \n              Chan Zuckerberg Biohub\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Toni Verbeiren\n      \n      Core Team Member\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Data Scientist and CEO \n           at \n              \n              Data Intuitive\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Vladimir Shitov\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          PhD Candidate \n           at \n              \n              Helmholtz Munich\n              \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Weiwei Schultz\n      \n      Contributor\n      \n      \n      \n      \n        \n          Associate Director Data Sciences \n           at \n            \n              Janssen R&D US\n            \n          \n        \n      \n       \n    \n  \n  \n  \n    \n    \n    \n    \n      Xichen Wu\n      \n      Contributor\n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n        \n      \n      \n      \n      \n        \n          Student Assistant \n           at \n              \n              Helmholtz Munich\n              \n          \n        \n      \n       \n    \n  \n  \n\n\nNo matching items"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html",
    "href": "components/modules/mapping/cellranger_count.html",
    "title": "Cellranger count",
    "section": "",
    "text": "ID: cellranger_count\nNamespace: mapping\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger count"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html#example-commands",
    "href": "components/modules/mapping/cellranger_count.html#example-commands",
    "title": "Cellranger count",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/cellranger_count/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"reference.tar.gz\"\n\n# Outputs\n# output: \"$id.$key.output\"\n\n# Arguments\n# expect_cells: 3000\n# force_cells: 3000\nchemistry: \"auto\"\nsecondary_analysis: false\ngenerate_bam: true\ninclude_introns: true\n# r1_length: 123\n# r2_length: 123\n# lanes: [1, 2, 3]\nlibrary_compatibility_check: true\n# min_crispr_umi: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/cellranger_count/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger count"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html#argument-groups",
    "href": "components/modules/mapping/cellranger_count.html#argument-groups",
    "title": "Cellranger count",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, required, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nThe path to Cell Ranger reference tar.gz file. Can also be a directory.\nfile, required, example: \"reference.tar.gz\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe folder to store the alignment results.\nfile, required, example: \"/path/to/output\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--force_cells\nForce pipeline to use this number of cells, bypassing cell calling algorithm.\ninteger, example: 3000\n\n\n--chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3’ - fiveprime: Single Cell 5’ - SC3Pv1: Single Cell 3’ v1 NOTE: this mode cannot be auto-detected. It must be set explicitly with this option. - SC3Pv2: Single Cell 3’ v2 - SC3Pv3: Single Cell 3’ v3 - SC3Pv4: Single Cell 3’ v4 - SC3Pv3LT: Single Cell 3’ v3 LT - SC3Pv3HT: Single Cell 3’ v3 HT - SC5P-PE-v3: Single Cell 5’ paired-end v3 (GEM-X) - SC5P-PE: Single Cell 5’ paired-end - SC5P-R2: Single Cell 5’ R2-only - SC-FB: Single Cell Antibody-only 3’ v2 or 5’ - ARC-v1: for analyzing the Gene Expression portion of Multiome data. NOTE: when the pipeline auto-detects ARC-v1 chemistry, an error is triggered. See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--secondary_analysis\nWhether or not to run the secondary analysis e.g. clustering.\nboolean, default: FALSE\n\n\n--generate_bam\nWhether to generate a BAM file.\nboolean, default: TRUE\n\n\n--include_introns\nInclude intronic reads in count.\nboolean, default: TRUE\n\n\n--r1_length\nHard trim the input Read 1 to this length before analysis\ninteger\n\n\n--r2_length\nHard trim the input Read 2 to this length before analysis\ninteger\n\n\n--lanes\nOnly use FASTQs from selected lanes.\nList of integer, example: 1, 2, 3, multiple_sep: \";\"\n\n\n--library_compatibility_check\nWhether to check for barcode compatibility between libraries.\nboolean, default: TRUE\n\n\n--min_crispr_umi\nSet the minimum number of CRISPR guide RNA UMIs required for protospacer detection. If a lower or higher sensitivity is desired for detection, this value can be customized according to specific experimental needs. Applicable only to datasets that include a CRISPR Guide Capture library.\ninteger",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger count"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html#authors",
    "href": "components/modules/mapping/cellranger_count.html#authors",
    "title": "Cellranger count",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nSamuel D’Souza   (author)\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger count"
    ]
  },
  {
    "objectID": "components/modules/mapping/multi_star.html",
    "href": "components/modules/mapping/multi_star.html",
    "title": "Multi star",
    "section": "",
    "text": "ID: multi_star\nNamespace: mapping\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Multi star"
    ]
  },
  {
    "objectID": "components/modules/mapping/multi_star.html#example-commands",
    "href": "components/modules/mapping/multi_star.html#example-commands",
    "title": "Multi star",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/multi_star/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ninput_id: # please fill in - example: [\"mysample\", \"mysample\"]\ninput_r1: # please fill in - example: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L002_R1_001.fastq.gz\"]\n# input_r2: [\"mysample_S1_L001_R2_001.fastq.gz\", \"mysample_S1_L002_R2_001.fastq.gz\"]\nreference_index: # please fill in - example: \"/path/to/reference\"\nreference_gtf: # please fill in - example: \"genes.gtf\"\n# output: \"$id.$key.output\"\n\n# Processing arguments\nrun_htseq_count: true\nrun_multiqc: true\nmin_success_rate: 0.5\n\n# Run Parameters\n# runRNGseed: 777\n\n# Genome Parameters\n# genomeFastaFiles: [\"path/to/file\"]\n\n# Splice Junctions Database\n# sjdbFileChrStartEnd: [\"foo\"]\n# sjdbGTFfile: \"path/to/file\"\n# sjdbGTFchrPrefix: \"foo\"\n# sjdbGTFfeatureExon: \"exon\"\n# sjdbGTFtagExonParentTranscript: \"transcript_id\"\n# sjdbGTFtagExonParentGene: \"gene_id\"\n# sjdbGTFtagExonParentGeneName: [\"gene_name\"]\n# sjdbGTFtagExonParentGeneType: [\"gene_type\", \"gene_biotype\"]\n# sjdbOverhang: 100\n# sjdbScore: 2\n# sjdbInsertSave: \"Basic\"\n\n# Variation parameters\n# varVCFfile: \"foo\"\n\n# Read Parameters\n# readFilesType: \"Fastx\"\n# readFilesSAMattrKeep: [\"All\"]\n# readFilesManifest: \"path/to/file\"\n# readFilesPrefix: \"foo\"\n# readFilesCommand: [\"foo\"]\n# readMapNumber: -1\n# readMatesLengthsIn: \"NotEqual\"\n# readNameSeparator: [\"/\"]\n# readQualityScoreBase: 33\n\n# Read Clipping\n# clipAdapterType: \"Hamming\"\n# clip3pNbases: [0]\n# clip3pAdapterSeq: [\"foo\"]\n# clip3pAdapterMMp: [0.1]\n# clip3pAfterAdapterNbases: [0]\n# clip5pNbases: [0]\n\n# Limits\n# limitGenomeGenerateRAM: 31000000000\n# limitIObufferSize: [30000000, 50000000]\n# limitOutSAMoneReadBytes: 100000\n# limitOutSJoneRead: 1000\n# limitOutSJcollapsed: 1000000\n# limitBAMsortRAM: 0\n# limitSjdbInsertNsj: 1000000\n# limitNreadsSoft: -1\n\n# Output: general\n# outTmpKeep: \"foo\"\n# outStd: \"Log\"\n# outReadsUnmapped: \"foo\"\n# outQSconversionAdd: 0\n# outMultimapperOrder: \"Old_2.4\"\n\n# Output: SAM and BAM\n# outSAMmode: \"Full\"\n# outSAMstrandField: \"foo\"\n# outSAMattributes: [\"Standard\"]\n# outSAMattrIHstart: 1\n# outSAMunmapped: [\"foo\"]\n# outSAMorder: \"Paired\"\n# outSAMprimaryFlag: \"OneBestScore\"\n# outSAMreadID: \"Standard\"\n# outSAMmapqUnique: 255\n# outSAMflagOR: 0\n# outSAMflagAND: 65535\n# outSAMattrRGline: [\"foo\"]\n# outSAMheaderHD: [\"foo\"]\n# outSAMheaderPG: [\"foo\"]\n# outSAMheaderCommentFile: \"foo\"\n# outSAMfilter: [\"foo\"]\n# outSAMmultNmax: -1\n# outSAMtlen: 1\n# outBAMcompression: 1\n# outBAMsortingThreadN: 0\n# outBAMsortingBinsN: 50\n\n# BAM processing\n# bamRemoveDuplicatesType: \"foo\"\n# bamRemoveDuplicatesMate2basesN: 0\n\n# Output Wiggle\n# outWigType: [\"foo\"]\n# outWigStrand: \"Stranded\"\n# outWigReferencesPrefix: \"foo\"\n# outWigNorm: \"RPM\"\n\n# Output Filtering\n# outFilterType: \"Normal\"\n# outFilterMultimapScoreRange: 1\n# outFilterMultimapNmax: 10\n# outFilterMismatchNmax: 10\n# outFilterMismatchNoverLmax: 0.3\n# outFilterMismatchNoverReadLmax: 1.0\n# outFilterScoreMin: 0\n# outFilterScoreMinOverLread: 0.66\n# outFilterMatchNmin: 0\n# outFilterMatchNminOverLread: 0.66\n# outFilterIntronMotifs: \"foo\"\n# outFilterIntronStrands: \"RemoveInconsistentStrands\"\n\n# Output splice junctions (SJ.out.tab)\n# outSJtype: \"Standard\"\n\n# Output Filtering: Splice Junctions\n# outSJfilterReads: \"All\"\n# outSJfilterOverhangMin: [30, 12, 12, 12]\n# outSJfilterCountUniqueMin: [3, 1, 1, 1]\n# outSJfilterCountTotalMin: [3, 1, 1, 1]\n# outSJfilterDistToOtherSJmin: [10, 0, 5, 10]\n# outSJfilterIntronMaxVsReadN: [50000, 100000, 200000]\n\n# Scoring\n# scoreGap: 0\n# scoreGapNoncan: -8\n# scoreGapGCAG: -4\n# scoreGapATAC: -8\n# scoreGenomicLengthLog2scale: 0\n# scoreDelOpen: -2\n# scoreDelBase: -2\n# scoreInsOpen: -2\n# scoreInsBase: -2\n# scoreStitchSJshift: 1\n\n# Alignments and Seeding\n# seedSearchStartLmax: 50\n# seedSearchStartLmaxOverLread: 1.0\n# seedSearchLmax: 0\n# seedMultimapNmax: 10000\n# seedPerReadNmax: 1000\n# seedPerWindowNmax: 50\n# seedNoneLociPerWindow: 10\n# seedSplitMin: 12\n# seedMapMin: 5\n# alignIntronMin: 21\n# alignIntronMax: 0\n# alignMatesGapMax: 0\n# alignSJoverhangMin: 5\n# alignSJstitchMismatchNmax: [0, -1, 0, 0]\n# alignSJDBoverhangMin: 3\n# alignSplicedMateMapLmin: 0\n# alignSplicedMateMapLminOverLmate: 0.66\n# alignWindowsPerReadNmax: 10000\n# alignTranscriptsPerWindowNmax: 100\n# alignTranscriptsPerReadNmax: 10000\n# alignEndsType: \"Local\"\n# alignEndsProtrude: \"0    ConcordantPair\"\n# alignSoftClipAtReferenceEnds: \"Yes\"\n# alignInsertionFlush: \"foo\"\n\n# Paired-End reads\n# peOverlapNbasesMin: 0\n# peOverlapMMp: 0.01\n\n# Windows, Anchors, Binning\n# winAnchorMultimapNmax: 50\n# winBinNbits: 16\n# winAnchorDistNbins: 9\n# winFlankNbins: 4\n# winReadCoverageRelativeMin: 0.5\n# winReadCoverageBasesMin: 0\n\n# Chimeric Alignments\n# chimOutType: [\"Junctions\"]\n# chimSegmentMin: 0\n# chimScoreMin: 0\n# chimScoreDropMax: 20\n# chimScoreSeparation: 10\n# chimScoreJunctionNonGTAG: -1\n# chimJunctionOverhangMin: 20\n# chimSegmentReadGapMax: 0\n# chimFilter: [\"banGenomicN\"]\n# chimMainSegmentMultNmax: 10\n# chimMultimapNmax: 0\n# chimMultimapScoreRange: 1\n# chimNonchimScoreDropMin: 20\n# chimOutJunctionFormat: 0\n\n# Quantification of Annotations\n# quantMode: [\"foo\"]\n# quantTranscriptomeBAMcompression: 1\n# quantTranscriptomeBan: \"IndelSoftclipSingleend\"\n\n# 2-pass Mapping\n# twopassMode: \"foo\"\n# twopass1readsN: -1\n\n# WASP parameters\n# waspOutputMode: \"foo\"\n\n# STARsolo (single cell RNA-seq) parameters\n# soloType: [\"foo\"]\n# soloCBwhitelist: [\"foo\"]\n# soloCBstart: 1\n# soloCBlen: 16\n# soloUMIstart: 17\n# soloUMIlen: 10\n# soloBarcodeReadLength: 1\n# soloBarcodeMate: 0\n# soloCBposition: [\"foo\"]\n# soloUMIposition: \"foo\"\n# soloAdapterSequence: \"foo\"\n# soloAdapterMismatchesNmax: 1\n# soloCBmatchWLtype: \"1MM_multi\"\n# soloInputSAMattrBarcodeSeq: [\"foo\"]\n# soloInputSAMattrBarcodeQual: [\"foo\"]\n# soloStrand: \"Forward\"\n# soloFeatures: [\"Gene\"]\n# soloMultiMappers: [\"Unique\"]\n# soloUMIdedup: [\"1MM_All\"]\n# soloUMIfiltering: [\"foo\"]\n# soloOutFileNames: [\"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\"]\n# soloCellFilter: [\"CellRanger2.2\", \"3000\", \"0.99\", \"10\"]\n# soloOutFormatFeaturesGeneField3: [\"Gene Expression\"]\n# soloCellReadStats: \"foo\"\n\n# HTSeq arguments\nstranded: \"yes\"\nminimum_alignment_quality: 10\n# type: \"exon\"\n# id_attribute: [\"gene_id\"]\n# additional_attributes: [\"gene_name\"]\nadd_chromosome_info: false\nmode: \"union\"\nnon_unique: \"none\"\n# secondary_alignments: \"foo\"\n# supplementary_alignments: \"foo\"\ncounts_output_sparse: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/multi_star/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Multi star"
    ]
  },
  {
    "objectID": "components/modules/mapping/multi_star.html#argument-groups",
    "href": "components/modules/mapping/multi_star.html#argument-groups",
    "title": "Multi star",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_id\nThe ID of the sample being processed. This vector should have the same length as the --input_r1 argument.\nList of string, required, example: \"mysample\", \"mysample\", multiple_sep: \";\"\n\n\n--input_r1\nPaths to the sequences to be mapped. If using Illumina paired-end reads, only the R1 files should be passed.\nList of file, required, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L002_R1_001.fastq.gz\", multiple_sep: \";\"\n\n\n--input_r2\nPaths to the sequences to be mapped. If using Illumina paired-end reads, only the R2 files should be passed.\nList of file, example: \"mysample_S1_L001_R2_001.fastq.gz\", \"mysample_S1_L002_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference_index\nPath to the reference built by star_build_reference. Corresponds to the –genomeDir argument in the STAR command.\nfile, required, example: \"/path/to/reference\"\n\n\n--reference_gtf\nPath to the gtf reference file.\nfile, required, example: \"genes.gtf\"\n\n\n--output\nPath to output directory. Corresponds to the –outFileNamePrefix argument in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nProcessing arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--run_htseq_count\nWhether or not to also run htseq-count after STAR.\nboolean, default: TRUE\n\n\n--run_multiqc\nWhether or not to also run MultiQC at the end.\nboolean, default: TRUE\n\n\n--min_success_rate\nFail when the success rate is below this threshold.\ndouble, default: 0.5\n\n\n\n\n\nRun Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--runRNGseed\nrandom number generator seed.\ninteger, example: 777\n\n\n\n\n\nGenome Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeFastaFiles\npath(s) to the fasta files with the genome sequences, separated by spaces. These files should be plain text FASTA files, they cannot be zipped. Required for the genome generation (–runMode genomeGenerate). Can also be used in the mapping (–runMode alignReads) to add extra (new) sequences to the genome (e.g. spike-ins).\nList of file, multiple_sep: \";\"\n\n\n\n\n\nSplice Junctions Database\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sjdbFileChrStartEnd\npath to the files with genomic coordinates (chr  start  end  strand) for the splice junction introns. Multiple files can be supplied and will be concatenated.\nList of string, multiple_sep: \";\"\n\n\n--sjdbGTFfile\npath to the GTF file with annotations\nfile\n\n\n--sjdbGTFchrPrefix\nprefix for chromosome names in a GTF file (e.g. ‘chr’ for using ENSMEBL annotations with UCSC genomes)\nstring\n\n\n--sjdbGTFfeatureExon\nfeature type in GTF file to be used as exons for building transcripts\nstring, example: \"exon\"\n\n\n--sjdbGTFtagExonParentTranscript\nGTF attribute name for parent transcript ID (default “transcript_id” works for GTF files)\nstring, example: \"transcript_id\"\n\n\n--sjdbGTFtagExonParentGene\nGTF attribute name for parent gene ID (default “gene_id” works for GTF files)\nstring, example: \"gene_id\"\n\n\n--sjdbGTFtagExonParentGeneName\nGTF attribute name for parent gene name\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--sjdbGTFtagExonParentGeneType\nGTF attribute name for parent gene type\nList of string, example: \"gene_type\", \"gene_biotype\", multiple_sep: \";\"\n\n\n--sjdbOverhang\nlength of the donor/acceptor sequence on each side of the junctions, ideally = (mate_length - 1)\ninteger, example: 100\n\n\n--sjdbScore\nextra alignment score for alignments that cross database junctions\ninteger, example: 2\n\n\n--sjdbInsertSave\nwhich files to save when sjdb junctions are inserted on the fly at the mapping step - Basic … only small junction / transcript files - All … all files including big Genome, SA and SAindex - this will create a complete genome directory\nstring, example: \"Basic\"\n\n\n\n\n\nVariation parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--varVCFfile\npath to the VCF file that contains variation data. The 10th column should contain the genotype information, e.g. 0/1\nstring\n\n\n\n\n\nRead Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--readFilesType\nformat of input read files - Fastx … FASTA or FASTQ - SAM SE … SAM or BAM single-end reads; for BAM use –readFilesCommand samtools view - SAM PE … SAM or BAM paired-end reads; for BAM use –readFilesCommand samtools view\nstring, example: \"Fastx\"\n\n\n--readFilesSAMattrKeep\nfor –readFilesType SAM SE/PE, which SAM tags to keep in the output BAM, e.g.: –readFilesSAMtagsKeep RG PL - All … keep all tags - None … do not keep any tags\nList of string, example: \"All\", multiple_sep: \";\"\n\n\n--readFilesManifest\npath to the “manifest” file with the names of read files. The manifest file should contain 3 tab-separated columns: paired-end reads: read1_file_name \\(tab\\) read2_file_name \\(tab\\) read_group_line. single-end reads: read1_file_name \\(tab\\) - \\(tab\\) read_group_line. Spaces, but not tabs are allowed in file names. If read_group_line does not start with ID:, it can only contain one ID field, and ID: will be added to it. If read_group_line starts with ID:, it can contain several fields separated by \\(tab\\), and all fields will be be copied verbatim into SAM @RG header line.\nfile\n\n\n--readFilesPrefix\nprefix for the read files names, i.e. it will be added in front of the strings in –readFilesIn\nstring\n\n\n--readFilesCommand\ncommand line to execute for each of the input file. This command should generate FASTA or FASTQ text and send it to stdout For example: zcat - to uncompress .gz files, bzcat - to uncompress .bz2 files, etc.\nList of string, multiple_sep: \";\"\n\n\n--readMapNumber\nnumber of reads to map from the beginning of the file -1: map all reads\ninteger, example: -1\n\n\n--readMatesLengthsIn\nEqual/NotEqual - lengths of names,sequences,qualities for both mates are the same / not the same. NotEqual is safe in all situations.\nstring, example: \"NotEqual\"\n\n\n--readNameSeparator\ncharacter(s) separating the part of the read names that will be trimmed in output (read name after space is always trimmed)\nList of string, example: \"/\", multiple_sep: \";\"\n\n\n--readQualityScoreBase\nnumber to be subtracted from the ASCII code to get Phred quality score\ninteger, example: 33\n\n\n\n\n\nRead Clipping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clipAdapterType\nadapter clipping type - Hamming … adapter clipping based on Hamming distance, with the number of mismatches controlled by –clip5pAdapterMMp - CellRanger4 … 5p and 3p adapter clipping similar to CellRanger4. Utilizes Opal package by Martin Sosic: https://github.com/Martinsos/opal - None … no adapter clipping, all other clip* parameters are disregarded\nstring, example: \"Hamming\"\n\n\n--clip3pNbases\nnumber(s) of bases to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip3pAdapterSeq\nadapter sequences to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates. - polyA … polyA sequence with the length equal to read length\nList of string, multiple_sep: \";\"\n\n\n--clip3pAdapterMMp\nmax proportion of mismatches for 3p adapter clipping for each mate. If one value is given, it will be assumed the same for both mates.\nList of double, example: 0.1, multiple_sep: \";\"\n\n\n--clip3pAfterAdapterNbases\nnumber of bases to clip from 3p of each mate after the adapter clipping. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip5pNbases\nnumber(s) of bases to clip from 5p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n\n\n\nLimits\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--limitGenomeGenerateRAM\nmaximum available RAM (bytes) for genome generation\nlong, example: NA\n\n\n--limitIObufferSize\nmax available buffers size (bytes) for input/output, per thread\nList of long, example: 30000000, 50000000, multiple_sep: \";\"\n\n\n--limitOutSAMoneReadBytes\nmax size of the SAM record (bytes) for one read. Recommended value: &gt;(2(LengthMate1+LengthMate2+100)outFilterMultimapNmax\nlong, example: 100000\n\n\n--limitOutSJoneRead\nmax number of junctions for one read (including all multi-mappers)\ninteger, example: 1000\n\n\n--limitOutSJcollapsed\nmax number of collapsed junctions\ninteger, example: 1000000\n\n\n--limitBAMsortRAM\nmaximum available RAM (bytes) for sorting BAM. If =0, it will be set to the genome index size. 0 value can only be used with –genomeLoad NoSharedMemory option.\nlong, example: 0\n\n\n--limitSjdbInsertNsj\nmaximum number of junctions to be inserted to the genome on the fly at the mapping stage, including those from annotations and those detected in the 1st step of the 2-pass run\ninteger, example: 1000000\n\n\n--limitNreadsSoft\nsoft limit on the number of reads\ninteger, example: -1\n\n\n\n\n\nOutput: general\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outTmpKeep\nwhether to keep the temporary files after STAR runs is finished - None … remove all temporary files - All … keep all files\nstring\n\n\n--outStd\nwhich output will be directed to stdout (standard out) - Log … log messages - SAM … alignments in SAM format (which normally are output to Aligned.out.sam file), normal standard output will go into Log.std.out - BAM_Unsorted … alignments in BAM format, unsorted. Requires –outSAMtype BAM Unsorted - BAM_SortedByCoordinate … alignments in BAM format, sorted by coordinate. Requires –outSAMtype BAM SortedByCoordinate - BAM_Quant … alignments to transcriptome in BAM format, unsorted. Requires –quantMode TranscriptomeSAM\nstring, example: \"Log\"\n\n\n--outReadsUnmapped\noutput of unmapped and partially mapped (i.e. mapped only one mate of a paired end read) reads in separate file(s). - None … no output - Fastx … output in separate fasta/fastq files, Unmapped.out.mate1/2\nstring\n\n\n--outQSconversionAdd\nadd this number to the quality score (e.g. to convert from Illumina to Sanger, use -31)\ninteger, example: 0\n\n\n--outMultimapperOrder\norder of multimapping alignments in the output files - Old_2.4 … quasi-random order used before 2.5.0 - Random … random order of alignments for each multi-mapper. Read mates (pairs) are always adjacent, all alignment for each read stay together. This option will become default in the future releases.\nstring, example: \"Old_2.4\"\n\n\n\n\n\nOutput: SAM and BAM\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSAMmode\nmode of SAM output - None … no SAM output - Full … full SAM output - NoQS … full SAM but without quality scores\nstring, example: \"Full\"\n\n\n--outSAMstrandField\nCufflinks-like strand field flag - None … not used - intronMotif … strand derived from the intron motif. This option changes the output alignments: reads with inconsistent and/or non-canonical introns are filtered out.\nstring\n\n\n--outSAMattributes\na string of desired SAM attributes, in the order desired for the output SAM. Tags can be listed in any combination/order. Presets: - None … no attributes - Standard … NH HI AS nM - All … NH HI AS nM NM MD jM jI MC ch Alignment: - NH … number of loci the reads maps to: =1 for unique mappers, &gt;1 for multimappers. Standard SAM tag. - HI … multiple alignment index, starts with –outSAMattrIHstart (=1 by default). Standard SAM tag. - AS … local alignment score, +1/-1 for matches/mismateches, score* penalties for indels and gaps. For PE reads, total score for two mates. Stadnard SAM tag. - nM … number of mismatches. For PE reads, sum over two mates. - NM … edit distance to the reference (number of mismatched + inserted + deleted bases) for each mate. Standard SAM tag. - MD … string encoding mismatched and deleted reference bases (see standard SAM specifications). Standard SAM tag. - jM … intron motifs for all junctions (i.e. N in CIGAR): 0: non-canonical; 1: GT/AG, 2: CT/AC, 3: GC/AG, 4: CT/GC, 5: AT/AC, 6: GT/AT. If splice junctions database is used, and a junction is annotated, 20 is added to its motif value. - jI … start and end of introns for all junctions (1-based). - XS … alignment strand according to –outSAMstrandField. - MC … mate’s CIGAR string. Standard SAM tag. - ch … marks all segment of all chimeric alingments for –chimOutType WithinBAM output. - cN … number of bases clipped from the read ends: 5’ and 3’ Variation: - vA … variant allele - vG … genomic coordinate of the variant overlapped by the read. - vW … 1 - alignment passes WASP filtering; 2,3,4,5,6,7 - alignment does not pass WASP filtering. Requires –waspOutputMode SAMtag. STARsolo: - CR CY UR UY … sequences and quality scores of cell barcodes and UMIs for the solo* demultiplexing. - GX GN … gene ID and gene name for unique-gene reads. - gx gn … gene IDs and gene names for unique- and multi-gene reads. - CB UB … error-corrected cell barcodes and UMIs for solo* demultiplexing. Requires –outSAMtype BAM SortedByCoordinate. - sM … assessment of CB and UMI. - sS … sequence of the entire barcode (CB,UMI,adapter). - sQ … quality of the entire barcode. ***Unsupported/undocumented: - ha … haplotype (1/2) when mapping to the diploid genome. Requires genome generated with –genomeTransformType Diploid . - rB … alignment block read/genomic coordinates. - vR … read coordinate of the variant.\nList of string, example: \"Standard\", multiple_sep: \";\"\n\n\n--outSAMattrIHstart\nstart value for the IH attribute. 0 may be required by some downstream software, such as Cufflinks or StringTie.\ninteger, example: 1\n\n\n--outSAMunmapped\noutput of unmapped reads in the SAM format 1st word: - None … no output - Within … output unmapped reads within the main SAM file (i.e. Aligned.out.sam) 2nd word: - KeepPairs … record unmapped mate for each alignment, and, in case of unsorted output, keep it adjacent to its mapped mate. Only affects multi-mapping reads.\nList of string, multiple_sep: \";\"\n\n\n--outSAMorder\ntype of sorting for the SAM output Paired: one mate after the other for all paired alignments PairedKeepInputOrder: one mate after the other for all paired alignments, the order is kept the same as in the input FASTQ files\nstring, example: \"Paired\"\n\n\n--outSAMprimaryFlag\nwhich alignments are considered primary - all others will be marked with 0x100 bit in the FLAG - OneBestScore … only one alignment with the best score is primary - AllBestScore … all alignments with the best score are primary\nstring, example: \"OneBestScore\"\n\n\n--outSAMreadID\nread ID record type - Standard … first word (until space) from the FASTx read ID line, removing /1,/2 from the end - Number … read number (index) in the FASTx file\nstring, example: \"Standard\"\n\n\n--outSAMmapqUnique\n0 to 255: the MAPQ value for unique mappers\ninteger, example: 255\n\n\n--outSAMflagOR\n0 to 65535: sam FLAG will be bitwise OR’d with this value, i.e. FLAG=FLAG | outSAMflagOR. This is applied after all flags have been set by STAR, and after outSAMflagAND. Can be used to set specific bits that are not set otherwise.\ninteger, example: 0\n\n\n--outSAMflagAND\n0 to 65535: sam FLAG will be bitwise AND’d with this value, i.e. FLAG=FLAG & outSAMflagOR. This is applied after all flags have been set by STAR, but before outSAMflagOR. Can be used to unset specific bits that are not set otherwise.\ninteger, example: 65535\n\n\n--outSAMattrRGline\nSAM/BAM read group line. The first word contains the read group identifier and must start with “ID:”, e.g. –outSAMattrRGline ID:xxx CN:yy “DS:z z z”. xxx will be added as RG tag to each output alignment. Any spaces in the tag values have to be double quoted. Comma separated RG lines correspons to different (comma separated) input files in –readFilesIn. Commas have to be surrounded by spaces, e.g. –outSAMattrRGline ID:xxx , ID:zzz “DS:z z” , ID:yyy DS:yyyy\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderHD\n@HD (header) line of the SAM header\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderPG\nextra @PG (software) line of the SAM header (in addition to STAR)\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderCommentFile\npath to the file with @CO (comment) lines of the SAM header\nstring\n\n\n--outSAMfilter\nfilter the output into main SAM/BAM files - KeepOnlyAddedReferences … only keep the reads for which all alignments are to the extra reference sequences added with –genomeFastaFiles at the mapping stage. - KeepAllAddedReferences … keep all alignments to the extra reference sequences added with –genomeFastaFiles at the mapping stage.\nList of string, multiple_sep: \";\"\n\n\n--outSAMmultNmax\nmax number of multiple alignments for a read that will be output to the SAM/BAM files. Note that if this value is not equal to -1, the top scoring alignment will be output first - -1 … all alignments (up to –outFilterMultimapNmax) will be output\ninteger, example: -1\n\n\n--outSAMtlen\ncalculation method for the TLEN field in the SAM/BAM files - 1 … leftmost base of the (+)strand mate to rightmost base of the (-)mate. (+)sign for the (+)strand mate - 2 … leftmost base of any mate to rightmost base of any mate. (+)sign for the mate with the leftmost base. This is different from 1 for overlapping mates with protruding ends\ninteger, example: 1\n\n\n--outBAMcompression\n-1 to 10 BAM compression level, -1=default compression (6?), 0=no compression, 10=maximum compression\ninteger, example: 1\n\n\n--outBAMsortingThreadN\n&gt;=0: number of threads for BAM sorting. 0 will default to min(6,–runThreadN).\ninteger, example: 0\n\n\n--outBAMsortingBinsN\n&gt;0: number of genome bins for coordinate-sorting\ninteger, example: 50\n\n\n\n\n\nBAM processing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bamRemoveDuplicatesType\nmark duplicates in the BAM file, for now only works with (i) sorted BAM fed with inputBAMfile, and (ii) for paired-end alignments only - - … no duplicate removal/marking - UniqueIdentical … mark all multimappers, and duplicate unique mappers. The coordinates, FLAG, CIGAR must be identical - UniqueIdenticalNotMulti … mark duplicate unique mappers but not multimappers.\nstring\n\n\n--bamRemoveDuplicatesMate2basesN\nnumber of bases from the 5’ of mate 2 to use in collapsing (e.g. for RAMPAGE)\ninteger, example: 0\n\n\n\n\n\nOutput Wiggle\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outWigType\ntype of signal output, e.g. “bedGraph” OR “bedGraph read1_5p”. Requires sorted BAM: –outSAMtype BAM SortedByCoordinate . 1st word: - None … no signal output - bedGraph … bedGraph format - wiggle … wiggle format 2nd word: - read1_5p … signal from only 5’ of the 1st read, useful for CAGE/RAMPAGE etc - read2 … signal from only 2nd read\nList of string, multiple_sep: \";\"\n\n\n--outWigStrand\nstrandedness of wiggle/bedGraph output - Stranded … separate strands, str1 and str2 - Unstranded … collapsed strands\nstring, example: \"Stranded\"\n\n\n--outWigReferencesPrefix\nprefix matching reference names to include in the output wiggle file, e.g. “chr”, default “-” - include all references\nstring\n\n\n--outWigNorm\ntype of normalization for the signal - RPM … reads per million of mapped reads - None … no normalization, “raw” counts\nstring, example: \"RPM\"\n\n\n\n\n\nOutput Filtering\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outFilterType\ntype of filtering - Normal … standard filtering using only current alignment - BySJout … keep only those reads that contain junctions that passed filtering into SJ.out.tab\nstring, example: \"Normal\"\n\n\n--outFilterMultimapScoreRange\nthe score range below the maximum score for multimapping alignments\ninteger, example: 1\n\n\n--outFilterMultimapNmax\nmaximum number of loci the read is allowed to map to. Alignments (all of them) will be output only if the read maps to no more loci than this value. Otherwise no alignments will be output, and the read will be counted as “mapped to too many loci” in the Log.final.out .\ninteger, example: 10\n\n\n--outFilterMismatchNmax\nalignment will be output only if it has no more mismatches than this value.\ninteger, example: 10\n\n\n--outFilterMismatchNoverLmax\nalignment will be output only if its ratio of mismatches to mapped length is less than or equal to this value.\ndouble, example: 0.3\n\n\n--outFilterMismatchNoverReadLmax\nalignment will be output only if its ratio of mismatches to read length is less than or equal to this value.\ndouble, example: 1\n\n\n--outFilterScoreMin\nalignment will be output only if its score is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterScoreMinOverLread\nsame as outFilterScoreMin, but normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 0.66\n\n\n--outFilterMatchNmin\nalignment will be output only if the number of matched bases is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterMatchNminOverLread\nsam as outFilterMatchNmin, but normalized to the read length (sum of mates’ lengths for paired-end reads).\ndouble, example: 0.66\n\n\n--outFilterIntronMotifs\nfilter alignment using their motifs - None … no filtering - RemoveNoncanonical … filter out alignments that contain non-canonical junctions - RemoveNoncanonicalUnannotated … filter out alignments that contain non-canonical unannotated junctions when using annotated splice junctions database. The annotated non-canonical junctions will be kept.\nstring\n\n\n--outFilterIntronStrands\nfilter alignments - RemoveInconsistentStrands … remove alignments that have junctions with inconsistent strands - None … no filtering\nstring, example: \"RemoveInconsistentStrands\"\n\n\n\n\n\nOutput splice junctions (SJ.out.tab)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJtype\ntype of splice junction output - Standard … standard SJ.out.tab output - None … no splice junction output\nstring, example: \"Standard\"\n\n\n\n\n\nOutput Filtering: Splice Junctions\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJfilterReads\nwhich reads to consider for collapsed splice junctions output - All … all reads, unique- and multi-mappers - Unique … uniquely mapping reads only\nstring, example: \"All\"\n\n\n--outSJfilterOverhangMin\nminimum overhang length for splice junctions on both sides for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif does not apply to annotated junctions\nList of integer, example: 30, 12, 12, 12, multiple_sep: \";\"\n\n\n--outSJfilterCountUniqueMin\nminimum uniquely mapping read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterCountTotalMin\nminimum total (multi-mapping+unique) read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterDistToOtherSJmin\nminimum allowed distance to other junctions’ donor/acceptor does not apply to annotated junctions\nList of integer, example: 10, 0, 5, 10, multiple_sep: \";\"\n\n\n--outSJfilterIntronMaxVsReadN\nmaximum gap allowed for junctions supported by 1,2,3,,,N reads i.e. by default junctions supported by 1 read can have gaps &lt;=50000b, by 2 reads: &lt;=100000b, by 3 reads: &lt;=200000. by &gt;=4 reads any gap &lt;=alignIntronMax does not apply to annotated junctions\nList of integer, example: 50000, 100000, 200000, multiple_sep: \";\"\n\n\n\n\n\nScoring\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scoreGap\nsplice junction penalty (independent on intron motif)\ninteger, example: 0\n\n\n--scoreGapNoncan\nnon-canonical junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGapGCAG\nGC/AG and CT/GC junction penalty (in addition to scoreGap)\ninteger, example: -4\n\n\n--scoreGapATAC\nAT/AC and GT/AT junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGenomicLengthLog2scale\nextra score logarithmically scaled with genomic length of the alignment: scoreGenomicLengthLog2scale*log2(genomicLength)\ninteger, example: 0\n\n\n--scoreDelOpen\ndeletion open penalty\ninteger, example: -2\n\n\n--scoreDelBase\ndeletion extension penalty per base (in addition to scoreDelOpen)\ninteger, example: -2\n\n\n--scoreInsOpen\ninsertion open penalty\ninteger, example: -2\n\n\n--scoreInsBase\ninsertion extension penalty per base (in addition to scoreInsOpen)\ninteger, example: -2\n\n\n--scoreStitchSJshift\nmaximum score reduction while searching for SJ boundaries in the stitching step\ninteger, example: 1\n\n\n\n\n\nAlignments and Seeding\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--seedSearchStartLmax\ndefines the search start point through the read - the read is split into pieces no longer than this value\ninteger, example: 50\n\n\n--seedSearchStartLmaxOverLread\nseedSearchStartLmax normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 1\n\n\n--seedSearchLmax\ndefines the maximum length of the seeds, if =0 seed length is not limited\ninteger, example: 0\n\n\n--seedMultimapNmax\nonly pieces that map fewer than this value are utilized in the stitching procedure\ninteger, example: 10000\n\n\n--seedPerReadNmax\nmax number of seeds per read\ninteger, example: 1000\n\n\n--seedPerWindowNmax\nmax number of seeds per window\ninteger, example: 50\n\n\n--seedNoneLociPerWindow\nmax number of one seed loci per window\ninteger, example: 10\n\n\n--seedSplitMin\nmin length of the seed sequences split by Ns or mate gap\ninteger, example: 12\n\n\n--seedMapMin\nmin length of seeds to be mapped\ninteger, example: 5\n\n\n--alignIntronMin\nminimum intron size, genomic gap is considered intron if its length&gt;=alignIntronMin, otherwise it is considered Deletion\ninteger, example: 21\n\n\n--alignIntronMax\nmaximum intron size, if 0, max intron size will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignMatesGapMax\nmaximum gap between two mates, if 0, max intron gap will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignSJoverhangMin\nminimum overhang (i.e. block size) for spliced alignments\ninteger, example: 5\n\n\n--alignSJstitchMismatchNmax\nmaximum number of mismatches for stitching of the splice junctions (-1: no limit). (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif.\nList of integer, example: 0, -1, 0, 0, multiple_sep: \";\"\n\n\n--alignSJDBoverhangMin\nminimum overhang (i.e. block size) for annotated (sjdb) spliced alignments\ninteger, example: 3\n\n\n--alignSplicedMateMapLmin\nminimum mapped length for a read mate that is spliced\ninteger, example: 0\n\n\n--alignSplicedMateMapLminOverLmate\nalignSplicedMateMapLmin normalized to mate length\ndouble, example: 0.66\n\n\n--alignWindowsPerReadNmax\nmax number of windows per read\ninteger, example: 10000\n\n\n--alignTranscriptsPerWindowNmax\nmax number of transcripts per window\ninteger, example: 100\n\n\n--alignTranscriptsPerReadNmax\nmax number of different alignments per read to consider\ninteger, example: 10000\n\n\n--alignEndsType\ntype of read ends alignment - Local … standard local alignment with soft-clipping allowed - EndToEnd … force end-to-end read alignment, do not soft-clip - Extend5pOfRead1 … fully extend only the 5p of the read1, all other ends: local alignment - Extend5pOfReads12 … fully extend only the 5p of the both read1 and read2, all other ends: local alignment\nstring, example: \"Local\"\n\n\n--alignEndsProtrude\nallow protrusion of alignment ends, i.e. start (end) of the +strand mate downstream of the start (end) of the -strand mate 1st word: int: maximum number of protrusion bases allowed 2nd word: string: - ConcordantPair … report alignments with non-zero protrusion as concordant pairs - DiscordantPair … report alignments with non-zero protrusion as discordant pairs\nstring, example: \"0    ConcordantPair\"\n\n\n--alignSoftClipAtReferenceEnds\nallow the soft-clipping of the alignments past the end of the chromosomes - Yes … allow - No … prohibit, useful for compatibility with Cufflinks\nstring, example: \"Yes\"\n\n\n--alignInsertionFlush\nhow to flush ambiguous insertion positions - None … insertions are not flushed - Right … insertions are flushed to the right\nstring\n\n\n\n\n\nPaired-End reads\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--peOverlapNbasesMin\nminimum number of overlapping bases to trigger mates merging and realignment. Specify &gt;0 value to switch on the “merginf of overlapping mates” algorithm.\ninteger, example: 0\n\n\n--peOverlapMMp\nmaximum proportion of mismatched bases in the overlap area\ndouble, example: 0.01\n\n\n\n\n\nWindows, Anchors, Binning\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--winAnchorMultimapNmax\nmax number of loci anchors are allowed to map to\ninteger, example: 50\n\n\n--winBinNbits\n=log2(winBin), where winBin is the size of the bin for the windows/clustering, each window will occupy an integer number of bins.\ninteger, example: 16\n\n\n--winAnchorDistNbins\nmax number of bins between two anchors that allows aggregation of anchors into one window\ninteger, example: 9\n\n\n--winFlankNbins\nlog2(winFlank), where win Flank is the size of the left and right flanking regions for each window\ninteger, example: 4\n\n\n--winReadCoverageRelativeMin\nminimum relative coverage of the read sequence by the seeds in a window, for STARlong algorithm only.\ndouble, example: 0.5\n\n\n--winReadCoverageBasesMin\nminimum number of bases covered by the seeds in a window , for STARlong algorithm only.\ninteger, example: 0\n\n\n\n\n\nChimeric Alignments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--chimOutType\ntype of chimeric output - Junctions … Chimeric.out.junction - SeparateSAMold … output old SAM into separate Chimeric.out.sam file - WithinBAM … output into main aligned BAM files (Aligned.*.bam) - WithinBAM HardClip … (default) hard-clipping in the CIGAR for supplemental chimeric alignments (default if no 2nd word is present) - WithinBAM SoftClip … soft-clipping in the CIGAR for supplemental chimeric alignments\nList of string, example: \"Junctions\", multiple_sep: \";\"\n\n\n--chimSegmentMin\nminimum length of chimeric segment length, if ==0, no chimeric output\ninteger, example: 0\n\n\n--chimScoreMin\nminimum total (summed) score of the chimeric segments\ninteger, example: 0\n\n\n--chimScoreDropMax\nmax drop (difference) of chimeric score (the sum of scores of all chimeric segments) from the read length\ninteger, example: 20\n\n\n--chimScoreSeparation\nminimum difference (separation) between the best chimeric score and the next one\ninteger, example: 10\n\n\n--chimScoreJunctionNonGTAG\npenalty for a non-GT/AG chimeric junction\ninteger, example: -1\n\n\n--chimJunctionOverhangMin\nminimum overhang for a chimeric junction\ninteger, example: 20\n\n\n--chimSegmentReadGapMax\nmaximum gap in the read sequence between chimeric segments\ninteger, example: 0\n\n\n--chimFilter\ndifferent filters for chimeric alignments - None … no filtering - banGenomicN … Ns are not allowed in the genome sequence around the chimeric junction\nList of string, example: \"banGenomicN\", multiple_sep: \";\"\n\n\n--chimMainSegmentMultNmax\nmaximum number of multi-alignments for the main chimeric segment. =1 will prohibit multimapping main segments.\ninteger, example: 10\n\n\n--chimMultimapNmax\nmaximum number of chimeric multi-alignments - 0 … use the old scheme for chimeric detection which only considered unique alignments\ninteger, example: 0\n\n\n--chimMultimapScoreRange\nthe score range for multi-mapping chimeras below the best chimeric score. Only works with –chimMultimapNmax &gt; 1\ninteger, example: 1\n\n\n--chimNonchimScoreDropMin\nto trigger chimeric detection, the drop in the best non-chimeric alignment score with respect to the read length has to be greater than this value\ninteger, example: 20\n\n\n--chimOutJunctionFormat\nformatting type for the Chimeric.out.junction file - 0 … no comment lines/headers - 1 … comment lines at the end of the file: command line and Nreads: total, unique/multi-mapping\ninteger, example: 0\n\n\n\n\n\nQuantification of Annotations\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--quantMode\ntypes of quantification requested - - … none - TranscriptomeSAM … output SAM/BAM alignments to transcriptome into a separate file - GeneCounts … count reads per gene\nList of string, multiple_sep: \";\"\n\n\n--quantTranscriptomeBAMcompression\n-2 to 10 transcriptome BAM compression level - -2 … no BAM output - -1 … default compression (6?) - 0 … no compression - 10 … maximum compression\ninteger, example: 1\n\n\n--quantTranscriptomeBan\nprohibit various alignment type - IndelSoftclipSingleend … prohibit indels, soft clipping and single-end alignments - compatible with RSEM - Singleend … prohibit single-end alignments\nstring, example: \"IndelSoftclipSingleend\"\n\n\n\n\n\n2-pass Mapping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--twopassMode\n2-pass mapping mode. - None … 1-pass mapping - Basic … basic 2-pass mapping, with all 1st pass junctions inserted into the genome indices on the fly\nstring\n\n\n--twopass1readsN\nnumber of reads to process for the 1st step. Use very large number (or default -1) to map all reads in the first step.\ninteger, example: -1\n\n\n\n\n\nWASP parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--waspOutputMode\nWASP allele-specific output type. This is re-implementation of the original WASP mappability filtering by Bryce van de Geijn, Graham McVicker, Yoav Gilad & Jonathan K Pritchard. Please cite the original WASP paper: Nature Methods 12, 1061-1063 (2015), https://www.nature.com/articles/nmeth.3582 . - SAMtag … add WASP tags to the alignments that pass WASP filtering\nstring\n\n\n\n\n\nSTARsolo (single cell RNA-seq) parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--soloType\ntype of single-cell RNA-seq - CB_UMI_Simple … (a.k.a. Droplet) one UMI and one Cell Barcode of fixed length in read2, e.g. Drop-seq and 10X Chromium. - CB_UMI_Complex … multiple Cell Barcodes of varying length, one UMI of fixed length and one adapter sequence of fixed length are allowed in read2 only (e.g. inDrop, ddSeq). - CB_samTagOut … output Cell Barcode as CR and/or CB SAm tag. No UMI counting. –readFilesIn cDNA_read1 [cDNA_read2 if paired-end] CellBarcode_read . Requires –outSAMtype BAM Unsorted [and/or SortedByCoordinate] - SmartSeq … Smart-seq: each cell in a separate FASTQ (paired- or single-end), barcodes are corresponding read-groups, no UMI sequences, alignments deduplicated according to alignment start and end (after extending soft-clipped bases)\nList of string, multiple_sep: \";\"\n\n\n--soloCBwhitelist\nfile(s) with whitelist(s) of cell barcodes. Only –soloType CB_UMI_Complex allows more than one whitelist file. - None … no whitelist: all cell barcodes are allowed\nList of string, multiple_sep: \";\"\n\n\n--soloCBstart\ncell barcode start base\ninteger, example: 1\n\n\n--soloCBlen\ncell barcode length\ninteger, example: 16\n\n\n--soloUMIstart\nUMI start base\ninteger, example: 17\n\n\n--soloUMIlen\nUMI length\ninteger, example: 10\n\n\n--soloBarcodeReadLength\nlength of the barcode read - 1 … equal to sum of soloCBlen+soloUMIlen - 0 … not defined, do not check\ninteger, example: 1\n\n\n--soloBarcodeMate\nidentifies which read mate contains the barcode (CB+UMI) sequence - 0 … barcode sequence is on separate read, which should always be the last file in the –readFilesIn listed - 1 … barcode sequence is a part of mate 1 - 2 … barcode sequence is a part of mate 2\ninteger, example: 0\n\n\n--soloCBposition\nposition of Cell Barcode(s) on the barcode read. Presently only works with –soloType CB_UMI_Complex, and barcodes are assumed to be on Read2. Format for each barcode: startAnchor_startPosition_endAnchor_endPosition start(end)Anchor defines the Anchor Base for the CB: 0: read start; 1: read end; 2: adapter start; 3: adapter end start(end)Position is the 0-based position with of the CB start(end) with respect to the Anchor Base String for different barcodes are separated by space. Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 0_0_2_-1 3_1_3_8\nList of string, multiple_sep: \";\"\n\n\n--soloUMIposition\nposition of the UMI on the barcode read, same as soloCBposition Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 3_9_3_14\nstring\n\n\n--soloAdapterSequence\nadapter sequence to anchor barcodes. Only one adapter sequence is allowed.\nstring\n\n\n--soloAdapterMismatchesNmax\nmaximum number of mismatches allowed in adapter sequence.\ninteger, example: 1\n\n\n--soloCBmatchWLtype\nmatching the Cell Barcodes to the WhiteList - Exact … only exact matches allowed - 1MM … only one match in whitelist with 1 mismatched base allowed. Allowed CBs have to have at least one read with exact match. - 1MM_multi … multiple matches in whitelist with 1 mismatched base allowed, posterior probability calculation is used choose one of the matches. Allowed CBs have to have at least one read with exact match. This option matches best with CellRanger 2.2.0 - 1MM_multi_pseudocounts … same as 1MM_Multi, but pseudocounts of 1 are added to all whitelist barcodes. - 1MM_multi_Nbase_pseudocounts … same as 1MM_multi_pseudocounts, multimatching to WL is allowed for CBs with N-bases. This option matches best with CellRanger &gt;= 3.0.0 - EditDist_2 … allow up to edit distance of 3 fpr each of the barcodes. May include one deletion + one insertion. Only works with –soloType CB_UMI_Complex. Matches to multiple passlist barcdoes are not allowed. Similar to ParseBio Split-seq pipeline.\nstring, example: \"1MM_multi\"\n\n\n--soloInputSAMattrBarcodeSeq\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode sequence (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeSeq CR UR . This parameter is required when running STARsolo with input from SAM.\nList of string, multiple_sep: \";\"\n\n\n--soloInputSAMattrBarcodeQual\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode qualities (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeQual CY UY . If this parameter is ‘-’ (default), the quality ‘H’ will be assigned to all bases.\nList of string, multiple_sep: \";\"\n\n\n--soloStrand\nstrandedness of the solo libraries: - Unstranded … no strand information - Forward … read strand same as the original RNA molecule - Reverse … read strand opposite to the original RNA molecule\nstring, example: \"Forward\"\n\n\n--soloFeatures\ngenomic features for which the UMI counts per Cell Barcode are collected - Gene … genes: reads match the gene transcript - SJ … splice junctions: reported in SJ.out.tab - GeneFull … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns - GeneFull_ExonOverIntron … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns: prioritize 100% overlap with exons - GeneFull_Ex50pAS … full gene (pre-RNA): count all reads overlapping genes’ exons and introns: prioritize &gt;50% overlap with exons. Do not count reads with 100% exonic overlap in the antisense direction.\nList of string, example: \"Gene\", multiple_sep: \";\"\n\n\n--soloMultiMappers\ncounting method for reads mapping to multiple genes - Unique … count only reads that map to unique genes - Uniform … uniformly distribute multi-genic UMIs to all genes - Rescue … distribute UMIs proportionally to unique+uniform counts (~ first iteration of EM) - PropUnique … distribute UMIs proportionally to unique mappers, if present, and uniformly if not. - EM … multi-gene UMIs are distributed using Expectation Maximization algorithm\nList of string, example: \"Unique\", multiple_sep: \";\"\n\n\n--soloUMIdedup\ntype of UMI deduplication (collapsing) algorithm - 1MM_All … all UMIs with 1 mismatch distance to each other are collapsed (i.e. counted once). - 1MM_Directional_UMItools … follows the “directional” method from the UMI-tools by Smith, Heger and Sudbery (Genome Research 2017). - 1MM_Directional … same as 1MM_Directional_UMItools, but with more stringent criteria for duplicate UMIs - Exact … only exactly matching UMIs are collapsed. - NoDedup … no deduplication of UMIs, count all reads. - 1MM_CR … CellRanger2-4 algorithm for 1MM UMI collapsing.\nList of string, example: \"1MM_All\", multiple_sep: \";\"\n\n\n--soloUMIfiltering\ntype of UMI filtering (for reads uniquely mapping to genes) - - … basic filtering: remove UMIs with N and homopolymers (similar to CellRanger 2.2.0). - MultiGeneUMI … basic + remove lower-count UMIs that map to more than one gene. - MultiGeneUMI_All … basic + remove all UMIs that map to more than one gene. - MultiGeneUMI_CR … basic + remove lower-count UMIs that map to more than one gene, matching CellRanger &gt; 3.0.0 . Only works with –soloUMIdedup 1MM_CR\nList of string, multiple_sep: \";\"\n\n\n--soloOutFileNames\nfile names for STARsolo output: file_name_prefix gene_names barcode_sequences cell_feature_count_matrix\nList of string, example: \"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\", multiple_sep: \";\"\n\n\n--soloCellFilter\ncell filtering type and parameters - None … do not output filtered cells - TopCells … only report top cells by UMI count, followed by the exact number of cells - CellRanger2.2 … simple filtering of CellRanger 2.2. Can be followed by numbers: number of expected cells, robust maximum percentile for UMI count, maximum to minimum ratio for UMI count The harcoded values are from CellRanger: nExpectedCells=3000; maxPercentile=0.99; maxMinRatio=10 - EmptyDrops_CR … EmptyDrops filtering in CellRanger flavor. Please cite the original EmptyDrops paper: A.T.L Lun et al, Genome Biology, 20, 63 (2019): https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1662-y Can be followed by 10 numeric parameters: nExpectedCells maxPercentile maxMinRatio indMin indMax umiMin umiMinFracMedian candMaxN FDR simN The harcoded values are from CellRanger: 3000 0.99 10 45000 90000 500 0.01 20000 0.01 10000\nList of string, example: \"CellRanger2.2\", \"3000\", \"0.99\", \"10\", multiple_sep: \";\"\n\n\n--soloOutFormatFeaturesGeneField3\nfield 3 in the Gene features.tsv file. If “-”, then no 3rd field is output.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--soloCellReadStats\nOutput reads statistics for each CB - Standard … standard output\nstring\n\n\n\n\n\nHTSeq arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--stranded\nWhether the data is from a strand-specific assay. ‘reverse’ means ‘yes’ with reversed strand interpretation.\nstring, default: \"yes\"\n\n\n--minimum_alignment_quality\nSkip all reads with MAPQ alignment quality lower than the given minimum value. MAPQ is the 5th column of a SAM/BAM file and its usage depends on the software used to map the reads.\ninteger, default: 10\n\n\n--type\nFeature type (3rd column in GTF file) to be used, all features of other type are ignored (default, suitable for Ensembl GTF files: exon)\nstring, example: \"exon\"\n\n\n--id_attribute\nGTF attribute to be used as feature ID (default, suitable for Ensembl GTF files: gene_id). All feature of the right type (see -t option) within the same GTF attribute will be added together. The typical way of using this option is to count all exonic reads from each gene and add the exons but other uses are possible as well. You can call this option multiple times: in that case, the combination of all attributes separated by colons (:) will be used as a unique identifier, e.g. for exons you might use -i gene_id -i exon_number.\nList of string, example: \"gene_id\", multiple_sep: \";\"\n\n\n--additional_attributes\nAdditional feature attributes (suitable for Ensembl GTF files: gene_name). Use multiple times for more than one additional attribute. These attributes are only used as annotations in the output, while the determination of how the counts are added together is done based on option -i.\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--add_chromosome_info\nStore information about the chromosome of each feature as an additional attribute (e.g. colunm in the TSV output file).\nboolean_true\n\n\n--mode\nMode to handle reads overlapping more than one feature.\nstring, default: \"union\"\n\n\n--non_unique\nWhether and how to score reads that are not uniquely aligned or ambiguously assigned to features.\nstring, default: \"none\"\n\n\n--secondary_alignments\nWhether to score secondary alignments (0x100 flag).\nstring\n\n\n--supplementary_alignments\nWhether to score supplementary alignments (0x800 flag).\nstring\n\n\n--counts_output_sparse\nStore the counts as a sparse matrix (mtx, h5ad, loom).\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Multi star"
    ]
  },
  {
    "objectID": "components/modules/mapping/multi_star.html#authors",
    "href": "components/modules/mapping/multi_star.html#authors",
    "title": "Multi star",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Multi star"
    ]
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html",
    "href": "components/modules/mapping/bd_rhapsody.html",
    "title": "Bd rhapsody",
    "section": "",
    "text": "ID: bd_rhapsody\nNamespace: mapping\n\n\n\nSource\nThe supported sequencing libraries are those generated by the BD Rhapsody assay kits, including: Whole Transcriptome mRNA, Targeted mRNA, AbSeq Antibody-Oligonucleotides, Single-Cell Multiplexing, TCR/BCR, and ATAC-Seq\nThe CWL pipeline file is obtained by cloning ‘https://bitbucket.org/CRSwDev/cwl’ and removing all objects with class ‘DockerRequirement’ from the YAML.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Bd rhapsody"
    ]
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html#example-commands",
    "href": "components/modules/mapping/bd_rhapsody.html#example-commands",
    "title": "Bd rhapsody",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/bd_rhapsody/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\n# reads: [\"WTALibrary_S1_L001_R1_001.fastq.gz\", \"WTALibrary_S1_L001_R2_001.fastq.gz\"]\n# reads_atac: [\"ATACLibrary_S2_L001_R1_001.fastq.gz\", \"ATACLibrary_S2_L001_R2_001.fastq.gz\", \"ATACLibrary_S2_L001_I2_001.fastq.gz\"]\n\n# References\n# reference_archive: \"RhapRef_Human_WTA_2023-02.tar.gz\"\n# targeted_reference: [\"BD_Rhapsody_Immune_Response_Panel_Hs.fasta\"]\n# abseq_reference: [\"AbSeq_reference.fasta\"]\n# supplemental_reference: [\"supplemental_reference.fasta\"]\n\n# Outputs\n# output_dir: \"$id.$key.output_dir\"\n# output_seurat: \"$id.$key.output_seurat.rds\"\n# output_mudata: \"$id.$key.output_mudata.h5mu\"\n# metrics_summary: \"$id.$key.metrics_summary.csv\"\n# pipeline_report: \"$id.$key.pipeline_report.html\"\n# rsec_mols_per_cell: \"$id.$key.rsec_mols_per_cell.zip\"\n# dbec_mols_per_cell: \"$id.$key.dbec_mols_per_cell.zip\"\n# rsec_mols_per_cell_unfiltered: \"$id.$key.rsec_mols_per_cell_unfiltered.zip\"\n# bam: \"$id.$key.bam.bam\"\n# bam_index: \"$id.$key.bam_index.bai\"\n# bioproduct_stats: \"$id.$key.bioproduct_stats.csv\"\n# dimred_tsne: \"$id.$key.dimred_tsne.csv\"\n# dimred_umap: \"$id.$key.dimred_umap.csv\"\n# immune_cell_classification: \"$id.$key.immune_cell_classification.csv\"\n\n# Multiplex outputs\n# sample_tag_metrics: \"$id.$key.sample_tag_metrics.csv\"\n# sample_tag_calls: \"$id.$key.sample_tag_calls.csv\"\n# sample_tag_counts: [\"$id.$key.sample_tag_counts_*.zip\"]\n# sample_tag_counts_unassigned: \"$id.$key.sample_tag_counts_unassigned.zip\"\n\n# VDJ Outputs\n# vdj_metrics: \"$id.$key.vdj_metrics.csv\"\n# vdj_per_cell: \"$id.$key.vdj_per_cell.csv\"\n# vdj_per_cell_uncorrected: \"$id.$key.vdj_per_cell_uncorrected.csv\"\n# vdj_dominant_contigs: \"$id.$key.vdj_dominant_contigs.csv\"\n# vdj_unfiltered_contigs: \"$id.$key.vdj_unfiltered_contigs.csv\"\n\n# ATAC-Seq outputs\n# atac_metrics: \"$id.$key.atac_metrics.csv\"\n# atac_metrics_json: \"$id.$key.atac_metrics_json.json\"\n# atac_fragments: \"$id.$key.atac_fragments.gz\"\n# atac_fragments_index: \"$id.$key.atac_fragments_index.tbi\"\n# atac_transposase_sites: \"$id.$key.atac_transposase_sites.gz\"\n# atac_transposase_sites_index: \"$id.$key.atac_transposase_sites_index.tbi\"\n# atac_peaks: \"$id.$key.atac_peaks.gz\"\n# atac_peaks_index: \"$id.$key.atac_peaks_index.tbi\"\n# atac_peak_annotation: \"$id.$key.atac_peak_annotation.gz\"\n# atac_cell_by_peak: \"$id.$key.atac_cell_by_peak.zip\"\n# atac_cell_by_peak_unfiltered: \"$id.$key.atac_cell_by_peak_unfiltered.zip\"\n# atac_bam: \"$id.$key.atac_bam.bam\"\n# atac_bam_index: \"$id.$key.atac_bam_index.bai\"\n\n# AbSeq Cell Calling outputs\n# protein_aggregates_experimental: \"$id.$key.protein_aggregates_experimental.csv\"\n\n# Putative Cell Calling Settings\n# cell_calling_data: \"mRNA\"\n# cell_calling_bioproduct_algorithm: \"Basic\"\n# cell_calling_atac_algorithm: \"Basic\"\n# exact_cell_count: 10000\n# expected_cell_count: 20000\n\n# Intronic Reads Settings\n# exclude_intronic_reads: false\n\n# Multiplex Settings\n# sample_tags_version: \"human\"\n# tag_names: [\"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\"]\n\n# VDJ arguments\n# vdj_version: \"human\"\n\n# ATAC options\n# predefined_atac_peaks: \"predefined_peaks.bed\"\n\n# Additional options\nrun_name: \"sample\"\ngenerate_bam: false\n# long_reads: true\n\n# Advanced options\n# custom_star_params: \"--alignIntronMax 6000 --outFilterScoreMinOverLread 0.1 --limitOutSJcollapsed 2000000\"\n# custom_bwa_mem2_params: \"-k 16 -w 200 -r\"\n\n# CWL-runner arguments\nparallel: true\ntimestamps: false\n\n# Undocumented arguments\n# abseq_umi: 123\n# target_analysis: true\n# vdj_jgene_evalue: 123.0\n# vdj_vgene_evalue: 123.0\n# write_filtered_reads: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/bd_rhapsody/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Bd rhapsody"
    ]
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html#argument-groups",
    "href": "components/modules/mapping/bd_rhapsody.html#argument-groups",
    "title": "Bd rhapsody",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reads\nReads (optional) - Path to your FASTQ.GZ formatted read files from libraries that may include: - WTA mRNA - Targeted mRNA - AbSeq - Sample Multiplexing - VDJ You may specify as many R1/R2 read pairs as you want.\nList of file, example: \"WTALibrary_S1_L001_R1_001.fastq.gz\", \"WTALibrary_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reads_atac\nPath to your FASTQ.GZ formatted read files from ATAC-Seq libraries. You may specify as many R1/R2/I2 files as you want.\nList of file, example: \"ATACLibrary_S2_L001_R1_001.fastq.gz\", \"ATACLibrary_S2_L001_R2_001.fastq.gz\", \"ATACLibrary_S2_L001_I2_001.fastq.gz\", multiple_sep: \";\"\n\n\n\n\n\nReferences\nAssay type will be inferred from the provided reference(s). Do not provide both reference_archive and targeted_reference at the same time.\nValid reference input combinations: - reference_archive: WTA only - reference_archive & abseq_reference: WTA + AbSeq - reference_archive & supplemental_reference: WTA + extra transgenes - reference_archive & abseq_reference & supplemental_reference: WTA + AbSeq + extra transgenes - reference_archive: WTA + ATAC or ATAC only - reference_archive & supplemental_reference: WTA + ATAC + extra transgenes - targeted_reference: Targeted only - targeted_reference & abseq_reference: Targeted + AbSeq - abseq_reference: AbSeq only\nThe reference_archive can be generated with the bd_rhapsody_make_reference component. Alternatively, BD also provides standard references which can be downloaded from these locations:\n\nHuman: https://bd-rhapsody-public.s3.amazonaws.com/Rhapsody-WTA/Pipeline-version2.x_WTA_references/RhapRef_Human_WTA_2023-02.tar.gz\nMouse: https://bd-rhapsody-public.s3.amazonaws.com/Rhapsody-WTA/Pipeline-version2.x_WTA_references/RhapRef_Mouse_WTA_2023-02.tar.gz\n\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference_archive\nPath to Rhapsody WTA Reference in the tar.gz format. Structure of the reference archive: - BD_Rhapsody_Reference_Files/: top level folder - star_index/: sub-folder containing STAR index, that is files created with STAR --runMode genomeGenerate - GTF for gene-transcript-annotation e.g. “gencode.v43.primary_assembly.annotation.gtf”\nfile, example: \"RhapRef_Human_WTA_2023-02.tar.gz\"\n\n\n--targeted_reference\nPath to the targeted reference file in FASTA format.\nList of file, example: \"BD_Rhapsody_Immune_Response_Panel_Hs.fasta\", multiple_sep: \";\"\n\n\n--abseq_reference\nPath to the AbSeq reference file in FASTA format. Only needed if BD AbSeq Ab-Oligos are used.\nList of file, example: \"AbSeq_reference.fasta\", multiple_sep: \";\"\n\n\n--supplemental_reference\nPath to the supplemental reference file in FASTA format. Only needed if there are additional transgene sequences to be aligned against in a WTA assay experiment.\nList of file, example: \"supplemental_reference.fasta\", multiple_sep: \";\"\n\n\n\n\n\nOutputs\nOutputs for all pipeline runs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_dir\nThe unprocessed output directory containing all the outputs from the pipeline.\nfile, required, example: \"output_dir\"\n\n\n--output_seurat\nSingle-cell analysis tool inputs. Seurat (.rds) input file containing RSEC molecules data table and all cell annotation metadata.\nfile, example: \"output_seurat.rds\"\n\n\n--output_mudata\n\nfile, example: \"output_mudata.h5mu\"\n\n\n--metrics_summary\nMetrics Summary. Report containing sequencing, molecules, and cell metrics.\nfile, example: \"metrics_summary.csv\"\n\n\n--pipeline_report\nPipeline Report. Summary report containing the results from the sequencing analysis pipeline run.\nfile, example: \"pipeline_report.html\"\n\n\n--rsec_mols_per_cell\nMolecules per bioproduct per cell bassed on RSEC\nfile, example: \"RSEC_MolsPerCell_MEX.zip\"\n\n\n--dbec_mols_per_cell\nMolecules per bioproduct per cell bassed on DBEC. DBEC data table is only output if the experiment includes targeted mRNA or AbSeq bioproducts.\nfile, example: \"DBEC_MolsPerCell_MEX.zip\"\n\n\n--rsec_mols_per_cell_unfiltered\nUnfiltered tables containing all cell labels with 10 reads.\nfile, example: \"RSEC_MolsPerCell_Unfiltered_MEX.zip\"\n\n\n--bam\nAlignment file of R2 with associated R1 annotations for Bioproduct.\nfile, example: \"BioProduct.bam\"\n\n\n--bam_index\nIndex file for the alignment file.\nfile, example: \"BioProduct.bam.bai\"\n\n\n--bioproduct_stats\nBioproduct Stats. Metrics from RSEC and DBEC Unique Molecular Identifier adjustment algorithms on a per-bioproduct basis.\nfile, example: \"Bioproduct_Stats.csv\"\n\n\n--dimred_tsne\nt-SNE dimensionality reduction coordinates per cell index\nfile, example: \"tSNE_coordinates.csv\"\n\n\n--dimred_umap\nUMAP dimensionality reduction coordinates per cell index\nfile, example: \"UMAP_coordinates.csv\"\n\n\n--immune_cell_classification\nImmune Cell Classification. Cell type classification based on the expression of immune cell markers.\nfile, example: \"Immune_Cell_Classification.csv\"\n\n\n\n\n\nMultiplex outputs\nOutputs when multiplex option is selected\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sample_tag_metrics\nSample Tag Metrics. Metrics from the sample determination algorithm.\nfile, example: \"Sample_Tag_Metrics.csv\"\n\n\n--sample_tag_calls\nSample Tag Calls. Assigned Sample Tag for each putative cell\nfile, example: \"Sample_Tag_Calls.csv\"\n\n\n--sample_tag_counts\nSample Tag Counts. Separate data tables and metric summary for cells assigned to each sample tag. Note: For putative cells that could not be assigned a specific Sample Tag, a Multiplet_and_Undetermined.zip file is also output.\nList of file, example: \"Sample_Tag1.zip\", multiple_sep: \";\"\n\n\n--sample_tag_counts_unassigned\nSample Tag Counts Unassigned. Data table and metric summary for cells that could not be assigned a specific Sample Tag.\nfile, example: \"Multiplet_and_Undetermined.zip\"\n\n\n\n\n\nVDJ Outputs\nOutputs when VDJ option selected\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vdj_metrics\nVDJ Metrics. Overall metrics from the VDJ analysis.\nfile, example: \"VDJ_Metrics.csv\"\n\n\n--vdj_per_cell\nVDJ Per Cell. Cell specific read and molecule counts, VDJ gene segments, CDR3 sequences, paired chains, and cell type.\nfile, example: \"VDJ_perCell.csv\"\n\n\n--vdj_per_cell_uncorrected\nVDJ Per Cell Uncorrected. Cell specific read and molecule counts, VDJ gene segments, CDR3 sequences, paired chains, and cell type.\nfile, example: \"VDJ_perCell_uncorrected.csv\"\n\n\n--vdj_dominant_contigs\nVDJ Dominant Contigs. Dominant contig for each cell label chain type combination (putative cells only).\nfile, example: \"VDJ_Dominant_Contigs_AIRR.csv\"\n\n\n--vdj_unfiltered_contigs\nVDJ Unfiltered Contigs. All contigs that were assembled and annotated successfully (all cells).\nfile, example: \"VDJ_Unfiltered_Contigs_AIRR.csv\"\n\n\n\n\n\nATAC-Seq outputs\nOutputs when ATAC-Seq option selected\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--atac_metrics\nATAC Metrics. Overall metrics from the ATAC-Seq analysis.\nfile, example: \"ATAC_Metrics.csv\"\n\n\n--atac_metrics_json\nATAC Metrics JSON. Overall metrics from the ATAC-Seq analysis in JSON format.\nfile, example: \"ATAC_Metrics.json\"\n\n\n--atac_fragments\nATAC Fragments. Chromosomal location, cell index, and read support for each fragment detected\nfile, example: \"ATAC_Fragments.bed.gz\"\n\n\n--atac_fragments_index\nIndex of ATAC Fragments.\nfile, example: \"ATAC_Fragments.bed.gz.tbi\"\n\n\n--atac_transposase_sites\nATAC Transposase Sites. Chromosomal location, cell index, and read support for each transposase site detected\nfile, example: \"ATAC_Transposase_Sites.bed.gz\"\n\n\n--atac_transposase_sites_index\nIndex of ATAC Transposase Sites.\nfile, example: \"ATAC_Transposase_Sites.bed.gz.tbi\"\n\n\n--atac_peaks\nATAC Peaks. Peak regions of transposase activity\nfile, example: \"ATAC_Peaks.bed.gz\"\n\n\n--atac_peaks_index\nIndex of ATAC Peaks.\nfile, example: \"ATAC_Peaks.bed.gz.tbi\"\n\n\n--atac_peak_annotation\nATAC Peak Annotation. Estimated annotation of peak-to-gene connections\nfile, example: \"peak_annotation.tsv.gz\"\n\n\n--atac_cell_by_peak\nATAC Cell by Peak. Peak regions of transposase activity per cell\nfile, example: \"ATAC_Cell_by_Peak_MEX.zip\"\n\n\n--atac_cell_by_peak_unfiltered\nATAC Cell by Peak Unfiltered. Unfiltered file containing all cell labels with &gt;=1 transposase sites in peaks.\nfile, example: \"ATAC_Cell_by_Peak_Unfiltered_MEX.zip\"\n\n\n--atac_bam\nATAC BAM. Alignment file for R1 and R2 with associated I2 annotations for ATAC-Seq. Only output if the BAM generation flag is set to true.\nfile, example: \"ATAC.bam\"\n\n\n--atac_bam_index\nIndex of ATAC BAM.\nfile, example: \"ATAC.bam.bai\"\n\n\n\n\n\nAbSeq Cell Calling outputs\nOutputs when Cell Calling Abseq is selected\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--protein_aggregates_experimental\nProtein Aggregates Experimental\nfile, example: \"Protein_Aggregates_Experimental.csv\"\n\n\n\n\n\nPutative Cell Calling Settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_calling_data\nSpecify the dataset to be used for putative cell calling: mRNA, AbSeq, ATAC, mRNA_and_ATAC For putative cell calling using an AbSeq dataset, please provide an AbSeq_Reference fasta file above. For putative cell calling using an ATAC dataset, please provide a WTA+ATAC-Seq Reference_Archive file above. The default data for putative cell calling, will be determined the following way: - If mRNA Reads and ATAC Reads exist: mRNA_and_ATAC - If only ATAC Reads exist: ATAC - Otherwise: mRNA\nstring, example: \"mRNA\"\n\n\n--cell_calling_bioproduct_algorithm\nSpecify the bioproduct algorithm to be used for putative cell calling: Basic or Refined By default, the Basic algorithm will be used for putative cell calling.\nstring, example: \"Basic\"\n\n\n--cell_calling_atac_algorithm\nSpecify the ATAC-seq algorithm to be used for putative cell calling: Basic or Refined By default, the Basic algorithm will be used for putative cell calling.\nstring, example: \"Basic\"\n\n\n--exact_cell_count\nSet a specific number of cells as putative, based on those with the highest error-corrected read count\ninteger, example: 10000\n\n\n--expected_cell_count\nGuide the basic putative cell calling algorithm by providing an estimate of the number of cells expected. Usually this can be the number of cells loaded into the Rhapsody cartridge. If there are multiple inflection points on the second derivative cumulative curve, this will ensure the one selected is near the expected.\ninteger, example: 20000\n\n\n\n\n\nIntronic Reads Settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--exclude_intronic_reads\nBy default, the flag is false, and reads aligned to exons and introns are considered and represented in molecule counts. When the flag is set to true, intronic reads will be excluded. The value can be true or false.\nboolean, example: FALSE\n\n\n\n\n\nMultiplex Settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sample_tags_version\nSpecify the version of the Sample Tags used in the run: * If Sample Tag Multiplexing was done, specify the appropriate version: human, mouse, flex, nuclei_includes_mrna, nuclei_atac_only * If this is an SMK + Nuclei mRNA run or an SMK + Multiomic ATAC-Seq (WTA+ATAC-Seq) run (and not an SMK + ATAC-Seq only run), choose the “nuclei_includes_mrna” option. * If this is an SMK + ATAC-Seq only run (and not SMK + Multiomic ATAC-Seq (WTA+ATAC-Seq)), choose the “nuclei_atac_only” option.\nstring, example: \"human\"\n\n\n--tag_names\nSpecify the tag number followed by ‘-’ and the desired sample name to appear in Sample_Tag_Metrics.csv Do not use the special characters.\nList of string, example: \"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\", multiple_sep: \";\"\n\n\n\n\n\nVDJ arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vdj_version\nIf VDJ was done, specify the appropriate option: human, mouse, humanBCR, humanTCR, mouseBCR, mouseTCR\nstring, example: \"human\"\n\n\n\n\n\nATAC options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--predefined_atac_peaks\nAn optional BED file containing pre-established chromatin accessibility peak regions for generating the ATAC cell-by-peak matrix.\nfile, example: \"predefined_peaks.bed\"\n\n\n\n\n\nAdditional options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--run_name\nSpecify a run name to use as the output file base name. Use only letters, numbers, or hyphens. Do not use special characters or spaces.\nstring, default: \"sample\"\n\n\n--generate_bam\nSpecify whether to create the BAM file output\nboolean, default: FALSE\n\n\n--long_reads\nUse STARlong (default: undefined - i.e. autodetects based on read lengths) - Specify if the STARlong aligner should be used instead of STAR. Set to true if the reads are longer than 650bp.\nboolean\n\n\n\n\n\nAdvanced options\nNOTE: Only change these if you are really sure about what you are doing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--custom_star_params\nModify STAR alignment parameters - Set this parameter to fully override default STAR mapping parameters used in the pipeline. For reference this is the default that is used: Short Reads: --outFilterScoreMinOverLread 0 --outFilterMatchNminOverLread 0 --outFilterMultimapScoreRange 0 --clip3pAdapterSeq AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA --seedSearchStartLmax 50 --outFilterMatchNmin 25 --limitOutSJcollapsed 2000000 Long Reads: Same as Short Reads + --seedPerReadNmax 10000 This applies to fastqs provided in the Reads user input Do NOT set any non-mapping related params like --genomeDir, --outSAMtype, --outSAMunmapped, --readFilesIn, --runThreadN, etc. We use STAR version 2.7.10b\nstring, example: \"--alignIntronMax 6000 --outFilterScoreMinOverLread 0.1 --limitOutSJcollapsed 2000000\"\n\n\n--custom_bwa_mem2_params\nModify bwa-mem2 alignment parameters - Set this parameter to fully override bwa-mem2 mapping parameters used in the pipeline The pipeline does not specify any custom mapping params to bwa-mem2 so program default values are used This applies to fastqs provided in the Reads_ATAC user input Do NOT set any non-mapping related params like -C, -t, etc. We use bwa-mem2 version 2.2.1\nstring, example: \"-k 16 -w 200 -r\"\n\n\n\n\n\nCWL-runner arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--parallel\nRun jobs in parallel.\nboolean, default: TRUE\n\n\n--timestamps\nAdd timestamps to the errors, warnings, and notifications.\nboolean_true\n\n\n\n\n\nUndocumented arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--abseq_umi\n\ninteger\n\n\n--target_analysis\n\nboolean\n\n\n--vdj_jgene_evalue\ne-value threshold for J gene. The e-value threshold for J gene call by IgBlast/PyIR, default is set as 0.001\ndouble\n\n\n--vdj_vgene_evalue\ne-value threshold for V gene. The e-value threshold for V gene call by IgBlast/PyIR, default is set as 0.001\ndouble\n\n\n--write_filtered_reads\n\nboolean",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Bd rhapsody"
    ]
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html#authors",
    "href": "components/modules/mapping/bd_rhapsody.html#authors",
    "title": "Bd rhapsody",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Bd rhapsody"
    ]
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html",
    "href": "components/modules/mapping/multi_star_to_h5mu.html",
    "title": "Multi star to h5mu",
    "section": "",
    "text": "ID: multi_star_to_h5mu\nNamespace: mapping\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Multi star to h5mu"
    ]
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html#example-commands",
    "href": "components/modules/mapping/multi_star_to_h5mu.html#example-commands",
    "title": "Multi star to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/multi_star_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"/path/to/foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/multi_star_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Multi star to h5mu"
    ]
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html#argument-group",
    "href": "components/modules/mapping/multi_star_to_h5mu.html#argument-group",
    "title": "Multi star to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe directory created by multi_star\nfile, required, example: \"/path/to/foo\"\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Multi star to h5mu"
    ]
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html#authors",
    "href": "components/modules/mapping/multi_star_to_h5mu.html#authors",
    "title": "Multi star to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Multi star to h5mu"
    ]
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html",
    "href": "components/modules/mapping/samtools_sort.html",
    "title": "Samtools sort",
    "section": "",
    "text": "ID: samtools_sort\nNamespace: mapping\n\n\n\nSource\nReads are sorted by leftmost coordinates, or by read name when --sort_by_read_names is used.\nAn appropriate @HD-SO sort order header tag will be added or an existing one updated if necessary.\nNote that to generate an index file (by specifying --output_bai), the default coordinate sort must be used. Thus the --sort_by_read_names and --sort_by &lt;TAG&gt; options are incompatible with --output_bai.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Samtools sort"
    ]
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html#example-commands",
    "href": "components/modules/mapping/samtools_sort.html#example-commands",
    "title": "Samtools sort",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/samtools_sort/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\ninput: # please fill in - example: \"input.bam\"\n\n# Output\n# output_bam: \"$id.$key.output_bam.bam\"\n# output_bai: \"$id.$key.output_bai.bai\"\n# output_format: \"bam\"\n# compression: 5\n\n# Arguments\nminimizer_cluster: false\n# minimizer_kmer: 20\nsort_by_read_names: false\n# sort_by: \"foo\"\nno_pg: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/samtools_sort/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Samtools sort"
    ]
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html#argument-groups",
    "href": "components/modules/mapping/samtools_sort.html#argument-groups",
    "title": "Samtools sort",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the SAM/BAM/CRAM files containing the mapped reads.\nfile, required, example: \"input.bam\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_bam\nFilename to output the counts to.\nfile, required, example: \"output.bam\"\n\n\n--output_bai\nBAI-format index for BAM file.\nfile, example: \"output.bam.bai\"\n\n\n--output_format\nThe output format. By default, samtools tries to select a format based on the -o filename extension; if output is to standard output or no format can be deduced, bam is selected.\nstring, example: \"bam\"\n\n\n--compression\nCompression level, from 0 (uncompressed) to 9 (best\ninteger, example: 5\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--minimizer_cluster\nSort unmapped reads (those in chromosome “*“) by their sequence minimiser (Schleimer et al., 2003; Roberts et al., 2004), also reverse complementing as appropriate. This has the effect of collating some similar data together, improving the compressibility of the unmapped sequence. The minimiser kmer size is adjusted using the -K option. Note data compressed in this manner may need to be name collated prior to conversion back to fastq. Mapped sequences are sorted by chromosome and position.\nboolean_true\n\n\n--minimizer_kmer\nSets the kmer size to be used in the -M option.\ninteger, example: 20\n\n\n--sort_by_read_names\nSort by read names (i.e., the QNAME field) rather than by chromosomal coordinates.\nboolean_true\n\n\n--sort_by\nSort first by this value in the alignment tag, then by position or name (if also using -n).\nstring\n\n\n--no_pg\nDo not add a @PG line to the header of the output file.\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Samtools sort"
    ]
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html#authors",
    "href": "components/modules/mapping/samtools_sort.html#authors",
    "title": "Samtools sort",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Samtools sort"
    ]
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html",
    "href": "components/modules/mapping/htseq_count.html",
    "title": "Htseq count",
    "section": "",
    "text": "ID: htseq_count\nNamespace: mapping\n\n\n\nSource\nThis script takes one or more alignment files in SAM/BAM format and a feature file in GFF format and calculates for each feature the number of reads mapping to it.\nSee http://htseq.readthedocs.io/en/master/count.html for details.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Htseq count"
    ]
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html#example-commands",
    "href": "components/modules/mapping/htseq_count.html#example-commands",
    "title": "Htseq count",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/htseq_count/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\ninput: # please fill in - example: [\"mysample1.BAM\", \"mysample2.BAM\"]\nreference: # please fill in - example: \"reference.gtf\"\n\n# Output\n# output: \"$id.$key.output.tsv\"\n# output_delimiter: \"   \"\n# output_sam: [\"$id.$key.output_sam_*.BAM\"]\n# output_sam_format: \"foo\"\n\n# Arguments\norder: \"name\"\nstranded: \"yes\"\nminimum_alignment_quality: 10\n# type: \"exon\"\n# id_attribute: [\"gene_id\"]\n# additional_attributes: [\"gene_name\"]\nadd_chromosome_info: false\nmode: \"union\"\nnon_unique: \"none\"\n# secondary_alignments: \"foo\"\n# supplementary_alignments: \"foo\"\ncounts_output_sparse: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/htseq_count/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Htseq count"
    ]
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html#argument-groups",
    "href": "components/modules/mapping/htseq_count.html#argument-groups",
    "title": "Htseq count",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the SAM/BAM files containing the mapped reads.\nList of file, required, example: \"mysample1.BAM\", \"mysample2.BAM\", multiple_sep: \";\"\n\n\n--reference\nPath to the GTF file containing the features.\nfile, required, example: \"reference.gtf\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nFilename to output the counts to.\nfile, required, example: \"htseq-count.tsv\"\n\n\n--output_delimiter\nColumn delimiter in output.\nstring, example: \"    \"\n\n\n--output_sam\nWrite out all SAM alignment records into SAM/BAM files (one per input file needed), annotating each line with its feature assignment (as an optional field with tag ‘XF’). See the -p option to use BAM instead of SAM.\nList of file, example: \"mysample1_out.BAM\", \"mysample2_out.BAM\", multiple_sep: \";\"\n\n\n--output_sam_format\nFormat to use with the –output_sam argument.\nstring\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--order\nSorting order of . Paired-end sequencing data must be sorted either by position or by read name, and the sorting order must be specified. Ignored for single-end data.\nstring, default: \"name\"\n\n\n--stranded\nWhether the data is from a strand-specific assay. ‘reverse’ means ‘yes’ with reversed strand interpretation.\nstring, default: \"yes\"\n\n\n--minimum_alignment_quality\nSkip all reads with MAPQ alignment quality lower than the given minimum value. MAPQ is the 5th column of a SAM/BAM file and its usage depends on the software used to map the reads.\ninteger, default: 10\n\n\n--type\nFeature type (3rd column in GTF file) to be used, all features of other type are ignored (default, suitable for Ensembl GTF files: exon)\nstring, example: \"exon\"\n\n\n--id_attribute\nGTF attribute to be used as feature ID (default, suitable for Ensembl GTF files: gene_id). All feature of the right type (see -t option) within the same GTF attribute will be added together. The typical way of using this option is to count all exonic reads from each gene and add the exons but other uses are possible as well. You can call this option multiple times: in that case, the combination of all attributes separated by colons (:) will be used as a unique identifier, e.g. for exons you might use -i gene_id -i exon_number.\nList of string, example: \"gene_id\", multiple_sep: \";\"\n\n\n--additional_attributes\nAdditional feature attributes (suitable for Ensembl GTF files: gene_name). Use multiple times for more than one additional attribute. These attributes are only used as annotations in the output, while the determination of how the counts are added together is done based on option -i.\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--add_chromosome_info\nStore information about the chromosome of each feature as an additional attribute (e.g. colunm in the TSV output file).\nboolean_true\n\n\n--mode\nMode to handle reads overlapping more than one feature.\nstring, default: \"union\"\n\n\n--non_unique\nWhether and how to score reads that are not uniquely aligned or ambiguously assigned to features.\nstring, default: \"none\"\n\n\n--secondary_alignments\nWhether to score secondary alignments (0x100 flag).\nstring\n\n\n--supplementary_alignments\nWhether to score supplementary alignments (0x800 flag).\nstring\n\n\n--counts_output_sparse\nStore the counts as a sparse matrix (mtx, h5ad, loom).\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Htseq count"
    ]
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html#authors",
    "href": "components/modules/mapping/htseq_count.html#authors",
    "title": "Htseq count",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Htseq count"
    ]
  },
  {
    "objectID": "components/modules/dimred/lsi.html",
    "href": "components/modules/dimred/lsi.html",
    "title": "Lsi",
    "section": "",
    "text": "ID: lsi\nNamespace: dimred\n\n\n\nSource\nComputes cell embeddings, feature loadings and singular values. Uses the implementation of scipy",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Lsi"
    ]
  },
  {
    "objectID": "components/modules/dimred/lsi.html#example-commands",
    "href": "components/modules/dimred/lsi.html#example-commands",
    "title": "Lsi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/dimred/lsi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"atac\"\n# layer: \"foo\"\n# var_input: \"foo\"\n\n# LSI options\nnum_components: 50\nscale_embeddings: true\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\noutput_compression: \"gzip\"\nobsm_output: \"X_lsi\"\nvarm_output: \"lsi\"\nuns_output: \"lsi\"\noverwrite: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dimred/lsi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Lsi"
    ]
  },
  {
    "objectID": "components/modules/dimred/lsi.html#argument-groups",
    "href": "components/modules/dimred/lsi.html#argument-groups",
    "title": "Lsi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to input h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nOn which modality to run LSI on.\nstring, default: \"atac\"\n\n\n--layer\nUse specified layer for expression values. If not specified, uses adata.X.\nstring\n\n\n--var_input\nColumn name in .var matrix that will be used to select which genes to run the LSI on. If not specified, uses all features.\nstring\n\n\n\n\n\nLSI options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--num_components\nNumber of components to compute.\ninteger, default: 50\n\n\n--scale_embeddings\nScale embeddings to zero mean and unit variance.\nboolean, default: TRUE\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, default: \"gzip\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting embedding.\nstring, default: \"X_lsi\"\n\n\n--varm_output\nIn which .varm slot to store the resulting loadings matrix.\nstring, default: \"lsi\"\n\n\n--uns_output\nIn which .uns slot to store the stdev.\nstring, default: \"lsi\"\n\n\n--overwrite\nAllow overwriting .obsm, .varm and .uns slots.\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Lsi"
    ]
  },
  {
    "objectID": "components/modules/dimred/lsi.html#authors",
    "href": "components/modules/dimred/lsi.html#authors",
    "title": "Lsi",
    "section": "Authors",
    "text": "Authors\n\nSarah Ouologuem   (contributor)\nVladimir Shitov    (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Lsi"
    ]
  },
  {
    "objectID": "components/modules/dimred/pca.html",
    "href": "components/modules/dimred/pca.html",
    "title": "Pca",
    "section": "",
    "text": "ID: pca\nNamespace: dimred\n\n\n\nSource\nUses the implementation of scikit-learn [Pedregosa11]",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Pca"
    ]
  },
  {
    "objectID": "components/modules/dimred/pca.html#example-commands",
    "href": "components/modules/dimred/pca.html#example-commands",
    "title": "Pca",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/dimred/pca/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n# var_input: \"filter_with_hvg\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_output: \"X_pca\"\nvarm_output: \"pca_loadings\"\nuns_output: \"pca_variance\"\n# num_components: 25\noverwrite: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dimred/pca/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Pca"
    ]
  },
  {
    "objectID": "components/modules/dimred/pca.html#argument-group",
    "href": "components/modules/dimred/pca.html#argument-group",
    "title": "Pca",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nUse specified layer for expression values instead of the .X object from the modality.\nstring\n\n\n--var_input\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring, example: \"filter_with_hvg\"\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting embedding.\nstring, default: \"X_pca\"\n\n\n--varm_output\nIn which .varm slot to store the resulting loadings matrix.\nstring, default: \"pca_loadings\"\n\n\n--uns_output\nIn which .uns slot to store the resulting variance objects.\nstring, default: \"pca_variance\"\n\n\n--num_components\nNumber of principal components to compute. Defaults to 50, or 1 - minimum dimension size of selected representation.\ninteger, example: 25\n\n\n--overwrite\nAllow overwriting .obsm, .varm and .uns slots.\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Pca"
    ]
  },
  {
    "objectID": "components/modules/dimred/pca.html#authors",
    "href": "components/modules/dimred/pca.html#authors",
    "title": "Pca",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Pca"
    ]
  },
  {
    "objectID": "components/modules/dimred/tsne.html",
    "href": "components/modules/dimred/tsne.html",
    "title": "Tsne",
    "section": "",
    "text": "ID: tsne\nNamespace: dimred\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Tsne"
    ]
  },
  {
    "objectID": "components/modules/dimred/tsne.html#example-commands",
    "href": "components/modules/dimred/tsne.html#example-commands",
    "title": "Tsne",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/dimred/tsne/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: # please fill in - example: \"rna\"\nuse_rep: # please fill in - example: \"X_pca\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_output: \"X_tsne\"\n\n# Arguments\nn_pcs: 50\nperplexity: 30.0\nmin_dist: 0.5\nmetric: \"euclidean\"\nearly_exaggeration: 12.0\nlearning_rate: 1000.0\nrandom_state: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dimred/tsne/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Tsne"
    ]
  },
  {
    "objectID": "components/modules/dimred/tsne.html#argument-groups",
    "href": "components/modules/dimred/tsne.html#argument-groups",
    "title": "Tsne",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, required, default: \"rna\"\n\n\n--use_rep\nThe .obsm slot to use as input for the tSNE computation.\nstring, required, example: \"X_pca\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nThe .obsm key to use for storing the tSNE results.\nstring, default: \"X_tsne\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_pcs\nThe number of principal components to use for the tSNE computation.\ninteger, default: 50\n\n\n--perplexity\nThe perplexity is related to the number of nearest neighbors that is used in other manifold learning algorithms. Larger datasets usually require a larger perplexity. Consider selecting a value between 5 and 50. Different values can result in significantly different results.\ndouble, default: 30\n\n\n--min_dist\nThe effective minimum distance between embedded points. Smaller values will result in a more clustered/clumped embedding where nearby points on the manifold are drawn closer together, while larger values will result on a more even dispersal of points. The value should be set relative to the spread value, which determines the scale at which embedded points will be spread out.\ndouble, default: 0.5\n\n\n--metric\nDistance metric to calculate neighbors on.\nstring, default: \"euclidean\"\n\n\n--early_exaggeration\nControls how tight natural clusters in the original space are in the embedded space and how much space will be between them. For larger values, the space between natural clusters will be larger in the embedded space. Again, the choice of this parameter is not very critical. If the cost function increases during initial optimization, the early exaggeration factor or the learning rate might be too high.\ndouble, default: 12\n\n\n--learning_rate\nThe learning rate for t-SNE optimization. Typical values range between 10.0 and 1000.0.\ndouble, default: 1000\n\n\n--random_state\nThe random seed to use for the tSNE computation.\ninteger, default: 0",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Tsne"
    ]
  },
  {
    "objectID": "components/modules/dimred/tsne.html#authors",
    "href": "components/modules/dimred/tsne.html#authors",
    "title": "Tsne",
    "section": "Authors",
    "text": "Authors\n\nJakub Majercik   (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Tsne"
    ]
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html",
    "href": "components/modules/qc/calculate_qc_metrics.html",
    "title": "Calculate qc metrics",
    "section": "",
    "text": "ID: calculate_qc_metrics\nNamespace: qc\n\n\n\nSource\nThe metrics are comparable to what scanpy.pp.calculate_qc_metrics output, although they have slightly different names:\nVar metrics (name in this component -&gt; name in scanpy): - pct_dropout -&gt; pct_dropout_by_{expr_type} - num_nonzero_obs -&gt; n_cells_by_{expr_type} - obs_mean -&gt; mean_{expr_type} - total_counts -&gt; total_{expr_type}\nObs metrics: - num_nonzero_vars -&gt; n_genes_by_{expr_type} - pct_{var_qc_metrics} -&gt; pct_{expr_type}{qc_var} - total_counts{var_qc_metrics} -&gt; total_{expr_type}{qc_var} - pct_of_counts_in_top{top_n_vars}vars -&gt; pct{expr_type}in_top{n}{var_type} - total_counts -&gt; total{expr_type}",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Calculate qc metrics"
    ]
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html#example-commands",
    "href": "components/modules/qc/calculate_qc_metrics.html#example-commands",
    "title": "Calculate qc metrics",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/qc/calculate_qc_metrics/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\n\n# Metrics added to .obs\n# var_qc_metrics: [\"ercc,highly_variable,mitochondrial\"]\n# var_qc_metrics_fill_na_value: true\n# top_n_vars: [123]\noutput_obs_num_nonzero_vars: \"num_nonzero_vars\"\noutput_obs_total_counts_vars: \"total_counts\"\n\n# Metrics added to .var\noutput_var_num_nonzero_obs: \"num_nonzero_obs\"\noutput_var_total_counts_obs: \"total_counts\"\noutput_var_obs_mean: \"obs_mean\"\noutput_var_pct_dropout: \"pct_dropout\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/qc/calculate_qc_metrics/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Calculate qc metrics"
    ]
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html#argument-groups",
    "href": "components/modules/qc/calculate_qc_metrics.html#argument-groups",
    "title": "Calculate qc metrics",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\n\nstring, example: \"raw_counts\"\n\n\n\n\n\nMetrics added to .obs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes.\nList of string, example: \"ercc,highly_variable,mitochondrial\", multiple_sep: \";\"\n\n\n--var_qc_metrics_fill_na_value\nFill any ‘NA’ values found in the columns specified with –var_qc_metrics to ‘True’ or ‘False’. as False.\nboolean\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20;50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, multiple_sep: \";\"\n\n\n--output_obs_num_nonzero_vars\nName of column in .obs describing, for each observation, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each row the number of columns that contain data.\nstring, default: \"num_nonzero_vars\"\n\n\n--output_obs_total_counts_vars\nName of the column for .obs describing, for each observation (row), the sum of the stored values in the columns.\nstring, default: \"total_counts\"\n\n\n\n\n\nMetrics added to .var\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_var_num_nonzero_obs\nName of column describing, for each feature, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each column the number of rows that contain data.\nstring, default: \"num_nonzero_obs\"\n\n\n--output_var_total_counts_obs\nName of the column in .var describing, for each feature (column), the sum of the stored values in the rows.\nstring, default: \"total_counts\"\n\n\n--output_var_obs_mean\nName of the column in .obs providing the mean of the values in each row.\nstring, default: \"obs_mean\"\n\n\n--output_var_pct_dropout\nName of the column in .obs providing for each feature the percentage of observations the feature does not appear on (i.e. is missing). Same as --num_nonzero_obs but percentage based.\nstring, default: \"pct_dropout\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Calculate qc metrics"
    ]
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html#authors",
    "href": "components/modules/qc/calculate_qc_metrics.html#authors",
    "title": "Calculate qc metrics",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Calculate qc metrics"
    ]
  },
  {
    "objectID": "components/modules/qc/fastqc.html",
    "href": "components/modules/qc/fastqc.html",
    "title": "Fastqc",
    "section": "",
    "text": "ID: fastqc\nNamespace: qc\n\n\n\nSource\nThis component can take one or more files (by means of shell globbing) or a complete directory",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Fastqc"
    ]
  },
  {
    "objectID": "components/modules/qc/fastqc.html#example-commands",
    "href": "components/modules/qc/fastqc.html#example-commands",
    "title": "Fastqc",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/qc/fastqc/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nmode: \"files\"\ninput: # please fill in - example: \"fastq_dir\"\n# output: \"$id.$key.output\"\n# threads: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/qc/fastqc/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Fastqc"
    ]
  },
  {
    "objectID": "components/modules/qc/fastqc.html#argument-group",
    "href": "components/modules/qc/fastqc.html#argument-group",
    "title": "Fastqc",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--mode\nThe mode in which the component works. Can be either files or dir.\nstring, default: \"files\"\n\n\n--input\nDirectory containing input fastq files.\nfile, required, example: \"fastq_dir\"\n\n\n--output\nOutput directory to write reports to.\nfile, required, example: \"qc\"\n\n\n--threads\nSpecifies the number of files which can be processed simultaneously. Each thread will be allocated 250MB of memory.\ninteger",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Fastqc"
    ]
  },
  {
    "objectID": "components/modules/files/make_params.html",
    "href": "components/modules/files/make_params.html",
    "title": "Make params",
    "section": "",
    "text": "ID: make_params\nNamespace: files\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Files",
      "Make params"
    ]
  },
  {
    "objectID": "components/modules/files/make_params.html#example-commands",
    "href": "components/modules/files/make_params.html#example-commands",
    "title": "Make params",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/files/make_params/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nbase_dir: # please fill in - example: \"/path/to/dir\"\npattern: # please fill in - example: \"*.fastq.gz\"\nn_dirname_drop: 0\nn_basename_id: 0\nid_name: \"id\"\npath_name: \"path\"\n# group_name: \"param_list\"\n# output: \"$id.$key.output.yaml\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/files/make_params/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Files",
      "Make params"
    ]
  },
  {
    "objectID": "components/modules/files/make_params.html#argument-group",
    "href": "components/modules/files/make_params.html#argument-group",
    "title": "Make params",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--base_dir\nBase directory to search recursively\nfile, required, example: \"/path/to/dir\"\n\n\n--pattern\nAn optional regular expression. Only file names which match the regular expression will be matched.\nstring, required, example: \"*.fastq.gz\"\n\n\n--n_dirname_drop\nFor every matched file, the parent directory will be traversed N times.\ninteger, default: 0\n\n\n--n_basename_id\nThe unique identifiers will consist of at least N dirnames.\ninteger, default: 0\n\n\n--id_name\nThe name for storing the identifier field in the yaml.\nstring, default: \"id\"\n\n\n--path_name\nThe name for storing the path field in the yaml.\nstring, default: \"path\"\n\n\n--group_name\nTop level name for the group of entries.\nstring, example: \"param_list\"\n\n\n--output\nOutput YAML file.\nfile, required, example: \"params.yaml\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Files",
      "Make params"
    ]
  },
  {
    "objectID": "components/modules/files/make_params.html#authors",
    "href": "components/modules/files/make_params.html#authors",
    "title": "Make params",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (maintainer, author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Files",
      "Make params"
    ]
  },
  {
    "objectID": "components/modules/scgpt/cross_check_genes.html",
    "href": "components/modules/scgpt/cross_check_genes.html",
    "title": "Cross check genes",
    "section": "",
    "text": "ID: cross_check_genes\nNamespace: scgpt\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Cross check genes"
    ]
  },
  {
    "objectID": "components/modules/scgpt/cross_check_genes.html#example-commands",
    "href": "components/modules/scgpt/cross_check_genes.html#example-commands",
    "title": "Cross check genes",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/scgpt/cross_check_genes/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nvocab_file: # please fill in - example: \"resources_test/scgpt/vocab.json\"\n# input_var_gene_names: \"gene_name\"\n# var_input: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_var_filter: \"id_in_vocab\"\n\n# Arguments\npad_token: \"&lt;pad&gt;\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/scgpt/cross_check_genes/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Cross check genes"
    ]
  },
  {
    "objectID": "components/modules/scgpt/cross_check_genes.html#argument-groups",
    "href": "components/modules/scgpt/cross_check_genes.html#argument-groups",
    "title": "Cross check genes",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe input h5mu file containing of pre-processed data.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nThe modality key of the MuData object containing the RNA AnnData object.\nstring, default: \"rna\"\n\n\n--vocab_file\nModel vocabulary file path.\nfile, required, example: \"resources_test/scgpt/vocab.json\"\n\n\n--input_var_gene_names\nThe name of the adata.var column containing gene names. By default the .var index will be used.\nstring, example: \"gene_name\"\n\n\n--var_input\n.var column containing highly variable genes. If provided, will only cross-check HVG filtered genes with model vocabulary.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe output cross-checked anndata file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--output_var_filter\nIn which .var slot to store a boolean array corresponding to which observations should be filtered out based on HVG and model vocabulary.\nstring, default: \"id_in_vocab\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pad_token\nThe padding token used in the model.\nstring, default: \"&lt;pad&gt;\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Cross check genes"
    ]
  },
  {
    "objectID": "components/modules/scgpt/cross_check_genes.html#authors",
    "href": "components/modules/scgpt/cross_check_genes.html#authors",
    "title": "Cross check genes",
    "section": "Authors",
    "text": "Authors\n\nJakub Majercik   (author)\nDorien Roosen   (maintainer, author)\nElizabeth Mlynarski (author)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Cross check genes"
    ]
  },
  {
    "objectID": "components/modules/scgpt/embedding.html",
    "href": "components/modules/scgpt/embedding.html",
    "title": "Embedding",
    "section": "",
    "text": "ID: embedding\nNamespace: scgpt\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Embedding"
    ]
  },
  {
    "objectID": "components/modules/scgpt/embedding.html#example-commands",
    "href": "components/modules/scgpt/embedding.html#example-commands",
    "title": "Embedding",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/scgpt/embedding/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nmodel: # please fill in - example: \"best_model.pt\"\nmodel_vocab: # please fill in - example: \"vocab.json\"\nmodel_config: # please fill in - example: \"args.json\"\nobsm_gene_tokens: \"gene_id_tokens\"\nobsm_tokenized_values: \"values_tokenized\"\nobsm_padding_mask: \"padding_mask\"\n# var_gene_names: \"foo\"\n# obs_batch_label: \"foo\"\n# finetuned_checkpoints_key: \"model_state_dict\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_embeddings: \"X_scGPT\"\n\n# Arguments\npad_token: \"&lt;pad&gt;\"\npad_value: -2\ndsbn: true\nbatch_size: 64\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/scgpt/embedding/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Embedding"
    ]
  },
  {
    "objectID": "components/modules/scgpt/embedding.html#argument-groups",
    "href": "components/modules/scgpt/embedding.html#argument-groups",
    "title": "Embedding",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe input h5mu file containing tokenized gene and count data.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--model\nPath to scGPT model file.\nfile, required, example: \"best_model.pt\"\n\n\n--model_vocab\nPath to scGPT model vocabulary file.\nfile, required, example: \"vocab.json\"\n\n\n--model_config\nPath to scGPT model config file.\nfile, required, example: \"args.json\"\n\n\n--obsm_gene_tokens\nThe key of the .obsm array containing the gene token ids\nstring, default: \"gene_id_tokens\", example: \"values.pt\"\n\n\n--obsm_tokenized_values\nThe key of the .obsm array containing the count values of the tokenized genes\nstring, default: \"values_tokenized\"\n\n\n--obsm_padding_mask\nThe key of the .obsm array containing the padding mask.\nstring, default: \"padding_mask\"\n\n\n--var_gene_names\nThe name of the .var column containing gene names. When no gene_name_layer is provided, the .var index will be used.\nstring\n\n\n--obs_batch_label\nThe name of the adata.obs column containing the batch labels. Must be provided when ‘dsbn’ is set to True.\nstring\n\n\n--finetuned_checkpoints_key\nKey in the model file containing the pretrained checkpoints. Only relevant for fine-tuned models.\nstring, example: \"model_state_dict\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nPath to output anndata file containing pre-processed data as well as scGPT embeddings.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression algorithm to use for the output h5mu file.\nstring, example: \"gzip\"\n\n\n--obsm_embeddings\nThe name of the adata.obsm array to which scGPT embeddings will be written.\nstring, default: \"X_scGPT\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pad_token\nThe token to be used for padding.\nstring, default: \"&lt;pad&gt;\"\n\n\n--pad_value\nThe value of the padding token.\ninteger, default: -2\n\n\n--dsbn\nWhether to apply domain-specific batch normalization for generating embeddings. When set to True, ‘obs_batch_labels’ must be set as well.\nboolean, default: TRUE\n\n\n--batch_size\nThe batch size to be used for inference\ninteger, default: 64",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Embedding"
    ]
  },
  {
    "objectID": "components/modules/scgpt/embedding.html#authors",
    "href": "components/modules/scgpt/embedding.html#authors",
    "title": "Embedding",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (maintainer, author)\nElizabeth Mlynarski (author)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Embedding"
    ]
  },
  {
    "objectID": "components/modules/interpret/lianapy.html",
    "href": "components/modules/interpret/lianapy.html",
    "title": "Lianapy",
    "section": "",
    "text": "ID: lianapy\nNamespace: interpret\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Interpret",
      "Lianapy"
    ]
  },
  {
    "objectID": "components/modules/interpret/lianapy.html#example-commands",
    "href": "components/modules/interpret/lianapy.html#example-commands",
    "title": "Lianapy",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/interpret/lianapy/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output\"\noutput_compression: \"gzip\"\nmodality: \"rna\"\n# layer: \"foo\"\ngroupby: # please fill in - example: \"foo\"\nresource_name: \"consensus\"\ngene_symbol: \"gene_symbol\"\nexpr_prop: 0.1\nmin_cells: 5\naggregate_method: \"rra\"\nreturn_all_lrs: false\nn_perms: 100\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/interpret/lianapy/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Interpret",
      "Lianapy"
    ]
  },
  {
    "objectID": "components/modules/interpret/lianapy.html#argument-group",
    "href": "components/modules/interpret/lianapy.html#argument-group",
    "title": "Lianapy",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_compression\n\nstring, default: \"gzip\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nLayer in anndata.AnnData.layers to use. If None, use mudata.mod[modality].X.\nstring\n\n\n--groupby\nThe key of the observations grouping to consider.\nstring, required\n\n\n--resource_name\nName of the resource to be loaded and use for ligand-receptor inference.\nstring, default: \"consensus\"\n\n\n--gene_symbol\nColumn name in var DataFrame in which gene symbol are stored.\nstring, default: \"gene_symbol\"\n\n\n--expr_prop\nMinimum expression proportion for the ligands/receptors (and their subunits) in the corresponding cell identities. Set to ‘0’, to return unfiltered results.\ndouble, default: 0.1\n\n\n--min_cells\nMinimum cells per cell identity (‘groupby’) to be considered for downstream analysis.\ninteger, default: 5\n\n\n--aggregate_method\nMethod aggregation approach, one of [‘mean’, ‘rra’], where ‘mean’ represents the mean rank, while ‘rra’ is the RobustRankAggregate (Kolde et al., 2014) of the interactions.\nstring, default: \"rra\"\n\n\n--return_all_lrs\nBool whether to return all LRs, or only those that surpass the ‘expr_prop’ threshold. Those interactions that do not pass the ‘expr_prop’ threshold will be assigned to the worst score of the ones that do. ‘False’ by default.\nboolean, default: FALSE\n\n\n--n_perms\nNumber of permutations for the permutation test. Note that this is relevant only for permutation-based methods - e.g. ’CellPhoneDB\ninteger, default: 100",
    "crumbs": [
      "Reference",
      "Modules",
      "Interpret",
      "Lianapy"
    ]
  },
  {
    "objectID": "components/modules/interpret/lianapy.html#authors",
    "href": "components/modules/interpret/lianapy.html#authors",
    "title": "Lianapy",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Interpret",
      "Lianapy"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html",
    "title": "From h5mu to h5ad",
    "section": "",
    "text": "ID: from_h5mu_to_h5ad\nNamespace: convert\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5mu to h5ad"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html#example-commands",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html#example-commands",
    "title": "From h5mu to h5ad",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/convert/from_h5mu_to_h5ad/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# output: \"output.h5ad\"\noutput_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_h5mu_to_h5ad/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5mu to h5ad"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html#argument-group",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html#argument-group",
    "title": "From h5mu to h5ad",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput MuData file\nfile, required, default: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--output\nOutput AnnData file.\nfile, default: \"output.h5ad\"\n\n\n--output_compression\nThe compression format to be used on the final h5ad object.\nstring, default: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5mu to h5ad"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html#authors",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html#authors",
    "title": "From h5mu to h5ad",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5mu to h5ad"
    ]
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html",
    "title": "From cellranger multi to h5mu",
    "section": "",
    "text": "ID: from_cellranger_multi_to_h5mu\nNamespace: convert\n\n\n\nSource\nBy default, will map the following library type names to modality names: - Gene Expression: rna - Peaks: atac - Antibody Capture: prot - VDJ: vdj - VDJ-T: vdj_t - VDJ-B: vdj_b - CRISPR Guide Capture: crispr - Multiplexing Capture: hashing\nOther library types have their whitepace removed and dashes replaced by underscores to generate the modality name.\nCurrently does not allow parsing the output from cell barcode demultiplexing.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From cellranger multi to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html#example-commands",
    "title": "From cellranger multi to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/convert/from_cellranger_multi_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input_dir_containing_modalities\"\n# output: [\"$id.$key.output_*.h5mu\"]\n# sample_csv: \"$id.$key.sample_csv.csv\"\n# output_compression: \"gzip\"\nuns_metrics: \"metrics_cellranger\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_cellranger_multi_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From cellranger multi to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html#argument-group",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html#argument-group",
    "title": "From cellranger multi to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput folder. Must contain the output from a cellranger multi run.\nfile, required, example: \"input_dir_containing_modalities\"\n\n\n--output\nLocations for the output files. Must contain a wildcard (*) character, which will be replaced with the sample name.\nList of file, example: \"*.h5mu\", multiple_sep: \";\"\n\n\n--sample_csv\nCSV file describing the sample name per output file\nfile, example: \"samples.csv\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_cellranger\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From cellranger multi to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html#authors",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html#authors",
    "title": "From cellranger multi to h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From cellranger multi to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html",
    "title": "From h5ad to h5mu",
    "section": "",
    "text": "ID: from_h5ad_to_h5mu\nNamespace: convert\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5ad to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html#example-commands",
    "title": "From h5ad to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/convert/from_h5ad_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"input.h5ad\"]\nmodality: [\"rna\"]\n# output: \"output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_h5ad_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5ad to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html#argument-group",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html#argument-group",
    "title": "From h5ad to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5ad files\nList of file, required, default: \"input.h5ad\", multiple_sep: \";\"\n\n\n--modality\n\nList of string, default: \"rna\", multiple_sep: \";\"\n\n\n--output\nOutput MuData file.\nfile, default: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5ad to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html#authors",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html#authors",
    "title": "From h5ad to h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5ad to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_seurat.html",
    "href": "components/modules/convert/from_h5mu_to_seurat.html",
    "title": "From h5mu to seurat",
    "section": "",
    "text": "ID: from_h5mu_to_seurat\nNamespace: convert\n\n\n\nSource\nRestrictions: - Only the intersection of cells is currently loaded into the Seurat object due to the object structure limitation. - Multimodal embeddings (global .obsm slot) are loaded with the assay.used field set to the default assay. - Embeddings names are changed in order to comply with R & Seurat requirements and conventions. - Feature names with underscores (’_‘) are automatically replaced with dashes (’-’) - Seurat does not support global variables metadata /var.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5mu to seurat"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_seurat.html#example-commands",
    "href": "components/modules/convert/from_h5mu_to_seurat.html#example-commands",
    "title": "From h5mu to seurat",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/convert/from_h5mu_to_seurat/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\n# output: \"$id.$key.output.rds\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_h5mu_to_seurat/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5mu to seurat"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_seurat.html#argument-group",
    "href": "components/modules/convert/from_h5mu_to_seurat.html#argument-group",
    "title": "From h5mu to seurat",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--output\nOutput Seurat file\nfile, required, example: \"output.rds\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5mu to seurat"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_seurat.html#authors",
    "href": "components/modules/convert/from_h5mu_to_seurat.html#authors",
    "title": "From h5mu to seurat",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5mu to seurat"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_seurat.html",
    "href": "components/modules/convert/from_h5ad_to_seurat.html",
    "title": "From h5ad to seurat",
    "section": "",
    "text": "ID: from_h5ad_to_seurat\nNamespace: convert\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5ad to seurat"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_seurat.html#example-commands",
    "href": "components/modules/convert/from_h5ad_to_seurat.html#example-commands",
    "title": "From h5ad to seurat",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/convert/from_h5ad_to_seurat/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5ad\"\nassay: \"RNA\"\n# output: \"$id.$key.output.rds\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_h5ad_to_seurat/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5ad to seurat"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_seurat.html#argument-group",
    "href": "components/modules/convert/from_h5ad_to_seurat.html#argument-group",
    "title": "From h5ad to seurat",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5ad file\nfile, required, example: \"input.h5ad\"\n\n\n--assay\nName of the assay to be created.\nstring, default: \"RNA\"\n\n\n--output\nOutput Seurat file\nfile, required, example: \"output.rds\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5ad to seurat"
    ]
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_seurat.html#authors",
    "href": "components/modules/convert/from_h5ad_to_seurat.html#authors",
    "title": "From h5ad to seurat",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From h5ad to seurat"
    ]
  },
  {
    "objectID": "components/modules/metadata/add_id.html",
    "href": "components/modules/metadata/add_id.html",
    "title": "Add id",
    "section": "",
    "text": "ID: add_id\nNamespace: metadata\n\n\n\nSource\nAlso allows to make .obs_names (the .obs index) unique by prefixing the values with an unique id per .h5mu file",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Add id"
    ]
  },
  {
    "objectID": "components/modules/metadata/add_id.html#example-commands",
    "href": "components/modules/metadata/add_id.html#example-commands",
    "title": "Add id",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/metadata/add_id/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"sample_path\"\ninput_id: # please fill in - example: \"foo\"\nobs_output: \"sample_id\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nmake_observation_keys_unique: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/add_id/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Add id"
    ]
  },
  {
    "objectID": "components/modules/metadata/add_id.html#argument-group",
    "href": "components/modules/metadata/add_id.html#argument-group",
    "title": "Add id",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the input .h5mu.\nfile, required, example: \"sample_path\"\n\n\n--input_id\nThe input id.\nstring, required\n\n\n--obs_output\nName of the .obs column where to store the id.\nstring, default: \"sample_id\"\n\n\n--output\n\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--make_observation_keys_unique\nJoin the id to the .obs index (.obs_names).\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Add id"
    ]
  },
  {
    "objectID": "components/modules/metadata/add_id.html#authors",
    "href": "components/modules/metadata/add_id.html#authors",
    "title": "Add id",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Add id"
    ]
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html",
    "href": "components/modules/metadata/move_obsm_to_obs.html",
    "title": "Move obsm to obs",
    "section": "",
    "text": "ID: move_obsm_to_obs\nNamespace: metadata\n\n\n\nSource\nNewly created columns in .obs will be created from the .obsm key suffixed with an underscore and the name of the columns of the specified .obsm matrix",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Move obsm to obs"
    ]
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html#example-commands",
    "href": "components/modules/metadata/move_obsm_to_obs.html#example-commands",
    "title": "Move obsm to obs",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/metadata/move_obsm_to_obs/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# MuData Input\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nobsm_key: # please fill in - example: \"foo\"\n\n# MuData Output\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/move_obsm_to_obs/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Move obsm to obs"
    ]
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html#argument-groups",
    "href": "components/modules/metadata/move_obsm_to_obs.html#argument-groups",
    "title": "Move obsm to obs",
    "section": "Argument groups",
    "text": "Argument groups\n\nMuData Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_key\nKey of a data structure to move from .obsm to .obs.\nstring, required\n\n\n\n\n\nMuData Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Move obsm to obs"
    ]
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html#authors",
    "href": "components/modules/metadata/move_obsm_to_obs.html#authors",
    "title": "Move obsm to obs",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Move obsm to obs"
    ]
  },
  {
    "objectID": "components/modules/metadata/join_uns_to_obs.html",
    "href": "components/modules/metadata/join_uns_to_obs.html",
    "title": "Join uns to obs",
    "section": "",
    "text": "ID: join_uns_to_obs\nNamespace: metadata\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Join uns to obs"
    ]
  },
  {
    "objectID": "components/modules/metadata/join_uns_to_obs.html#example-commands",
    "href": "components/modules/metadata/join_uns_to_obs.html#example-commands",
    "title": "Join uns to obs",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/metadata/join_uns_to_obs/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nuns_key: # please fill in - example: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/join_uns_to_obs/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Join uns to obs"
    ]
  },
  {
    "objectID": "components/modules/metadata/join_uns_to_obs.html#argument-group",
    "href": "components/modules/metadata/join_uns_to_obs.html#argument-group",
    "title": "Join uns to obs",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--uns_key\n\nstring, required\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Join uns to obs"
    ]
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html",
    "href": "components/modules/reference/build_bdrhap_reference.html",
    "title": "Build bdrhap reference",
    "section": "",
    "text": "ID: build_bdrhap_reference\nNamespace: reference\n\n\n\nSource\nThe app takes as input one or more FASTA and GTF files and produces a compressed archive in the form of a tar.gz file. The archive contains:",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build bdrhap reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html#example-commands",
    "href": "components/modules/reference/build_bdrhap_reference.html#example-commands",
    "title": "Build bdrhap reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/reference/build_bdrhap_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ngenome_fasta: # please fill in - example: [\"genome_sequence.fa.gz\"]\ngtf: # please fill in - example: [\"transcriptome_annotation.gtf.gz\"]\n# extra_sequences: [\"path/to/file\"]\n\n# Outputs\n# reference_archive: \"$id.$key.reference_archive.gz\"\n\n# Arguments\nmitochondrial_contigs: [\"chrM\", \"chrMT\", \"M\", \"MT\"]\nfiltering_off: false\nwta_only_index: false\n# extra_star_params: \"--limitGenomeGenerateRAM 48000 --genomeSAindexNbases 11\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/build_bdrhap_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build bdrhap reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html#argument-groups",
    "href": "components/modules/reference/build_bdrhap_reference.html#argument-groups",
    "title": "Build bdrhap reference",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nReference genome file in FASTA or FASTA.GZ format. The BD Rhapsody Sequencing Analysis Pipeline uses GRCh38 for Human and GRCm39 for Mouse.\nList of file, required, example: \"genome_sequence.fa.gz\", multiple_sep: \";\"\n\n\n--gtf\nFile path to the transcript annotation files in GTF or GTF.GZ format. The Sequence Analysis Pipeline requires the ‘gene_name’ or ‘gene_id’ attribute to be set on each gene and exon feature. Gene and exon feature lines must have the same attribute, and exons must have a corresponding gene with the same value. For TCR/BCR assays, the TCR or BCR gene segments must have the ‘gene_type’ or ‘gene_biotype’ attribute set, and the value should begin with ‘TR’ or ‘IG’, respectively.\nList of file, required, example: \"transcriptome_annotation.gtf.gz\", multiple_sep: \";\"\n\n\n--extra_sequences\nFile path to additional sequences in FASTA format to use when building the STAR index. (e.g. transgenes or CRISPR guide barcodes). GTF lines for these sequences will be automatically generated and combined with the main GTF.\nList of file, multiple_sep: \";\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference_archive\nA Compressed archive containing the Reference Genome Index and annotation GTF files. This archive is meant to be used as an input in the BD Rhapsody Sequencing Analysis Pipeline.\nfile, required, example: \"reference.tar.gz\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--mitochondrial_contigs\nNames of the Mitochondrial contigs in the provided Reference Genome. Fragments originating from contigs other than these are identified as ‘nuclear fragments’ in the ATACseq analysis pipeline.\nList of string, default: \"chrM\", \"chrMT\", \"M\", \"MT\", multiple_sep: \";\"\n\n\n--filtering_off\nBy default the input Transcript Annotation files are filtered based on the gene_type/gene_biotype attribute. Only features having the following attribute values are kept: - protein_coding - lncRNA - IG_LV_gene - IG_V_gene - IG_V_pseudogene - IG_D_gene - IG_J_gene - IG_J_pseudogene - IG_C_gene - IG_C_pseudogene - TR_V_gene - TR_V_pseudogene - TR_D_gene - TR_J_gene - TR_J_pseudogene - TR_C_gene If you have already pre-filtered the input Annotation files and/or wish to turn-off the filtering, please set this option to True.\nboolean_true\n\n\n--wta_only_index\nBuild a WTA only index, otherwise builds a WTA + ATAC index.\nboolean_true\n\n\n--extra_star_params\nAdditional parameters to pass to STAR when building the genome index. Specify exactly like how you would on the command line.\nstring, example: \"--limitGenomeGenerateRAM 48000 --genomeSAindexNbases 11\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build bdrhap reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html#authors",
    "href": "components/modules/reference/build_bdrhap_reference.html#authors",
    "title": "Build bdrhap reference",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build bdrhap reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html",
    "href": "components/modules/reference/build_cellranger_reference.html",
    "title": "Build cellranger reference",
    "section": "",
    "text": "ID: build_cellranger_reference\nNamespace: reference\n\n\n\nSource\nCreates a new folder named after the genome.",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build cellranger reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html#example-commands",
    "href": "components/modules/reference/build_cellranger_reference.html#example-commands",
    "title": "Build cellranger reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/reference/build_cellranger_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ngenome_fasta: # please fill in - example: \"genome_sequence.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"transcriptome_annotation.gtf.gz\"\n# reference_version: \"foo\"\n# output: \"$id.$key.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/build_cellranger_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build cellranger reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html#argument-group",
    "href": "components/modules/reference/build_cellranger_reference.html#argument-group",
    "title": "Build cellranger reference",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nReference genome fasta.\nfile, required, example: \"genome_sequence.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"transcriptome_annotation.gtf.gz\"\n\n\n--reference_version\nOptional reference version string to include with reference\nstring\n\n\n--output\nOutput folder\nfile, required, example: \"cellranger_reference\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build cellranger reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html#authors",
    "href": "components/modules/reference/build_cellranger_reference.html#authors",
    "title": "Build cellranger reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build cellranger reference"
    ]
  },
  {
    "objectID": "components/modules/reference/make_reference.html",
    "href": "components/modules/reference/make_reference.html",
    "title": "Make reference",
    "section": "",
    "text": "ID: make_reference\nNamespace: reference\n\n\n\nSource\nExample input files are: - genome_fasta: https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz - transcriptome_gtf: https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz - ercc: https://assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Make reference"
    ]
  },
  {
    "objectID": "components/modules/reference/make_reference.html#example-commands",
    "href": "components/modules/reference/make_reference.html#example-commands",
    "title": "Make reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/reference/make_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ngenome_fasta: # please fill in - example: \"genome_fasta.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"transcriptome.gtf.gz\"\n# ercc: \"ercc.zip\"\n# subset_regex: \"(ERCC-00002|chr1)\"\n# output_fasta: \"$id.$key.output_fasta.gz\"\n# output_gtf: \"$id.$key.output_gtf.gz\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/make_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Make reference"
    ]
  },
  {
    "objectID": "components/modules/reference/make_reference.html#argument-group",
    "href": "components/modules/reference/make_reference.html#argument-group",
    "title": "Make reference",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nReference genome fasta. Example:\nfile, required, example: \"genome_fasta.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"transcriptome.gtf.gz\"\n\n\n--ercc\nERCC sequence and annotation file.\nfile, example: \"ercc.zip\"\n\n\n--subset_regex\nWill subset the reference chromosomes using the given regex.\nstring, example: \"(ERCC-00002&#124;chr1)\"\n\n\n--output_fasta\nOutput genome sequence fasta.\nfile, required, example: \"genome_sequence.fa.gz\"\n\n\n--output_gtf\nOutput transcriptome annotation gtf.\nfile, required, example: \"transcriptome_annotation.gtf.gz\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Make reference"
    ]
  },
  {
    "objectID": "components/modules/reference/make_reference.html#authors",
    "href": "components/modules/reference/make_reference.html#authors",
    "title": "Make reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Make reference"
    ]
  },
  {
    "objectID": "components/modules/annotate/svm_annotation.html",
    "href": "components/modules/annotate/svm_annotation.html",
    "title": "Svm annotation",
    "section": "",
    "text": "ID: svm_annotation\nNamespace: annotate\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Svm annotation"
    ]
  },
  {
    "objectID": "components/modules/annotate/svm_annotation.html#example-commands",
    "href": "components/modules/annotate/svm_annotation.html#example-commands",
    "title": "Svm annotation",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/annotate/svm_annotation/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# input_var_gene_names: \"foo\"\ninput_reference_gene_overlap: 100\n\n# Reference\n# reference: \"reference.h5mu\"\n# reference_layer: \"foo\"\nreference_obs_target: # please fill in - example: \"foo\"\n# reference_var_gene_names: \"foo\"\n# reference_var_input: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_obs_prediction: \"svm_pred\"\noutput_obs_probability: \"svm_probability\"\n\n# Model arguments\n# model: \"pretrained_model.pkl\"\nfeature_selection: true\nmax_iter: 5000\nc_reg: 1.0\nclass_weight: \"balanced\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/annotate/svm_annotation/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Svm annotation"
    ]
  },
  {
    "objectID": "components/modules/annotate/svm_annotation.html#argument-groups",
    "href": "components/modules/annotate/svm_annotation.html#argument-groups",
    "title": "Svm annotation",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe input (query) data to be labeled. Should be a .h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--input_layer\nThe layer in the input data to be used for cell type annotation if .X is not to be used.\nstring\n\n\n--input_var_gene_names\nThe name of the adata var column in the input data containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--input_reference_gene_overlap\nThe minimum number of genes present in both the reference and query datasets.\ninteger, default: 100\n\n\n\n\n\nReference\nArguments related to the reference dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train the CellTypist classifiers on. Only required if a pre-trained –model is not provided.\nfile, example: \"reference.h5mu\"\n\n\n--reference_layer\nThe layer in the reference data to be used for cell type annotation if .X is not to be used. Data are expected to be processed in the same way as the –input query dataset.\nstring\n\n\n--reference_obs_target\n\nstring, required\n\n\n--reference_var_gene_names\nThe name of the adata var column in the reference data containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--reference_var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--output_obs_prediction\nIn which .obs slots to store the predicted information.\nstring, default: \"svm_pred\"\n\n\n--output_obs_probability\nIn which .obs slots to store the probability of the predictions.\nstring, default: \"svm_probability\"\n\n\n\n\n\nModel arguments\nModel arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--model\nPretrained model in pkl format. If not provided, the model will be trained on the reference data and –reference should be provided.\nfile, example: \"pretrained_model.pkl\"\n\n\n--feature_selection\nWhether to perform feature selection.\nboolean, default: TRUE\n\n\n--max_iter\nMaximum number of iterations for the SVM.\ninteger, default: 5000\n\n\n--c_reg\nRegularization parameter for the SVM.\ndouble, default: 1\n\n\n--class_weight\n“Class weights for the SVM. The uniform mode gives all classes a weight of one. The balanced mode (default) uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))”\nstring, default: \"balanced\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Svm annotation"
    ]
  },
  {
    "objectID": "components/modules/annotate/svm_annotation.html#authors",
    "href": "components/modules/annotate/svm_annotation.html#authors",
    "title": "Svm annotation",
    "section": "Authors",
    "text": "Authors\n\nJakub Majercik   (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Svm annotation"
    ]
  },
  {
    "objectID": "components/modules/annotate/celltypist.html",
    "href": "components/modules/annotate/celltypist.html",
    "title": "Celltypist",
    "section": "",
    "text": "ID: celltypist\nNamespace: annotate\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Celltypist"
    ]
  },
  {
    "objectID": "components/modules/annotate/celltypist.html#example-commands",
    "href": "components/modules/annotate/celltypist.html#example-commands",
    "title": "Celltypist",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/annotate/celltypist/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# input_var_gene_names: \"foo\"\ninput_reference_gene_overlap: 100\n\n# Reference\n# reference: \"reference.h5mu\"\n# reference_layer: \"foo\"\nreference_obs_target: \"cell_ontology_class\"\n# reference_var_gene_names: \"foo\"\n# reference_var_input: \"foo\"\n\n# Model arguments\n# model: \"pretrained_model.pkl\"\nfeature_selection: false\nmajority_voting: false\nC: 1.0\nmax_iter: 1000\nuse_SGD: false\nmin_prop: 0.0\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_obs_predictions: \"celltypist_pred\"\noutput_obs_probability: \"celltypist_probability\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/annotate/celltypist/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Celltypist"
    ]
  },
  {
    "objectID": "components/modules/annotate/celltypist.html#argument-groups",
    "href": "components/modules/annotate/celltypist.html#argument-groups",
    "title": "Celltypist",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe input (query) data to be labeled. Should be a .h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--input_layer\nThe layer in the input data containing log normalized counts to be used for cell type annotation if .X is not to be used.\nstring\n\n\n--input_var_gene_names\nThe name of the adata var column in the input data containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--input_reference_gene_overlap\nThe minimum number of genes present in both the reference and query datasets.\ninteger, default: 100\n\n\n\n\n\nReference\nArguments related to the reference dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train the CellTypist classifiers on. Only required if a pre-trained –model is not provided.\nfile, example: \"reference.h5mu\"\n\n\n--reference_layer\nThe layer in the reference data to be used for cell type annotation if .X is not to be used. Data are expected to be processed in the same way as the –input query dataset.\nstring\n\n\n--reference_obs_target\nThe name of the adata obs column in the reference data containing cell type annotations.\nstring, default: \"cell_ontology_class\"\n\n\n--reference_var_gene_names\nThe name of the adata var column in the reference data containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--reference_var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n\n\n\nModel arguments\nModel arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--model\nPretrained model in pkl format. If not provided, the model will be trained on the reference data and –reference should be provided.\nfile, example: \"pretrained_model.pkl\"\n\n\n--feature_selection\nWhether to perform feature selection.\nboolean, default: FALSE\n\n\n--majority_voting\nWhether to refine the predicted labels by running the majority voting classifier after over-clustering.\nboolean, default: FALSE\n\n\n--C\nInverse of regularization strength in logistic regression.\ndouble, default: 1\n\n\n--max_iter\nMaximum number of iterations before reaching the minimum of the cost function.\ninteger, default: 1000\n\n\n--use_SGD\nWhether to use the stochastic gradient descent algorithm.\nboolean_true\n\n\n--min_prop\n“For the dominant cell type within a subcluster, the minimum proportion of cells required to support naming of the subcluster by this cell type. Ignored if majority_voting is set to False. Subcluster that fails to pass this proportion threshold will be assigned ‘Heterogeneous’.”\ndouble, default: 0\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted information.\nstring, default: \"celltypist_pred\"\n\n\n--output_obs_probability\nIn which .obs slots to store the probability of the predictions.\nstring, default: \"celltypist_probability\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Celltypist"
    ]
  },
  {
    "objectID": "components/modules/annotate/celltypist.html#authors",
    "href": "components/modules/annotate/celltypist.html#authors",
    "title": "Celltypist",
    "section": "Authors",
    "text": "Authors\n\nJakub Majercik   (author)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Celltypist"
    ]
  },
  {
    "objectID": "components/modules/annotate/scanvi.html",
    "href": "components/modules/annotate/scanvi.html",
    "title": "Scanvi",
    "section": "",
    "text": "ID: scanvi\nNamespace: annotate\n\n\n\nSource\nscANVI is an scVI extension that can leverage the cell type knowledge for a subset of the cells present in the data sets to infer the states of the rest of the cells. This component will instantiate a scANVI model from a pre-trained scVI model, integrate the data and perform label prediction",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Scanvi"
    ]
  },
  {
    "objectID": "components/modules/annotate/scanvi.html#example-commands",
    "href": "components/modules/annotate/scanvi.html#example-commands",
    "title": "Scanvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/annotate/scanvi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# var_input: \"foo\"\n# var_gene_names: \"foo\"\nobs_labels: # please fill in - example: \"foo\"\nunlabeled_category: \"Unknown\"\n\n# scVI Model\nscvi_model: # please fill in - example: \"scvi_model.pt\"\n\n# Outputs\n# output: \"$id.$key.output\"\n# output_model: \"$id.$key.output_model\"\n# output_compression: \"gzip\"\nobsm_output: \"X_scanvi_integrated\"\nobs_output_predictions: \"scanvi_pred\"\nobs_output_probabilities: \"scanvi_proba\"\n\n# scANVI training arguments\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30.0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/annotate/scanvi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Scanvi"
    ]
  },
  {
    "objectID": "components/modules/annotate/scanvi.html#argument-groups",
    "href": "components/modules/annotate/scanvi.html#argument-groups",
    "title": "Scanvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file. Note that this needs to be the exact same dataset as the –scvi_model was trained on.\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer to use. If None, X is used\nstring\n\n\n--var_input\n.var column containing highly variable genes that were used to train the scVi model. By default, do not subset genes.\nstring\n\n\n--var_gene_names\n.var column containing gene names. By default, use the index.\nstring\n\n\n--obs_labels\n.obs field containing the labels\nstring, required\n\n\n--unlabeled_category\nValue in the –obs_labels field that indicates unlabeled observations\nstring, default: \"Unknown\"\n\n\n\n\n\nscVI Model\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scvi_model\nPretrained SCVI reference model to initialize the SCANVI model with.\nfile, required, example: \"scvi_model.pt\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scanvi_integrated\"\n\n\n--obs_output_predictions\nIn which .obs slot to store the predicted labels.\nstring, default: \"scanvi_pred\"\n\n\n--obs_output_probabilities\nIn which. obs slot to store the probabilities of the predicted labels.\nstring, default: \"scanvi_proba\"\n\n\n\n\n\nscANVI training arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Scanvi"
    ]
  },
  {
    "objectID": "components/modules/annotate/scanvi.html#authors",
    "href": "components/modules/annotate/scanvi.html#authors",
    "title": "Scanvi",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (maintainer)\nJakub Majercik   (author)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Scanvi"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_h5mu_train_test.html",
    "href": "components/modules/dataflow/split_h5mu_train_test.html",
    "title": "Split h5mu train test",
    "section": "",
    "text": "ID: split_h5mu_train_test\nNamespace: dataflow\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split h5mu train test"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_h5mu_train_test.html#example-commands",
    "href": "components/modules/dataflow/split_h5mu_train_test.html#example-commands",
    "title": "Split h5mu train test",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/dataflow/split_h5mu_train_test/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n\n# Outputs\n# output_train: \"$id.$key.output_train.h5mu\"\n# output_test: \"$id.$key.output_test.h5mu\"\n# output_val: \"$id.$key.output_val.h5mu\"\n# compression: \"gzip\"\n\n# Split arguments\ntest_size: 0.2\n# val_size: 123.0\nshuffle: false\n# random_state: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/split_h5mu_train_test/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split h5mu train test"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_h5mu_train_test.html#argument-groups",
    "href": "components/modules/dataflow/split_h5mu_train_test.html#argument-groups",
    "title": "Split h5mu train test",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nInput dataset in mudata format.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe input (query) data to be labeled. Should be a .h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_train\nThe output training data in mudata format.\nfile, required, example: \"output_train.h5mu\"\n\n\n--output_test\nThe output testing data in mudata format.\nfile, required, example: \"output_test.h5mu\"\n\n\n--output_val\nThe output validation data in mudata format.\nfile, example: \"output_val.h5mu\"\n\n\n--compression\n\nstring, example: \"gzip\"\n\n\n\n\n\nSplit arguments\nModel arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--test_size\nThe proportion of the dataset to include in the test split.\ndouble, default: 0.2\n\n\n--val_size\nThe proportion of the dataset to include in the validation split.\ndouble\n\n\n--shuffle\nWhether or not to shuffle the data before splitting.\nboolean_true\n\n\n--random_state\nThe seed used by the random number generator.\ninteger",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split h5mu train test"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_h5mu_train_test.html#authors",
    "href": "components/modules/dataflow/split_h5mu_train_test.html#authors",
    "title": "Split h5mu train test",
    "section": "Authors",
    "text": "Authors\n\nJakub Majercik   (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split h5mu train test"
    ]
  },
  {
    "objectID": "components/modules/dataflow/merge.html",
    "href": "components/modules/dataflow/merge.html",
    "title": "Merge",
    "section": "",
    "text": "ID: merge\nNamespace: dataflow\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Merge"
    ]
  },
  {
    "objectID": "components/modules/dataflow/merge.html#example-commands",
    "href": "components/modules/dataflow/merge.html#example-commands",
    "title": "Merge",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/dataflow/merge/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"sample_paths\"]\n# output: \"output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/merge/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Merge"
    ]
  },
  {
    "objectID": "components/modules/dataflow/merge.html#argument-group",
    "href": "components/modules/dataflow/merge.html#argument-group",
    "title": "Merge",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPaths to the single-modality .h5mu files that need to be combined\nList of file, required, default: \"sample_paths\", multiple_sep: \";\"\n\n\n--output\nPath to the output file.\nfile, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Merge"
    ]
  },
  {
    "objectID": "components/modules/dataflow/merge.html#authors",
    "href": "components/modules/dataflow/merge.html#authors",
    "title": "Merge",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Merge"
    ]
  },
  {
    "objectID": "components/modules/cluster/leiden.html",
    "href": "components/modules/cluster/leiden.html",
    "title": "Leiden",
    "section": "",
    "text": "ID: leiden\nNamespace: cluster\n\n\n\nSource\nLeiden is an improved version of the [Louvain algorithm] [Blondel08]. It has been proposed for single-cell analysis by [Levine15] [Levine15]. This requires having ran neighbors/find_neighbors or neighbors/bbknn first.\n[Blondel08]: Blondel et al. (2008), Fast unfolding of communities in large networks, J. Stat. Mech.\n[Levine15]: Levine et al. (2015), Data-Driven Phenotypic Dissection of AML Reveals Progenitor-like Cells that Correlate with Prognosis, Cell.\n[Traag18]: Traag et al. (2018), From Louvain to Leiden: guaranteeing well-connected communities arXiv.\n[Wolf18]: Wolf et al. (2018), Scanpy: large-scale single-cell gene expression data analysis, Genome Biology.",
    "crumbs": [
      "Reference",
      "Modules",
      "Cluster",
      "Leiden"
    ]
  },
  {
    "objectID": "components/modules/cluster/leiden.html#example-commands",
    "href": "components/modules/cluster/leiden.html#example-commands",
    "title": "Leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/cluster/leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nobsp_connectivities: \"connectivities\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_name: \"leiden\"\nresolution: # please fill in - example: [1.0]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/cluster/leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Cluster",
      "Leiden"
    ]
  },
  {
    "objectID": "components/modules/cluster/leiden.html#argument-group",
    "href": "components/modules/cluster/leiden.html#argument-group",
    "title": "Leiden",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsp_connectivities\nIn which .obsp slot the neighbor connectivities can be found.\nstring, default: \"connectivities\"\n\n\n--output\nOutput file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--obsm_name\nName of the .obsm key under which to add the cluster labels. The name of the columns in the matrix will correspond to the resolutions.\nstring, default: \"leiden\"\n\n\n--resolution\nA parameter value controlling the coarseness of the clustering. Higher values lead to more clusters. Multiple values will result in clustering being performed multiple times.\nList of double, required, default: 1, multiple_sep: \";\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Cluster",
      "Leiden"
    ]
  },
  {
    "objectID": "components/modules/cluster/leiden.html#authors",
    "href": "components/modules/cluster/leiden.html#authors",
    "title": "Leiden",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Cluster",
      "Leiden"
    ]
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html",
    "href": "components/modules/labels_transfer/xgboost.html",
    "title": "Xgboost",
    "section": "",
    "text": "ID: xgboost\nNamespace: labels_transfer\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Labels Transfer",
      "Xgboost"
    ]
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html#example-commands",
    "href": "components/modules/labels_transfer/xgboost.html#example-commands",
    "title": "Xgboost",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/labels_transfer/xgboost/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input dataset (query) arguments\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\n# input_obsm_features: \"X_scvi\"\n\n# Reference dataset arguments\n# reference: \"reference.h5mu\"\n# reference_obsm_features: \"X_scvi\"\nreference_obs_targets: [\"ann_level_1\", \"ann_level_2\", \"ann_level_3\", \"ann_level_4\", \"ann_level_5\", \"ann_finest_level\"]\n\n# Outputs\n# output: \"$id.$key.output\"\n# output_obs_predictions: [\"foo\"]\n# output_obs_probability: [\"foo\"]\n# output_compression: \"gzip\"\n\n# Execution arguments\nforce_retrain: false\nuse_gpu: false\nverbosity: 1\n# model_output: \"model\"\noutput_uns_parameters: \"xgboost_parameters\"\n\n# Learning parameters\nlearning_rate: 0.3\nmin_split_loss: 0.0\nmax_depth: 6\nmin_child_weight: 1\nmax_delta_step: 0.0\nsubsample: 1.0\nsampling_method: \"uniform\"\ncolsample_bytree: 1.0\ncolsample_bylevel: 1.0\ncolsample_bynode: 1.0\nreg_lambda: 1.0\nreg_alpha: 0.0\nscale_pos_weight: 1.0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/labels_transfer/xgboost/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Labels Transfer",
      "Xgboost"
    ]
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html#argument-groups",
    "href": "components/modules/labels_transfer/xgboost.html#argument-groups",
    "title": "Xgboost",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe query data to transfer the labels to. Should be a .h5mu file.\nfile, required\n\n\n--modality\nWhich modality to use.\nstring, default: \"rna\"\n\n\n--input_obsm_features\nThe .obsm key of the embedding to use for the classifier’s inference. If not provided, the .X slot will be used instead. Make sure that embedding was obtained in the same way as the reference embedding (e.g. by the same model or preprocessing).\nstring, example: \"X_scvi\"\n\n\n\n\n\nReference dataset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train classifiers on.\nfile, example: \"reference.h5mu\"\n\n\n--reference_obsm_features\nThe .obsm key of the embedding to use for the classifier’s training. If not provided, the .X slot will be used instead. Make sure that embedding was obtained in the same way as the query embedding (e.g. by the same model or preprocessing).\nstring, example: \"X_scvi\"\n\n\n--reference_obs_targets\nThe .obs key(s) of the target labels to tranfer.\nList of string, default: \"ann_level_1\", \"ann_level_2\", \"ann_level_3\", \"ann_level_4\", \"ann_level_5\", \"ann_finest_level\", multiple_sep: \";\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe query data in .h5mu format with predicted labels transfered from the reference.\nfile, required\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted information. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_pred\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_obs_probability\nIn which .obs slots to store the probability of the predictions. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_probability\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n\n\n\nExecution arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--force_retrain\nRetrain models on the reference even if model_output directory already has trained classifiers. WARNING! It will rewrite existing classifiers for targets in the model_output directory!\nboolean_true\n\n\n--use_gpu\nUse GPU during models training and inference (recommended).\nboolean, default: FALSE\n\n\n--verbosity\nThe verbosity level for evaluation of the classifier from the range [0,2]\ninteger, default: 1\n\n\n--model_output\nOutput directory for model\nfile, default: \"model\"\n\n\n--output_uns_parameters\nThe key in uns slot of the output AnnData object to store the parameters of the XGBoost classifier.\nstring, default: \"xgboost_parameters\"\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--learning_rate\nStep size shrinkage used in update to prevents overfitting. Range: [0,1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0.3\n\n\n--min_split_loss\nMinimum loss reduction required to make a further partition on a leaf node of the tree. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0\n\n\n--max_depth\nMaximum depth of a tree. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ninteger, default: 6\n\n\n--min_child_weight\nMinimum sum of instance weight (hessian) needed in a child. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ninteger, default: 1\n\n\n--max_delta_step\nMaximum delta step we allow each leaf output to be. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0\n\n\n--subsample\nSubsample ratio of the training instances. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--sampling_method\nThe method to use to sample the training instances. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\nstring, default: \"uniform\"\n\n\n--colsample_bytree\nFraction of columns to be subsampled. Range (0, 1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--colsample_bylevel\nSubsample ratio of columns for each level. Range (0, 1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--colsample_bynode\nSubsample ratio of columns for each node (split). Range (0, 1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--reg_lambda\nL2 regularization term on weights. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--reg_alpha\nL1 regularization term on weights. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0\n\n\n--scale_pos_weight\nControl the balance of positive and negative weights, useful for unbalanced classes. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1",
    "crumbs": [
      "Reference",
      "Modules",
      "Labels Transfer",
      "Xgboost"
    ]
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html#authors",
    "href": "components/modules/labels_transfer/xgboost.html#authors",
    "title": "Xgboost",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Labels Transfer",
      "Xgboost"
    ]
  },
  {
    "objectID": "components/modules/download/download_file.html",
    "href": "components/modules/download/download_file.html",
    "title": "Download file",
    "section": "",
    "text": "ID: download_file\nNamespace: download\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Download",
      "Download file"
    ]
  },
  {
    "objectID": "components/modules/download/download_file.html#example-commands",
    "href": "components/modules/download/download_file.html#example-commands",
    "title": "Download file",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/download/download_file/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_protein_v3/pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n# output: \"$id.$key.output.h5\"\nverbose: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/download/download_file/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Download",
      "Download file"
    ]
  },
  {
    "objectID": "components/modules/download/download_file.html#argument-group",
    "href": "components/modules/download/download_file.html#argument-group",
    "title": "Download file",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nURL to a file to download.\nstring, required, example: \"https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_protein_v3/pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n\n\n--output\nPath where to store output.\nfile, required, example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n\n\n--verbose\nIncrease verbosity\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Download",
      "Download file"
    ]
  },
  {
    "objectID": "components/modules/download/download_file.html#authors",
    "href": "components/modules/download/download_file.html#authors",
    "title": "Download file",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Download",
      "Download file"
    ]
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background_v0_2.html",
    "href": "components/modules/correction/cellbender_remove_background_v0_2.html",
    "title": "Cellbender remove background v0 2",
    "section": "",
    "text": "ID: cellbender_remove_background_v0_2\nNamespace: correction\n\n\n\nSource\nThis module removes counts due to ambient RNA molecules and random barcode swapping from (raw) UMI-based scRNA-seq count matrices. At the moment, only the count matrices produced by the CellRanger count pipeline is supported. Support for additional tools and protocols will be added in the future. A quick start tutorial can be found here.\nFleming et al. 2022, bioRxiv.",
    "crumbs": [
      "Reference",
      "Modules",
      "Correction",
      "Cellbender remove background v0 2"
    ]
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background_v0_2.html#example-commands",
    "href": "components/modules/correction/cellbender_remove_background_v0_2.html#example-commands",
    "title": "Cellbender remove background v0 2",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/correction/cellbender_remove_background_v0_2/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nlayer_output: \"corrected\"\nobs_latent_rt_efficiency: \"latent_rt_efficiency\"\nobs_latent_cell_probability: \"latent_cell_probability\"\nobs_latent_scale: \"latent_scale\"\nvar_ambient_expression: \"ambient_expression\"\nobsm_latent_gene_encoding: \"cellbender_latent_gene_encoding\"\n\n# Arguments\n# expected_cells: 1000\n# total_droplets_included: 25000\nexpected_cells_from_qc: true\nmodel: \"full\"\nepochs: 150\nlow_count_threshold: 15\nz_dim: 100\nz_layers: [500]\ntraining_fraction: 0.9\nempty_drop_training_fraction: 0.5\nfpr: [0.01]\nexclude_antibody_capture: false\n# learning_rate: 1.0E-4\ncuda: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/correction/cellbender_remove_background_v0_2/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Correction",
      "Cellbender remove background v0 2"
    ]
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background_v0_2.html#argument-groups",
    "href": "components/modules/correction/cellbender_remove_background_v0_2.html#argument-groups",
    "title": "Cellbender remove background v0 2",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nList of modalities to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nFull count matrix as an h5mu file, with background RNA removed. This file contains all the original droplet barcodes.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--layer_output\nOutput layer\nstring, default: \"corrected\"\n\n\n--obs_latent_rt_efficiency\n\nstring, default: \"latent_rt_efficiency\"\n\n\n--obs_latent_cell_probability\n\nstring, default: \"latent_cell_probability\"\n\n\n--obs_latent_scale\n\nstring, default: \"latent_scale\"\n\n\n--var_ambient_expression\n\nstring, default: \"ambient_expression\"\n\n\n--obsm_latent_gene_encoding\n\nstring, default: \"cellbender_latent_gene_encoding\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expected_cells\nNumber of cells expected in the dataset (a rough estimate within a factor of 2 is sufficient).\ninteger, example: 1000\n\n\n--total_droplets_included\nThe number of droplets from the rank-ordered UMI plot that will be analyzed. The largest ‘total_droplets’ droplets will have their cell probabilities inferred as an output.\ninteger, example: 25000\n\n\n--expected_cells_from_qc\nWill use the Cell Ranger QC to determine the estimated number of cells\nboolean, default: TRUE\n\n\n--model\nWhich model is being used for count data. ‘simple’ does not model either ambient RNA or random barcode swapping (for debugging purposes – not recommended). ‘ambient’ assumes background RNA is incorporated into droplets. ‘swapping’ assumes background RNA comes from random barcode swapping. ‘full’ uses a combined ambient and swapping model.\nstring, default: \"full\"\n\n\n--epochs\nNumber of epochs to train.\ninteger, default: 150\n\n\n--low_count_threshold\nDroplets with UMI counts below this number are completely excluded from the analysis. This can help identify the correct prior for empty droplet counts in the rare case where empty counts are extremely high (over 200).\ninteger, default: 15\n\n\n--z_dim\nDimension of latent variable z.\ninteger, default: 100\n\n\n--z_layers\nDimension of hidden layers in the encoder for z.\nList of integer, default: 500, multiple_sep: \";\"\n\n\n--training_fraction\nTraining detail: the fraction of the data used for training. The rest is never seen by the inference algorithm. Speeds up learning.\ndouble, default: 0.9\n\n\n--empty_drop_training_fraction\nTraining detail: the fraction of the training data each epoch that is drawn (randomly sampled) from surely empty droplets.\ndouble, default: 0.5\n\n\n--fpr\nTarget false positive rate in (0, 1). A false positive is a true signal count that is erroneously removed. More background removal is accompanied by more signal removal at high values of FPR. You can specify multiple values, which will create multiple output files.\nList of double, default: 0.01, multiple_sep: \";\"\n\n\n--exclude_antibody_capture\nIncluding the flag –exclude-antibody-capture will cause remove-background to operate on gene counts only, ignoring other features.\nboolean_true\n\n\n--learning_rate\nTraining detail: lower learning rate for inference. A OneCycle learning rate schedule is used, where the upper learning rate is ten times this value. (For this value, probably do not exceed 1e-3).\ndouble, example: 1e-04\n\n\n--cuda\nIncluding the flag –cuda will run the inference on a GPU.\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Correction",
      "Cellbender remove background v0 2"
    ]
  },
  {
    "objectID": "components/modules/compression/tar_extract.html",
    "href": "components/modules/compression/tar_extract.html",
    "title": "Tar extract",
    "section": "",
    "text": "ID: tar_extract\nNamespace: compression\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Compression",
      "Tar extract"
    ]
  },
  {
    "objectID": "components/modules/compression/tar_extract.html#example-commands",
    "href": "components/modules/compression/tar_extract.html#example-commands",
    "title": "Tar extract",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/compression/tar_extract/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.tar.gz\"\n# output: \"$id.$key.output\"\n# strip_components: 1\n# exclude: \"docs/figures\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/compression/tar_extract/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Compression",
      "Tar extract"
    ]
  },
  {
    "objectID": "components/modules/compression/tar_extract.html#argument-group",
    "href": "components/modules/compression/tar_extract.html#argument-group",
    "title": "Tar extract",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput file\nfile, required, example: \"input.tar.gz\"\n\n\n--output\nFolder to restore file(s) to.\nfile, required, example: \"output_folder\"\n\n\n--strip_components\nStrip this amount of leading components from file names on extraction. For example, to extract only ‘myfile.txt’ from an archive containing the structure this/goes/deep/myfile.txt', use 3 to strip 'this/goes/deep/'. |integer, example:1| |–exclude|Prevents any file or member whose name matches the shell wildcard (pattern) from being extracted.                                                                                                                        |string, example:“docs/figures”`",
    "crumbs": [
      "Reference",
      "Modules",
      "Compression",
      "Tar extract"
    ]
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html",
    "href": "components/modules/neighbors/find_neighbors.html",
    "title": "Find neighbors",
    "section": "",
    "text": "ID: find_neighbors\nNamespace: neighbors\n\n\n\nSource\nThe neighbor search efficiency of this heavily relies on UMAP [McInnes18], which also provides a method for estimating connectivities of data points - the connectivity of the manifold (method==‘umap’). If method==‘gauss’, connectivities are computed according to [Coifman05], in the adaption of [Haghverdi16].",
    "crumbs": [
      "Reference",
      "Modules",
      "Neighbors",
      "Find neighbors"
    ]
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html#example-commands",
    "href": "components/modules/neighbors/find_neighbors.html#example-commands",
    "title": "Find neighbors",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/neighbors/find_neighbors/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nobsm_input: \"X_pca\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_output: \"neighbors\"\nobsp_distances: \"distances\"\nobsp_connectivities: \"connectivities\"\nmetric: \"euclidean\"\nnum_neighbors: 15\nseed: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/neighbors/find_neighbors/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Neighbors",
      "Find neighbors"
    ]
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html#argument-group",
    "href": "components/modules/neighbors/find_neighbors.html#argument-group",
    "title": "Find neighbors",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_input\nWhich .obsm slot to use as a starting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--output\nOutput h5mu file containing the found neighbors.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--uns_output\nMandatory .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n--metric\nThe distance metric to be used in the generation of the nearest neighborhood network.\nstring, default: \"euclidean\"\n\n\n--num_neighbors\nThe size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor.\ninteger, default: 15\n\n\n--seed\nA random seed.\ninteger, default: 0",
    "crumbs": [
      "Reference",
      "Modules",
      "Neighbors",
      "Find neighbors"
    ]
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html#authors",
    "href": "components/modules/neighbors/find_neighbors.html#authors",
    "title": "Find neighbors",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)\nRobrecht Cannoodt    (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Neighbors",
      "Find neighbors"
    ]
  },
  {
    "objectID": "components/modules/transform/log1p.html",
    "href": "components/modules/transform/log1p.html",
    "title": "Log1p",
    "section": "",
    "text": "ID: log1p\nNamespace: transform\n\n\n\nSource\nComputes X = log(X + 1), where log denotes the natural logarithm unless a different base is given",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Log1p"
    ]
  },
  {
    "objectID": "components/modules/transform/log1p.html#example-commands",
    "href": "components/modules/transform/log1p.html#example-commands",
    "title": "Log1p",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/transform/log1p/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# output_layer: \"foo\"\n# output: \"output.h5mu\"\n# output_compression: \"gzip\"\n# base: 2.0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/log1p/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Log1p"
    ]
  },
  {
    "objectID": "components/modules/transform/log1p.html#argument-group",
    "href": "components/modules/transform/log1p.html#argument-group",
    "title": "Log1p",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer to use. If None, X is normalized\nstring\n\n\n--output_layer\nOutput layer to use. By default, use X.\nstring\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--base\n\ndouble, example: 2",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Log1p"
    ]
  },
  {
    "objectID": "components/modules/transform/log1p.html#authors",
    "href": "components/modules/transform/log1p.html#authors",
    "title": "Log1p",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)\nRobrecht Cannoodt    (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Log1p"
    ]
  },
  {
    "objectID": "components/modules/transform/bpcells_regress_out.html",
    "href": "components/modules/transform/bpcells_regress_out.html",
    "title": "Bpcells regress out",
    "section": "",
    "text": "ID: bpcells_regress_out\nNamespace: transform\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Bpcells regress out"
    ]
  },
  {
    "objectID": "components/modules/transform/bpcells_regress_out.html#example-commands",
    "href": "components/modules/transform/bpcells_regress_out.html#example-commands",
    "title": "Bpcells regress out",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/transform/bpcells_regress_out/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\n# output: \"output.h5mu\"\n# output_compression: \"gzip\"\nmodality: \"rna\"\n# obs_keys: [\"foo\"]\n# input_layer: \"X_normalized\"\n# output_layer: \"X_regressed\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/bpcells_regress_out/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Bpcells regress out"
    ]
  },
  {
    "objectID": "components/modules/transform/bpcells_regress_out.html#argument-group",
    "href": "components/modules/transform/bpcells_regress_out.html#argument-group",
    "title": "Bpcells regress out",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--modality\nThe modality to run this component on.\nstring, default: \"rna\"\n\n\n--obs_keys\nThe .obs keys to regress on.\nList of string, multiple_sep: \";\"\n\n\n--input_layer\nThe layer of the adata object to regress on. If not provided, the X attribute of the adata object will be used.\nstring, example: \"X_normalized\"\n\n\n--output_layer\nThe layer of the adata object containing the regressed count data. If not provided, the X attribute of the adata object will be used.\nstring, example: \"X_regressed\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Bpcells regress out"
    ]
  },
  {
    "objectID": "components/modules/transform/bpcells_regress_out.html#authors",
    "href": "components/modules/transform/bpcells_regress_out.html#authors",
    "title": "Bpcells regress out",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (maintainer, author)\nRobrecht Cannoodt    (contributor, author)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Bpcells regress out"
    ]
  },
  {
    "objectID": "components/modules/transform/scale.html",
    "href": "components/modules/transform/scale.html",
    "title": "Scale",
    "section": "",
    "text": "ID: scale\nNamespace: transform\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Scale"
    ]
  },
  {
    "objectID": "components/modules/transform/scale.html#example-commands",
    "href": "components/modules/transform/scale.html#example-commands",
    "title": "Scale",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/transform/scale/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# output_layer: \"foo\"\n# max_value: 123.0\nzero_center: true\n# output: \"output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/scale/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Scale"
    ]
  },
  {
    "objectID": "components/modules/transform/scale.html#argument-group",
    "href": "components/modules/transform/scale.html#argument-group",
    "title": "Scale",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nList of modalities to process.\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer with data to scale. Uses .X by default\nstring\n\n\n--output_layer\nOutput layer where scaled data will be stored. If not specified, .X will be used.\nstring\n\n\n--max_value\nClip (truncate) to this value after scaling. Does not clip by default.\ndouble\n\n\n--zero_center\nIf set, omit zero-centering variables, which allows to handle sparse input efficiently.\nboolean_false\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Scale"
    ]
  },
  {
    "objectID": "components/modules/transform/scale.html#authors",
    "href": "components/modules/transform/scale.html#authors",
    "title": "Scale",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Scale"
    ]
  },
  {
    "objectID": "components/modules/transform/delete_layer.html",
    "href": "components/modules/transform/delete_layer.html",
    "title": "Delete layer",
    "section": "",
    "text": "ID: delete_layer\nNamespace: transform\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Delete layer"
    ]
  },
  {
    "objectID": "components/modules/transform/delete_layer.html#example-commands",
    "href": "components/modules/transform/delete_layer.html#example-commands",
    "title": "Delete layer",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/transform/delete_layer/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nlayer: # please fill in - example: [\"foo\"]\n# output: \"output.h5mu\"\n# output_compression: \"gzip\"\nmissing_ok: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/delete_layer/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Delete layer"
    ]
  },
  {
    "objectID": "components/modules/transform/delete_layer.html#argument-group",
    "href": "components/modules/transform/delete_layer.html#argument-group",
    "title": "Delete layer",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nInput layer to remove\nList of string, required, multiple_sep: \";\"\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--missing_ok\nDo not raise an error if the layer does not exist for all modalities.\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Delete layer"
    ]
  },
  {
    "objectID": "components/modules/transform/delete_layer.html#authors",
    "href": "components/modules/transform/delete_layer.html#authors",
    "title": "Delete layer",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Delete layer"
    ]
  },
  {
    "objectID": "components/modules/transform/normalize_total.html",
    "href": "components/modules/transform/normalize_total.html",
    "title": "Normalize total",
    "section": "",
    "text": "ID: normalize_total\nNamespace: transform\n\n\n\nSource\nNormalize each cell by total counts over all genes, so that every cell has the same total count after normalization. If choosing target_sum=1e6, this is CPM normalization.\nIf exclude_highly_expressed=True, very highly expressed genes are excluded from the computation of the normalization factor (size factor) for each cell. This is meaningful as these can strongly influence the resulting normalized values for all other genes [Weinreb17].",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Normalize total"
    ]
  },
  {
    "objectID": "components/modules/transform/normalize_total.html#example-commands",
    "href": "components/modules/transform/normalize_total.html#example-commands",
    "title": "Normalize total",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/transform/normalize_total/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# output: \"output.h5mu\"\n# output_compression: \"gzip\"\n# output_layer: \"foo\"\n# target_sum: 123\nexclude_highly_expressed: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/normalize_total/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Normalize total"
    ]
  },
  {
    "objectID": "components/modules/transform/normalize_total.html#argument-group",
    "href": "components/modules/transform/normalize_total.html#argument-group",
    "title": "Normalize total",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer to use. By default, X is normalized\nstring\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_layer\nOutput layer to use. By default, use X.\nstring\n\n\n--target_sum\nIf None, after normalization, each observation (cell) has a total count equal to the median of total counts for observations (cells) before normalization.\ninteger\n\n\n--exclude_highly_expressed\nExclude (very) highly expressed genes for the computation of the normalization factor (size factor) for each cell. A gene is considered highly expressed, if it has more than max_fraction of the total counts in at least one cell. The not-excluded genes will sum up to target_sum.\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Normalize total"
    ]
  },
  {
    "objectID": "components/modules/transform/normalize_total.html#authors",
    "href": "components/modules/transform/normalize_total.html#authors",
    "title": "Normalize total",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)\nRobrecht Cannoodt    (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Normalize total"
    ]
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html",
    "href": "components/modules/demux/bcl2fastq.html",
    "title": "Bcl2fastq",
    "section": "",
    "text": "ID: bcl2fastq\nNamespace: demux\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Bcl2fastq"
    ]
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html#example-commands",
    "href": "components/modules/demux/bcl2fastq.html#example-commands",
    "title": "Bcl2fastq",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/demux/bcl2fastq/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"bcl_dir\"\nsample_sheet: # please fill in - example: \"SampleSheet.csv\"\n# output: \"$id.$key.output\"\n# reports: \"$id.$key.reports\"\nignore_missing: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/demux/bcl2fastq/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Bcl2fastq"
    ]
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html#argument-group",
    "href": "components/modules/demux/bcl2fastq.html#argument-group",
    "title": "Bcl2fastq",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput run directory\nfile, required, example: \"bcl_dir\"\n\n\n--sample_sheet\nPointer to the sample sheet\nfile, required, example: \"SampleSheet.csv\"\n\n\n--output\nOutput directory containig fastq files\nfile, required, example: \"fastq_dir\"\n\n\n--reports\nReports directory\nfile, example: \"reports_dir\"\n\n\n--ignore_missing\n\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Bcl2fastq"
    ]
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html#authors",
    "href": "components/modules/demux/bcl2fastq.html#authors",
    "title": "Bcl2fastq",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Bcl2fastq"
    ]
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html",
    "href": "components/modules/demux/cellranger_mkfastq.html",
    "title": "Cellranger mkfastq",
    "section": "",
    "text": "ID: cellranger_mkfastq\nNamespace: demux\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Cellranger mkfastq"
    ]
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html#example-commands",
    "href": "components/modules/demux/cellranger_mkfastq.html#example-commands",
    "title": "Cellranger mkfastq",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/demux/cellranger_mkfastq/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"/path/to/bcl\"\nsample_sheet: # please fill in - example: \"SampleSheet.csv\"\n# output: \"fastqs\"\n# reports: \"$id.$key.reports\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/demux/cellranger_mkfastq/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Cellranger mkfastq"
    ]
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html#argument-group",
    "href": "components/modules/demux/cellranger_mkfastq.html#argument-group",
    "title": "Cellranger mkfastq",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the (untarred) BCL files. Expects ‘RunParameters.xml’ at ‘./’.\nfile, required, example: \"/path/to/bcl\"\n\n\n--sample_sheet\nThe path to the sample sheet.\nfile, required, example: \"SampleSheet.csv\"\n\n\n--output\nThe folder to store the demux results\nfile, required, default: \"fastqs\", example: \"/path/to/output\"\n\n\n--reports\nReports directory\nfile, example: \"reports_dir\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Cellranger mkfastq"
    ]
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html#authors",
    "href": "components/modules/demux/cellranger_mkfastq.html#authors",
    "title": "Cellranger mkfastq",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nSamuel D’Souza   (author)\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Cellranger mkfastq"
    ]
  },
  {
    "objectID": "components/modules/velocity/velocyto.html",
    "href": "components/modules/velocity/velocyto.html",
    "title": "Velocyto",
    "section": "",
    "text": "ID: velocyto\nNamespace: velocity\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Velocity",
      "Velocyto"
    ]
  },
  {
    "objectID": "components/modules/velocity/velocyto.html#example-commands",
    "href": "components/modules/velocity/velocyto.html#example-commands",
    "title": "Velocyto",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/velocity/velocyto/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\ntranscriptome: # please fill in - example: \"path/to/file\"\n# barcode: \"path/to/file\"\nwithout_umi: false\n# output: \"$id.$key.output\"\nlogic: \"Default\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/velocity/velocyto/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Velocity",
      "Velocyto"
    ]
  },
  {
    "objectID": "components/modules/velocity/velocyto.html#argument-group",
    "href": "components/modules/velocity/velocyto.html#argument-group",
    "title": "Velocyto",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to BAM file\nfile, required\n\n\n--transcriptome\nPath to GTF file\nfile, required\n\n\n--barcode\nValid barcodes file, to filter the bam. If –bcfile is not specified all the cell barcodes will be included. Cell barcodes should be specified in the bcfile as the ‘CB’ tag for each read\nfile\n\n\n--without_umi\nfoo\nboolean_true\n\n\n--output\nVelocyto loom file\nfile, required\n\n\n--logic\nThe logic to use for the filtering.\nstring, default: \"Default\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Velocity",
      "Velocyto"
    ]
  },
  {
    "objectID": "components/modules/velocity/velocyto.html#authors",
    "href": "components/modules/velocity/velocyto.html#authors",
    "title": "Velocyto",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Velocity",
      "Velocyto"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/freebayes.html",
    "href": "components/modules/genetic_demux/freebayes.html",
    "title": "Freebayes",
    "section": "",
    "text": "ID: freebayes\nNamespace: genetic_demux\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Freebayes"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/freebayes.html#example-commands",
    "href": "components/modules/genetic_demux/freebayes.html#example-commands",
    "title": "Freebayes",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/genetic_demux/freebayes/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# bam: \"path/to/file\"\n# bam_list: \"path/to/file\"\nstdin: false\n# fasta_reference: \"path/to/file\"\n# fasta_reference_index: \"path/to/file\"\n# targets: \"path/to/file\"\n# region: \"foo\"\n# samples: \"path/to/file\"\n# populations: \"path/to/file\"\n# cnv_map: \"path/to/file\"\ngvcf: false\n# gvcf_chunk: 123\n# variant_input: \"path/to/file\"\nonly_use_input_alleles: false\n# haplotype_basis_alleles: \"path/to/file\"\nreport_all_haplotype_alleles: false\nreport_monomorphic: false\npvar: 0.0\nstrict_vcf: false\ntheta: 0.001\nploidy: 2\npooled_discrete: false\npooled_continuous: false\nuse_reference_allele: false\nreference_quality: \"100,60\"\nthrow_away_snp_obs: false\nthrow_away_mnps_obs: true\nthrow_away_indel_obs: true\nthrow_away_complex_obs: true\nuse_best_n_alleles: 0\nmax_complex_gap: 3\nmin_repeat_size: 5\nmin_repeat_entropy: 1\nno_partial_observations: false\ndont_left_align_indels: false\nuse_duplicate_reads: false\nmin_mapping_quality: 1\nmin_base_quality: 1\nmin_supporting_allele_qsum: 0\nmin_supporting_mapping_qsum: 0\nmismatch_base_quality_threshold: 10\nread_max_mismatch_fraction: 1.0\n# read_mismatch_limit: 123\n# read_snp_limit: 123\n# read_indel_limit: 123\nstandard_filters: false\nmin_alternate_fraction: 0.05\nmin_alternate_count: 2\nmin_alternate_qsum: 0\nmin_alternate_total: 1\nmin_coverage: 0\n# max_coverage: 123\nno_population_priors: false\nhwe_priors_off: false\nbinomial_obs_priors_off: false\nallele_balance_priors_off: false\n# observation_bias: \"path/to/file\"\n# base_quality_cap: 123\nprob_contamination: 1.0E-8\nlegacy_gls: false\n# contamination_estimates: \"path/to/file\"\nreport_genotype_likelihood_max: false\ngenotyping_max_iterations: 1000\ngenotyping_max_banddepth: 6\nposterior_integration_limits: \"1,3\"\nexclude_unobserved_genotypes: false\n# genotype_variant_threshold: 123\nuse_mapping_quality: false\nharmonic_indel_quality: false\nread_dependence_factor: 0.9\ngenotype_qualities: false\ndebug: false\ndd: false\n\n# Output\n# output: \"$id.$key.output\"\n# vcf: \"snp.vcf\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/freebayes/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Freebayes"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/freebayes.html#argument-groups",
    "href": "components/modules/genetic_demux/freebayes.html#argument-groups",
    "title": "Freebayes",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bam\nAdd FILE to the set of BAM files to be analyzed.\nfile\n\n\n--bam_list\nA file containing a list of BAM files to be analyzed.\nfile\n\n\n--stdin\nRead BAM input on stdin.\nboolean_true\n\n\n--fasta_reference\nUse FILE as the reference sequence for analysis. An index file (FILE.fai) will be created if none exists. If neither –targets nor –region are specified, FreeBayes will analyze every position in this reference.\nfile\n\n\n--fasta_reference_index\nUse FILE.fai as the index of reference sequence for analysis.\nfile\n\n\n--targets\nLimit analysis to targets listed in the BED-format FILE.\nfile\n\n\n--region\nLimit analysis to the specified region, 0-base coordinates, end_position not included (same as BED format).\nstring\n\n\n--samples\nLimit analysis to samples listed (one per line) in the FILE. By default FreeBayes will analyze all samples in its input BAM files.\nfile\n\n\n--populations\nEach line of FILE should list a sample and a population which it is part of. The population-based bayesian inference model will then be partitioned on the basis of the populations.\nfile\n\n\n--cnv_map\nRead a copy number map from the BED file FILE, which has either a sample-level ploidy or a region-specific format.\nfile\n\n\n--gvcf\nWrite gVCF output, which indicates coverage in uncalled regions.\nboolean_true\n\n\n--gvcf_chunk\nWhen writing gVCF output emit a record for every NUM bases.\ninteger\n\n\n--variant_input\nUse variants reported in VCF file as input to the algorithm. Variants in this file will included in the output even if there is not enough support in the data to pass input filters.\nfile\n\n\n--only_use_input_alleles\nOnly provide variant calls and genotype likelihoods for sites and alleles which are provided in the VCF input, and provide output in the VCF for all input alleles, not just those which have support in the data.\nboolean_true\n\n\n--haplotype_basis_alleles\nWhen specified, only variant alleles provided in this input VCF will be used for the construction of complex or haplotype alleles.\nfile\n\n\n--report_all_haplotype_alleles\nAt sites where genotypes are made over haplotype alleles, provide information about all alleles in output, not only those which are called.\nboolean_true\n\n\n--report_monomorphic\nReport even loci which appear to be monomorphic, and report all considered alleles, even those which are not in called genotypes.\nboolean_true\n\n\n--pvar\nReport sites if the probability that there is a polymorphism at the site is greater than N. Note that post-filtering is generally recommended over the use of this parameter.\ndouble, default: 0\n\n\n--strict_vcf\nGenerate strict VCF format (FORMAT/GQ will be an int).\nboolean_true\n\n\n--theta\nThe expected mutation rate or pairwise nucleotide diversity among the population under analysis. This serves as the single parameter to the Ewens Sampling Formula prior model.\ndouble, default: 0.001\n\n\n--ploidy\nSets the default ploidy for the analysis to N.\ninteger, default: 2\n\n\n--pooled_discrete\nAssume that samples result from pooled sequencing. Model pooled samples using discrete genotypes across pools.\nboolean_true\n\n\n--pooled_continuous\nOutput all alleles which pass input filters, regardles of genotyping outcome or model.\nboolean_true\n\n\n--use_reference_allele\nThis flag includes the reference allele in the analysis as if it is another sample from the same population.\nboolean_true\n\n\n--reference_quality\nAssign mapping quality of MQ to the reference allele at each site and base quality of BQ.\nstring, default: \"100,60\"\n\n\n--throw_away_snp_obs\nIgnore SNP alleles.\nboolean_true\n\n\n--throw_away_mnps_obs\nIgnore multi-nuceotide polymorphisms, MNPs. MNPs are excluded as default.\nboolean_false\n\n\n--throw_away_indel_obs\nIgnore insertion and deletion alleles. Indels are excluded as default.\nboolean_false\n\n\n--throw_away_complex_obs\nIgnore complex events (composites of other classes). Complex are excluded as default\nboolean_false\n\n\n--use_best_n_alleles\nEvaluate only the best N SNP alleles, ranked by sum of supporting quality scores.\ninteger, default: 0\n\n\n--max_complex_gap\nAllow haplotype calls with contiguous embedded matches of up to this length.\ninteger, default: 3\n\n\n--min_repeat_size\nWhen assembling observations across repeats, require the total repeat length at least this many bp.\ninteger, default: 5\n\n\n--min_repeat_entropy\nTo detect interrupted repeats, build across sequence until it has entropy &gt; N bits per bp. Set to 0 to turn off.\ninteger, default: 1\n\n\n--no_partial_observations\nExclude observations which do not fully span the dynamically-determined detection window. (default, use all observations, dividing partial support across matching haplotypes when generating haplotypes.)\nboolean_true\n\n\n--dont_left_align_indels\nTurn off left-alignment of indels, which is enabled by default.\nboolean_true\n\n\n--use_duplicate_reads\nInclude duplicate-marked alignments in the analysis. default: exclude duplicates marked as such in alignments\nboolean_true\n\n\n--min_mapping_quality\nExclude alignments from analysis if they have a mapping quality less than Q.\ninteger, default: 1\n\n\n--min_base_quality\nExclude alleles from analysis if their supporting base quality is less than Q. Default value is changed according to the instruction of scSplit.\ninteger, default: 1\n\n\n--min_supporting_allele_qsum\nConsider any allele in which the sum of qualities of supporting observations is at least Q.\ninteger, default: 0\n\n\n--min_supporting_mapping_qsum\nConsider any allele in which and the sum of mapping qualities of supporting reads is at least.\ninteger, default: 0\n\n\n--mismatch_base_quality_threshold\nCount mismatches toward –read-mismatch-limit if the base quality of the mismatch is &gt;= Q.\ninteger, default: 10\n\n\n--read_max_mismatch_fraction\nExclude reads with more than N mismatches where each mismatch has base quality &gt;= mismatch-base-quality-threshold.\ndouble, default: 1\n\n\n--read_mismatch_limit\nExclude reads with more than N [0,1] fraction of mismatches where each mismatch has base quality &gt;= mismatch-base-quality-threshold.\ninteger\n\n\n--read_snp_limit\nExclude reads with more than N base mismatches, ignoring gaps with quality &gt;= mismatch-base-quality-threshold.\ninteger\n\n\n--read_indel_limit\nExclude reads with more than N separate gaps.\ninteger\n\n\n--standard_filters\nUse stringent input base and mapping quality filters, equivalent to -m 30 -q 20 -R 0 -S 0\nboolean_true\n\n\n--min_alternate_fraction\nRequire at least this fraction of observations supporting an alternate allele within a single individual in order to evaluate the position.\ndouble, default: 0.05\n\n\n--min_alternate_count\nRequire at least this count of observations supporting an alternate allele within a single individual in order to evaluate the position.\ninteger, default: 2\n\n\n--min_alternate_qsum\nRequire at least this sum of quality of observations supporting an alternate allele within a single individual in order to evaluate the position.\ninteger, default: 0\n\n\n--min_alternate_total\nRequire at least this count of observations supporting an alternate allele within the total population in order to use the allele in analysis.\ninteger, default: 1\n\n\n--min_coverage\nRequire at least this coverage to process a site.\ninteger, default: 0\n\n\n--max_coverage\nDo not process sites with greater than this coverage.\ninteger\n\n\n--no_population_priors\nEquivalent to –pooled-discrete –hwe-priors-off and removal of Ewens Sampling Formula component of priors.\nboolean_true\n\n\n--hwe_priors_off\nDisable estimation of the probability of the combination arising under HWE given the allele frequency as estimated by observation frequency.\nboolean_true\n\n\n--binomial_obs_priors_off\nDisable incorporation of prior expectations about observations. Uses read placement probability, strand balance probability, and read position probability.\nboolean_true\n\n\n--allele_balance_priors_off\nDisable use of aggregate probability of observation balance between alleles as a component of the priors.\nboolean_true\n\n\n--observation_bias\nRead length-dependent allele observation biases from FILE. The format is [length] [alignment efficiency relative to reference] where the efficiency is 1 if there is no relative observation bias.\nfile\n\n\n--base_quality_cap\nLimit estimated observation quality by capping base quality at Q.\ninteger\n\n\n--prob_contamination\nAn estimate of contamination to use for all samples.\ndouble, default: 1e-08\n\n\n--legacy_gls\nUse legacy (polybayes equivalent) genotype likelihood calculations\nboolean_true\n\n\n--contamination_estimates\nA file containing per-sample estimates of contamination, such as those generated by VerifyBamID.\nfile\n\n\n--report_genotype_likelihood_max\nReport genotypes using the maximum-likelihood estimate provided from genotype likelihoods.\nboolean_true\n\n\n--genotyping_max_iterations\nIterate no more than N times during genotyping step.\ninteger, default: 1000\n\n\n--genotyping_max_banddepth\nIntegrate no deeper than the Nth best genotype by likelihood when genotyping.\ninteger, default: 6\n\n\n--posterior_integration_limits\nIntegrate all genotype combinations in our posterior space which include no more than N samples with their Mth best data likelihood.\nstring, default: \"1,3\"\n\n\n--exclude_unobserved_genotypes\nSkip sample genotypings for which the sample has no supporting reads.\nboolean_true\n\n\n--genotype_variant_threshold\nLimit posterior integration to samples where the second-best genotype likelihood is no more than log(N) from the highest genotype likelihood for the sample.\ninteger\n\n\n--use_mapping_quality\nUse mapping quality of alleles when calculating data likelihoods.\nboolean_true\n\n\n--harmonic_indel_quality\nUse a weighted sum of base qualities around an indel, scaled by the distance from the indel. By default use a minimum BQ in flanking sequence.\nboolean_true\n\n\n--read_dependence_factor\nIncorporate non-independence of reads by scaling successive observations by this factor during data likelihood calculations.\ndouble, default: 0.9\n\n\n--genotype_qualities\nCalculate the marginal probability of genotypes and report as GQ in each sample field in the VCF output.\nboolean_true\n\n\n--debug\nPrint debugging output.\nboolean_true\n\n\n--dd\nPrint more verbose debugging output\nboolean_true\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"freebayes_out\"\n\n\n--vcf\nOutput VCF-format results to FILE.\nstring, example: \"snp.vcf\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Freebayes"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/freebayes.html#authors",
    "href": "components/modules/genetic_demux/freebayes.html#authors",
    "title": "Freebayes",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Freebayes"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/demuxlet.html",
    "href": "components/modules/genetic_demux/demuxlet.html",
    "title": "Demuxlet",
    "section": "",
    "text": "ID: demuxlet\nNamespace: genetic_demux\n\n\n\nSource\nIf external genotyping data for each sample is available (e.g. from SNP arrays), demuxlet would be recommended. Be careful that the parameters on the github is not in line with the newest help version",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Demuxlet"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/demuxlet.html#example-commands",
    "href": "components/modules/genetic_demux/demuxlet.html#example-commands",
    "title": "Demuxlet",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/genetic_demux/demuxlet/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# sam: \"path/to/file\"\ntag_group: \"CB\"\ntag_umi: \"UB\"\n# plp: \"foo\"\n# vcf: \"path/to/file\"\nfield: \"GT\"\ngeno_error_offset: 0.1\ngeno_error_coeff: 0.0\nr2_info: \"R2\"\nmin_mac: 1\nmin_call_rate: 0.5\nalpha: \"0.5\"\ndoublet_prior: 0.5\n# sm: \"foo\"\n# sm_list: \"foo\"\nsam_verbose: 1000000\nvcf_verbose: 1000\ncap_bq: 20\nmin_bq: 13\nmin_mq: 20\nmin_td: 0\nexcl_flag: 3844\n# group_list: \"foo\"\nmin_total: 0\nmin_snp: 0\nmin_umi: 0\n\n# Output\n# output: \"$id.$key.output\"\n# out: \"demuxlet\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/demuxlet/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Demuxlet"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/demuxlet.html#argument-groups",
    "href": "components/modules/genetic_demux/demuxlet.html#argument-groups",
    "title": "Demuxlet",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sam\nInput SAM/BAM/CRAM file. Must be sorted by coordinates and indexed.\nfile\n\n\n--tag_group\nTag representing readgroup or cell barcodes, in the case to partition the BAM file into multiple groups. For 10x genomics, use CB.\nstring, default: \"CB\"\n\n\n--tag_umi\nTag representing UMIs. For 10x genomiucs, use UB.\nstring, default: \"UB\"\n\n\n--plp\nInput pileup format. If the value is a string, it will be considered as the path of the plp file. If the value is boolean true, it will perform dscpileup.\nstring\n\n\n--vcf\nInput VCF/BCF file, containing the individual genotypes (GT), posterior probability (GP), or genotype likelihood (PL).\nfile\n\n\n--field\nFORMAT field to extract the genotype, likelihood, or posterior from\nstring, default: \"GT\"\n\n\n--geno_error_offset\nOffset of genotype error rate. [error] = [offset] + [1-offset][coeff][1-r2]\ndouble, default: 0.1\n\n\n--geno_error_coeff\nSlope of genotype error rate. [error] = [offset] + [1-offset][coeff][1-r2]\ndouble, default: 0\n\n\n--r2_info\nINFO field name representing R2 value. Used for representing imputation quality.\nstring, default: \"R2\"\n\n\n--min_mac\nMinimum minor allele frequency.\ninteger, default: 1\n\n\n--min_call_rate\nMinimum call rate.\ndouble, default: 0.5\n\n\n--alpha\nGrid of alpha to search for (default is 0.1, 0.2, 0.3, 0.4, 0.5)\nstring, default: \"0.5\"\n\n\n--doublet_prior\nPrior of doublet\ndouble, default: 0.5\n\n\n--sm\nList of sample IDs to compare to (default: use all).\nstring\n\n\n--sm_list\nFile containing the list of sample IDs to compare.\nstring\n\n\n--sam_verbose\nVerbose message frequency for SAM/BAM/CRAM.\ninteger, default: 1000000\n\n\n--vcf_verbose\nVerbose message frequency for VCF/BCF.\ninteger, default: 1000\n\n\n--cap_bq\nMaximum base quality (higher BQ will be capped).\ninteger, default: 20\n\n\n--min_bq\nMinimum base quality to consider (lower BQ will be skipped).\ninteger, default: 13\n\n\n--min_mq\nMinimum mapping quality to consider (lower MQ will be ignored).\ninteger, default: 20\n\n\n--min_td\nMinimum distance to the tail (lower will be ignored).\ninteger, default: 0\n\n\n--excl_flag\nSAM/BAM FLAGs to be excluded.\ninteger, default: 3844\n\n\n--group_list\nList of tag readgroup/cell barcode to consider in this run. All other barcodes will be ignored. This is useful for parallelized run.\nstring\n\n\n--min_total\nMinimum number of total reads for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_snp\nMinimum number of SNPs with coverage for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_umi\nMinimum number of UMIs for a droplet/cell to be considered.\ninteger, default: 0\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"demux\"\n\n\n--out\ndemuxlet output file prefix\nstring, example: \"demuxlet\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Demuxlet"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/demuxlet.html#authors",
    "href": "components/modules/genetic_demux/demuxlet.html#authors",
    "title": "Demuxlet",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Demuxlet"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/samtools.html",
    "href": "components/modules/genetic_demux/samtools.html",
    "title": "Samtools",
    "section": "",
    "text": "ID: samtools\nNamespace: genetic_demux\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Samtools"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/samtools.html#example-commands",
    "href": "components/modules/genetic_demux/samtools.html#example-commands",
    "title": "Samtools",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/genetic_demux/samtools/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nbam: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/samtools/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Samtools"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/samtools.html#argument-group",
    "href": "components/modules/genetic_demux/samtools.html#argument-group",
    "title": "Samtools",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bam\nInput bam file for filtering.\nfile, required\n\n\n--output\nSamtools output directory.\nfile, example: \"samtools_out\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Samtools"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/samtools.html#authors",
    "href": "components/modules/genetic_demux/samtools.html#authors",
    "title": "Samtools",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Samtools"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/freemuxlet.html",
    "href": "components/modules/genetic_demux/freemuxlet.html",
    "title": "Freemuxlet",
    "section": "",
    "text": "ID: freemuxlet\nNamespace: genetic_demux\n\n\n\nSource\nIf external genotyping data is not available, the genotyping-free version demuxlet, freemuxlet, would be recommended",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Freemuxlet"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/freemuxlet.html#example-commands",
    "href": "components/modules/genetic_demux/freemuxlet.html#example-commands",
    "title": "Freemuxlet",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/genetic_demux/freemuxlet/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# plp: \"foo\"\n# init_cluster: \"path/to/file\"\nnsample: 2\naux_files: false\nverbose: 100\ndoublet_prior: 0.5\ngeno_error: 0.1\nbf_thres: 5.41\nfrac_init_clust: 1.0\niter_init: 10\nkeep_init_missing: false\nrandomize_singlet_score: false\nseed: 0\ncap_bq: 20\nmin_bq: 13\n# group_list: \"foo\"\nmin_total: 0\nmin_umi: 0\nmin_snp: 0\n\n# Output\n# output: \"$id.$key.output\"\n# out: \"freemuxlet\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/freemuxlet/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Freemuxlet"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/freemuxlet.html#argument-groups",
    "href": "components/modules/genetic_demux/freemuxlet.html#argument-groups",
    "title": "Freemuxlet",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--plp\nPrefix of input files generated by dsc-pileup\nstring\n\n\n--init_cluster\nInput file containing the initial cluster information.\nfile\n\n\n--nsample\nNumber of samples multiplexed together\ninteger, default: 2\n\n\n--aux_files\nTurn on writing auxilary output files\nboolean_true\n\n\n--verbose\nTurn on verbose mode with specific verbosity threshold. 0: fully verbose, 100 : no verbose messages.\ninteger, default: 100\n\n\n--doublet_prior\nPrior of doublet.\ndouble, default: 0.5\n\n\n--geno_error\nGenotype error parameter per cluster.\ndouble, default: 0.1\n\n\n--bf_thres\nBayes Factor Threshold used in the initial clustering.\ndouble, default: 5.41\n\n\n--frac_init_clust\nFraction of droplets to be clustered in the very first round of initial clustering procedure.\ndouble, default: 1\n\n\n--iter_init\nIteration for initial cluster assignment (set to zero to skip the iterations).\ninteger, default: 10\n\n\n--keep_init_missing\nKeep missing cluster assignment as missing in the initial iteration.\nboolean_true\n\n\n--randomize_singlet_score\nRandomize the singlet scores to test its effect.\nboolean_true\n\n\n--seed\nSeed for random number (use clocks if not set).\ninteger, default: 0\n\n\n--cap_bq\nMaximum base quality (higher BQ will be capped).\ninteger, default: 20\n\n\n--min_bq\nMinimum base quality to consider (lower BQ will be skipped).\ninteger, default: 13\n\n\n--group_list\nList of tag readgroup/cell barcode to consider in this run. All other barcodes will be ignored. This is useful for parallelized run.\nstring\n\n\n--min_total\nMinimum number of total reads for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_umi\nMinimum number of UMIs for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_snp\nMinimum number of SNPs with coverage for a droplet/cell to be considered.\ninteger, default: 0\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"freemux\"\n\n\n--out\nfreemuxlet Output file prefix\nstring, example: \"freemuxlet\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Freemuxlet"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/freemuxlet.html#authors",
    "href": "components/modules/genetic_demux/freemuxlet.html#authors",
    "title": "Freemuxlet",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Freemuxlet"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/souporcell.html",
    "href": "components/modules/genetic_demux/souporcell.html",
    "title": "Souporcell",
    "section": "",
    "text": "ID: souporcell\nNamespace: genetic_demux\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Souporcell"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/souporcell.html#example-commands",
    "href": "components/modules/genetic_demux/souporcell.html#example-commands",
    "title": "Souporcell",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/genetic_demux/souporcell/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# fasta: \"path/to/file\"\n# bam: \"path/to/file\"\n# bam_index: \"path/to/file\"\n# barcodes: \"path/to/file\"\n# clusters: 123\nploidy: 2\nmin_alt: 10\nmin_ref: 10\nmax_loci: 2048\n# restarts: 123\n# common_variants: \"path/to/file\"\n# known_genotypes: \"path/to/file\"\n# known_genotypes_sample_names: \"foo\"\nskip_remap: false\nignore: false\n\n# Output\n# output: \"$id.$key.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/souporcell/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Souporcell"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/souporcell.html#argument-groups",
    "href": "components/modules/genetic_demux/souporcell.html#argument-groups",
    "title": "Souporcell",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--fasta\nreference fasta file\nfile\n\n\n--bam\ncellranger bam\nfile\n\n\n--bam_index\ncellranger bam index\nfile\n\n\n--barcodes\nbarcodes.tsv from cellranger\nfile\n\n\n--clusters\nnumber cluster, tbd add easy way to run on a range of k\ninteger\n\n\n--ploidy\nploidy, must be 1 or 2\ninteger, default: 2\n\n\n--min_alt\nmin alt to use locus\ninteger, default: 10\n\n\n--min_ref\nmin ref to use locus\ninteger, default: 10\n\n\n--max_loci\nmax loci per cell, affects speed\ninteger, default: 2048\n\n\n--restarts\nnumber of restarts in clustering, when there are &gt; 12 clusters we recommend increasing this to avoid local minima\ninteger\n\n\n--common_variants\ncommon variant loci or known variant loci vcf, must be vs same reference fasta\nfile\n\n\n--known_genotypes\nknown variants per clone in population vcf mode, must be .vcf right now we dont accept gzip or bcf sorry\nfile\n\n\n--known_genotypes_sample_names\nwhich samples in population vcf from known genotypes option represent the donors in your sample\nstring\n\n\n--skip_remap\ndont remap with minimap2 (not recommended unless in conjunction with –common_variants\nboolean_true\n\n\n--ignore\nset to True to ignore data error assertions\nboolean_true\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nname of directory to place souporcell files\nfile, example: \"souporcell_out\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Souporcell"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/souporcell.html#authors",
    "href": "components/modules/genetic_demux/souporcell.html#authors",
    "title": "Souporcell",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Souporcell"
    ]
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html",
    "href": "components/modules/filter/subset_h5mu.html",
    "title": "Subset h5mu",
    "section": "",
    "text": "ID: subset_h5mu\nNamespace: filter\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Subset h5mu"
    ]
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html#example-commands",
    "href": "components/modules/filter/subset_h5mu.html#example-commands",
    "title": "Subset h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/filter/subset_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n# number_of_observations: 5\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/subset_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Subset h5mu"
    ]
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html#argument-group",
    "href": "components/modules/filter/subset_h5mu.html#argument-group",
    "title": "Subset h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--number_of_observations\nNumber of observations to be selected from the h5mu file.\ninteger, example: 5",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Subset h5mu"
    ]
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html#authors",
    "href": "components/modules/filter/subset_h5mu.html#authors",
    "title": "Subset h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Subset h5mu"
    ]
  },
  {
    "objectID": "components/modules/filter/intersect_obs.html",
    "href": "components/modules/filter/intersect_obs.html",
    "title": "Intersect obs",
    "section": "",
    "text": "ID: intersect_obs\nNamespace: filter\n\n\n\nSource\nThis component removes any observations which are not present in all modalities.",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Intersect obs"
    ]
  },
  {
    "objectID": "components/modules/filter/intersect_obs.html#example-commands",
    "href": "components/modules/filter/intersect_obs.html#example-commands",
    "title": "Intersect obs",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/filter/intersect_obs/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodalities: # please fill in - example: [\"rna\", \"prot\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/intersect_obs/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Intersect obs"
    ]
  },
  {
    "objectID": "components/modules/filter/intersect_obs.html#argument-group",
    "href": "components/modules/filter/intersect_obs.html#argument-group",
    "title": "Intersect obs",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modalities\n\nList of string, required, example: \"rna\", \"prot\", multiple_sep: \";\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Intersect obs"
    ]
  },
  {
    "objectID": "components/modules/filter/intersect_obs.html#authors",
    "href": "components/modules/filter/intersect_obs.html#authors",
    "title": "Intersect obs",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)\nIsabelle Bergiers   (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Intersect obs"
    ]
  },
  {
    "objectID": "components/modules/filter/remove_modality.html",
    "href": "components/modules/filter/remove_modality.html",
    "title": "Remove modality",
    "section": "",
    "text": "ID: remove_modality\nNamespace: filter\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Remove modality"
    ]
  },
  {
    "objectID": "components/modules/filter/remove_modality.html#example-commands",
    "href": "components/modules/filter/remove_modality.html#example-commands",
    "title": "Remove modality",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/filter/remove_modality/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: # please fill in - example: [\"foo\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/remove_modality/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Remove modality"
    ]
  },
  {
    "objectID": "components/modules/filter/remove_modality.html#argument-group",
    "href": "components/modules/filter/remove_modality.html#argument-group",
    "title": "Remove modality",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nList of string, required, multiple_sep: \";\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Remove modality"
    ]
  },
  {
    "objectID": "components/modules/filter/remove_modality.html#authors",
    "href": "components/modules/filter/remove_modality.html#authors",
    "title": "Remove modality",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Remove modality"
    ]
  },
  {
    "objectID": "components/modules/filter/subset_obsp.html",
    "href": "components/modules/filter/subset_obsp.html",
    "title": "Subset obsp",
    "section": "",
    "text": "ID: subset_obsp\nNamespace: filter\n\n\n\nSource\nThe resulting subset is moved to an .obsm slot",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Subset obsp"
    ]
  },
  {
    "objectID": "components/modules/filter/subset_obsp.html#example-commands",
    "href": "components/modules/filter/subset_obsp.html#example-commands",
    "title": "Subset obsp",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/filter/subset_obsp/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\ninput_obsp_key: # please fill in - example: \"foo\"\ninput_obs_key: # please fill in - example: \"foo\"\ninput_obs_value: # please fill in - example: \"foo\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\noutput_obsm_key: # please fill in - example: \"foo\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/subset_obsp/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Subset obsp"
    ]
  },
  {
    "objectID": "components/modules/filter/subset_obsp.html#argument-groups",
    "href": "components/modules/filter/subset_obsp.html#argument-groups",
    "title": "Subset obsp",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_obsp_key\nThe .obsp field to be filtered.\nstring, required\n\n\n--input_obs_key\nThe .obs column to filter on.\nstring, required\n\n\n--input_obs_value\nThe value to filter on in the .obs column.\nstring, required\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_obsm_key\nThe .obsm key to store the subset in.\nstring, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Subset obsp"
    ]
  },
  {
    "objectID": "components/modules/filter/subset_obsp.html#authors",
    "href": "components/modules/filter/subset_obsp.html#authors",
    "title": "Subset obsp",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Subset obsp"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/highly_variable_features_scanpy.html",
    "href": "components/modules/feature_annotation/highly_variable_features_scanpy.html",
    "title": "Highly variable features scanpy",
    "section": "",
    "text": "ID: highly_variable_features_scanpy\nNamespace: feature_annotation\n\n\n\nSource\nExpects logarithmized data, except when flavor=‘seurat_v3’ in which count data is expected.\nDepending on flavor, this reproduces the R-implementations of Seurat [Satija15], Cell Ranger [Zheng17], and Seurat v3 [Stuart19].\nFor the dispersion-based methods ([Satija15] and [Zheng17]), the normalized dispersion is obtained by scaling with the mean and standard deviation of the dispersions for features falling into a given bin for mean expression of features. This means that for each bin of mean expression, highly variable features are selected.\nFor [Stuart19], a normalized variance for each feature is computed. First, the data are standardized (i.e., z-score normalization per feature) with a regularized standard deviation. Next, the normalized variance is computed as the variance of each feature after the transformation. Features are ranked by the normalized variance.",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Highly variable features scanpy"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/highly_variable_features_scanpy.html#example-commands",
    "href": "components/modules/feature_annotation/highly_variable_features_scanpy.html#example-commands",
    "title": "Highly variable features scanpy",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/feature_annotation/highly_variable_features_scanpy/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n# var_input: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nvar_name_filter: \"filter_with_hvg\"\nvarm_name: \"hvg\"\nflavor: \"seurat\"\n# n_top_features: 123\nmin_mean: 0.0125\nmax_mean: 3.0\nmin_disp: 0.5\n# max_disp: 123.0\nspan: 0.3\nn_bins: 20\n# obs_batch_key: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/feature_annotation/highly_variable_features_scanpy/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Highly variable features scanpy"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/highly_variable_features_scanpy.html#argument-group",
    "href": "components/modules/feature_annotation/highly_variable_features_scanpy.html#argument-group",
    "title": "Highly variable features scanpy",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nuse adata.layers[layer] for expression values instead of adata.X.\nstring\n\n\n--var_input\nIf specified, use boolean array in adata.var[var_input] to calculate hvg on subset of vars.\nstring\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--var_name_filter\nIn which .var slot to store a boolean array corresponding to which observations should be filtered out.\nstring, default: \"filter_with_hvg\"\n\n\n--varm_name\nIn which .varm slot to store additional metadata.\nstring, default: \"hvg\"\n\n\n--flavor\nChoose the flavor for identifying highly variable features. For the dispersion based methods in their default workflows, Seurat passes the cutoffs whereas Cell Ranger passes n_top_features.\nstring, default: \"seurat\"\n\n\n--n_top_features\nNumber of highly-variable features to keep. Mandatory if flavor=‘seurat_v3’.\ninteger\n\n\n--min_mean\nIf n_top_features is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‘seurat_v3’.\ndouble, default: 0.0125\n\n\n--max_mean\nIf n_top_features is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‘seurat_v3’.\ndouble, default: 3\n\n\n--min_disp\nIf n_top_features is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‘seurat_v3’.\ndouble, default: 0.5\n\n\n--max_disp\nIf n_top_features is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‘seurat_v3’. Default is +inf.\ndouble\n\n\n--span\nThe fraction of the data (cells) used when estimating the variance in the loess model fit if flavor=‘seurat_v3’.\ndouble, default: 0.3\n\n\n--n_bins\nNumber of bins for binning the mean feature expression. Normalization is done with respect to each bin. If just a single feature falls into a bin, the normalized dispersion is artificially set to 1.\ninteger, default: 20\n\n\n--obs_batch_key\nIf specified, highly-variable features are selected within each batch separately and merged. This simple process avoids the selection of batch-specific features and acts as a lightweight batch correction method. For all flavors, features are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If flavor = ‘seurat_v3’, ties are broken by the median (across batches) rank based on within-batch normalized variance.\nstring",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Highly variable features scanpy"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/highly_variable_features_scanpy.html#authors",
    "href": "components/modules/feature_annotation/highly_variable_features_scanpy.html#authors",
    "title": "Highly variable features scanpy",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (contributor)\nRobrecht Cannoodt    (maintainer, contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Highly variable features scanpy"
    ]
  },
  {
    "objectID": "components/modules/integrate/scvi.html",
    "href": "components/modules/integrate/scvi.html",
    "title": "Scvi",
    "section": "",
    "text": "ID: scvi\nNamespace: integrate\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scvi"
    ]
  },
  {
    "objectID": "components/modules/integrate/scvi.html#example-commands",
    "href": "components/modules/integrate/scvi.html#example-commands",
    "title": "Scvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/integrate/scvi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\n# input_layer: \"foo\"\nobs_batch: \"sample_id\"\n# var_gene_names: \"foo\"\n# var_input: \"foo\"\n# obs_labels: \"foo\"\n# obs_size_factor: \"foo\"\n# obs_categorical_covariate: [\"foo\"]\n# obs_continuous_covariate: [\"foo\"]\n\n# Outputs\n# output: \"$id.$key.output\"\n# output_model: \"$id.$key.output_model\"\n# output_compression: \"gzip\"\nobsm_output: \"X_scvi_integrated\"\n\n# SCVI options\nn_hidden_nodes: 128\nn_dimensions_latent_space: 30\nn_hidden_layers: 2\ndropout_rate: 0.1\ndispersion: \"gene\"\ngene_likelihood: \"nb\"\n\n# Variational auto-encoder model options\nuse_layer_normalization: \"both\"\nuse_batch_normalization: \"none\"\nencode_covariates: true\ndeeply_inject_covariates: false\nuse_observed_lib_size: false\n\n# Early stopping arguments\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n\n# Learning parameters\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30.0\n\n# Data validition\nn_obs_min_count: 0\nn_var_min_count: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/scvi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scvi"
    ]
  },
  {
    "objectID": "components/modules/integrate/scvi.html#argument-groups",
    "href": "components/modules/integrate/scvi.html#argument-groups",
    "title": "Scvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer to use. If None, X is used\nstring\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--var_gene_names\n.var column containing gene names. By default, use the index.\nstring\n\n\n--var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n--obs_labels\nKey in adata.obs for label information. Categories will automatically be converted into integer categories and saved to adata.obs[’_scvi_labels’]. If None, assigns the same label to all the data.\nstring\n\n\n--obs_size_factor\nKey in adata.obs for size factor information. Instead of using library size as a size factor, the provided size factor column will be used as offset in the mean of the likelihood. Assumed to be on linear scale.\nstring\n\n\n--obs_categorical_covariate\nKeys in adata.obs that correspond to categorical data. These covariates can be added in addition to the batch covariate and are also treated as nuisance factors (i.e., the model tries to minimize their effects on the latent space). Thus, these should not be used for biologically-relevant factors that you do not want to correct for.\nList of string, multiple_sep: \";\"\n\n\n--obs_continuous_covariate\nKeys in adata.obs that correspond to continuous data. These covariates can be added in addition to the batch covariate and are also treated as nuisance factors (i.e., the model tries to minimize their effects on the latent space). Thus, these should not be used for biologically-relevant factors that you do not want to correct for.\nList of string, multiple_sep: \";\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n\n\n\nSCVI options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_hidden_nodes\nNumber of nodes per hidden layer.\ninteger, default: 128\n\n\n--n_dimensions_latent_space\nDimensionality of the latent space.\ninteger, default: 30\n\n\n--n_hidden_layers\nNumber of hidden layers used for encoder and decoder neural-networks.\ninteger, default: 2\n\n\n--dropout_rate\nDropout rate for the neural networks.\ndouble, default: 0.1\n\n\n--dispersion\nSet the behavior for the dispersion for negative binomial distributions: - gene: dispersion parameter of negative binomial is constant per gene across cells - gene-batch: dispersion can differ between different batches - gene-label: dispersion can differ between different labels - gene-cell: dispersion can differ for every gene in every cell\nstring, default: \"gene\"\n\n\n--gene_likelihood\nModel used to generate the expression data from a count-based likelihood distribution. - nb: Negative binomial distribution - zinb: Zero-inflated negative binomial distribution - poisson: Poisson distribution\nstring, default: \"nb\"\n\n\n\n\n\nVariational auto-encoder model options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--use_layer_normalization\nNeural networks for which to enable layer normalization.\nstring, default: \"both\"\n\n\n--use_batch_normalization\nNeural networks for which to enable batch normalization.\nstring, default: \"none\"\n\n\n--encode_covariates\nWhether to concatenate covariates to expression in encoder\nboolean_false\n\n\n--deeply_inject_covariates\nWhether to concatenate covariates into output of hidden layers in encoder/decoder. This option only applies when n_layers &gt; 1. The covariates are concatenated to the input of subsequent hidden layers.\nboolean_true\n\n\n--use_observed_lib_size\nUse observed library size for RNA as scaling factor in mean of conditional distribution.\nboolean_true\n\n\n\n\n\nEarly stopping arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nData validition\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_obs_min_count\nMinimum number of cells threshold ensuring that every obs_batch category has sufficient observations (cells) for model training.\ninteger, default: 0\n\n\n--n_var_min_count\nMinimum number of genes threshold ensuring that every var_input filter has sufficient observations (genes) for model training.\ninteger, default: 0",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scvi"
    ]
  },
  {
    "objectID": "components/modules/integrate/scvi.html#authors",
    "href": "components/modules/integrate/scvi.html#authors",
    "title": "Scvi",
    "section": "Authors",
    "text": "Authors\n\nMalte D. Luecken    (author)\nDries Schaumont    (maintainer)\nMatthias Beyens    (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scvi"
    ]
  },
  {
    "objectID": "components/modules/integrate/scarches.html",
    "href": "components/modules/integrate/scarches.html",
    "title": "Scarches",
    "section": "",
    "text": "ID: scarches\nNamespace: integrate\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scarches"
    ]
  },
  {
    "objectID": "components/modules/integrate/scarches.html#example-commands",
    "href": "components/modules/integrate/scarches.html#example-commands",
    "title": "Scarches",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/integrate/scarches/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\n# layer: \"foo\"\nmodality: \"rna\"\n# input_obs_batch: \"foo\"\n# input_obs_label: \"foo\"\n# input_var_gene_names: \"foo\"\n# input_obs_size_factor: \"foo\"\n\n# Reference\nreference: # please fill in - example: \"path/to/file\"\n\n# Outputs\n# output: \"$id.$key.output\"\n# output_compression: \"gzip\"\n# model_output: \"model\"\nobsm_output: \"X_integrated_scanvi\"\nobs_output_predictions: \"scanvi_pred\"\nobs_output_probabilities: \"scanvi_proba\"\n\n# Early stopping arguments\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n\n# Learning parameters\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30.0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/scarches/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scarches"
    ]
  },
  {
    "objectID": "components/modules/integrate/scarches.html#argument-groups",
    "href": "components/modules/integrate/scarches.html#argument-groups",
    "title": "Scarches",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nArguments related to the input (query) dataset\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file to use as a query\nfile, required\n\n\n--layer\nLayer to be used for scArches, if .X is not to be used.\nstring\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_obs_batch\nName of the .obs column with batch information.\nstring\n\n\n--input_obs_label\nName of the .obs column with celltype information.\nstring\n\n\n--input_var_gene_names\nName of the .var column with gene names, if the var .index is not to be used.\nstring\n\n\n--input_obs_size_factor\nKey in adata.obs for size factor information. Instead of using library size as a size factor, the provided size factor column will be used as offset in the mean of the likelihood. Assumed to be on linear scale.\nstring\n\n\n\n\n\nReference\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nPath to the directory with reference model or a web link.\nfile, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--model_output\nOutput directory for model\nfile, default: \"model\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_integrated_scanvi\"\n\n\n--obs_output_predictions\nIn which .obs slot to store the resulting label predictions. Only relevant if a scANVI model was provided.\nstring, default: \"scanvi_pred\"\n\n\n--obs_output_probabilities\nIn which .obs slot to store the probabilities of the label predictions. Only relevant if a scANVI model was provided.\nstring, default: \"scanvi_proba\"\n\n\n\n\n\nEarly stopping arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scarches"
    ]
  },
  {
    "objectID": "components/modules/integrate/scarches.html#authors",
    "href": "components/modules/integrate/scarches.html#authors",
    "title": "Scarches",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (author)\nDorien Roosen   (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scarches"
    ]
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html",
    "href": "components/modules/integrate/harmonypy.html",
    "title": "Harmonypy",
    "section": "",
    "text": "ID: harmonypy\nNamespace: integrate\n\n\n\nSource\nBased on an implementation in python from https://github.com/slowkow/harmonypy",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Harmonypy"
    ]
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html#example-commands",
    "href": "components/modules/integrate/harmonypy.html#example-commands",
    "title": "Harmonypy",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/integrate/harmonypy/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output\"\n# output_compression: \"gzip\"\nmodality: \"rna\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_pca_integrated\"\ntheta: [2.0]\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/harmonypy/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Harmonypy"
    ]
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html#argument-group",
    "href": "components/modules/integrate/harmonypy.html#argument-group",
    "title": "Harmonypy",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_input\nWhich .obsm slot to use as a starting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--theta\nDiversity clustering penalty parameter. Can be set as a single value for all batch observations or as multiple values, one for each observation in the batches defined by –obs_covariates. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.\nList of double, default: 2, multiple_sep: \";\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nList of string, required, example: \"batch\", \"sample\", multiple_sep: \";\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Harmonypy"
    ]
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html#authors",
    "href": "components/modules/integrate/harmonypy.html#authors",
    "title": "Harmonypy",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)\nRobrecht Cannoodt    (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Harmonypy"
    ]
  },
  {
    "objectID": "components/workflows/qc/qc.html",
    "href": "components/workflows/qc/qc.html",
    "title": "Qc",
    "section": "",
    "text": "ID: qc\nNamespace: workflows/qc\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Qc",
      "Qc"
    ]
  },
  {
    "objectID": "components/workflows/qc/qc.html#example-commands",
    "href": "components/workflows/qc/qc.html#example-commands",
    "title": "Qc",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/qc/qc/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\n\n# Mitochondrial & Ribosomal Gene Detection\n# var_gene_names: \"gene_symbol\"\n# var_name_mitochondrial_genes: \"foo\"\n# obs_name_mitochondrial_fraction: \"foo\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n# var_name_ribosomal_genes: \"foo\"\n# obs_name_ribosomal_fraction: \"foo\"\nribosomal_gene_regex: \"^[Mm]?[Rr][Pp][LlSs]\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc,highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\noutput_obs_num_nonzero_vars: \"num_nonzero_vars\"\noutput_obs_total_counts_vars: \"total_counts\"\noutput_var_num_nonzero_obs: \"num_nonzero_obs\"\noutput_var_total_counts_obs: \"total_counts\"\noutput_var_obs_mean: \"obs_mean\"\noutput_var_pct_dropout: \"pct_dropout\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/qc/qc/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Qc",
      "Qc"
    ]
  },
  {
    "objectID": "components/workflows/qc/qc.html#argument-groups",
    "href": "components/workflows/qc/qc.html#argument-groups",
    "title": "Qc",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--layer\nLayer to calculate qc metrics for.\nstring, example: \"raw_counts\"\n\n\n\n\n\nMitochondrial & Ribosomal Gene Detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial/ribosomal genes instead of .var_names (default if not set). Gene names matching with the regex value from –mitochondrial_gene_regex or –ribosomal_gene_regex will be identified as mitochondrial or ribosomal genes, respectively.\nstring, example: \"gene_symbol\"\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--obs_name_mitochondrial_fraction\n.Obs slot to store the fraction of reads found to be mitochondrial. Defaults to ‘fraction_’ suffixed by the value of –var_name_mitochondrial_genes\nstring\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from –var_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\"\n\n\n--var_name_ribosomal_genes\nIn which .var slot to store a boolean array corresponding the ribosomal genes.\nstring\n\n\n--obs_name_ribosomal_fraction\nWhen specified, write the fraction of counts originating from ribosomal genes (based on –ribosomal_gene_regex) to an .obs column with the specified name. Requires –var_name_ribosomal_genes.\nstring\n\n\n--ribosomal_gene_regex\nRegex string that identifies ribosomal genes from –var_gene_names. By default will detect human and mouse ribosomal genes from a gene symbol.\nstring, default: \"^[Mm]?[Rr][Pp][LlSs]\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes. Defaults to the value from –var_name_mitochondrial_genes.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n--output_obs_num_nonzero_vars\nName of column in .obs describing, for each observation, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each row the number of columns that contain data.\nstring, default: \"num_nonzero_vars\"\n\n\n--output_obs_total_counts_vars\nName of the column for .obs describing, for each observation (row), the sum of the stored values in the columns.\nstring, default: \"total_counts\"\n\n\n--output_var_num_nonzero_obs\nName of column describing, for each feature, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each column the number of rows that contain data.\nstring, default: \"num_nonzero_obs\"\n\n\n--output_var_total_counts_obs\nName of the column in .var describing, for each feature (column), the sum of the stored values in the rows.\nstring, default: \"total_counts\"\n\n\n--output_var_obs_mean\nName of the column in .obs providing the mean of the values in each row.\nstring, default: \"obs_mean\"\n\n\n--output_var_pct_dropout\nName of the column in .obs providing for each feature the percentage of observations the feature does not appear on (i.e. is missing). Same as --output_var_num_nonzero_obs but percentage based.\nstring, default: \"pct_dropout\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Qc",
      "Qc"
    ]
  },
  {
    "objectID": "components/workflows/qc/qc.html#authors",
    "href": "components/workflows/qc/qc.html#authors",
    "title": "Qc",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Qc",
      "Qc"
    ]
  },
  {
    "objectID": "components/workflows/qc/qc.html#visualisation",
    "href": "components/workflows/qc/qc.html#visualisation",
    "title": "Qc",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v14(branch)\n    v41(concat)\n    v19(grep_mitochondrial_genes)\n    v26(cross)\n    v36(cross)\n    v45(branch)\n    v72(concat)\n    v50(grep_ribosomal_genes)\n    v57(cross)\n    v67(cross)\n    v73(filter)\n    v103(concat)\n    v81(calculate_qc_metrics)\n    v88(cross)\n    v98(cross)\n    v110(cross)\n    v117(cross)\n    v129(cross)\n    v136(cross)\n    v140(Output)\n    v14--&gt;v41\n    v45--&gt;v72\n    v72--&gt;v73\n    v0--&gt;v2\n    v14--&gt;v19\n    v19--&gt;v26\n    v14--&gt;v26\n    v14--&gt;v36\n    v36--&gt;v41\n    v45--&gt;v50\n    v50--&gt;v57\n    v45--&gt;v57\n    v45--&gt;v67\n    v67--&gt;v72\n    v73--&gt;v81\n    v81--&gt;v88\n    v73--&gt;v88\n    v73--&gt;v98\n    v98--&gt;v103\n    v103--&gt;v110\n    v2--&gt;v110\n    v110--&gt;v117\n    v2--&gt;v117\n    v2--&gt;v129\n    v129--&gt;v136\n    v2--&gt;v136\n    v136--&gt;v140\n    v2--&gt;v14\n    v19--&gt;v36\n    v41--&gt;v45\n    v50--&gt;v67\n    v81--&gt;v98\n    v103--&gt;v129\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v14 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v19 fill:#e3dcea,stroke:#7a4baa;\n    style v26 fill:#e3dcea,stroke:#7a4baa;\n    style v36 fill:#e3dcea,stroke:#7a4baa;\n    style v45 fill:#e3dcea,stroke:#7a4baa;\n    style v72 fill:#e3dcea,stroke:#7a4baa;\n    style v50 fill:#e3dcea,stroke:#7a4baa;\n    style v57 fill:#e3dcea,stroke:#7a4baa;\n    style v67 fill:#e3dcea,stroke:#7a4baa;\n    style v73 fill:#e3dcea,stroke:#7a4baa;\n    style v103 fill:#e3dcea,stroke:#7a4baa;\n    style v81 fill:#e3dcea,stroke:#7a4baa;\n    style v88 fill:#e3dcea,stroke:#7a4baa;\n    style v98 fill:#e3dcea,stroke:#7a4baa;\n    style v110 fill:#e3dcea,stroke:#7a4baa;\n    style v117 fill:#e3dcea,stroke:#7a4baa;\n    style v129 fill:#e3dcea,stroke:#7a4baa;\n    style v136 fill:#e3dcea,stroke:#7a4baa;\n    style v140 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Qc",
      "Qc"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/demux.html",
    "href": "components/workflows/ingestion/demux.html",
    "title": "Demux",
    "section": "",
    "text": "ID: demux\nNamespace: workflows/ingestion\n\n\n\nSource\nConvert .bcl files to .fastq files using bcl2fastq, bcl-convert or Cell Ranger mkfastq.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Demux"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#example-commands",
    "href": "components/workflows/ingestion/demux.html#example-commands",
    "title": "Demux",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/ingestion/demux/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"bcl_dir\"\nsample_sheet: # please fill in - example: \"bcl_dir\"\ndemultiplexer: \"bcl2fastq\"\n# ignore_missing: true\n# output_fastq: \"$id.$key.output_fastq\"\n# output_fastqc: \"$id.$key.output_fastqc\"\n# output_multiqc: \"$id.$key.output_multiqc\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/ingestion/demux/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Demux"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#argument-group",
    "href": "components/workflows/ingestion/demux.html#argument-group",
    "title": "Demux",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput run directory\nfile, required, example: \"bcl_dir\"\n\n\n--sample_sheet\nPointer to the sample sheet\nfile, required, example: \"bcl_dir\"\n\n\n--demultiplexer\nThe multiplexer to use, one of bclconvert or mkfastq\nstring, default: \"bcl2fastq\"\n\n\n--ignore_missing\nShould the demultiplexer ignore missing entities (filter, …)\nboolean\n\n\n--output_fastq\nOutput directory containig fastq files\nfile, required, example: \"fastq_dir\"\n\n\n--output_fastqc\nReports directory produced by FastQC\nfile, example: \"reports_dir\"\n\n\n--output_multiqc\nReports directory produced by MultiQC\nfile, example: \"reports_dir\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Demux"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#authors",
    "href": "components/workflows/ingestion/demux.html#authors",
    "title": "Demux",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (author, maintainer)\nMarijke Van Moerbeke    (author)\nAngela Oliveira Pisco    (author)\nSamuel D’Souza   (author)\nRobrecht Cannoodt    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Demux"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#visualisation",
    "href": "components/workflows/ingestion/demux.html#visualisation",
    "title": "Demux",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v12(filter)\n    v20(cellranger_mkfastq)\n    v27(cross)\n    v37(cross)\n    v117(mix)\n    v48(filter)\n    v56(bcl_convert)\n    v63(cross)\n    v73(cross)\n    v84(filter)\n    v92(bcl2fastq)\n    v99(cross)\n    v109(cross)\n    v118(filter)\n    v126(fastqc)\n    v133(cross)\n    v143(cross)\n    v149(filter)\n    v179(concat)\n    v157(multiqc)\n    v164(cross)\n    v174(cross)\n    v186(cross)\n    v193(cross)\n    v205(cross)\n    v212(cross)\n    v216(Output)\n    v117--&gt;v118\n    v0--&gt;v2\n    v12--&gt;v20\n    v20--&gt;v27\n    v12--&gt;v27\n    v12--&gt;v37\n    v48--&gt;v56\n    v56--&gt;v63\n    v48--&gt;v63\n    v48--&gt;v73\n    v84--&gt;v92\n    v92--&gt;v99\n    v84--&gt;v99\n    v84--&gt;v109\n    v118--&gt;v126\n    v126--&gt;v133\n    v118--&gt;v133\n    v118--&gt;v143\n    v149--&gt;v157\n    v157--&gt;v164\n    v149--&gt;v164\n    v149--&gt;v174\n    v174--&gt;v179\n    v179--&gt;v186\n    v2--&gt;v186\n    v186--&gt;v193\n    v2--&gt;v193\n    v2--&gt;v205\n    v205--&gt;v212\n    v2--&gt;v212\n    v212--&gt;v216\n    v2--&gt;v12\n    v37--&gt;v117\n    v20--&gt;v37\n    v2--&gt;v48\n    v73--&gt;v117\n    v56--&gt;v73\n    v2--&gt;v84\n    v109--&gt;v117\n    v92--&gt;v109\n    v143--&gt;v149\n    v126--&gt;v143\n    v157--&gt;v174\n    v179--&gt;v205\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v12 fill:#e3dcea,stroke:#7a4baa;\n    style v20 fill:#e3dcea,stroke:#7a4baa;\n    style v27 fill:#e3dcea,stroke:#7a4baa;\n    style v37 fill:#e3dcea,stroke:#7a4baa;\n    style v117 fill:#e3dcea,stroke:#7a4baa;\n    style v48 fill:#e3dcea,stroke:#7a4baa;\n    style v56 fill:#e3dcea,stroke:#7a4baa;\n    style v63 fill:#e3dcea,stroke:#7a4baa;\n    style v73 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v92 fill:#e3dcea,stroke:#7a4baa;\n    style v99 fill:#e3dcea,stroke:#7a4baa;\n    style v109 fill:#e3dcea,stroke:#7a4baa;\n    style v118 fill:#e3dcea,stroke:#7a4baa;\n    style v126 fill:#e3dcea,stroke:#7a4baa;\n    style v133 fill:#e3dcea,stroke:#7a4baa;\n    style v143 fill:#e3dcea,stroke:#7a4baa;\n    style v149 fill:#e3dcea,stroke:#7a4baa;\n    style v179 fill:#e3dcea,stroke:#7a4baa;\n    style v157 fill:#e3dcea,stroke:#7a4baa;\n    style v164 fill:#e3dcea,stroke:#7a4baa;\n    style v174 fill:#e3dcea,stroke:#7a4baa;\n    style v186 fill:#e3dcea,stroke:#7a4baa;\n    style v193 fill:#e3dcea,stroke:#7a4baa;\n    style v205 fill:#e3dcea,stroke:#7a4baa;\n    style v212 fill:#e3dcea,stroke:#7a4baa;\n    style v216 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Demux"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html",
    "href": "components/workflows/ingestion/make_reference.html",
    "title": "Make reference",
    "section": "",
    "text": "ID: make_reference\nNamespace: workflows/ingestion\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Make reference"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#example-commands",
    "href": "components/workflows/ingestion/make_reference.html#example-commands",
    "title": "Make reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/ingestion/make_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ngenome_fasta: # please fill in - example: \"https:/ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"https:/ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz\"\n# ercc: \"https:/assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip\"\n\n# STAR Settings\nstar_genome_sa_index_nbases: 14\n\n# BD Rhapsody Settings\nbdrhap_mitochondrial_contigs: [\"chrM\", \"chrMT\", \"M\", \"MT\"]\nbdrhap_filtering_off: false\nbdrhap_wta_only_index: false\n# bdrhap_extra_star_params: \"--limitGenomeGenerateRAM 48000 --genomeSAindexNbases 11\"\n\n# Cellranger ARC options\n# motifs_file: \"path/to/file\"\n# non_nuclear_contigs: [\"foo\"]\n\n# Outputs\ntarget: [\"star\"]\n# output_fasta: \"$id.$key.output_fasta.gz\"\n# output_gtf: \"$id.$key.output_gtf.gz\"\n# output_cellranger: \"$id.$key.output_cellranger.gz\"\n# output_cellranger_arc: \"$id.$key.output_cellranger_arc.gz\"\n# output_bd_rhapsody: \"$id.$key.output_bd_rhapsody.gz\"\n# output_star: \"$id.$key.output_star.gz\"\n\n# Arguments\n# subset_regex: \"(ERCC-00002|chr1)\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/ingestion/make_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Make reference"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#argument-groups",
    "href": "components/workflows/ingestion/make_reference.html#argument-groups",
    "title": "Make reference",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the reference.\nstring, required, example: \"foo\"\n\n\n--genome_fasta\nReference genome fasta.\nfile, required, example: \"https:/ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"https:/ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz\"\n\n\n--ercc\nERCC sequence and annotation file.\nfile, example: \"https:/assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip\"\n\n\n\n\n\nSTAR Settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--star_genome_sa_index_nbases\nLength (bases) of the SA pre-indexing string. Typically between 10 and 15. Longer strings will use much more memory, but allow faster searches. For small genomes, the parameter {genomeSAindexNbases must be scaled down to min(14, log2(GenomeLength)/2 - 1).\ninteger, default: 14\n\n\n\n\n\nBD Rhapsody Settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bdrhap_mitochondrial_contigs\nNames of the Mitochondrial contigs in the provided Reference Genome. Fragments originating from contigs other than these are identified as ‘nuclear fragments’ in the ATACseq analysis pipeline.\nList of string, default: \"chrM\", \"chrMT\", \"M\", \"MT\", multiple_sep: \";\"\n\n\n--bdrhap_filtering_off\nBy default the input Transcript Annotation files are filtered based on the gene_type/gene_biotype attribute. Only features having the following attribute values are kept: - protein_coding - lncRNA - IG_LV_gene - IG_V_gene - IG_V_pseudogene - IG_D_gene - IG_J_gene - IG_J_pseudogene - IG_C_gene - IG_C_pseudogene - TR_V_gene - TR_V_pseudogene - TR_D_gene - TR_J_gene - TR_J_pseudogene - TR_C_gene If you have already pre-filtered the input Annotation files and/or wish to turn-off the filtering, please set this option to True.\nboolean_true\n\n\n--bdrhap_wta_only_index\nBuild a WTA only index, otherwise builds a WTA + ATAC index.\nboolean_true\n\n\n--bdrhap_extra_star_params\nAdditional parameters to pass to STAR when building the genome index. Specify exactly like how you would on the command line.\nstring, example: \"--limitGenomeGenerateRAM 48000 --genomeSAindexNbases 11\"\n\n\n\n\n\nCellranger ARC options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--motifs_file\nPath to file containing transcription factor motifs in JASPAR format.\nfile\n\n\n--non_nuclear_contigs\nName(s) of contig(s) that do not have any chromatin structure, for example, mitochondria or plastids. These contigs are excluded from peak calling since the entire contig will be “open” due to a lack of chromatin structure. Leave empty if there are no such contigs.\nList of string, multiple_sep: \";\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--target\nWhich reference indices to generate.\nList of string, default: \"star\", multiple_sep: \";\"\n\n\n--output_fasta\nOutput genome sequence fasta.\nfile, example: \"genome_sequence.fa.gz\"\n\n\n--output_gtf\nOutput transcriptome annotation gtf.\nfile, example: \"transcriptome_annotation.gtf.gz\"\n\n\n--output_cellranger\nOutput index\nfile, example: \"cellranger_index.tar.gz\"\n\n\n--output_cellranger_arc\nOutput index\nfile, example: \"cellranger_index_arc.tar.gz\"\n\n\n--output_bd_rhapsody\nOutput index\nfile, example: \"bdrhap_index.tar.gz\"\n\n\n--output_star\nOutput index\nfile, example: \"star_index.tar.gz\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--subset_regex\nWill subset the reference chromosomes using the given regex.\nstring, example: \"(ERCC-00002&#124;chr1)\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Make reference"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#authors",
    "href": "components/workflows/ingestion/make_reference.html#authors",
    "title": "Make reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Make reference"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#visualisation",
    "href": "components/workflows/ingestion/make_reference.html#visualisation",
    "title": "Make reference",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(make_reference_component)\n    v25(cross)\n    v35(cross)\n    v44(branch)\n    v71(concat)\n    v49(build_cellranger_arc_reference)\n    v56(cross)\n    v66(cross)\n    v75(branch)\n    v102(concat)\n    v80(build_cellranger_reference)\n    v87(cross)\n    v97(cross)\n    v106(branch)\n    v133(concat)\n    v111(build_star_reference)\n    v118(cross)\n    v128(cross)\n    v137(branch)\n    v164(concat)\n    v142(build_bdrhap_reference)\n    v149(cross)\n    v159(cross)\n    v171(cross)\n    v178(cross)\n    v190(cross)\n    v197(cross)\n    v201(Output)\n    v44--&gt;v71\n    v75--&gt;v102\n    v106--&gt;v133\n    v137--&gt;v164\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v44--&gt;v49\n    v49--&gt;v56\n    v44--&gt;v56\n    v44--&gt;v66\n    v66--&gt;v71\n    v75--&gt;v80\n    v80--&gt;v87\n    v75--&gt;v87\n    v75--&gt;v97\n    v97--&gt;v102\n    v106--&gt;v111\n    v111--&gt;v118\n    v106--&gt;v118\n    v106--&gt;v128\n    v128--&gt;v133\n    v137--&gt;v142\n    v142--&gt;v149\n    v137--&gt;v149\n    v137--&gt;v159\n    v159--&gt;v164\n    v164--&gt;v171\n    v2--&gt;v171\n    v171--&gt;v178\n    v2--&gt;v178\n    v2--&gt;v190\n    v190--&gt;v197\n    v2--&gt;v197\n    v197--&gt;v201\n    v18--&gt;v35\n    v35--&gt;v44\n    v49--&gt;v66\n    v71--&gt;v75\n    v80--&gt;v97\n    v102--&gt;v106\n    v111--&gt;v128\n    v133--&gt;v137\n    v142--&gt;v159\n    v164--&gt;v190\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v44 fill:#e3dcea,stroke:#7a4baa;\n    style v71 fill:#e3dcea,stroke:#7a4baa;\n    style v49 fill:#e3dcea,stroke:#7a4baa;\n    style v56 fill:#e3dcea,stroke:#7a4baa;\n    style v66 fill:#e3dcea,stroke:#7a4baa;\n    style v75 fill:#e3dcea,stroke:#7a4baa;\n    style v102 fill:#e3dcea,stroke:#7a4baa;\n    style v80 fill:#e3dcea,stroke:#7a4baa;\n    style v87 fill:#e3dcea,stroke:#7a4baa;\n    style v97 fill:#e3dcea,stroke:#7a4baa;\n    style v106 fill:#e3dcea,stroke:#7a4baa;\n    style v133 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v118 fill:#e3dcea,stroke:#7a4baa;\n    style v128 fill:#e3dcea,stroke:#7a4baa;\n    style v137 fill:#e3dcea,stroke:#7a4baa;\n    style v164 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v149 fill:#e3dcea,stroke:#7a4baa;\n    style v159 fill:#e3dcea,stroke:#7a4baa;\n    style v171 fill:#e3dcea,stroke:#7a4baa;\n    style v178 fill:#e3dcea,stroke:#7a4baa;\n    style v190 fill:#e3dcea,stroke:#7a4baa;\n    style v197 fill:#e3dcea,stroke:#7a4baa;\n    style v201 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Make reference"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html",
    "href": "components/workflows/ingestion/cellranger_mapping.html",
    "title": "Cell Ranger mapping",
    "section": "",
    "text": "ID: cellranger_mapping\nNamespace: workflows/ingestion\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger mapping"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#example-commands",
    "href": "components/workflows/ingestion/cellranger_mapping.html#example-commands",
    "title": "Cell Ranger mapping",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/ingestion/cellranger_mapping/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"reference.tar.gz\"\n\n# Outputs\n# output_raw: \"$id.$key.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\nuns_metrics: \"metrics_summary\"\noutput_type: \"raw\"\n\n# Cell Ranger arguments\n# expect_cells: 3000\nchemistry: \"auto\"\nsecondary_analysis: false\ngenerate_bam: true\ninclude_introns: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/ingestion/cellranger_mapping/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger mapping"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#argument-groups",
    "href": "components/workflows/ingestion/cellranger_mapping.html#argument-groups",
    "title": "Cell Ranger mapping",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, required, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nThe path to Cell Ranger reference tar.gz file.\nfile, required, example: \"reference.tar.gz\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nLocation where the output folder from Cell Ranger will be stored.\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nThe output from Cell Ranger, converted to h5mu.\nfile, required, example: \"output.h5mu\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_summary\"\n\n\n--output_type\nWhich Cell Ranger output to use for converting to h5mu.\nstring, default: \"raw\"\n\n\n\n\n\nCell Ranger arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3’ - fiveprime: Single Cell 5’ - SC3Pv1: Single Cell 3’ v1 - SC3Pv2: Single Cell 3’ v2 - SC3Pv3: Single Cell 3’ v3 - SC3Pv3LT: Single Cell 3’ v3 LT - SC3Pv3HT: Single Cell 3’ v3 HT - SC5P-PE: Single Cell 5’ paired-end - SC5P-R2: Single Cell 5’ R2-only - SC-FB: Single Cell Antibody-only 3’ v2 or 5’ See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--secondary_analysis\nWhether or not to run the secondary analysis e.g. clustering.\nboolean, default: FALSE\n\n\n--generate_bam\nWhether to generate a BAM file.\nboolean, default: TRUE\n\n\n--include_introns\nInclude intronic reads in count (default=true unless –target-panel is specified in which case default=false)\nboolean, default: TRUE",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger mapping"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#authors",
    "href": "components/workflows/ingestion/cellranger_mapping.html#authors",
    "title": "Cell Ranger mapping",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)\nDries De Maeyer   (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger mapping"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#visualisation",
    "href": "components/workflows/ingestion/cellranger_mapping.html#visualisation",
    "title": "Cell Ranger mapping",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v9(filter)\n    v17(cellranger_count)\n    v24(cross)\n    v34(cross)\n    v40(filter)\n    v48(cellranger_count_split)\n    v55(cross)\n    v65(cross)\n    v71(filter)\n    v101(concat)\n    v79(from_10xh5_to_h5mu)\n    v86(cross)\n    v96(cross)\n    v108(cross)\n    v115(cross)\n    v127(cross)\n    v134(cross)\n    v138(Output)\n    v0--&gt;v2\n    v2--&gt;v9\n    v9--&gt;v17\n    v17--&gt;v24\n    v9--&gt;v24\n    v9--&gt;v34\n    v40--&gt;v48\n    v48--&gt;v55\n    v40--&gt;v55\n    v40--&gt;v65\n    v71--&gt;v79\n    v79--&gt;v86\n    v71--&gt;v86\n    v71--&gt;v96\n    v96--&gt;v101\n    v101--&gt;v108\n    v2--&gt;v108\n    v108--&gt;v115\n    v2--&gt;v115\n    v2--&gt;v127\n    v127--&gt;v134\n    v2--&gt;v134\n    v134--&gt;v138\n    v34--&gt;v40\n    v17--&gt;v34\n    v65--&gt;v71\n    v48--&gt;v65\n    v79--&gt;v96\n    v101--&gt;v127\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v9 fill:#e3dcea,stroke:#7a4baa;\n    style v17 fill:#e3dcea,stroke:#7a4baa;\n    style v24 fill:#e3dcea,stroke:#7a4baa;\n    style v34 fill:#e3dcea,stroke:#7a4baa;\n    style v40 fill:#e3dcea,stroke:#7a4baa;\n    style v48 fill:#e3dcea,stroke:#7a4baa;\n    style v55 fill:#e3dcea,stroke:#7a4baa;\n    style v65 fill:#e3dcea,stroke:#7a4baa;\n    style v71 fill:#e3dcea,stroke:#7a4baa;\n    style v101 fill:#e3dcea,stroke:#7a4baa;\n    style v79 fill:#e3dcea,stroke:#7a4baa;\n    style v86 fill:#e3dcea,stroke:#7a4baa;\n    style v96 fill:#e3dcea,stroke:#7a4baa;\n    style v108 fill:#e3dcea,stroke:#7a4baa;\n    style v115 fill:#e3dcea,stroke:#7a4baa;\n    style v127 fill:#e3dcea,stroke:#7a4baa;\n    style v134 fill:#e3dcea,stroke:#7a4baa;\n    style v138 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger mapping"
    ]
  },
  {
    "objectID": "components/workflows/prot/prot_singlesample.html",
    "href": "components/workflows/prot/prot_singlesample.html",
    "title": "Prot singlesample",
    "section": "",
    "text": "ID: prot_singlesample\nNamespace: workflows/prot\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Prot",
      "Prot singlesample"
    ]
  },
  {
    "objectID": "components/workflows/prot/prot_singlesample.html#example-commands",
    "href": "components/workflows/prot/prot_singlesample.html#example-commands",
    "title": "Prot singlesample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/prot/prot_singlesample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n# layer: \"foo\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering options\n# min_counts: 200\n# max_counts: 5000000\n# min_proteins_per_cell: 200\n# max_proteins_per_cell: 1500000\n# min_cells_per_protein: 3\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/prot/prot_singlesample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Prot",
      "Prot singlesample"
    ]
  },
  {
    "objectID": "components/workflows/prot/prot_singlesample.html#argument-groups",
    "href": "components/workflows/prot/prot_singlesample.html#argument-groups",
    "title": "Prot singlesample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nInput layer to start from. By default, .X will be used.\nstring\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_proteins_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_proteins_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_protein\nMinimum of non-zero values per gene.\ninteger, example: 3",
    "crumbs": [
      "Reference",
      "Workflows",
      "Prot",
      "Prot singlesample"
    ]
  },
  {
    "objectID": "components/workflows/prot/prot_singlesample.html#authors",
    "href": "components/workflows/prot/prot_singlesample.html#authors",
    "title": "Prot singlesample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Prot",
      "Prot singlesample"
    ]
  },
  {
    "objectID": "components/workflows/prot/prot_singlesample.html#visualisation",
    "href": "components/workflows/prot/prot_singlesample.html#visualisation",
    "title": "Prot singlesample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(prot_filter_with_counts)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v71(concat)\n    v49(prot_do_filter)\n    v56(cross)\n    v66(cross)\n    v78(cross)\n    v85(cross)\n    v97(cross)\n    v104(cross)\n    v108(Output)\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v49\n    v49--&gt;v56\n    v41--&gt;v56\n    v41--&gt;v66\n    v66--&gt;v71\n    v71--&gt;v78\n    v2--&gt;v78\n    v78--&gt;v85\n    v2--&gt;v85\n    v2--&gt;v97\n    v97--&gt;v104\n    v2--&gt;v104\n    v104--&gt;v108\n    v35--&gt;v41\n    v18--&gt;v35\n    v49--&gt;v66\n    v71--&gt;v97\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v71 fill:#e3dcea,stroke:#7a4baa;\n    style v49 fill:#e3dcea,stroke:#7a4baa;\n    style v56 fill:#e3dcea,stroke:#7a4baa;\n    style v66 fill:#e3dcea,stroke:#7a4baa;\n    style v78 fill:#e3dcea,stroke:#7a4baa;\n    style v85 fill:#e3dcea,stroke:#7a4baa;\n    style v97 fill:#e3dcea,stroke:#7a4baa;\n    style v104 fill:#e3dcea,stroke:#7a4baa;\n    style v108 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Prot",
      "Prot singlesample"
    ]
  },
  {
    "objectID": "components/workflows/gdo/gdo_singlesample.html",
    "href": "components/workflows/gdo/gdo_singlesample.html",
    "title": "GDO Singlesample",
    "section": "",
    "text": "ID: gdo_singlesample\nNamespace: workflows/gdo\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Gdo",
      "GDO Singlesample"
    ]
  },
  {
    "objectID": "components/workflows/gdo/gdo_singlesample.html#example-commands",
    "href": "components/workflows/gdo/gdo_singlesample.html#example-commands",
    "title": "GDO Singlesample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/gdo/gdo_singlesample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n# layer: \"foo\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering options\n# min_counts: 200\n# max_counts: 5000000\n# min_guides_per_cell: 200\n# max_guides_per_cell: 1500000\n# min_cells_per_guide: 3\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/gdo/gdo_singlesample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Gdo",
      "GDO Singlesample"
    ]
  },
  {
    "objectID": "components/workflows/gdo/gdo_singlesample.html#argument-groups",
    "href": "components/workflows/gdo/gdo_singlesample.html#argument-groups",
    "title": "GDO Singlesample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nInput layer to start from. By default, .X will be used.\nstring\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_guides_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_guides_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_guide\nMinimum of non-zero values per gene.\ninteger, example: 3",
    "crumbs": [
      "Reference",
      "Workflows",
      "Gdo",
      "GDO Singlesample"
    ]
  },
  {
    "objectID": "components/workflows/gdo/gdo_singlesample.html#authors",
    "href": "components/workflows/gdo/gdo_singlesample.html#authors",
    "title": "GDO Singlesample",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Gdo",
      "GDO Singlesample"
    ]
  },
  {
    "objectID": "components/workflows/gdo/gdo_singlesample.html#visualisation",
    "href": "components/workflows/gdo/gdo_singlesample.html#visualisation",
    "title": "GDO Singlesample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(gdo_filter_with_counts)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v71(concat)\n    v49(gdo_do_filter)\n    v56(cross)\n    v66(cross)\n    v78(cross)\n    v85(cross)\n    v97(cross)\n    v104(cross)\n    v108(Output)\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v49\n    v49--&gt;v56\n    v41--&gt;v56\n    v41--&gt;v66\n    v66--&gt;v71\n    v71--&gt;v78\n    v2--&gt;v78\n    v78--&gt;v85\n    v2--&gt;v85\n    v2--&gt;v97\n    v97--&gt;v104\n    v2--&gt;v104\n    v104--&gt;v108\n    v35--&gt;v41\n    v18--&gt;v35\n    v49--&gt;v66\n    v71--&gt;v97\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v71 fill:#e3dcea,stroke:#7a4baa;\n    style v49 fill:#e3dcea,stroke:#7a4baa;\n    style v56 fill:#e3dcea,stroke:#7a4baa;\n    style v66 fill:#e3dcea,stroke:#7a4baa;\n    style v78 fill:#e3dcea,stroke:#7a4baa;\n    style v85 fill:#e3dcea,stroke:#7a4baa;\n    style v97 fill:#e3dcea,stroke:#7a4baa;\n    style v104 fill:#e3dcea,stroke:#7a4baa;\n    style v108 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Gdo",
      "GDO Singlesample"
    ]
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden.html",
    "href": "components/workflows/integration/scanorama_leiden.html",
    "title": "Scanorama leiden",
    "section": "",
    "text": "ID: scanorama_leiden\nNamespace: workflows/integration\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scanorama leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden.html#example-commands",
    "href": "components/workflows/integration/scanorama_leiden.html#example-commands",
    "title": "Scanorama leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/integration/scanorama_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"scanorama_integration_neighbors\"\nobsp_neighbor_distances: \"scanorama_integration_distances\"\nobsp_neighbor_connectivities: \"scanorama_integration_connectivities\"\n\n# Scanorama integration options\nobs_batch: \"sample_id\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_scanorama\"\nknn: 20\nbatch_size: 5000\nsigma: 15.0\napprox: true\nalpha: 0.1\n\n# Clustering options\nobs_cluster: \"scanorama_integration_leiden\"\nleiden_resolution: [1.0]\n\n# Umap options\nobsm_umap: \"X_leiden_scanorama_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/integration/scanorama_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scanorama leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden.html#argument-groups",
    "href": "components/workflows/integration/scanorama_leiden.html#argument-groups",
    "title": "Scanorama leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scanorama_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_connectivities\"\n\n\n\n\n\nScanorama integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--obsm_input\n.obsm slot that points to embedding to run scanorama on.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nThe name of the field in adata.obsm where the integrated embeddings will be stored after running this function. Defaults to X_scanorama.\nstring, default: \"X_scanorama\"\n\n\n--knn\nNumber of nearest neighbors to use for matching.\ninteger, default: 20\n\n\n--batch_size\nThe batch size used in the alignment vector computation. Useful when integrating very large (&gt;100k samples) datasets. Set to large value that runs within available memory.\ninteger, default: 5000\n\n\n--sigma\nCorrection smoothing parameter on Gaussian kernel.\ndouble, default: 15\n\n\n--approx\nUse approximate nearest neighbors with Python annoy; greatly speeds up matching runtime.\nboolean, default: TRUE\n\n\n--alpha\nAlignment score minimum cutoff\ndouble, default: 0.1\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions specified in ‘–leiden_resolution’.\nstring, default: \"scanorama_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_scanorama_umap\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scanorama leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden.html#authors",
    "href": "components/workflows/integration/scanorama_leiden.html#authors",
    "title": "Scanorama leiden",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scanorama leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden.html#visualisation",
    "href": "components/workflows/integration/scanorama_leiden.html#visualisation",
    "title": "Scanorama leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(scanorama)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v195(concat)\n    v50(filter)\n    v65(cross)\n    v75(cross)\n    v84(branch)\n    v111(concat)\n    v96(cross)\n    v106(cross)\n    v115(branch)\n    v142(concat)\n    v127(cross)\n    v137(cross)\n    v146(branch)\n    v173(concat)\n    v158(cross)\n    v168(cross)\n    v180(cross)\n    v190(cross)\n    v202(cross)\n    v209(cross)\n    v221(cross)\n    v228(cross)\n    v232(Output)\n    subgraph group_neighbors_leiden_umap [neighbors_leiden_umap]\n        v58(find_neighbors)\n        v89(leiden)\n        v120(move_obsm_to_obs)\n        v151(umap)\n    end\n    v84--&gt;v111\n    v115--&gt;v142\n    v146--&gt;v173\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v50\n    v50--&gt;v58\n    v58--&gt;v65\n    v50--&gt;v65\n    v50--&gt;v75\n    v84--&gt;v89\n    v89--&gt;v96\n    v84--&gt;v96\n    v84--&gt;v106\n    v106--&gt;v111\n    v115--&gt;v120\n    v120--&gt;v127\n    v115--&gt;v127\n    v115--&gt;v137\n    v137--&gt;v142\n    v146--&gt;v151\n    v151--&gt;v158\n    v146--&gt;v158\n    v146--&gt;v168\n    v168--&gt;v173\n    v173--&gt;v180\n    v41--&gt;v180\n    v41--&gt;v190\n    v190--&gt;v195\n    v195--&gt;v202\n    v2--&gt;v202\n    v202--&gt;v209\n    v2--&gt;v209\n    v2--&gt;v221\n    v221--&gt;v228\n    v2--&gt;v228\n    v228--&gt;v232\n    v35--&gt;v41\n    v18--&gt;v35\n    v58--&gt;v75\n    v75--&gt;v84\n    v89--&gt;v106\n    v111--&gt;v115\n    v120--&gt;v137\n    v142--&gt;v146\n    v151--&gt;v168\n    v173--&gt;v190\n    v195--&gt;v221\n    style group_neighbors_leiden_umap fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v195 fill:#e3dcea,stroke:#7a4baa;\n    style v50 fill:#e3dcea,stroke:#7a4baa;\n    style v58 fill:#e3dcea,stroke:#7a4baa;\n    style v65 fill:#e3dcea,stroke:#7a4baa;\n    style v75 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v89 fill:#e3dcea,stroke:#7a4baa;\n    style v96 fill:#e3dcea,stroke:#7a4baa;\n    style v106 fill:#e3dcea,stroke:#7a4baa;\n    style v115 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v120 fill:#e3dcea,stroke:#7a4baa;\n    style v127 fill:#e3dcea,stroke:#7a4baa;\n    style v137 fill:#e3dcea,stroke:#7a4baa;\n    style v146 fill:#e3dcea,stroke:#7a4baa;\n    style v173 fill:#e3dcea,stroke:#7a4baa;\n    style v151 fill:#e3dcea,stroke:#7a4baa;\n    style v158 fill:#e3dcea,stroke:#7a4baa;\n    style v168 fill:#e3dcea,stroke:#7a4baa;\n    style v180 fill:#e3dcea,stroke:#7a4baa;\n    style v190 fill:#e3dcea,stroke:#7a4baa;\n    style v202 fill:#e3dcea,stroke:#7a4baa;\n    style v209 fill:#e3dcea,stroke:#7a4baa;\n    style v221 fill:#e3dcea,stroke:#7a4baa;\n    style v228 fill:#e3dcea,stroke:#7a4baa;\n    style v232 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scanorama leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scgpt_leiden.html",
    "href": "components/workflows/integration/scgpt_leiden.html",
    "title": "Scgpt leiden",
    "section": "",
    "text": "ID: scgpt_leiden\nNamespace: workflows/integration\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scgpt leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scgpt_leiden.html#example-commands",
    "href": "components/workflows/integration/scgpt_leiden.html#example-commands",
    "title": "Scgpt leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/integration/scgpt_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# var_gene_names: \"foo\"\n# obs_batch_label: \"foo\"\n\n# Model\nmodel: # please fill in - example: \"resources_test/scgpt/best_model.pt\"\nmodel_vocab: # please fill in - example: \"resources_test/scgpt/vocab.json\"\nmodel_config: # please fill in - example: \"args.json\"\n# finetuned_checkpoints_key: \"model_state_dict\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\nobsm_integrated: \"X_scgpt\"\n\n# Padding arguments\npad_token: \"&lt;pad&gt;\"\npad_value: -2\n\n# HVG subset arguments\nn_hvg: 1200\nhvg_flavor: \"cell_ranger\"\n\n# Tokenization arguments\n# max_seq_len: 123\n\n# Embedding arguments\ndsbn: true\nbatch_size: 64\n\n# Binning arguments\nn_input_bins: 51\n# seed: 123\n\n# Clustering arguments\nleiden_resolution: [1.0]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/integration/scgpt_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scgpt leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scgpt_leiden.html#argument-groups",
    "href": "components/workflows/integration/scgpt_leiden.html#argument-groups",
    "title": "Scgpt leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the input file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nThe layer of the input dataset to process if .X is not to be used. Should contain log normalized counts.\nstring\n\n\n--var_gene_names\nThe name of the adata var column containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--obs_batch_label\nThe name of the adata obs column containing the batch labels.\nstring\n\n\n\n\n\nModel\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--model\nPath to scGPT model file.\nfile, required, example: \"resources_test/scgpt/best_model.pt\"\n\n\n--model_vocab\nPath to scGPT model vocabulary file.\nfile, required, example: \"resources_test/scgpt/vocab.json\"\n\n\n--model_config\nPath to scGPT model config file.\nfile, required, example: \"args.json\"\n\n\n--finetuned_checkpoints_key\nKey in the model file containing the pretrained checkpoints. Only relevant for fine-tuned models.\nstring, example: \"model_state_dict\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput file path\nfile, required, example: \"output.h5mu\"\n\n\n--obsm_integrated\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scgpt\"\n\n\n\n\n\nPadding arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pad_token\nToken used for padding.\nstring, default: \"&lt;pad&gt;\"\n\n\n--pad_value\nThe value of the padding token.\ninteger, default: -2\n\n\n\n\n\nHVG subset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_hvg\nNumber of highly variable genes to subset for.\ninteger, default: 1200\n\n\n--hvg_flavor\nMethod to be used for identifying highly variable genes. Note that the default for this workflow (cell_ranger) is not the default method for scanpy hvg detection (seurat).\nstring, default: \"cell_ranger\"\n\n\n\n\n\nTokenization arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_seq_len\nThe maximum sequence length of the tokenized data. Defaults to the number of features if not provided.\ninteger\n\n\n\n\n\nEmbedding arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--dsbn\nApply domain-specific batch normalization\nboolean, default: TRUE\n\n\n--batch_size\nThe batch size to be used for embedding inference.\ninteger, default: 64\n\n\n\n\n\nBinning arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_input_bins\nThe number of bins to discretize the data into; When no value is provided, data won’t be binned.\ninteger, default: 51\n\n\n--seed\nSeed for random number generation used for binning. If not set, no seed is used.\ninteger\n\n\n\n\n\nClustering arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scgpt leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scgpt_leiden.html#authors",
    "href": "components/workflows/integration/scgpt_leiden.html#authors",
    "title": "Scgpt leiden",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (maintainer, author)\nElizabeth Mlynarski (author)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scgpt leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scgpt_leiden.html#visualisation",
    "href": "components/workflows/integration/scgpt_leiden.html#visualisation",
    "title": "Scgpt leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(highly_variable_features_scanpy)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v49(cross_check_genes)\n    v56(cross)\n    v66(cross)\n    v72(filter)\n    v80(binning)\n    v87(cross)\n    v97(cross)\n    v103(filter)\n    v111(pad_tokenize)\n    v118(cross)\n    v128(cross)\n    v134(filter)\n    v142(embedding)\n    v149(cross)\n    v159(cross)\n    v165(filter)\n    v319(concat)\n    v174(filter)\n    v189(cross)\n    v199(cross)\n    v208(branch)\n    v235(concat)\n    v220(cross)\n    v230(cross)\n    v239(branch)\n    v266(concat)\n    v251(cross)\n    v261(cross)\n    v270(branch)\n    v297(concat)\n    v282(cross)\n    v292(cross)\n    v304(cross)\n    v314(cross)\n    v326(cross)\n    v333(cross)\n    v345(cross)\n    v352(cross)\n    v356(Output)\n    subgraph group_neighbors_leiden_umap [neighbors_leiden_umap]\n        v182(find_neighbors)\n        v213(leiden)\n        v244(move_obsm_to_obs)\n        v275(umap)\n    end\n    v208--&gt;v235\n    v239--&gt;v266\n    v270--&gt;v297\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v49\n    v49--&gt;v56\n    v41--&gt;v56\n    v41--&gt;v66\n    v72--&gt;v80\n    v80--&gt;v87\n    v72--&gt;v87\n    v72--&gt;v97\n    v103--&gt;v111\n    v111--&gt;v118\n    v103--&gt;v118\n    v103--&gt;v128\n    v134--&gt;v142\n    v142--&gt;v149\n    v134--&gt;v149\n    v134--&gt;v159\n    v165--&gt;v174\n    v174--&gt;v182\n    v182--&gt;v189\n    v174--&gt;v189\n    v174--&gt;v199\n    v208--&gt;v213\n    v213--&gt;v220\n    v208--&gt;v220\n    v208--&gt;v230\n    v230--&gt;v235\n    v239--&gt;v244\n    v244--&gt;v251\n    v239--&gt;v251\n    v239--&gt;v261\n    v261--&gt;v266\n    v270--&gt;v275\n    v275--&gt;v282\n    v270--&gt;v282\n    v270--&gt;v292\n    v292--&gt;v297\n    v297--&gt;v304\n    v165--&gt;v304\n    v165--&gt;v314\n    v314--&gt;v319\n    v319--&gt;v326\n    v2--&gt;v326\n    v326--&gt;v333\n    v2--&gt;v333\n    v2--&gt;v345\n    v345--&gt;v352\n    v2--&gt;v352\n    v352--&gt;v356\n    v35--&gt;v41\n    v18--&gt;v35\n    v66--&gt;v72\n    v49--&gt;v66\n    v97--&gt;v103\n    v80--&gt;v97\n    v128--&gt;v134\n    v111--&gt;v128\n    v159--&gt;v165\n    v142--&gt;v159\n    v182--&gt;v199\n    v199--&gt;v208\n    v213--&gt;v230\n    v235--&gt;v239\n    v244--&gt;v261\n    v266--&gt;v270\n    v275--&gt;v292\n    v297--&gt;v314\n    v319--&gt;v345\n    style group_neighbors_leiden_umap fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v49 fill:#e3dcea,stroke:#7a4baa;\n    style v56 fill:#e3dcea,stroke:#7a4baa;\n    style v66 fill:#e3dcea,stroke:#7a4baa;\n    style v72 fill:#e3dcea,stroke:#7a4baa;\n    style v80 fill:#e3dcea,stroke:#7a4baa;\n    style v87 fill:#e3dcea,stroke:#7a4baa;\n    style v97 fill:#e3dcea,stroke:#7a4baa;\n    style v103 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v118 fill:#e3dcea,stroke:#7a4baa;\n    style v128 fill:#e3dcea,stroke:#7a4baa;\n    style v134 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v149 fill:#e3dcea,stroke:#7a4baa;\n    style v159 fill:#e3dcea,stroke:#7a4baa;\n    style v165 fill:#e3dcea,stroke:#7a4baa;\n    style v319 fill:#e3dcea,stroke:#7a4baa;\n    style v174 fill:#e3dcea,stroke:#7a4baa;\n    style v182 fill:#e3dcea,stroke:#7a4baa;\n    style v189 fill:#e3dcea,stroke:#7a4baa;\n    style v199 fill:#e3dcea,stroke:#7a4baa;\n    style v208 fill:#e3dcea,stroke:#7a4baa;\n    style v235 fill:#e3dcea,stroke:#7a4baa;\n    style v213 fill:#e3dcea,stroke:#7a4baa;\n    style v220 fill:#e3dcea,stroke:#7a4baa;\n    style v230 fill:#e3dcea,stroke:#7a4baa;\n    style v239 fill:#e3dcea,stroke:#7a4baa;\n    style v266 fill:#e3dcea,stroke:#7a4baa;\n    style v244 fill:#e3dcea,stroke:#7a4baa;\n    style v251 fill:#e3dcea,stroke:#7a4baa;\n    style v261 fill:#e3dcea,stroke:#7a4baa;\n    style v270 fill:#e3dcea,stroke:#7a4baa;\n    style v297 fill:#e3dcea,stroke:#7a4baa;\n    style v275 fill:#e3dcea,stroke:#7a4baa;\n    style v282 fill:#e3dcea,stroke:#7a4baa;\n    style v292 fill:#e3dcea,stroke:#7a4baa;\n    style v304 fill:#e3dcea,stroke:#7a4baa;\n    style v314 fill:#e3dcea,stroke:#7a4baa;\n    style v326 fill:#e3dcea,stroke:#7a4baa;\n    style v333 fill:#e3dcea,stroke:#7a4baa;\n    style v345 fill:#e3dcea,stroke:#7a4baa;\n    style v352 fill:#e3dcea,stroke:#7a4baa;\n    style v356 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scgpt leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/totalvi_leiden.html",
    "href": "components/workflows/integration/totalvi_leiden.html",
    "title": "Totalvi leiden",
    "section": "",
    "text": "ID: totalvi_leiden\nNamespace: workflows/integration\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Totalvi leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/totalvi_leiden.html#example-commands",
    "href": "components/workflows/integration/totalvi_leiden.html#example-commands",
    "title": "Totalvi leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/integration/totalvi_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n# layer: \"foo\"\nmodality: \"rna\"\nprot_modality: \"prot\"\nreference: # please fill in - example: \"path/to/file\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# reference_model_path: \"totalvi_model_reference\"\n# query_model_path: \"totalvi_model_query\"\n\n# General TotalVI Options\nobs_batch: \"sample_id\"\nmax_epochs: 400\nmax_query_epochs: 200\nweight_decay: 0.0\nforce_retrain: false\n# var_input: \"foo\"\n\n# TotalVI integration options RNA\nrna_reference_modality: \"rna\"\nrna_obsm_output: \"X_totalvi\"\n\n# TotalVI integration options ADT\nprot_reference_modality: \"prot\"\nprot_obsm_output: \"X_totalvi\"\n\n# Neighbour calculation RNA\nrna_uns_neighbors: \"totalvi_integration_neighbors\"\nrna_obsp_neighbor_distances: \"totalvi_integration_distances\"\nrna_obsp_neighbor_connectivities: \"totalvi_integration_connectivities\"\n\n# Neighbour calculation ADT\nprot_uns_neighbors: \"totalvi_integration_neighbors\"\nprot_obsp_neighbor_distances: \"totalvi_integration_distances\"\nprot_obsp_neighbor_connectivities: \"totalvi_integration_connectivities\"\n\n# Clustering options RNA\nrna_obs_cluster: \"totalvi_integration_leiden\"\nrna_leiden_resolution: [1.0]\n\n# Clustering options ADT\nprot_obs_cluster: \"totalvi_integration_leiden\"\nprot_leiden_resolution: [1.0]\n\n# Umap options\nobsm_umap: \"X_totalvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/integration/totalvi_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Totalvi leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/totalvi_leiden.html#argument-groups",
    "href": "components/workflows/integration/totalvi_leiden.html#argument-groups",
    "title": "Totalvi leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--prot_modality\nWhich modality to process.\nstring, default: \"prot\"\n\n\n--reference\nInput h5mu file with reference data to train the TOTALVI model.\nfile, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--reference_model_path\nDirectory with the reference model. If not exists, trained model will be saved there\nfile, default: \"totalvi_model_reference\"\n\n\n--query_model_path\nDirectory, where the query model will be saved\nfile, default: \"totalvi_model_query\"\n\n\n\n\n\nGeneral TotalVI Options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\n.Obs column name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--max_epochs\nNumber of passes through the dataset\ninteger, default: 400\n\n\n--max_query_epochs\nNumber of passes through the dataset, when fine-tuning model for query\ninteger, default: 200\n\n\n--weight_decay\nWeight decay, when fine-tuning model for query\ndouble, default: 0\n\n\n--force_retrain\nIf true, retrain the model and save it to reference_model_path\nboolean_true\n\n\n--var_input\nBoolean .var column to subset data with (e.g. containing highly variable genes). By default, do not subset genes.\nstring\n\n\n\n\n\nTotalVI integration options RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_reference_modality\n\nstring, default: \"rna\"\n\n\n--rna_obsm_output\nIn which .obsm slot to store the normalized RNA from TOTALVI.\nstring, default: \"X_totalvi\"\n\n\n\n\n\nTotalVI integration options ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_reference_modality\nName of the modality containing proteins in the reference\nstring, default: \"prot\"\n\n\n--prot_obsm_output\nIn which .obsm slot to store the normalized protein data from TOTALVI.\nstring, default: \"X_totalvi\"\n\n\n\n\n\nNeighbour calculation RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"totalvi_integration_neighbors\"\n\n\n--rna_obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_distances\"\n\n\n--rna_obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_connectivities\"\n\n\n\n\n\nNeighbour calculation ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"totalvi_integration_neighbors\"\n\n\n--prot_obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_distances\"\n\n\n--prot_obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_connectivities\"\n\n\n\n\n\nClustering options RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"totalvi_integration_leiden\"\n\n\n--rna_leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nClustering options ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"totalvi_integration_leiden\"\n\n\n--prot_leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_totalvi_umap\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Totalvi leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/totalvi_leiden.html#authors",
    "href": "components/workflows/integration/totalvi_leiden.html#authors",
    "title": "Totalvi leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Totalvi leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/totalvi_leiden.html#visualisation",
    "href": "components/workflows/integration/totalvi_leiden.html#visualisation",
    "title": "Totalvi leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(totalvi)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v50(filter)\n    v65(cross)\n    v75(cross)\n    v84(branch)\n    v111(concat)\n    v96(cross)\n    v106(cross)\n    v115(branch)\n    v142(concat)\n    v127(cross)\n    v137(cross)\n    v146(branch)\n    v173(concat)\n    v158(cross)\n    v168(cross)\n    v180(cross)\n    v190(cross)\n    v196(filter)\n    v350(concat)\n    v205(filter)\n    v220(cross)\n    v230(cross)\n    v239(branch)\n    v266(concat)\n    v251(cross)\n    v261(cross)\n    v270(branch)\n    v297(concat)\n    v282(cross)\n    v292(cross)\n    v301(branch)\n    v328(concat)\n    v313(cross)\n    v323(cross)\n    v335(cross)\n    v345(cross)\n    v357(cross)\n    v364(cross)\n    v376(cross)\n    v383(cross)\n    v387(Output)\n    subgraph group_rna_neighbors_leiden_umap [rna_neighbors_leiden_umap]\n        v58(find_neighbors)\n        v89(leiden)\n        v120(move_obsm_to_obs)\n        v151(umap)\n    end\n    subgraph group_adt_neighbors_leiden_umap [adt_neighbors_leiden_umap]\n        v213(find_neighbors)\n        v244(leiden)\n        v275(move_obsm_to_obs)\n        v306(umap)\n    end\n    v84--&gt;v111\n    v115--&gt;v142\n    v146--&gt;v173\n    v239--&gt;v266\n    v270--&gt;v297\n    v301--&gt;v328\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v50\n    v50--&gt;v58\n    v58--&gt;v65\n    v50--&gt;v65\n    v50--&gt;v75\n    v84--&gt;v89\n    v89--&gt;v96\n    v84--&gt;v96\n    v84--&gt;v106\n    v106--&gt;v111\n    v115--&gt;v120\n    v120--&gt;v127\n    v115--&gt;v127\n    v115--&gt;v137\n    v137--&gt;v142\n    v146--&gt;v151\n    v151--&gt;v158\n    v146--&gt;v158\n    v146--&gt;v168\n    v168--&gt;v173\n    v173--&gt;v180\n    v41--&gt;v180\n    v41--&gt;v190\n    v196--&gt;v205\n    v205--&gt;v213\n    v213--&gt;v220\n    v205--&gt;v220\n    v205--&gt;v230\n    v239--&gt;v244\n    v244--&gt;v251\n    v239--&gt;v251\n    v239--&gt;v261\n    v261--&gt;v266\n    v270--&gt;v275\n    v275--&gt;v282\n    v270--&gt;v282\n    v270--&gt;v292\n    v292--&gt;v297\n    v301--&gt;v306\n    v306--&gt;v313\n    v301--&gt;v313\n    v301--&gt;v323\n    v323--&gt;v328\n    v328--&gt;v335\n    v196--&gt;v335\n    v196--&gt;v345\n    v345--&gt;v350\n    v350--&gt;v357\n    v2--&gt;v357\n    v357--&gt;v364\n    v2--&gt;v364\n    v2--&gt;v376\n    v376--&gt;v383\n    v2--&gt;v383\n    v383--&gt;v387\n    v35--&gt;v41\n    v18--&gt;v35\n    v190--&gt;v196\n    v58--&gt;v75\n    v75--&gt;v84\n    v89--&gt;v106\n    v111--&gt;v115\n    v120--&gt;v137\n    v142--&gt;v146\n    v151--&gt;v168\n    v173--&gt;v190\n    v213--&gt;v230\n    v230--&gt;v239\n    v244--&gt;v261\n    v266--&gt;v270\n    v275--&gt;v292\n    v297--&gt;v301\n    v306--&gt;v323\n    v328--&gt;v345\n    v350--&gt;v376\n    style group_rna_neighbors_leiden_umap fill:#F0F0F0,stroke:#969696;\n    style group_adt_neighbors_leiden_umap fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v50 fill:#e3dcea,stroke:#7a4baa;\n    style v58 fill:#e3dcea,stroke:#7a4baa;\n    style v65 fill:#e3dcea,stroke:#7a4baa;\n    style v75 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v89 fill:#e3dcea,stroke:#7a4baa;\n    style v96 fill:#e3dcea,stroke:#7a4baa;\n    style v106 fill:#e3dcea,stroke:#7a4baa;\n    style v115 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v120 fill:#e3dcea,stroke:#7a4baa;\n    style v127 fill:#e3dcea,stroke:#7a4baa;\n    style v137 fill:#e3dcea,stroke:#7a4baa;\n    style v146 fill:#e3dcea,stroke:#7a4baa;\n    style v173 fill:#e3dcea,stroke:#7a4baa;\n    style v151 fill:#e3dcea,stroke:#7a4baa;\n    style v158 fill:#e3dcea,stroke:#7a4baa;\n    style v168 fill:#e3dcea,stroke:#7a4baa;\n    style v180 fill:#e3dcea,stroke:#7a4baa;\n    style v190 fill:#e3dcea,stroke:#7a4baa;\n    style v196 fill:#e3dcea,stroke:#7a4baa;\n    style v350 fill:#e3dcea,stroke:#7a4baa;\n    style v205 fill:#e3dcea,stroke:#7a4baa;\n    style v213 fill:#e3dcea,stroke:#7a4baa;\n    style v220 fill:#e3dcea,stroke:#7a4baa;\n    style v230 fill:#e3dcea,stroke:#7a4baa;\n    style v239 fill:#e3dcea,stroke:#7a4baa;\n    style v266 fill:#e3dcea,stroke:#7a4baa;\n    style v244 fill:#e3dcea,stroke:#7a4baa;\n    style v251 fill:#e3dcea,stroke:#7a4baa;\n    style v261 fill:#e3dcea,stroke:#7a4baa;\n    style v270 fill:#e3dcea,stroke:#7a4baa;\n    style v297 fill:#e3dcea,stroke:#7a4baa;\n    style v275 fill:#e3dcea,stroke:#7a4baa;\n    style v282 fill:#e3dcea,stroke:#7a4baa;\n    style v292 fill:#e3dcea,stroke:#7a4baa;\n    style v301 fill:#e3dcea,stroke:#7a4baa;\n    style v328 fill:#e3dcea,stroke:#7a4baa;\n    style v306 fill:#e3dcea,stroke:#7a4baa;\n    style v313 fill:#e3dcea,stroke:#7a4baa;\n    style v323 fill:#e3dcea,stroke:#7a4baa;\n    style v335 fill:#e3dcea,stroke:#7a4baa;\n    style v345 fill:#e3dcea,stroke:#7a4baa;\n    style v357 fill:#e3dcea,stroke:#7a4baa;\n    style v364 fill:#e3dcea,stroke:#7a4baa;\n    style v376 fill:#e3dcea,stroke:#7a4baa;\n    style v383 fill:#e3dcea,stroke:#7a4baa;\n    style v387 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Totalvi leiden"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scvi_knn.html",
    "href": "components/workflows/annotation/scvi_knn.html",
    "title": "scVI Annotation",
    "section": "",
    "text": "ID: scvi_knn\nNamespace: workflows/annotation\n\n\n\nSource\nThe query and reference datasets are expected to be pre-processed in the same way, for example with the process_samples workflow of OpenPipeline. Note that this workflow will integrate the reference dataset from scratch and integrate the query dataset in the same embedding space. The workflow does not currently output the trained SCVI reference model",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scVI Annotation"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scvi_knn.html#example-commands",
    "href": "components/workflows/annotation/scvi_knn.html#example-commands",
    "title": "scVI Annotation",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/annotation/scvi_knn/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Query Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"counts\"\n# input_layer_lognormalized: \"log_normalized\"\ninput_obs_batch_label: # please fill in - example: \"sample\"\n# input_var_gene_names: \"foo\"\ninput_reference_gene_overlap: 100\noverwrite_existing_key: false\n\n# Reference input\nreference: # please fill in - example: \"reference.h5mu\"\n# reference_layer: \"counts\"\n# reference_layer_lognormalized: \"log_normalized\"\nreference_obs_target: # please fill in - example: \"cell_type\"\n# reference_var_gene_names: \"foo\"\nreference_obs_batch_label: # please fill in - example: \"sample\"\n\n# HVG subset arguments\nn_hvg: 2000\n\n# scVI integration options\n# scvi_early_stopping: true\nscvi_early_stopping_monitor: \"elbo_validation\"\nscvi_early_stopping_patience: 45\nscvi_early_stopping_min_delta: 0.0\n# scvi_max_epochs: 123\nscvi_reduce_lr_on_plateau: true\nscvi_lr_factor: 0.6\nscvi_lr_patience: 30.0\n\n# Leiden clustering options\nleiden_resolution: [1.0]\n\n# Neighbor classifier arguments\nknn_weights: \"uniform\"\nknn_n_neighbors: 15\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_obs_predictions: [\"foo\"]\n# output_obs_probability: [\"foo\"]\noutput_obsm_integrated: \"X_integrated_scvi\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/annotation/scvi_knn/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scVI Annotation"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scvi_knn.html#argument-groups",
    "href": "components/workflows/annotation/scvi_knn.html#argument-groups",
    "title": "scVI Annotation",
    "section": "Argument groups",
    "text": "Argument groups\n\nQuery Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput dataset consisting of the (unlabeled) query observations.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process. Should match the modality of the –reference dataset.\nstring, default: \"rna\"\n\n\n--input_layer\nThe layer of the input dataset containing the raw counts if .X is not to be used.\nstring, example: \"counts\"\n\n\n--input_layer_lognormalized\nThe layer of the input dataset containing the lognormalized counts if .X is not to be used.\nstring, example: \"log_normalized\"\n\n\n--input_obs_batch_label\nThe .obs field in the input (query) dataset containing the batch labels.\nstring, required, example: \"sample\"\n\n\n--input_var_gene_names\nThe .var field in the input (query) dataset containing gene names; if not provided, the .var index will be used.\nstring\n\n\n--input_reference_gene_overlap\nThe minimum number of genes present in both the reference and query datasets.\ninteger, default: 100\n\n\n--overwrite_existing_key\nIf provided, will overwrite existing fields in the input dataset when data are copied during the reference alignment process.\nboolean_true\n\n\n\n\n\nReference input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nReference dataset consisting of the labeled observations.\nfile, required, example: \"reference.h5mu\"\n\n\n--reference_layer\nThe layer of the reference dataset containing the raw counts if .X is not to be used.\nstring, example: \"counts\"\n\n\n--reference_layer_lognormalized\nThe layer of the reference dataset containing the lognormalized counts if .X is not to be used.\nstring, example: \"log_normalized\"\n\n\n--reference_obs_target\nThe .obs key(s) of the target labels to transfer.\nstring, required, example: \"cell_type\"\n\n\n--reference_var_gene_names\nThe .var field in the reference dataset containing gene names; if not provided, the .var index will be used.\nstring\n\n\n--reference_obs_batch_label\nThe .obs field in the reference dataset containing the batch labels.\nstring, required, example: \"sample\"\n\n\n\n\n\nHVG subset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_hvg\nNumber of highly variable genes to subset for.\ninteger, default: 2000\n\n\n\n\n\nscVI integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scvi_early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--scvi_early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--scvi_early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--scvi_early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--scvi_max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--scvi_reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--scvi_lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--scvi_lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nLeiden clustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nNeighbor classifier arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--knn_weights\nWeight function used in prediction. Possible values are: uniform (all points in each neighborhood are weighted equally) or distance (weight points by the inverse of their distance)\nstring, default: \"uniform\"\n\n\n--knn_n_neighbors\nThe number of neighbors to use in k-neighbor graph structure used for fast approximate nearest neighbor search with PyNNDescent. Larger values will result in more accurate search results at the cost of computation time.\ninteger, default: 15\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe query data in .h5mu format with predicted labels predicted from the classifier trained on the reference.\nfile, required, example: \"output.h5mu\"\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted cell labels. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_pred\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_obs_probability\nIn which .obs slots to store the probability of the predictions. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_probability\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_obsm_integrated\nIn which .obsm slot to store the integrated embedding.\nstring, default: \"X_integrated_scvi\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scVI Annotation"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scvi_knn.html#authors",
    "href": "components/workflows/annotation/scvi_knn.html#authors",
    "title": "scVI Annotation",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (author, maintainer)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scVI Annotation"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scvi_knn.html#visualisation",
    "href": "components/workflows/annotation/scvi_knn.html#visualisation",
    "title": "scVI Annotation",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(align_query_reference)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v52(filter)\n    v64(cross)\n    v74(cross)\n    v84(concat)\n    v91(cross)\n    v101(cross)\n    v107(flatMap)\n    v111(filter)\n    v119(concatenate_h5mu)\n    v126(cross)\n    v136(cross)\n    v142(filter)\n    v150(highly_variable_features_scanpy)\n    v157(cross)\n    v167(cross)\n    v173(filter)\n    v181(delete_aligned_lognormalized_counts_layer)\n    v188(cross)\n    v198(cross)\n    v204(filter)\n    v212(filter)\n    v227(cross)\n    v237(cross)\n    v243(filter)\n    v397(concat)\n    v252(filter)\n    v267(cross)\n    v277(cross)\n    v286(branch)\n    v313(concat)\n    v298(cross)\n    v308(cross)\n    v317(branch)\n    v344(concat)\n    v329(cross)\n    v339(cross)\n    v348(branch)\n    v375(concat)\n    v360(cross)\n    v370(cross)\n    v382(cross)\n    v392(cross)\n    v404(cross)\n    v414(cross)\n    v420(filter)\n    v428(delete_aligned_counts_layer)\n    v435(cross)\n    v445(cross)\n    v451(filter)\n    v462(filter)\n    v474(cross)\n    v484(cross)\n    v494(concat)\n    v501(cross)\n    v511(cross)\n    v519(filter)\n    v527(knn)\n    v534(cross)\n    v544(cross)\n    v552(mix)\n    v555(filter)\n    v585(concat)\n    v563(merge)\n    v570(cross)\n    v580(cross)\n    v592(cross)\n    v599(cross)\n    v611(cross)\n    v618(cross)\n    v622(Output)\n    subgraph group_split_modalities [split_modalities]\n        v57(split_modalities_component)\n    end\n    subgraph group_scvi_leiden_workflow [scvi_leiden_workflow]\n        v220(scvi)\n        v260(find_neighbors)\n        v291(leiden)\n        v322(move_obsm_to_obs)\n        v353(umap)\n    end\n    subgraph group_split_h5mu [split_h5mu]\n        v467(split_h5mu_component)\n    end\n    v286--&gt;v313\n    v317--&gt;v344\n    v348--&gt;v375\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v52--&gt;v57\n    v57--&gt;v64\n    v52--&gt;v64\n    v52--&gt;v74\n    v84--&gt;v91\n    v41--&gt;v91\n    v41--&gt;v101\n    v111--&gt;v119\n    v119--&gt;v126\n    v111--&gt;v126\n    v111--&gt;v136\n    v142--&gt;v150\n    v150--&gt;v157\n    v142--&gt;v157\n    v142--&gt;v167\n    v173--&gt;v181\n    v181--&gt;v188\n    v173--&gt;v188\n    v173--&gt;v198\n    v204--&gt;v212\n    v212--&gt;v220\n    v220--&gt;v227\n    v212--&gt;v227\n    v212--&gt;v237\n    v243--&gt;v252\n    v252--&gt;v260\n    v260--&gt;v267\n    v252--&gt;v267\n    v252--&gt;v277\n    v286--&gt;v291\n    v291--&gt;v298\n    v286--&gt;v298\n    v286--&gt;v308\n    v308--&gt;v313\n    v317--&gt;v322\n    v322--&gt;v329\n    v317--&gt;v329\n    v317--&gt;v339\n    v339--&gt;v344\n    v348--&gt;v353\n    v353--&gt;v360\n    v348--&gt;v360\n    v348--&gt;v370\n    v370--&gt;v375\n    v375--&gt;v382\n    v243--&gt;v382\n    v243--&gt;v392\n    v392--&gt;v397\n    v397--&gt;v404\n    v204--&gt;v404\n    v204--&gt;v414\n    v420--&gt;v428\n    v428--&gt;v435\n    v420--&gt;v435\n    v420--&gt;v445\n    v462--&gt;v467\n    v467--&gt;v474\n    v462--&gt;v474\n    v462--&gt;v484\n    v494--&gt;v501\n    v451--&gt;v501\n    v451--&gt;v511\n    v519--&gt;v527\n    v527--&gt;v534\n    v519--&gt;v534\n    v519--&gt;v544\n    v555--&gt;v563\n    v563--&gt;v570\n    v555--&gt;v570\n    v555--&gt;v580\n    v580--&gt;v585\n    v585--&gt;v592\n    v2--&gt;v592\n    v592--&gt;v599\n    v2--&gt;v599\n    v2--&gt;v611\n    v611--&gt;v618\n    v2--&gt;v618\n    v618--&gt;v622\n    v35--&gt;v41\n    v18--&gt;v35\n    v101--&gt;v107\n    v41--&gt;v52\n    v74--&gt;v84\n    v57--&gt;v74\n    v84--&gt;v101\n    v107--&gt;v111\n    v136--&gt;v142\n    v119--&gt;v136\n    v167--&gt;v173\n    v150--&gt;v167\n    v198--&gt;v204\n    v181--&gt;v198\n    v414--&gt;v420\n    v237--&gt;v243\n    v220--&gt;v237\n    v260--&gt;v277\n    v277--&gt;v286\n    v291--&gt;v308\n    v313--&gt;v317\n    v322--&gt;v339\n    v344--&gt;v348\n    v353--&gt;v370\n    v375--&gt;v392\n    v397--&gt;v414\n    v445--&gt;v451\n    v428--&gt;v445\n    v511--&gt;v519\n    v451--&gt;v462\n    v484--&gt;v494\n    v467--&gt;v484\n    v494--&gt;v511\n    v544--&gt;v552\n    v527--&gt;v544\n    v107--&gt;v552\n    v552--&gt;v555\n    v563--&gt;v580\n    v585--&gt;v611\n    style group_split_modalities fill:#F0F0F0,stroke:#969696;\n    style group_scvi_leiden_workflow fill:#F0F0F0,stroke:#969696;\n    style group_split_h5mu fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v52 fill:#e3dcea,stroke:#7a4baa;\n    style v57 fill:#e3dcea,stroke:#7a4baa;\n    style v64 fill:#e3dcea,stroke:#7a4baa;\n    style v74 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v91 fill:#e3dcea,stroke:#7a4baa;\n    style v101 fill:#e3dcea,stroke:#7a4baa;\n    style v107 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v119 fill:#e3dcea,stroke:#7a4baa;\n    style v126 fill:#e3dcea,stroke:#7a4baa;\n    style v136 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v150 fill:#e3dcea,stroke:#7a4baa;\n    style v157 fill:#e3dcea,stroke:#7a4baa;\n    style v167 fill:#e3dcea,stroke:#7a4baa;\n    style v173 fill:#e3dcea,stroke:#7a4baa;\n    style v181 fill:#e3dcea,stroke:#7a4baa;\n    style v188 fill:#e3dcea,stroke:#7a4baa;\n    style v198 fill:#e3dcea,stroke:#7a4baa;\n    style v204 fill:#e3dcea,stroke:#7a4baa;\n    style v212 fill:#e3dcea,stroke:#7a4baa;\n    style v220 fill:#e3dcea,stroke:#7a4baa;\n    style v227 fill:#e3dcea,stroke:#7a4baa;\n    style v237 fill:#e3dcea,stroke:#7a4baa;\n    style v243 fill:#e3dcea,stroke:#7a4baa;\n    style v397 fill:#e3dcea,stroke:#7a4baa;\n    style v252 fill:#e3dcea,stroke:#7a4baa;\n    style v260 fill:#e3dcea,stroke:#7a4baa;\n    style v267 fill:#e3dcea,stroke:#7a4baa;\n    style v277 fill:#e3dcea,stroke:#7a4baa;\n    style v286 fill:#e3dcea,stroke:#7a4baa;\n    style v313 fill:#e3dcea,stroke:#7a4baa;\n    style v291 fill:#e3dcea,stroke:#7a4baa;\n    style v298 fill:#e3dcea,stroke:#7a4baa;\n    style v308 fill:#e3dcea,stroke:#7a4baa;\n    style v317 fill:#e3dcea,stroke:#7a4baa;\n    style v344 fill:#e3dcea,stroke:#7a4baa;\n    style v322 fill:#e3dcea,stroke:#7a4baa;\n    style v329 fill:#e3dcea,stroke:#7a4baa;\n    style v339 fill:#e3dcea,stroke:#7a4baa;\n    style v348 fill:#e3dcea,stroke:#7a4baa;\n    style v375 fill:#e3dcea,stroke:#7a4baa;\n    style v353 fill:#e3dcea,stroke:#7a4baa;\n    style v360 fill:#e3dcea,stroke:#7a4baa;\n    style v370 fill:#e3dcea,stroke:#7a4baa;\n    style v382 fill:#e3dcea,stroke:#7a4baa;\n    style v392 fill:#e3dcea,stroke:#7a4baa;\n    style v404 fill:#e3dcea,stroke:#7a4baa;\n    style v414 fill:#e3dcea,stroke:#7a4baa;\n    style v420 fill:#e3dcea,stroke:#7a4baa;\n    style v428 fill:#e3dcea,stroke:#7a4baa;\n    style v435 fill:#e3dcea,stroke:#7a4baa;\n    style v445 fill:#e3dcea,stroke:#7a4baa;\n    style v451 fill:#e3dcea,stroke:#7a4baa;\n    style v462 fill:#e3dcea,stroke:#7a4baa;\n    style v467 fill:#e3dcea,stroke:#7a4baa;\n    style v474 fill:#e3dcea,stroke:#7a4baa;\n    style v484 fill:#e3dcea,stroke:#7a4baa;\n    style v494 fill:#e3dcea,stroke:#7a4baa;\n    style v501 fill:#e3dcea,stroke:#7a4baa;\n    style v511 fill:#e3dcea,stroke:#7a4baa;\n    style v519 fill:#e3dcea,stroke:#7a4baa;\n    style v527 fill:#e3dcea,stroke:#7a4baa;\n    style v534 fill:#e3dcea,stroke:#7a4baa;\n    style v544 fill:#e3dcea,stroke:#7a4baa;\n    style v552 fill:#e3dcea,stroke:#7a4baa;\n    style v555 fill:#e3dcea,stroke:#7a4baa;\n    style v585 fill:#e3dcea,stroke:#7a4baa;\n    style v563 fill:#e3dcea,stroke:#7a4baa;\n    style v570 fill:#e3dcea,stroke:#7a4baa;\n    style v580 fill:#e3dcea,stroke:#7a4baa;\n    style v592 fill:#e3dcea,stroke:#7a4baa;\n    style v599 fill:#e3dcea,stroke:#7a4baa;\n    style v611 fill:#e3dcea,stroke:#7a4baa;\n    style v618 fill:#e3dcea,stroke:#7a4baa;\n    style v622 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scVI Annotation"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scgpt_annotation.html",
    "href": "components/workflows/annotation/scgpt_annotation.html",
    "title": "scGPT Annotation",
    "section": "",
    "text": "ID: scgpt_annotation\nNamespace: workflows/annotation\n\n\n\nSource\nThe workflow takes a pre-processed h5mu file as query input, and performs - subsetting for HVG - cross-checking of genes with the model vocabulary - binning of gene counts - padding and tokenizing of genes - transformer-based cell type prediction Note that cell-type prediction using scGPT is only possible using a fine-tuned scGPT model",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scGPT Annotation"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scgpt_annotation.html#example-commands",
    "href": "components/workflows/annotation/scgpt_annotation.html#example-commands",
    "title": "scGPT Annotation",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/annotation/scgpt_annotation/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Query input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# input_var_gene_names: \"foo\"\ninput_obs_batch_label: # please fill in - example: \"foo\"\n\n# Model input\nmodel: # please fill in - example: \"best_model.pt\"\nmodel_config: # please fill in - example: \"args.json\"\nmodel_vocab: # please fill in - example: \"vocab.json\"\nfinetuned_checkpoints_key: \"model_state_dict\"\nlabel_mapper_key: \"id_to_class\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_obs_predictions: \"scgpt_pred\"\noutput_obs_probability: \"scgpt_probability\"\n\n# Padding arguments\npad_token: \"&lt;pad&gt;\"\npad_value: -2\n\n# HVG subset arguments\nn_hvg: 1200\nhvg_flavor: \"cell_ranger\"\n\n# Tokenization arguments\n# max_seq_len: 123\n\n# Embedding arguments\ndsbn: true\nbatch_size: 64\n\n# Binning arguments\nn_input_bins: 51\n# seed: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/annotation/scgpt_annotation/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scGPT Annotation"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scgpt_annotation.html#argument-groups",
    "href": "components/workflows/annotation/scgpt_annotation.html#argument-groups",
    "title": "scGPT Annotation",
    "section": "Argument groups",
    "text": "Argument groups\n\nQuery input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the input file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nThe layer of the input dataset to process if .X is not to be used. Should contain log normalized counts.\nstring\n\n\n--input_var_gene_names\nThe .var field in the input (query) containing gene names; if not provided, the var index will be used.\nstring\n\n\n--input_obs_batch_label\nThe .obs field in the input (query) dataset containing the batch labels.\nstring, required\n\n\n\n\n\nModel input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--model\nThe scGPT model file. Must be a fine-tuned model that contains keys for checkpoints (–finetuned_checkpoints_key) and cell type label mapper(–label_mapper_key).\nfile, required, example: \"best_model.pt\"\n\n\n--model_config\nThe scGPT model configuration file.\nfile, required, example: \"args.json\"\n\n\n--model_vocab\nThe scGPT model vocabulary file.\nfile, required, example: \"vocab.json\"\n\n\n--finetuned_checkpoints_key\nKey in the model file containing the pre-trained checkpoints.\nstring, default: \"model_state_dict\"\n\n\n--label_mapper_key\nKey in the model file containing the cell type class to label mapper dictionary.\nstring, default: \"id_to_class\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput file path\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression algorithm to use for the output h5mu file.\nstring, example: \"gzip\"\n\n\n--output_obs_predictions\nThe name of the adata.obs column to write predicted cell type labels to.\nstring, default: \"scgpt_pred\"\n\n\n--output_obs_probability\nThe name of the adata.obs column to write predicted cell type labels to.\nstring, default: \"scgpt_probability\"\n\n\n\n\n\nPadding arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pad_token\nToken used for padding.\nstring, default: \"&lt;pad&gt;\"\n\n\n--pad_value\nThe value of the padding token.\ninteger, default: -2\n\n\n\n\n\nHVG subset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_hvg\nNumber of highly variable genes to subset for.\ninteger, default: 1200\n\n\n--hvg_flavor\nMethod to be used for identifying highly variable genes. Note that the default for this workflow (cell_ranger) is not the default method for scanpy hvg detection (seurat).\nstring, default: \"cell_ranger\"\n\n\n\n\n\nTokenization arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_seq_len\nThe maximum sequence length of the tokenized data.\ninteger\n\n\n\n\n\nEmbedding arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--dsbn\nApply domain-specific batch normalization\nboolean, default: TRUE\n\n\n--batch_size\nThe batch size to be used for embedding inference.\ninteger, default: 64\n\n\n\n\n\nBinning arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_input_bins\nThe number of bins to discretize the data into; When no value is provided, data won’t be binned.\ninteger, default: 51\n\n\n--seed\nSeed for random number generation used for binning. If not set, no seed is used.\ninteger",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scGPT Annotation"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scgpt_annotation.html#authors",
    "href": "components/workflows/annotation/scgpt_annotation.html#authors",
    "title": "scGPT Annotation",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (author, maintainer)\nElizabeth Mlynarski (contributor)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scGPT Annotation"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scgpt_annotation.html#visualisation",
    "href": "components/workflows/annotation/scgpt_annotation.html#visualisation",
    "title": "scGPT Annotation",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(highly_variable_features_scanpy)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v49(cross_check_genes)\n    v56(cross)\n    v66(cross)\n    v72(filter)\n    v80(binning)\n    v87(cross)\n    v97(cross)\n    v103(filter)\n    v111(pad_tokenize)\n    v118(cross)\n    v128(cross)\n    v134(filter)\n    v164(concat)\n    v142(scgpt_celltype_annotation)\n    v149(cross)\n    v159(cross)\n    v170(cross)\n    v177(cross)\n    v189(cross)\n    v196(cross)\n    v200(Output)\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v49\n    v49--&gt;v56\n    v41--&gt;v56\n    v41--&gt;v66\n    v72--&gt;v80\n    v80--&gt;v87\n    v72--&gt;v87\n    v72--&gt;v97\n    v103--&gt;v111\n    v111--&gt;v118\n    v103--&gt;v118\n    v103--&gt;v128\n    v134--&gt;v142\n    v142--&gt;v149\n    v134--&gt;v149\n    v134--&gt;v159\n    v159--&gt;v164\n    v164--&gt;v170\n    v2--&gt;v170\n    v170--&gt;v177\n    v2--&gt;v177\n    v2--&gt;v189\n    v189--&gt;v196\n    v2--&gt;v196\n    v196--&gt;v200\n    v35--&gt;v41\n    v18--&gt;v35\n    v66--&gt;v72\n    v49--&gt;v66\n    v97--&gt;v103\n    v80--&gt;v97\n    v128--&gt;v134\n    v111--&gt;v128\n    v142--&gt;v159\n    v164--&gt;v189\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v49 fill:#e3dcea,stroke:#7a4baa;\n    style v56 fill:#e3dcea,stroke:#7a4baa;\n    style v66 fill:#e3dcea,stroke:#7a4baa;\n    style v72 fill:#e3dcea,stroke:#7a4baa;\n    style v80 fill:#e3dcea,stroke:#7a4baa;\n    style v87 fill:#e3dcea,stroke:#7a4baa;\n    style v97 fill:#e3dcea,stroke:#7a4baa;\n    style v103 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v118 fill:#e3dcea,stroke:#7a4baa;\n    style v128 fill:#e3dcea,stroke:#7a4baa;\n    style v134 fill:#e3dcea,stroke:#7a4baa;\n    style v164 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v149 fill:#e3dcea,stroke:#7a4baa;\n    style v159 fill:#e3dcea,stroke:#7a4baa;\n    style v170 fill:#e3dcea,stroke:#7a4baa;\n    style v177 fill:#e3dcea,stroke:#7a4baa;\n    style v189 fill:#e3dcea,stroke:#7a4baa;\n    style v196 fill:#e3dcea,stroke:#7a4baa;\n    style v200 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scGPT Annotation"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/process_samples.html",
    "href": "components/workflows/multiomics/process_samples.html",
    "title": "Process samples",
    "section": "",
    "text": "ID: process_samples\nNamespace: workflows/multiomics\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Process samples"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/process_samples.html#example-commands",
    "href": "components/workflows/multiomics/process_samples.html#example-commands",
    "title": "Process samples",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/multiomics/process_samples/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n# rna_layer: \"foo\"\n# prot_layer: \"foo\"\n# gdo_layer: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Sample ID options\nadd_id_to_obs: true\nadd_id_obs_output: \"sample_id\"\nadd_id_make_observation_keys_unique: true\n\n# RNA filtering options\n# rna_min_counts: 200\n# rna_max_counts: 5000000\n# rna_min_genes_per_cell: 200\n# rna_max_genes_per_cell: 1500000\n# rna_min_cells_per_gene: 3\n# rna_min_fraction_mito: 0.0\n# rna_max_fraction_mito: 0.2\n# rna_min_fraction_ribo: 0.0\n# rna_max_fraction_ribo: 0.2\n\n# CITE-seq filtering options\n# prot_min_counts: 3\n# prot_max_counts: 5000000\n# prot_min_proteins_per_cell: 200\n# prot_max_proteins_per_cell: 100000000\n# prot_min_cells_per_protein: 3\n\n# GDO filtering options\n# gdo_min_counts: 3\n# gdo_max_counts: 5000000\n# gdo_min_guides_per_cell: 200\n# gdo_max_guides_per_cell: 100000000\n# gdo_min_cells_per_guide: 3\n\n# Highly variable features detection\nhighly_variable_features_var_output: \"filter_with_hvg\"\nhighly_variable_features_obs_batch_key: \"sample_id\"\n\n# Mitochondrial & Ribosomal Gene Detection\n# var_gene_names: \"gene_symbol\"\n# var_name_mitochondrial_genes: \"foo\"\n# obs_name_mitochondrial_fraction: \"foo\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n# var_name_ribosomal_genes: \"foo\"\n# obs_name_ribosomal_fraction: \"foo\"\nribosomal_gene_regex: \"^[Mm]?[Rr][Pp][LlSs]\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc,highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# PCA options\npca_overwrite: false\n\n# CLR options\nclr_axis: 0\n\n# RNA Scaling options\nrna_enable_scaling: false\nrna_scaling_output_layer: \"scaled\"\nrna_scaling_pca_obsm_output: \"scaled_pca\"\nrna_scaling_pca_loadings_varm_output: \"scaled_pca_loadings\"\nrna_scaling_pca_variance_uns_output: \"scaled_pca_variance\"\nrna_scaling_umap_obsm_output: \"scaled_umap\"\n# rna_scaling_max_value: 123.0\nrna_scaling_zero_center: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/multiomics/process_samples/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Process samples"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/process_samples.html#argument-groups",
    "href": "components/workflows/multiomics/process_samples.html#argument-groups",
    "title": "Process samples",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n--rna_layer\nInput layer for the gene expression modality. If not specified, .X is used.\nstring\n\n\n--prot_layer\nInput layer for the antibody capture modality. If not specified, .X is used.\nstring\n\n\n--gdo_layer\nInput layer for the guide-derived oligonucleotide (GDO) data. If not specified, .X is used.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nSample ID options\nOptions for adding the id to .obs on the MuData object. Having a sample id present in a requirement of several components for this pipeline.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--add_id_to_obs\nAdd the value passed with –id to .obs.\nboolean, default: TRUE\n\n\n--add_id_obs_output\n.Obs column to add the sample IDs to. Required and only used when –add_id_to_obs is set to ‘true’\nstring, default: \"sample_id\"\n\n\n--add_id_make_observation_keys_unique\nJoin the id to the .obs index (.obs_names). Only used when –add_id_to_obs is set to ‘true’.\nboolean, default: TRUE\n\n\n\n\n\nRNA filtering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--rna_max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--rna_min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--rna_max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--rna_min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3\n\n\n--rna_min_fraction_mito\nMinimum fraction of UMIs that are mitochondrial.\ndouble, example: 0\n\n\n--rna_max_fraction_mito\nMaximum fraction of UMIs that are mitochondrial.\ndouble, example: 0.2\n\n\n--rna_min_fraction_ribo\nMinimum fraction of UMIs that are mitochondrial.\ndouble, example: 0\n\n\n--rna_max_fraction_ribo\nMaximum fraction of UMIs that are mitochondrial.\ndouble, example: 0.2\n\n\n\n\n\nCITE-seq filtering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_min_counts\nMinimum number of counts per cell.\ninteger, example: 3\n\n\n--prot_max_counts\nMinimum number of counts per cell.\ninteger, example: 5000000\n\n\n--prot_min_proteins_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--prot_max_proteins_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 100000000\n\n\n--prot_min_cells_per_protein\nMinimum of non-zero values per protein.\ninteger, example: 3\n\n\n\n\n\nGDO filtering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gdo_min_counts\nMinimum number of counts per cell.\ninteger, example: 3\n\n\n--gdo_max_counts\nMinimum number of counts per cell.\ninteger, example: 5000000\n\n\n--gdo_min_guides_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--gdo_max_guides_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 100000000\n\n\n--gdo_min_cells_per_guide\nMinimum of non-zero values per guide.\ninteger, example: 3\n\n\n\n\n\nHighly variable features detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--highly_variable_features_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable genes.\nstring, default: \"filter_with_hvg\"\n\n\n--highly_variable_features_obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method.\nstring, default: \"sample_id\"\n\n\n\n\n\nMitochondrial & Ribosomal Gene Detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial/ribosomal genes instead of .var_names (default if not set). Gene names matching with the regex value from –mitochondrial_gene_regex or –ribosomal_gene_regex will be identified as mitochondrial or ribosomal genes, respectively.\nstring, example: \"gene_symbol\"\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--obs_name_mitochondrial_fraction\nWhen specified, write the fraction of counts originating from mitochondrial genes (based on –mitochondrial_gene_regex) to an .obs column with the specified name. Requires –var_name_mitochondrial_genes.\nstring\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from –var_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\"\n\n\n--var_name_ribosomal_genes\nIn which .var slot to store a boolean array corresponding the ribosomal genes.\nstring\n\n\n--obs_name_ribosomal_fraction\nWhen specified, write the fraction of counts originating from ribosomal genes (based on –ribosomal_gene_regex) to an .obs column with the specified name. Requires –var_name_ribosomal_genes.\nstring\n\n\n--ribosomal_gene_regex\nRegex string that identifies ribosomal genes from –var_gene_names. By default will detect human and mouse ribosomal genes from a gene symbol.\nstring, default: \"^[Mm]?[Rr][Pp][LlSs]\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes. Defaults to the combined values specified for –var_name_mitochondrial_genes and –highly_variable_features_var_output.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true\n\n\n\n\n\nCLR options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clr_axis\nAxis to perform the CLR transformation on.\ninteger, default: 0\n\n\n\n\n\nRNA Scaling options\nOptions for enabling scaling of the log-normalized data to unit variance and zero mean. The scaled data will be output a different layer and representation with reduced dimensions will be created and stored in addition to the non-scaled data.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_enable_scaling\nEnable scaling for the RNA modality.\nboolean_true\n\n\n--rna_scaling_output_layer\nOutput layer where the scaled log-normalized data will be stored.\nstring, default: \"scaled\"\n\n\n--rna_scaling_pca_obsm_output\nName of the .obsm key where the PCA representation of the log-normalized and scaled data is stored.\nstring, default: \"scaled_pca\"\n\n\n--rna_scaling_pca_loadings_varm_output\nName of the .varm key where the PCA loadings of the log-normalized and scaled data is stored.\nstring, default: \"scaled_pca_loadings\"\n\n\n--rna_scaling_pca_variance_uns_output\nName of the .uns key where the variance and variance ratio will be stored as a map. The map will contain two keys: variance and variance_ratio respectively.\nstring, default: \"scaled_pca_variance\"\n\n\n--rna_scaling_umap_obsm_output\nName of the .obsm key where the UMAP representation of the log-normalized and scaled data is stored.\nstring, default: \"scaled_umap\"\n\n\n--rna_scaling_max_value\nClip (truncate) data to this value after scaling. If not specified, do not clip.\ndouble\n\n\n--rna_scaling_zero_center\nIf set, omit zero-centering variables, which allows to handle sparse input efficiently.”\nboolean_false",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Process samples"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/process_samples.html#authors",
    "href": "components/workflows/multiomics/process_samples.html#authors",
    "title": "Process samples",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Process samples"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/process_samples.html#visualisation",
    "href": "components/workflows/multiomics/process_samples.html#visualisation",
    "title": "Process samples",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v15(filter)\n    v20(add_id)\n    v27(cross)\n    v37(cross)\n    v43(filter)\n    v54(filter)\n    v66(cross)\n    v76(cross)\n    v86(concat)\n    v93(cross)\n    v103(cross)\n    v109(flatMap)\n    v115(filter)\n    v124(filter)\n    v136(branch)\n    v163(concat)\n    v148(cross)\n    v158(cross)\n    v167(branch)\n    v194(concat)\n    v179(cross)\n    v189(cross)\n    v195(filter)\n    v225(concat)\n    v210(cross)\n    v220(cross)\n    v232(cross)\n    v242(cross)\n    v251(branch)\n    v278(concat)\n    v263(cross)\n    v273(cross)\n    v282(branch)\n    v309(concat)\n    v294(cross)\n    v304(cross)\n    v310(filter)\n    v325(cross)\n    v335(cross)\n    v341(filter)\n    v356(cross)\n    v366(cross)\n    v372(filter)\n    v402(concat)\n    v387(cross)\n    v397(cross)\n    v409(cross)\n    v419(cross)\n    v621(mix)\n    v430(filter)\n    v438(filter)\n    v453(cross)\n    v463(cross)\n    v469(filter)\n    v499(concat)\n    v484(cross)\n    v494(cross)\n    v506(cross)\n    v516(cross)\n    v527(filter)\n    v535(filter)\n    v550(cross)\n    v560(cross)\n    v566(filter)\n    v596(concat)\n    v581(cross)\n    v591(cross)\n    v603(cross)\n    v613(cross)\n    v623(mix)\n    v630(filter)\n    v638(concatenate_h5mu)\n    v645(cross)\n    v655(cross)\n    v664(filter)\n    v1959(concat)\n    v673(filter)\n    v684(filter)\n    v696(cross)\n    v706(cross)\n    v716(concat)\n    v723(cross)\n    v733(cross)\n    v739(flatMap)\n    v747(filter)\n    v755(filter)\n    v770(cross)\n    v780(cross)\n    v786(filter)\n    v801(cross)\n    v811(cross)\n    v817(filter)\n    v832(cross)\n    v842(cross)\n    v851(branch)\n    v878(concat)\n    v863(cross)\n    v873(cross)\n    v879(filter)\n    v894(cross)\n    v904(cross)\n    v910(filter)\n    v1033(concat)\n    v922(branch)\n    v949(concat)\n    v934(cross)\n    v944(cross)\n    v953(branch)\n    v980(concat)\n    v965(cross)\n    v975(cross)\n    v981(filter)\n    v1011(concat)\n    v996(cross)\n    v1006(cross)\n    v1018(cross)\n    v1028(cross)\n    v1040(cross)\n    v1050(cross)\n    v1248(mix)\n    v1061(filter)\n    v1069(filter)\n    v1084(cross)\n    v1094(cross)\n    v1100(filter)\n    v1223(concat)\n    v1112(branch)\n    v1139(concat)\n    v1124(cross)\n    v1134(cross)\n    v1143(branch)\n    v1170(concat)\n    v1155(cross)\n    v1165(cross)\n    v1171(filter)\n    v1201(concat)\n    v1186(cross)\n    v1196(cross)\n    v1208(cross)\n    v1218(cross)\n    v1230(cross)\n    v1240(cross)\n    v1250(mix)\n    v1258(filter)\n    v1273(cross)\n    v1283(cross)\n    v1293(branch)\n    v1505(concat)\n    v1298(filter)\n    v1313(cross)\n    v1323(cross)\n    v1329(filter)\n    v1483(concat)\n    v1338(filter)\n    v1353(cross)\n    v1363(cross)\n    v1372(branch)\n    v1399(concat)\n    v1384(cross)\n    v1394(cross)\n    v1403(branch)\n    v1430(concat)\n    v1415(cross)\n    v1425(cross)\n    v1434(branch)\n    v1461(concat)\n    v1446(cross)\n    v1456(cross)\n    v1468(cross)\n    v1478(cross)\n    v1490(cross)\n    v1500(cross)\n    v1509(branch)\n    v1721(concat)\n    v1514(filter)\n    v1529(cross)\n    v1539(cross)\n    v1545(filter)\n    v1699(concat)\n    v1554(filter)\n    v1569(cross)\n    v1579(cross)\n    v1588(branch)\n    v1615(concat)\n    v1600(cross)\n    v1610(cross)\n    v1619(branch)\n    v1646(concat)\n    v1631(cross)\n    v1641(cross)\n    v1650(branch)\n    v1677(concat)\n    v1662(cross)\n    v1672(cross)\n    v1684(cross)\n    v1694(cross)\n    v1706(cross)\n    v1716(cross)\n    v1725(branch)\n    v1937(concat)\n    v1730(filter)\n    v1745(cross)\n    v1755(cross)\n    v1761(filter)\n    v1915(concat)\n    v1770(filter)\n    v1785(cross)\n    v1795(cross)\n    v1804(branch)\n    v1831(concat)\n    v1816(cross)\n    v1826(cross)\n    v1835(branch)\n    v1862(concat)\n    v1847(cross)\n    v1857(cross)\n    v1866(branch)\n    v1893(concat)\n    v1878(cross)\n    v1888(cross)\n    v1900(cross)\n    v1910(cross)\n    v1922(cross)\n    v1932(cross)\n    v1944(cross)\n    v1954(cross)\n    v1966(cross)\n    v1973(cross)\n    v1985(cross)\n    v1992(cross)\n    v1996(Output)\n    subgraph group_split_modalities_workflow [split_modalities_workflow]\n        v59(split_modalities_component)\n    end\n    subgraph group_rna_singlesample [rna_singlesample]\n        v141(grep_mitochondrial_genes)\n        v172(grep_ribosomal_genes)\n        v203(calculate_qc_metrics)\n        v256(delimit_fraction)\n        v287(delimit_fraction)\n        v318(rna_filter_with_counts)\n        v349(rna_do_filter)\n        v380(filter_with_scrublet)\n    end\n    subgraph group_prot_singlesample [prot_singlesample]\n        v446(prot_filter_with_counts)\n        v477(prot_do_filter)\n    end\n    subgraph group_gdo_singlesample [gdo_singlesample]\n        v543(gdo_filter_with_counts)\n        v574(gdo_do_filter)\n    end\n    subgraph group_process_batches [process_batches]\n        v689(split_modalities_component)\n        v1266(merge)\n        v1306(pca)\n        v1522(pca)\n        v1738(pca)\n        subgraph group_rna_multisample [rna_multisample]\n            v763(normalize_total)\n            v794(log1p)\n            v825(delete_layer)\n            v856(scale)\n            v887(highly_variable_features_scanpy)\n            v927(grep_mitochondrial_genes)\n            v958(grep_ribosomal_genes)\n            v989(calculate_qc_metrics)\n        end\n        subgraph group_prot_multisample [prot_multisample]\n            v1077(clr)\n            v1117(grep_mitochondrial_genes)\n            v1148(grep_ribosomal_genes)\n            v1179(calculate_qc_metrics)\n        end\n        subgraph group_neighbors_leiden_umap [neighbors_leiden_umap]\n            v1346(find_neighbors)\n            v1377(leiden)\n            v1408(move_obsm_to_obs)\n            v1439(umap)\n            v1562(find_neighbors)\n            v1593(leiden)\n            v1624(move_obsm_to_obs)\n            v1655(umap)\n            v1778(find_neighbors)\n            v1809(leiden)\n            v1840(move_obsm_to_obs)\n            v1871(umap)\n        end\n    end\n    v136--&gt;v163\n    v167--&gt;v194\n    v194--&gt;v195\n    v251--&gt;v278\n    v282--&gt;v309\n    v309--&gt;v310\n    v621--&gt;v623\n    v851--&gt;v878\n    v878--&gt;v879\n    v922--&gt;v949\n    v953--&gt;v980\n    v980--&gt;v981\n    v1112--&gt;v1139\n    v1143--&gt;v1170\n    v1170--&gt;v1171\n    v1248--&gt;v1250\n    v1293--&gt;v1505\n    v1372--&gt;v1399\n    v1403--&gt;v1430\n    v1434--&gt;v1461\n    v1509--&gt;v1721\n    v1588--&gt;v1615\n    v1619--&gt;v1646\n    v1650--&gt;v1677\n    v1725--&gt;v1937\n    v1804--&gt;v1831\n    v1835--&gt;v1862\n    v1866--&gt;v1893\n    v0--&gt;v2\n    v15--&gt;v20\n    v20--&gt;v27\n    v15--&gt;v27\n    v15--&gt;v37\n    v54--&gt;v59\n    v59--&gt;v66\n    v54--&gt;v66\n    v54--&gt;v76\n    v86--&gt;v93\n    v43--&gt;v93\n    v43--&gt;v103\n    v115--&gt;v124\n    v136--&gt;v141\n    v141--&gt;v148\n    v136--&gt;v148\n    v136--&gt;v158\n    v158--&gt;v163\n    v167--&gt;v172\n    v172--&gt;v179\n    v167--&gt;v179\n    v167--&gt;v189\n    v189--&gt;v194\n    v195--&gt;v203\n    v203--&gt;v210\n    v195--&gt;v210\n    v195--&gt;v220\n    v220--&gt;v225\n    v225--&gt;v232\n    v124--&gt;v232\n    v124--&gt;v242\n    v251--&gt;v256\n    v256--&gt;v263\n    v251--&gt;v263\n    v251--&gt;v273\n    v273--&gt;v278\n    v282--&gt;v287\n    v287--&gt;v294\n    v282--&gt;v294\n    v282--&gt;v304\n    v304--&gt;v309\n    v310--&gt;v318\n    v318--&gt;v325\n    v310--&gt;v325\n    v310--&gt;v335\n    v341--&gt;v349\n    v349--&gt;v356\n    v341--&gt;v356\n    v341--&gt;v366\n    v372--&gt;v380\n    v380--&gt;v387\n    v372--&gt;v387\n    v372--&gt;v397\n    v397--&gt;v402\n    v402--&gt;v409\n    v115--&gt;v409\n    v115--&gt;v419\n    v430--&gt;v438\n    v438--&gt;v446\n    v446--&gt;v453\n    v438--&gt;v453\n    v438--&gt;v463\n    v469--&gt;v477\n    v477--&gt;v484\n    v469--&gt;v484\n    v469--&gt;v494\n    v494--&gt;v499\n    v499--&gt;v506\n    v430--&gt;v506\n    v430--&gt;v516\n    v527--&gt;v535\n    v535--&gt;v543\n    v543--&gt;v550\n    v535--&gt;v550\n    v535--&gt;v560\n    v566--&gt;v574\n    v574--&gt;v581\n    v566--&gt;v581\n    v566--&gt;v591\n    v591--&gt;v596\n    v596--&gt;v603\n    v527--&gt;v603\n    v527--&gt;v613\n    v630--&gt;v638\n    v638--&gt;v645\n    v630--&gt;v645\n    v630--&gt;v655\n    v684--&gt;v689\n    v689--&gt;v696\n    v684--&gt;v696\n    v684--&gt;v706\n    v716--&gt;v723\n    v673--&gt;v723\n    v673--&gt;v733\n    v747--&gt;v755\n    v755--&gt;v763\n    v763--&gt;v770\n    v755--&gt;v770\n    v755--&gt;v780\n    v786--&gt;v794\n    v794--&gt;v801\n    v786--&gt;v801\n    v786--&gt;v811\n    v817--&gt;v825\n    v825--&gt;v832\n    v817--&gt;v832\n    v817--&gt;v842\n    v851--&gt;v856\n    v856--&gt;v863\n    v851--&gt;v863\n    v851--&gt;v873\n    v873--&gt;v878\n    v879--&gt;v887\n    v887--&gt;v894\n    v879--&gt;v894\n    v879--&gt;v904\n    v922--&gt;v927\n    v927--&gt;v934\n    v922--&gt;v934\n    v922--&gt;v944\n    v944--&gt;v949\n    v953--&gt;v958\n    v958--&gt;v965\n    v953--&gt;v965\n    v953--&gt;v975\n    v975--&gt;v980\n    v981--&gt;v989\n    v989--&gt;v996\n    v981--&gt;v996\n    v981--&gt;v1006\n    v1006--&gt;v1011\n    v1011--&gt;v1018\n    v910--&gt;v1018\n    v910--&gt;v1028\n    v1028--&gt;v1033\n    v1033--&gt;v1040\n    v747--&gt;v1040\n    v747--&gt;v1050\n    v1061--&gt;v1069\n    v1069--&gt;v1077\n    v1077--&gt;v1084\n    v1069--&gt;v1084\n    v1069--&gt;v1094\n    v1112--&gt;v1117\n    v1117--&gt;v1124\n    v1112--&gt;v1124\n    v1112--&gt;v1134\n    v1134--&gt;v1139\n    v1143--&gt;v1148\n    v1148--&gt;v1155\n    v1143--&gt;v1155\n    v1143--&gt;v1165\n    v1165--&gt;v1170\n    v1171--&gt;v1179\n    v1179--&gt;v1186\n    v1171--&gt;v1186\n    v1171--&gt;v1196\n    v1196--&gt;v1201\n    v1201--&gt;v1208\n    v1100--&gt;v1208\n    v1100--&gt;v1218\n    v1218--&gt;v1223\n    v1223--&gt;v1230\n    v1061--&gt;v1230\n    v1061--&gt;v1240\n    v1258--&gt;v1266\n    v1266--&gt;v1273\n    v1258--&gt;v1273\n    v1258--&gt;v1283\n    v1293--&gt;v1298\n    v1298--&gt;v1306\n    v1306--&gt;v1313\n    v1298--&gt;v1313\n    v1298--&gt;v1323\n    v1329--&gt;v1338\n    v1338--&gt;v1346\n    v1346--&gt;v1353\n    v1338--&gt;v1353\n    v1338--&gt;v1363\n    v1372--&gt;v1377\n    v1377--&gt;v1384\n    v1372--&gt;v1384\n    v1372--&gt;v1394\n    v1394--&gt;v1399\n    v1403--&gt;v1408\n    v1408--&gt;v1415\n    v1403--&gt;v1415\n    v1403--&gt;v1425\n    v1425--&gt;v1430\n    v1434--&gt;v1439\n    v1439--&gt;v1446\n    v1434--&gt;v1446\n    v1434--&gt;v1456\n    v1456--&gt;v1461\n    v1461--&gt;v1468\n    v1329--&gt;v1468\n    v1329--&gt;v1478\n    v1478--&gt;v1483\n    v1483--&gt;v1490\n    v1293--&gt;v1490\n    v1293--&gt;v1500\n    v1500--&gt;v1505\n    v1509--&gt;v1514\n    v1514--&gt;v1522\n    v1522--&gt;v1529\n    v1514--&gt;v1529\n    v1514--&gt;v1539\n    v1545--&gt;v1554\n    v1554--&gt;v1562\n    v1562--&gt;v1569\n    v1554--&gt;v1569\n    v1554--&gt;v1579\n    v1588--&gt;v1593\n    v1593--&gt;v1600\n    v1588--&gt;v1600\n    v1588--&gt;v1610\n    v1610--&gt;v1615\n    v1619--&gt;v1624\n    v1624--&gt;v1631\n    v1619--&gt;v1631\n    v1619--&gt;v1641\n    v1641--&gt;v1646\n    v1650--&gt;v1655\n    v1655--&gt;v1662\n    v1650--&gt;v1662\n    v1650--&gt;v1672\n    v1672--&gt;v1677\n    v1677--&gt;v1684\n    v1545--&gt;v1684\n    v1545--&gt;v1694\n    v1694--&gt;v1699\n    v1699--&gt;v1706\n    v1509--&gt;v1706\n    v1509--&gt;v1716\n    v1716--&gt;v1721\n    v1725--&gt;v1730\n    v1730--&gt;v1738\n    v1738--&gt;v1745\n    v1730--&gt;v1745\n    v1730--&gt;v1755\n    v1761--&gt;v1770\n    v1770--&gt;v1778\n    v1778--&gt;v1785\n    v1770--&gt;v1785\n    v1770--&gt;v1795\n    v1804--&gt;v1809\n    v1809--&gt;v1816\n    v1804--&gt;v1816\n    v1804--&gt;v1826\n    v1826--&gt;v1831\n    v1835--&gt;v1840\n    v1840--&gt;v1847\n    v1835--&gt;v1847\n    v1835--&gt;v1857\n    v1857--&gt;v1862\n    v1866--&gt;v1871\n    v1871--&gt;v1878\n    v1866--&gt;v1878\n    v1866--&gt;v1888\n    v1888--&gt;v1893\n    v1893--&gt;v1900\n    v1761--&gt;v1900\n    v1761--&gt;v1910\n    v1910--&gt;v1915\n    v1915--&gt;v1922\n    v1725--&gt;v1922\n    v1725--&gt;v1932\n    v1932--&gt;v1937\n    v1937--&gt;v1944\n    v664--&gt;v1944\n    v664--&gt;v1954\n    v1954--&gt;v1959\n    v1959--&gt;v1966\n    v2--&gt;v1966\n    v1966--&gt;v1973\n    v2--&gt;v1973\n    v2--&gt;v1985\n    v1985--&gt;v1992\n    v2--&gt;v1992\n    v1992--&gt;v1996\n    v2--&gt;v15\n    v37--&gt;v43\n    v20--&gt;v37\n    v103--&gt;v109\n    v43--&gt;v54\n    v76--&gt;v86\n    v59--&gt;v76\n    v86--&gt;v103\n    v109--&gt;v115\n    v419--&gt;v621\n    v124--&gt;v136\n    v141--&gt;v158\n    v163--&gt;v167\n    v172--&gt;v189\n    v203--&gt;v220\n    v225--&gt;v242\n    v242--&gt;v251\n    v256--&gt;v273\n    v278--&gt;v282\n    v287--&gt;v304\n    v335--&gt;v341\n    v318--&gt;v335\n    v366--&gt;v372\n    v349--&gt;v366\n    v380--&gt;v397\n    v402--&gt;v419\n    v109--&gt;v430\n    v516--&gt;v621\n    v463--&gt;v469\n    v446--&gt;v463\n    v477--&gt;v494\n    v499--&gt;v516\n    v109--&gt;v527\n    v613--&gt;v621\n    v560--&gt;v566\n    v543--&gt;v560\n    v574--&gt;v591\n    v596--&gt;v613\n    v109--&gt;v623\n    v623--&gt;v630\n    v638--&gt;v655\n    v655--&gt;v664\n    v664--&gt;v673\n    v733--&gt;v739\n    v673--&gt;v684\n    v706--&gt;v716\n    v689--&gt;v706\n    v716--&gt;v733\n    v739--&gt;v747\n    v1050--&gt;v1248\n    v780--&gt;v786\n    v763--&gt;v780\n    v811--&gt;v817\n    v794--&gt;v811\n    v825--&gt;v842\n    v842--&gt;v851\n    v856--&gt;v873\n    v904--&gt;v910\n    v887--&gt;v904\n    v910--&gt;v922\n    v927--&gt;v944\n    v949--&gt;v953\n    v958--&gt;v975\n    v989--&gt;v1006\n    v1011--&gt;v1028\n    v1033--&gt;v1050\n    v739--&gt;v1061\n    v1240--&gt;v1248\n    v1094--&gt;v1100\n    v1077--&gt;v1094\n    v1100--&gt;v1112\n    v1117--&gt;v1134\n    v1139--&gt;v1143\n    v1148--&gt;v1165\n    v1179--&gt;v1196\n    v1201--&gt;v1218\n    v1223--&gt;v1240\n    v739--&gt;v1250\n    v1250--&gt;v1258\n    v1266--&gt;v1283\n    v1283--&gt;v1293\n    v1323--&gt;v1329\n    v1306--&gt;v1323\n    v1346--&gt;v1363\n    v1363--&gt;v1372\n    v1377--&gt;v1394\n    v1399--&gt;v1403\n    v1408--&gt;v1425\n    v1430--&gt;v1434\n    v1439--&gt;v1456\n    v1461--&gt;v1478\n    v1483--&gt;v1500\n    v1505--&gt;v1509\n    v1539--&gt;v1545\n    v1522--&gt;v1539\n    v1562--&gt;v1579\n    v1579--&gt;v1588\n    v1593--&gt;v1610\n    v1615--&gt;v1619\n    v1624--&gt;v1641\n    v1646--&gt;v1650\n    v1655--&gt;v1672\n    v1677--&gt;v1694\n    v1699--&gt;v1716\n    v1721--&gt;v1725\n    v1755--&gt;v1761\n    v1738--&gt;v1755\n    v1778--&gt;v1795\n    v1795--&gt;v1804\n    v1809--&gt;v1826\n    v1831--&gt;v1835\n    v1840--&gt;v1857\n    v1862--&gt;v1866\n    v1871--&gt;v1888\n    v1893--&gt;v1910\n    v1915--&gt;v1932\n    v1937--&gt;v1954\n    v1959--&gt;v1985\n    style group_split_modalities_workflow fill:#F0F0F0,stroke:#969696;\n    style group_rna_singlesample fill:#F0F0F0,stroke:#969696;\n    style group_prot_singlesample fill:#F0F0F0,stroke:#969696;\n    style group_gdo_singlesample fill:#F0F0F0,stroke:#969696;\n    style group_process_batches fill:#F0F0F0,stroke:#969696;\n    style group_rna_multisample fill:#D9D9D9,stroke:#737373;\n    style group_prot_multisample fill:#D9D9D9,stroke:#737373;\n    style group_neighbors_leiden_umap fill:#D9D9D9,stroke:#737373;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v15 fill:#e3dcea,stroke:#7a4baa;\n    style v20 fill:#e3dcea,stroke:#7a4baa;\n    style v27 fill:#e3dcea,stroke:#7a4baa;\n    style v37 fill:#e3dcea,stroke:#7a4baa;\n    style v43 fill:#e3dcea,stroke:#7a4baa;\n    style v54 fill:#e3dcea,stroke:#7a4baa;\n    style v59 fill:#e3dcea,stroke:#7a4baa;\n    style v66 fill:#e3dcea,stroke:#7a4baa;\n    style v76 fill:#e3dcea,stroke:#7a4baa;\n    style v86 fill:#e3dcea,stroke:#7a4baa;\n    style v93 fill:#e3dcea,stroke:#7a4baa;\n    style v103 fill:#e3dcea,stroke:#7a4baa;\n    style v109 fill:#e3dcea,stroke:#7a4baa;\n    style v115 fill:#e3dcea,stroke:#7a4baa;\n    style v124 fill:#e3dcea,stroke:#7a4baa;\n    style v136 fill:#e3dcea,stroke:#7a4baa;\n    style v163 fill:#e3dcea,stroke:#7a4baa;\n    style v141 fill:#e3dcea,stroke:#7a4baa;\n    style v148 fill:#e3dcea,stroke:#7a4baa;\n    style v158 fill:#e3dcea,stroke:#7a4baa;\n    style v167 fill:#e3dcea,stroke:#7a4baa;\n    style v194 fill:#e3dcea,stroke:#7a4baa;\n    style v172 fill:#e3dcea,stroke:#7a4baa;\n    style v179 fill:#e3dcea,stroke:#7a4baa;\n    style v189 fill:#e3dcea,stroke:#7a4baa;\n    style v195 fill:#e3dcea,stroke:#7a4baa;\n    style v225 fill:#e3dcea,stroke:#7a4baa;\n    style v203 fill:#e3dcea,stroke:#7a4baa;\n    style v210 fill:#e3dcea,stroke:#7a4baa;\n    style v220 fill:#e3dcea,stroke:#7a4baa;\n    style v232 fill:#e3dcea,stroke:#7a4baa;\n    style v242 fill:#e3dcea,stroke:#7a4baa;\n    style v251 fill:#e3dcea,stroke:#7a4baa;\n    style v278 fill:#e3dcea,stroke:#7a4baa;\n    style v256 fill:#e3dcea,stroke:#7a4baa;\n    style v263 fill:#e3dcea,stroke:#7a4baa;\n    style v273 fill:#e3dcea,stroke:#7a4baa;\n    style v282 fill:#e3dcea,stroke:#7a4baa;\n    style v309 fill:#e3dcea,stroke:#7a4baa;\n    style v287 fill:#e3dcea,stroke:#7a4baa;\n    style v294 fill:#e3dcea,stroke:#7a4baa;\n    style v304 fill:#e3dcea,stroke:#7a4baa;\n    style v310 fill:#e3dcea,stroke:#7a4baa;\n    style v318 fill:#e3dcea,stroke:#7a4baa;\n    style v325 fill:#e3dcea,stroke:#7a4baa;\n    style v335 fill:#e3dcea,stroke:#7a4baa;\n    style v341 fill:#e3dcea,stroke:#7a4baa;\n    style v349 fill:#e3dcea,stroke:#7a4baa;\n    style v356 fill:#e3dcea,stroke:#7a4baa;\n    style v366 fill:#e3dcea,stroke:#7a4baa;\n    style v372 fill:#e3dcea,stroke:#7a4baa;\n    style v402 fill:#e3dcea,stroke:#7a4baa;\n    style v380 fill:#e3dcea,stroke:#7a4baa;\n    style v387 fill:#e3dcea,stroke:#7a4baa;\n    style v397 fill:#e3dcea,stroke:#7a4baa;\n    style v409 fill:#e3dcea,stroke:#7a4baa;\n    style v419 fill:#e3dcea,stroke:#7a4baa;\n    style v621 fill:#e3dcea,stroke:#7a4baa;\n    style v430 fill:#e3dcea,stroke:#7a4baa;\n    style v438 fill:#e3dcea,stroke:#7a4baa;\n    style v446 fill:#e3dcea,stroke:#7a4baa;\n    style v453 fill:#e3dcea,stroke:#7a4baa;\n    style v463 fill:#e3dcea,stroke:#7a4baa;\n    style v469 fill:#e3dcea,stroke:#7a4baa;\n    style v499 fill:#e3dcea,stroke:#7a4baa;\n    style v477 fill:#e3dcea,stroke:#7a4baa;\n    style v484 fill:#e3dcea,stroke:#7a4baa;\n    style v494 fill:#e3dcea,stroke:#7a4baa;\n    style v506 fill:#e3dcea,stroke:#7a4baa;\n    style v516 fill:#e3dcea,stroke:#7a4baa;\n    style v527 fill:#e3dcea,stroke:#7a4baa;\n    style v535 fill:#e3dcea,stroke:#7a4baa;\n    style v543 fill:#e3dcea,stroke:#7a4baa;\n    style v550 fill:#e3dcea,stroke:#7a4baa;\n    style v560 fill:#e3dcea,stroke:#7a4baa;\n    style v566 fill:#e3dcea,stroke:#7a4baa;\n    style v596 fill:#e3dcea,stroke:#7a4baa;\n    style v574 fill:#e3dcea,stroke:#7a4baa;\n    style v581 fill:#e3dcea,stroke:#7a4baa;\n    style v591 fill:#e3dcea,stroke:#7a4baa;\n    style v603 fill:#e3dcea,stroke:#7a4baa;\n    style v613 fill:#e3dcea,stroke:#7a4baa;\n    style v623 fill:#e3dcea,stroke:#7a4baa;\n    style v630 fill:#e3dcea,stroke:#7a4baa;\n    style v638 fill:#e3dcea,stroke:#7a4baa;\n    style v645 fill:#e3dcea,stroke:#7a4baa;\n    style v655 fill:#e3dcea,stroke:#7a4baa;\n    style v664 fill:#e3dcea,stroke:#7a4baa;\n    style v1959 fill:#e3dcea,stroke:#7a4baa;\n    style v673 fill:#e3dcea,stroke:#7a4baa;\n    style v684 fill:#e3dcea,stroke:#7a4baa;\n    style v689 fill:#e3dcea,stroke:#7a4baa;\n    style v696 fill:#e3dcea,stroke:#7a4baa;\n    style v706 fill:#e3dcea,stroke:#7a4baa;\n    style v716 fill:#e3dcea,stroke:#7a4baa;\n    style v723 fill:#e3dcea,stroke:#7a4baa;\n    style v733 fill:#e3dcea,stroke:#7a4baa;\n    style v739 fill:#e3dcea,stroke:#7a4baa;\n    style v747 fill:#e3dcea,stroke:#7a4baa;\n    style v755 fill:#e3dcea,stroke:#7a4baa;\n    style v763 fill:#e3dcea,stroke:#7a4baa;\n    style v770 fill:#e3dcea,stroke:#7a4baa;\n    style v780 fill:#e3dcea,stroke:#7a4baa;\n    style v786 fill:#e3dcea,stroke:#7a4baa;\n    style v794 fill:#e3dcea,stroke:#7a4baa;\n    style v801 fill:#e3dcea,stroke:#7a4baa;\n    style v811 fill:#e3dcea,stroke:#7a4baa;\n    style v817 fill:#e3dcea,stroke:#7a4baa;\n    style v825 fill:#e3dcea,stroke:#7a4baa;\n    style v832 fill:#e3dcea,stroke:#7a4baa;\n    style v842 fill:#e3dcea,stroke:#7a4baa;\n    style v851 fill:#e3dcea,stroke:#7a4baa;\n    style v878 fill:#e3dcea,stroke:#7a4baa;\n    style v856 fill:#e3dcea,stroke:#7a4baa;\n    style v863 fill:#e3dcea,stroke:#7a4baa;\n    style v873 fill:#e3dcea,stroke:#7a4baa;\n    style v879 fill:#e3dcea,stroke:#7a4baa;\n    style v887 fill:#e3dcea,stroke:#7a4baa;\n    style v894 fill:#e3dcea,stroke:#7a4baa;\n    style v904 fill:#e3dcea,stroke:#7a4baa;\n    style v910 fill:#e3dcea,stroke:#7a4baa;\n    style v1033 fill:#e3dcea,stroke:#7a4baa;\n    style v922 fill:#e3dcea,stroke:#7a4baa;\n    style v949 fill:#e3dcea,stroke:#7a4baa;\n    style v927 fill:#e3dcea,stroke:#7a4baa;\n    style v934 fill:#e3dcea,stroke:#7a4baa;\n    style v944 fill:#e3dcea,stroke:#7a4baa;\n    style v953 fill:#e3dcea,stroke:#7a4baa;\n    style v980 fill:#e3dcea,stroke:#7a4baa;\n    style v958 fill:#e3dcea,stroke:#7a4baa;\n    style v965 fill:#e3dcea,stroke:#7a4baa;\n    style v975 fill:#e3dcea,stroke:#7a4baa;\n    style v981 fill:#e3dcea,stroke:#7a4baa;\n    style v1011 fill:#e3dcea,stroke:#7a4baa;\n    style v989 fill:#e3dcea,stroke:#7a4baa;\n    style v996 fill:#e3dcea,stroke:#7a4baa;\n    style v1006 fill:#e3dcea,stroke:#7a4baa;\n    style v1018 fill:#e3dcea,stroke:#7a4baa;\n    style v1028 fill:#e3dcea,stroke:#7a4baa;\n    style v1040 fill:#e3dcea,stroke:#7a4baa;\n    style v1050 fill:#e3dcea,stroke:#7a4baa;\n    style v1248 fill:#e3dcea,stroke:#7a4baa;\n    style v1061 fill:#e3dcea,stroke:#7a4baa;\n    style v1069 fill:#e3dcea,stroke:#7a4baa;\n    style v1077 fill:#e3dcea,stroke:#7a4baa;\n    style v1084 fill:#e3dcea,stroke:#7a4baa;\n    style v1094 fill:#e3dcea,stroke:#7a4baa;\n    style v1100 fill:#e3dcea,stroke:#7a4baa;\n    style v1223 fill:#e3dcea,stroke:#7a4baa;\n    style v1112 fill:#e3dcea,stroke:#7a4baa;\n    style v1139 fill:#e3dcea,stroke:#7a4baa;\n    style v1117 fill:#e3dcea,stroke:#7a4baa;\n    style v1124 fill:#e3dcea,stroke:#7a4baa;\n    style v1134 fill:#e3dcea,stroke:#7a4baa;\n    style v1143 fill:#e3dcea,stroke:#7a4baa;\n    style v1170 fill:#e3dcea,stroke:#7a4baa;\n    style v1148 fill:#e3dcea,stroke:#7a4baa;\n    style v1155 fill:#e3dcea,stroke:#7a4baa;\n    style v1165 fill:#e3dcea,stroke:#7a4baa;\n    style v1171 fill:#e3dcea,stroke:#7a4baa;\n    style v1201 fill:#e3dcea,stroke:#7a4baa;\n    style v1179 fill:#e3dcea,stroke:#7a4baa;\n    style v1186 fill:#e3dcea,stroke:#7a4baa;\n    style v1196 fill:#e3dcea,stroke:#7a4baa;\n    style v1208 fill:#e3dcea,stroke:#7a4baa;\n    style v1218 fill:#e3dcea,stroke:#7a4baa;\n    style v1230 fill:#e3dcea,stroke:#7a4baa;\n    style v1240 fill:#e3dcea,stroke:#7a4baa;\n    style v1250 fill:#e3dcea,stroke:#7a4baa;\n    style v1258 fill:#e3dcea,stroke:#7a4baa;\n    style v1266 fill:#e3dcea,stroke:#7a4baa;\n    style v1273 fill:#e3dcea,stroke:#7a4baa;\n    style v1283 fill:#e3dcea,stroke:#7a4baa;\n    style v1293 fill:#e3dcea,stroke:#7a4baa;\n    style v1505 fill:#e3dcea,stroke:#7a4baa;\n    style v1298 fill:#e3dcea,stroke:#7a4baa;\n    style v1306 fill:#e3dcea,stroke:#7a4baa;\n    style v1313 fill:#e3dcea,stroke:#7a4baa;\n    style v1323 fill:#e3dcea,stroke:#7a4baa;\n    style v1329 fill:#e3dcea,stroke:#7a4baa;\n    style v1483 fill:#e3dcea,stroke:#7a4baa;\n    style v1338 fill:#e3dcea,stroke:#7a4baa;\n    style v1346 fill:#e3dcea,stroke:#7a4baa;\n    style v1353 fill:#e3dcea,stroke:#7a4baa;\n    style v1363 fill:#e3dcea,stroke:#7a4baa;\n    style v1372 fill:#e3dcea,stroke:#7a4baa;\n    style v1399 fill:#e3dcea,stroke:#7a4baa;\n    style v1377 fill:#e3dcea,stroke:#7a4baa;\n    style v1384 fill:#e3dcea,stroke:#7a4baa;\n    style v1394 fill:#e3dcea,stroke:#7a4baa;\n    style v1403 fill:#e3dcea,stroke:#7a4baa;\n    style v1430 fill:#e3dcea,stroke:#7a4baa;\n    style v1408 fill:#e3dcea,stroke:#7a4baa;\n    style v1415 fill:#e3dcea,stroke:#7a4baa;\n    style v1425 fill:#e3dcea,stroke:#7a4baa;\n    style v1434 fill:#e3dcea,stroke:#7a4baa;\n    style v1461 fill:#e3dcea,stroke:#7a4baa;\n    style v1439 fill:#e3dcea,stroke:#7a4baa;\n    style v1446 fill:#e3dcea,stroke:#7a4baa;\n    style v1456 fill:#e3dcea,stroke:#7a4baa;\n    style v1468 fill:#e3dcea,stroke:#7a4baa;\n    style v1478 fill:#e3dcea,stroke:#7a4baa;\n    style v1490 fill:#e3dcea,stroke:#7a4baa;\n    style v1500 fill:#e3dcea,stroke:#7a4baa;\n    style v1509 fill:#e3dcea,stroke:#7a4baa;\n    style v1721 fill:#e3dcea,stroke:#7a4baa;\n    style v1514 fill:#e3dcea,stroke:#7a4baa;\n    style v1522 fill:#e3dcea,stroke:#7a4baa;\n    style v1529 fill:#e3dcea,stroke:#7a4baa;\n    style v1539 fill:#e3dcea,stroke:#7a4baa;\n    style v1545 fill:#e3dcea,stroke:#7a4baa;\n    style v1699 fill:#e3dcea,stroke:#7a4baa;\n    style v1554 fill:#e3dcea,stroke:#7a4baa;\n    style v1562 fill:#e3dcea,stroke:#7a4baa;\n    style v1569 fill:#e3dcea,stroke:#7a4baa;\n    style v1579 fill:#e3dcea,stroke:#7a4baa;\n    style v1588 fill:#e3dcea,stroke:#7a4baa;\n    style v1615 fill:#e3dcea,stroke:#7a4baa;\n    style v1593 fill:#e3dcea,stroke:#7a4baa;\n    style v1600 fill:#e3dcea,stroke:#7a4baa;\n    style v1610 fill:#e3dcea,stroke:#7a4baa;\n    style v1619 fill:#e3dcea,stroke:#7a4baa;\n    style v1646 fill:#e3dcea,stroke:#7a4baa;\n    style v1624 fill:#e3dcea,stroke:#7a4baa;\n    style v1631 fill:#e3dcea,stroke:#7a4baa;\n    style v1641 fill:#e3dcea,stroke:#7a4baa;\n    style v1650 fill:#e3dcea,stroke:#7a4baa;\n    style v1677 fill:#e3dcea,stroke:#7a4baa;\n    style v1655 fill:#e3dcea,stroke:#7a4baa;\n    style v1662 fill:#e3dcea,stroke:#7a4baa;\n    style v1672 fill:#e3dcea,stroke:#7a4baa;\n    style v1684 fill:#e3dcea,stroke:#7a4baa;\n    style v1694 fill:#e3dcea,stroke:#7a4baa;\n    style v1706 fill:#e3dcea,stroke:#7a4baa;\n    style v1716 fill:#e3dcea,stroke:#7a4baa;\n    style v1725 fill:#e3dcea,stroke:#7a4baa;\n    style v1937 fill:#e3dcea,stroke:#7a4baa;\n    style v1730 fill:#e3dcea,stroke:#7a4baa;\n    style v1738 fill:#e3dcea,stroke:#7a4baa;\n    style v1745 fill:#e3dcea,stroke:#7a4baa;\n    style v1755 fill:#e3dcea,stroke:#7a4baa;\n    style v1761 fill:#e3dcea,stroke:#7a4baa;\n    style v1915 fill:#e3dcea,stroke:#7a4baa;\n    style v1770 fill:#e3dcea,stroke:#7a4baa;\n    style v1778 fill:#e3dcea,stroke:#7a4baa;\n    style v1785 fill:#e3dcea,stroke:#7a4baa;\n    style v1795 fill:#e3dcea,stroke:#7a4baa;\n    style v1804 fill:#e3dcea,stroke:#7a4baa;\n    style v1831 fill:#e3dcea,stroke:#7a4baa;\n    style v1809 fill:#e3dcea,stroke:#7a4baa;\n    style v1816 fill:#e3dcea,stroke:#7a4baa;\n    style v1826 fill:#e3dcea,stroke:#7a4baa;\n    style v1835 fill:#e3dcea,stroke:#7a4baa;\n    style v1862 fill:#e3dcea,stroke:#7a4baa;\n    style v1840 fill:#e3dcea,stroke:#7a4baa;\n    style v1847 fill:#e3dcea,stroke:#7a4baa;\n    style v1857 fill:#e3dcea,stroke:#7a4baa;\n    style v1866 fill:#e3dcea,stroke:#7a4baa;\n    style v1893 fill:#e3dcea,stroke:#7a4baa;\n    style v1871 fill:#e3dcea,stroke:#7a4baa;\n    style v1878 fill:#e3dcea,stroke:#7a4baa;\n    style v1888 fill:#e3dcea,stroke:#7a4baa;\n    style v1900 fill:#e3dcea,stroke:#7a4baa;\n    style v1910 fill:#e3dcea,stroke:#7a4baa;\n    style v1922 fill:#e3dcea,stroke:#7a4baa;\n    style v1932 fill:#e3dcea,stroke:#7a4baa;\n    style v1944 fill:#e3dcea,stroke:#7a4baa;\n    style v1954 fill:#e3dcea,stroke:#7a4baa;\n    style v1966 fill:#e3dcea,stroke:#7a4baa;\n    style v1973 fill:#e3dcea,stroke:#7a4baa;\n    style v1985 fill:#e3dcea,stroke:#7a4baa;\n    style v1992 fill:#e3dcea,stroke:#7a4baa;\n    style v1996 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Process samples"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/split_h5mu.html",
    "href": "components/workflows/multiomics/split_h5mu.html",
    "title": "Split h5mu",
    "section": "",
    "text": "ID: split_h5mu\nNamespace: workflows/multiomics\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Split h5mu"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/split_h5mu.html#example-commands",
    "href": "components/workflows/multiomics/split_h5mu.html#example-commands",
    "title": "Split h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/multiomics/split_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input & specifications\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\nobs_feature: # please fill in - example: \"celltype\"\ndrop_obs_nan: false\nensure_unique_filenames: false\n\n# Outputs\n# output: \"$id.$key.output\"\n# output_compression: \"gzip\"\n# output_files: \"$id.$key.output_files.csv\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/multiomics/split_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Split h5mu"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/split_h5mu.html#argument-groups",
    "href": "components/workflows/multiomics/split_h5mu.html#argument-groups",
    "title": "Split h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput & specifications\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to a single .h5mu file.\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obs_feature\nThe .obs column to split the mudata on.\nstring, required, example: \"celltype\"\n\n\n--drop_obs_nan\nWhether to drop all .obs columns that contain only nan values after splitting.\nboolean_true\n\n\n--ensure_unique_filenames\nAppend number suffixes to ensure unique filenames after sanitizing obs feature values.\nboolean_true\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory containing multiple h5mu files.\nfile, required, example: \"/path/to/output\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_files\nA csv containing the base filename and obs feature by which it was split.\nfile, required, example: \"sample_files.csv\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Split h5mu"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/split_h5mu.html#authors",
    "href": "components/workflows/multiomics/split_h5mu.html#authors",
    "title": "Split h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Split h5mu"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/split_h5mu.html#visualisation",
    "href": "components/workflows/multiomics/split_h5mu.html#visualisation",
    "title": "Split h5mu",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v13(filter)\n    v18(split_h5mu_component)\n    v25(cross)\n    v35(cross)\n    v45(concat)\n    v52(cross)\n    v59(cross)\n    v71(cross)\n    v78(cross)\n    v82(Output)\n    v0--&gt;v2\n    v13--&gt;v18\n    v18--&gt;v25\n    v13--&gt;v25\n    v13--&gt;v35\n    v45--&gt;v52\n    v2--&gt;v52\n    v52--&gt;v59\n    v2--&gt;v59\n    v2--&gt;v71\n    v71--&gt;v78\n    v2--&gt;v78\n    v78--&gt;v82\n    v2--&gt;v13\n    v35--&gt;v45\n    v18--&gt;v35\n    v45--&gt;v71\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v13 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v45 fill:#e3dcea,stroke:#7a4baa;\n    style v52 fill:#e3dcea,stroke:#7a4baa;\n    style v59 fill:#e3dcea,stroke:#7a4baa;\n    style v71 fill:#e3dcea,stroke:#7a4baa;\n    style v78 fill:#e3dcea,stroke:#7a4baa;\n    style v82 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Split h5mu"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/split_modalities.html",
    "href": "components/workflows/multiomics/split_modalities.html",
    "title": "Split modalities",
    "section": "",
    "text": "ID: split_modalities\nNamespace: workflows/multiomics\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Split modalities"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/split_modalities.html#example-commands",
    "href": "components/workflows/multiomics/split_modalities.html#example-commands",
    "title": "Split modalities",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/multiomics/split_modalities/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output\"\n# output_types: \"$id.$key.output_types.csv\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/multiomics/split_modalities/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Split modalities"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/split_modalities.html#argument-groups",
    "href": "components/workflows/multiomics/split_modalities.html#argument-groups",
    "title": "Split modalities",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory containing multiple h5mu files.\nfile, required, example: \"/path/to/output\"\n\n\n--output_types\nA csv containing the base filename and modality type per output file.\nfile, required, example: \"types.csv\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Split modalities"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/split_modalities.html#authors",
    "href": "components/workflows/multiomics/split_modalities.html#authors",
    "title": "Split modalities",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Split modalities"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/split_modalities.html#visualisation",
    "href": "components/workflows/multiomics/split_modalities.html#visualisation",
    "title": "Split modalities",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v13(filter)\n    v18(split_modalities_component)\n    v25(cross)\n    v35(cross)\n    v45(concat)\n    v52(cross)\n    v59(cross)\n    v71(cross)\n    v78(cross)\n    v82(Output)\n    v0--&gt;v2\n    v13--&gt;v18\n    v18--&gt;v25\n    v13--&gt;v25\n    v13--&gt;v35\n    v45--&gt;v52\n    v2--&gt;v52\n    v52--&gt;v59\n    v2--&gt;v59\n    v2--&gt;v71\n    v71--&gt;v78\n    v2--&gt;v78\n    v78--&gt;v82\n    v2--&gt;v13\n    v35--&gt;v45\n    v18--&gt;v35\n    v45--&gt;v71\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v13 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v45 fill:#e3dcea,stroke:#7a4baa;\n    style v52 fill:#e3dcea,stroke:#7a4baa;\n    style v59 fill:#e3dcea,stroke:#7a4baa;\n    style v71 fill:#e3dcea,stroke:#7a4baa;\n    style v78 fill:#e3dcea,stroke:#7a4baa;\n    style v82 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Split modalities"
    ]
  },
  {
    "objectID": "components/workflows/rna/rna_singlesample.html",
    "href": "components/workflows/rna/rna_singlesample.html",
    "title": "Rna singlesample",
    "section": "",
    "text": "ID: rna_singlesample\nNamespace: workflows/rna\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Rna",
      "Rna singlesample"
    ]
  },
  {
    "objectID": "components/workflows/rna/rna_singlesample.html#example-commands",
    "href": "components/workflows/rna/rna_singlesample.html#example-commands",
    "title": "Rna singlesample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/rna/rna_singlesample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n# layer: \"foo\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering options\n# min_counts: 200\n# max_counts: 5000000\n# min_genes_per_cell: 200\n# max_genes_per_cell: 1500000\n# min_cells_per_gene: 3\n# min_fraction_mito: 0.0\n# max_fraction_mito: 0.2\n# min_fraction_ribo: 0.0\n# max_fraction_ribo: 0.2\n\n# Mitochondrial & Ribosomal Gene Detection\n# var_gene_names: \"gene_symbol\"\n# var_name_mitochondrial_genes: \"foo\"\n# obs_name_mitochondrial_fraction: \"foo\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n# var_name_ribosomal_genes: \"foo\"\n# obs_name_ribosomal_fraction: \"foo\"\nribosomal_gene_regex: \"^[Mm]?[Rr][Pp][LlSs]\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/rna/rna_singlesample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Rna",
      "Rna singlesample"
    ]
  },
  {
    "objectID": "components/workflows/rna/rna_singlesample.html#argument-groups",
    "href": "components/workflows/rna/rna_singlesample.html#argument-groups",
    "title": "Rna singlesample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nInput layer to start from. By default, .X will be used.\nstring\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3\n\n\n--min_fraction_mito\nMinimum fraction of UMIs that are mitochondrial. Requires –obs_name_mitochondrial_fraction.\ndouble, example: 0\n\n\n--max_fraction_mito\nMaximum fraction of UMIs that are mitochondrial. Requires –obs_name_mitochondrial_fraction.\ndouble, example: 0.2\n\n\n--min_fraction_ribo\nMinimum fraction of UMIs that are ribosomal. Requires –obs_name_ribosomal_fraction.\ndouble, example: 0\n\n\n--max_fraction_ribo\nMaximum fraction of UMIs that are ribosomal. Requires –obs_name_ribosomal_fraction.\ndouble, example: 0.2\n\n\n\n\n\nMitochondrial & Ribosomal Gene Detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial/ribosomal genes instead of .var_names (default if not set). Gene names matching with the regex value from –mitochondrial_gene_regex or –ribosomal_gene_regex will be identified as mitochondrial or ribosomal genes, respectively.\nstring, example: \"gene_symbol\"\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--obs_name_mitochondrial_fraction\nWhen specified, write the fraction of counts originating from mitochondrial genes (based on –mitochondrial_gene_regex) to an .obs column with the specified name. Requires –var_name_mitochondrial_genes.\nstring\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from –var_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\"\n\n\n--var_name_ribosomal_genes\nIn which .var slot to store a boolean array corresponding the ribosomal genes.\nstring\n\n\n--obs_name_ribosomal_fraction\nWhen specified, write the fraction of counts originating from ribosomal genes (based on –ribosomal_gene_regex) to an .obs column with the specified name. Requires –var_name_ribosomal_genes.\nstring\n\n\n--ribosomal_gene_regex\nRegex string that identifies ribosomal genes from –var_gene_names. By default will detect human and mouse ribosomal genes from a gene symbol.\nstring, default: \"^[Mm]?[Rr][Pp][LlSs]\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Rna",
      "Rna singlesample"
    ]
  },
  {
    "objectID": "components/workflows/rna/rna_singlesample.html#authors",
    "href": "components/workflows/rna/rna_singlesample.html#authors",
    "title": "Rna singlesample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Rna",
      "Rna singlesample"
    ]
  },
  {
    "objectID": "components/workflows/rna/rna_singlesample.html#visualisation",
    "href": "components/workflows/rna/rna_singlesample.html#visualisation",
    "title": "Rna singlesample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v11(filter)\n    v23(branch)\n    v50(concat)\n    v35(cross)\n    v45(cross)\n    v54(branch)\n    v81(concat)\n    v66(cross)\n    v76(cross)\n    v82(filter)\n    v112(concat)\n    v97(cross)\n    v107(cross)\n    v119(cross)\n    v129(cross)\n    v138(branch)\n    v165(concat)\n    v143(delimit_fraction)\n    v150(cross)\n    v160(cross)\n    v169(branch)\n    v196(concat)\n    v174(delimit_fraction)\n    v181(cross)\n    v191(cross)\n    v197(filter)\n    v205(rna_filter_with_counts)\n    v212(cross)\n    v222(cross)\n    v228(filter)\n    v236(rna_do_filter)\n    v243(cross)\n    v253(cross)\n    v259(filter)\n    v289(concat)\n    v267(filter_with_scrublet)\n    v274(cross)\n    v284(cross)\n    v296(cross)\n    v303(cross)\n    v315(cross)\n    v322(cross)\n    v326(Output)\n    subgraph group_qc [qc]\n        v28(grep_mitochondrial_genes)\n        v59(grep_ribosomal_genes)\n        v90(calculate_qc_metrics)\n    end\n    v23--&gt;v50\n    v54--&gt;v81\n    v81--&gt;v82\n    v138--&gt;v165\n    v169--&gt;v196\n    v196--&gt;v197\n    v0--&gt;v2\n    v2--&gt;v11\n    v23--&gt;v28\n    v28--&gt;v35\n    v23--&gt;v35\n    v23--&gt;v45\n    v45--&gt;v50\n    v54--&gt;v59\n    v59--&gt;v66\n    v54--&gt;v66\n    v54--&gt;v76\n    v76--&gt;v81\n    v82--&gt;v90\n    v90--&gt;v97\n    v82--&gt;v97\n    v82--&gt;v107\n    v107--&gt;v112\n    v112--&gt;v119\n    v11--&gt;v119\n    v11--&gt;v129\n    v138--&gt;v143\n    v143--&gt;v150\n    v138--&gt;v150\n    v138--&gt;v160\n    v160--&gt;v165\n    v169--&gt;v174\n    v174--&gt;v181\n    v169--&gt;v181\n    v169--&gt;v191\n    v191--&gt;v196\n    v197--&gt;v205\n    v205--&gt;v212\n    v197--&gt;v212\n    v197--&gt;v222\n    v228--&gt;v236\n    v236--&gt;v243\n    v228--&gt;v243\n    v228--&gt;v253\n    v259--&gt;v267\n    v267--&gt;v274\n    v259--&gt;v274\n    v259--&gt;v284\n    v284--&gt;v289\n    v289--&gt;v296\n    v2--&gt;v296\n    v296--&gt;v303\n    v2--&gt;v303\n    v2--&gt;v315\n    v315--&gt;v322\n    v2--&gt;v322\n    v322--&gt;v326\n    v11--&gt;v23\n    v28--&gt;v45\n    v50--&gt;v54\n    v59--&gt;v76\n    v90--&gt;v107\n    v112--&gt;v129\n    v129--&gt;v138\n    v143--&gt;v160\n    v165--&gt;v169\n    v174--&gt;v191\n    v222--&gt;v228\n    v205--&gt;v222\n    v253--&gt;v259\n    v236--&gt;v253\n    v267--&gt;v284\n    v289--&gt;v315\n    style group_qc fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v11 fill:#e3dcea,stroke:#7a4baa;\n    style v23 fill:#e3dcea,stroke:#7a4baa;\n    style v50 fill:#e3dcea,stroke:#7a4baa;\n    style v28 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v45 fill:#e3dcea,stroke:#7a4baa;\n    style v54 fill:#e3dcea,stroke:#7a4baa;\n    style v81 fill:#e3dcea,stroke:#7a4baa;\n    style v59 fill:#e3dcea,stroke:#7a4baa;\n    style v66 fill:#e3dcea,stroke:#7a4baa;\n    style v76 fill:#e3dcea,stroke:#7a4baa;\n    style v82 fill:#e3dcea,stroke:#7a4baa;\n    style v112 fill:#e3dcea,stroke:#7a4baa;\n    style v90 fill:#e3dcea,stroke:#7a4baa;\n    style v97 fill:#e3dcea,stroke:#7a4baa;\n    style v107 fill:#e3dcea,stroke:#7a4baa;\n    style v119 fill:#e3dcea,stroke:#7a4baa;\n    style v129 fill:#e3dcea,stroke:#7a4baa;\n    style v138 fill:#e3dcea,stroke:#7a4baa;\n    style v165 fill:#e3dcea,stroke:#7a4baa;\n    style v143 fill:#e3dcea,stroke:#7a4baa;\n    style v150 fill:#e3dcea,stroke:#7a4baa;\n    style v160 fill:#e3dcea,stroke:#7a4baa;\n    style v169 fill:#e3dcea,stroke:#7a4baa;\n    style v196 fill:#e3dcea,stroke:#7a4baa;\n    style v174 fill:#e3dcea,stroke:#7a4baa;\n    style v181 fill:#e3dcea,stroke:#7a4baa;\n    style v191 fill:#e3dcea,stroke:#7a4baa;\n    style v197 fill:#e3dcea,stroke:#7a4baa;\n    style v205 fill:#e3dcea,stroke:#7a4baa;\n    style v212 fill:#e3dcea,stroke:#7a4baa;\n    style v222 fill:#e3dcea,stroke:#7a4baa;\n    style v228 fill:#e3dcea,stroke:#7a4baa;\n    style v236 fill:#e3dcea,stroke:#7a4baa;\n    style v243 fill:#e3dcea,stroke:#7a4baa;\n    style v253 fill:#e3dcea,stroke:#7a4baa;\n    style v259 fill:#e3dcea,stroke:#7a4baa;\n    style v289 fill:#e3dcea,stroke:#7a4baa;\n    style v267 fill:#e3dcea,stroke:#7a4baa;\n    style v274 fill:#e3dcea,stroke:#7a4baa;\n    style v284 fill:#e3dcea,stroke:#7a4baa;\n    style v296 fill:#e3dcea,stroke:#7a4baa;\n    style v303 fill:#e3dcea,stroke:#7a4baa;\n    style v315 fill:#e3dcea,stroke:#7a4baa;\n    style v322 fill:#e3dcea,stroke:#7a4baa;\n    style v326 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Rna",
      "Rna singlesample"
    ]
  },
  {
    "objectID": "more_information/cheat_sheets.html",
    "href": "more_information/cheat_sheets.html",
    "title": "Cheat sheets",
    "section": "",
    "text": "Figure 1: Cheat sheet for developing modular pipeline components with Viash, including a sample Viash component (left) and common commands used throughout the various stages of a development cycle (right).",
    "crumbs": [
      "Fundamentals",
      "More information",
      "Cheat sheets"
    ]
  },
  {
    "objectID": "more_information/cheat_sheets.html#viash",
    "href": "more_information/cheat_sheets.html#viash",
    "title": "Cheat sheets",
    "section": "",
    "text": "Figure 1: Cheat sheet for developing modular pipeline components with Viash, including a sample Viash component (left) and common commands used throughout the various stages of a development cycle (right).",
    "crumbs": [
      "Fundamentals",
      "More information",
      "Cheat sheets"
    ]
  },
  {
    "objectID": "more_information/faq.html",
    "href": "more_information/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "It is possible to add additional resources such as a file containing helper functions or other resources. All you need to do is list those files under the functionality.resources section of your component and refer to them in your script using meta[\"resources_dir\"] + \"/myresource.txt\". Please visit the Viash documentation for concrete examples on how to add helper functions and other resources to your component.",
    "crumbs": [
      "Fundamentals",
      "More information",
      "FAQ"
    ]
  },
  {
    "objectID": "more_information/faq.html#how-can-i-add-an-external-resource-to-my-viash-component",
    "href": "more_information/faq.html#how-can-i-add-an-external-resource-to-my-viash-component",
    "title": "FAQ",
    "section": "",
    "text": "It is possible to add additional resources such as a file containing helper functions or other resources. All you need to do is list those files under the functionality.resources section of your component and refer to them in your script using meta[\"resources_dir\"] + \"/myresource.txt\". Please visit the Viash documentation for concrete examples on how to add helper functions and other resources to your component.",
    "crumbs": [
      "Fundamentals",
      "More information",
      "FAQ"
    ]
  },
  {
    "objectID": "more_information/faq.html#what-does-__merge__-do",
    "href": "more_information/faq.html#what-does-__merge__-do",
    "title": "FAQ",
    "section": "What does __merge__ do?",
    "text": "What does __merge__ do?\nThe __merge__ field is used to merge another YAML into a Viash config. One of its uses is in making sure that all of the components in a task has the same API.\nEach task in OpenProblems contains strict definitions of the input/output file interface of its components and the file formats of those files. These interfaces are stored as YAML files in the api subdirectory of each task.",
    "crumbs": [
      "Fundamentals",
      "More information",
      "FAQ"
    ]
  },
  {
    "objectID": "fundamentals/philosophy.html",
    "href": "fundamentals/philosophy.html",
    "title": "Philosophy",
    "section": "",
    "text": "Mission\nOpenPipelines are best-practice living workflows for single-cell uni- and multi-omics data. Building a best-practice pipeline requires knowledge and time that not one single person can provide, but rather requires input from a community. Additionally, a best-pratice pipeline needs constant maintenance to keep up to date with the latest standards, ideally sourcing input from a ‘living’ benchmark. Continuous improvement necessitates a robust system for sourcing and applying community input both from a technical and organisational standpoint.\n\n\n\n\n\ngraph TB\n  ben[\"🌱📈 Living benchmarks\"]\n  pra[\"🌱📖 Living best practices\"]\n  pip[\"🌱⚙️ Living reproducible pipelines\"]\n  ben --&gt; pra --&gt; pip",
    "crumbs": [
      "Fundamentals",
      "Philosophy"
    ]
  },
  {
    "objectID": "fundamentals/concepts.html",
    "href": "fundamentals/concepts.html",
    "title": "Concepts",
    "section": "",
    "text": "Goals\nOpenPipelines strives to provide easy ways to interact with the pipeline and/or codebase for three types of users:\n\nPipeline executor: runs the pipeline from a GUI side\nPipeline editor: adapts pipelines with existing components for specific projects\nComponent developer: develops novel components and or pipelines\n\nThis means that openpipelines must be:\n\nUsable by non-experts\nEasy to deploy\nProvide reproducable results\nScalable\nEasy to maintain and adapt\n\n\n\nRequirements\nTo meet these demands, the following concepts have been implemented at the core of Openpipeline:\n\n🌍 A language independent framework\n💾 A versitile storage solution\n🔳 Modularity\n🔀 A best-practice pipeline layout\n⌛ Versioning\n✅ Automatic testing\n💬 Community input\n📺 A graphical interace\n\n\n\nA common file format: AnnData and MuData 💾\nOne of the core principals of OpenPipelines is to use MuData as a common data format throughout the whole pipeline. This means that the input and output for most components and workflows will be a MuData file and converters from and to other common data formats are provided to improve compatibility with up-and downstream applications. Choosing a common data format greatly diminishes the development complexity because it facilitates interfacing between different tools in a pipeline without needing to convert multiple times.\nMuData is a format to store annotated multimodal data. It is derived from the AnnData format. If you are unfamiliar with AnnData or MuData, it is recommended to read up on AnnData first as it is the unimodal counterpart of MuData. MuData can be roughly described as collection of several AnnData objects (stored as a associative array in the .mod attribute). MuData provides a hierarchical way to store the data:\nMuData\n├─ .mod\n│  ├─ modality_1 (AnnData Object)\n│     ├─ .X\n│     ├─ .layers\n│         ├─ layer_1 \n│         ├─ ...\n│     ├─ .var\n│     ├─ .obs\n│     ├─ .obsm\n│     ├─ .varm\n│     ├─ .uns\n│  ├─ modality_2 (AnnData Object)\n├─ .var\n├─ .obs\n├─ .obms\n├─ .varm\n├─ .uns\n\n.mod: an associative array of AnnData objects. Used in OpenPipelines to store the different modalities (CITE-seq, RNA abundance, …)\n.X and .layers: matrices storing the measurements with the columns being the variables measured and the rows being the observations (cells in most cases).\n.var: metadata for the variables (i.e. annotation for the columns of .X or any matrix in .layers). The number of rows in the .var datafame (or the length of each entry in the dictionairy) is equal to the number of columns in the measurement matrices.\n.obs: metadata for the observations (i.e. annotation for the rows of .X or any matrix in .layers). The number of rows in the .obs datafame (or the length of each entry in the dictionairy) is equal to the number of rows in the measurement matrices.\nvarm: the multi-dimensional variable annotation. A key-dataframe mapping where the number of rows in each dataframe is equal to the number of columns in the measurement matrices.\nobsm: the multi-dimensional observation annotation. A key-dataframe mapping where the number of rows in each dataframe is equal to the number of rows in the measurement matrices.\n.uns: A mapping where no restrictions are enforced on the dimensions of the data.\n\n\n\nModularity and a language independent framework 🔳\nTODO\n\n\nA graphical interface 📺\nTODO",
    "crumbs": [
      "Fundamentals",
      "Concepts"
    ]
  },
  {
    "objectID": "fundamentals/index.html",
    "href": "fundamentals/index.html",
    "title": "Fundamentals",
    "section": "",
    "text": "Philosophy: Our approach and mission\n  \n  \n  \n    Concepts: The core concepts behind this project\n  \n  \n  \n    Architecture: Structure of the project\n  \n  \n  \n    Roadmap: Development roadmap\n  \n  \n\n\nNo matching items",
    "crumbs": [
      "Fundamentals"
    ]
  },
  {
    "objectID": "contributing/running_tests.html",
    "href": "contributing/running_tests.html",
    "title": "Running tests",
    "section": "",
    "text": "The input data that is needed to run the tests will need to be downloaded from the openpipelines Amazon AWS s3 bucket first. To do so, the download/sync_test_resource component can be used, which will download the data to the correct location (resources_test) by default.\nviash run src/download/sync_test_resources/config.vsh.yaml",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Running tests"
    ]
  },
  {
    "objectID": "contributing/running_tests.html#fetch-the-test-data",
    "href": "contributing/running_tests.html#fetch-the-test-data",
    "title": "Running tests",
    "section": "",
    "text": "The input data that is needed to run the tests will need to be downloaded from the openpipelines Amazon AWS s3 bucket first. To do so, the download/sync_test_resource component can be used, which will download the data to the correct location (resources_test) by default.\nviash run src/download/sync_test_resources/config.vsh.yaml",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Running tests"
    ]
  },
  {
    "objectID": "contributing/running_tests.html#run-component-tests",
    "href": "contributing/running_tests.html#run-component-tests",
    "title": "Running tests",
    "section": "Run component tests",
    "text": "Run component tests\nTo build and run tests for individual component that you are working on, use viash test with the config.vsh.yaml of the component you would like to test. For example:\nviash test src/convert/from_10xh5_to_h5mu/config.vsh.yaml\nKeep in mind that when no platform is passed to viash test, it will use the first platform that is specified in the config, which is docker for most of the components in openpipelines. Use -p native for example if you do not want to use docker.\nIt is also possible to execute the tests for all components in each namespace using:\nviash ns test --parallel -q convert",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Running tests"
    ]
  },
  {
    "objectID": "contributing/running_tests.html#run-integration-tests",
    "href": "contributing/running_tests.html#run-integration-tests",
    "title": "Running tests",
    "section": "Run integration tests",
    "text": "Run integration tests\nIndividual integration tests can be run by using the integration_test.sh scripts for a pipeline, located next to the main.nf in the src/workflows folder.\nsrc/workflows/ingestion/cellranger_demux/integration_test.sh",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Running tests"
    ]
  },
  {
    "objectID": "contributing/creating_components.html",
    "href": "contributing/creating_components.html",
    "title": "Creating components",
    "section": "",
    "text": "One of the core principals of OpenPipelines is to use MuData as a common data format troughout the whole pipeline. See the concepts page for more information on openpipelines uses MuData to store single-cell data.",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Creating components"
    ]
  },
  {
    "objectID": "contributing/creating_components.html#a-common-file-format",
    "href": "contributing/creating_components.html#a-common-file-format",
    "title": "Creating components",
    "section": "",
    "text": "One of the core principals of OpenPipelines is to use MuData as a common data format troughout the whole pipeline. See the concepts page for more information on openpipelines uses MuData to store single-cell data.",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Creating components"
    ]
  },
  {
    "objectID": "contributing/creating_components.html#component-location",
    "href": "contributing/creating_components.html#component-location",
    "title": "Creating components",
    "section": "Component location",
    "text": "Component location\nAs discussed in the project structure, components in the repository are stored within src. Additionally, components are grouped into namespaces, according to a common functionality. An example of such a namespace is the dimensionality reduction namespace (dimred), of which the components pca and umap are members. This means that within src, the namespace folders can be found that stores the components that belong to these namespaces.\nIn order to create a new component in OpenPipelines, you will need to create a new folder that will contain the different elements of the component:\nmkdir src/my_namespace/my_component\n\n\n\n\n\n\nTip\n\n\n\nTake a look at the components that are already in src/! There might be a component that already does something similar to what you need.",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Creating components"
    ]
  },
  {
    "objectID": "contributing/creating_components.html#the-elements-of-a-component",
    "href": "contributing/creating_components.html#the-elements-of-a-component",
    "title": "Creating components",
    "section": "The elements of a component",
    "text": "The elements of a component\nA component consists of one or more scripts that provide the functionality of the component together with metadata of the component in a configuration file. The Viash config contains metadata of your dataset, which script is used to run it, and the required dependencies. An in-depth guide on how to create components is available on the viash website, but a few specifics and guidelines will be discussed here.",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Creating components"
    ]
  },
  {
    "objectID": "contributing/creating_components.html#the-config",
    "href": "contributing/creating_components.html#the-config",
    "title": "Creating components",
    "section": "The config",
    "text": "The config\nfunctionality:\n  name: \"my_component\"\n  namespace: \"my_namespace\"\n  description: \"My new custom component\"\n  authors:\n    - __merge__: ../../authors/my_name.yaml\n      roles: [ author ]\n  arguments:\n    - name: \"--output\"\n      type: file\n      example: \"output_file.h5mu\"\n      description: \"Location were the output file should be written to.\"\n      direction: \"output\"\n  resources:\n    - type: python_script\n      path: script.py\nplatforms:\n  - type: docker\n    image: python:3.11\n    setup:\n      - type: python\n        packages: mudata~=0.2.3\n  - type: nextflow\n    directives:\n      label: [highcpu, midmem]\n\nBasic information\nEach component should have the name, a namespace, a description and author information defined in the config. Because a single author can contribute to multiple components, the author information is often duplicated across components, which was causing issues with the author information being out of date and not easy to maintain. Therefore, it was decided to move author information to ./src/authors. Each author has a yaml file containing the author information, and the viash __merge__ property is used to merge this information into the viash configs.\nBasic information checklist:\n\nGive the component a name\nAdd the component to an appropriate namespace\nAdd a description\nAdd author information\n\n\n\nArguments and argument groups\nIf you component requires arguments, they should be defined in arguments or argument_groups. Try tro group individual arguments into argument_groups when the number of arguments become too larg (10 or more as a rule of thumb).\nArgument checklist:\n\nAdd a description and name\nEach argument should have the appropriate type.\nInput and output files should be of type file instead of string and use the appropriate direction:\nIf possible: add an example\nIf the argument can accept multiple values, add multiple: true\nIf the possible input for an argument is limited to certain set of values, use choices:\n\n\n\n(Test)resources\nResources define files that are required for a component to perform its function. These can be scripts, but also additional files like settings for tools you might require. Defining resources is both a necessity because viash needs to know what code to execute, but defining resources also has the added benefit that these resources are automatically made available, regardless of the build environment. For example: resources are automatically mounted within a running docker container.\nThere is a difference between defining resources and test_resources. While resources are required for a component to function, test_resources only need to be included when testing the component (with for example viash test) in addition to the regular resources. Having a look at the example above, resources are defined using the resources: property. It takes a list of multiple files or folders.\nIn openpipelines, it was decided to not use a service like git lfs to include large resources into the repository. Instead, if large resources are required, there are two possibilities: * Large resources required for testing are to uploaded into an s3 bucket that is synced automatically before running tests (both locally and on github). Please ping a maintainer when you open a PR and ask them to upload the files for you. * Other large resources that are not needed for testing can be considered as input. This means that an argument of type: file needs to be created. The downside of this method is that viash is not able to natively support remote files f\nResources checklist: - Script resources are located next to the config and added to the config with the correct type (python_script, r_script, …) - Small resources (&lt;50MB) that are not scripts can also be checked in into the repo, next to the\n\n\nThe script file\nTODO\n\n\nAuthor information\nTODO",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Creating components"
    ]
  },
  {
    "objectID": "contributing/creating_components.html#adding-dependencies",
    "href": "contributing/creating_components.html#adding-dependencies",
    "title": "Creating components",
    "section": "Adding dependencies",
    "text": "Adding dependencies\nTODO",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Creating components"
    ]
  },
  {
    "objectID": "contributing/creating_components.html#building-components-from-their-source",
    "href": "contributing/creating_components.html#building-components-from-their-source",
    "title": "Creating components",
    "section": "Building components from their source",
    "text": "Building components from their source\nWhen running or testing individual components, it is not necessary to execute an extra command to run the build step, viash test and viash run will build the component on the fly. However, before integrating components into a pipeline, you will need to build the components. More specifically, openpipelines uses Nextflow to combine components into pipelines, so we need to have at least the components build for nextflow platform as target. The easiest method to build the components is to use:\nviash ns build --parallel --setup cachedbuild\nAfter using viash ns build, the target folder will be populated with three subfolders, corresponding to the build platforms that viash supports: native, docker and nextflow.\nBuilding an individual component can still be useful, for example when debugging a component for which the build fails or if you want to create a standalone executable for a component to execute it without the need to use viash. To build an individual component, viash build can be used. Note that the default build directory of this viash base command is output, which is not the location where build components will be imported from when integrating them in pipelines. Using the --output argument, you can set it to any directory you want, for example:\nviash build src/filter/do_filter/config.vsh.yaml -o target/native/filter/do_filter/ -p native",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Creating components"
    ]
  },
  {
    "objectID": "contributing/creating_components.html#containerization",
    "href": "contributing/creating_components.html#containerization",
    "title": "Creating components",
    "section": "Containerization",
    "text": "Containerization\nOne of the key benefits of using Viash is that containers can be created that gather dependencies per component, which avoids building one container that has to encorporate all dependencies for a pipeline together. The containers for a single component can be reduced in size, defining the minimal requirements to run the component. That being said, building containers from scratch can be labour intensive and error prone, with base containers from reputable publishers often benefiting from improved reliability and security. Hence, a balance has to be made between reducing the container’s size and adding many dependencies to a small base container.\nThe preferred containerization setup in OpenPipelines uses the following guidelines:\n\nChoose a base container from a reputable source and use its latest version\nDo not use base containers that have not been updated in a while\nUse package managers to install dependencies as much as possible\nAvoid building depdencies from source.\n\nExamples of base containers that are currently being used are:\n\npython:3.11 for python environments\nubuntu:focal for general linux environments and bash scripts\neddelbuettel/r2u:22.04 for R\nnvcr.io/nvidia/pytorch:22.09-py3 for using GPU accelerated calculations using pytorch in python",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Creating components"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OpenPipelines",
    "section": "",
    "text": "Reusable components built with Viash for flexible pipeline construction.\n\n\n\n\nLeverage Nextflow for execution on various platforms (local, cloud, HPC).\n\n\n\n\nContainerized components and unit testing ensure reliable analyses.\n\n\n\n\n\n\nA framework for sharing and integrating components to foster teamwork.\n\n\n\n\nAdapts to evolving single-cell analysis by incorporating current best practices and novel methods.\n\n\n\n\nSupports diverse single-cell data types (RNA, protein, VDJ, ATAC) for multi-omics analyses."
  },
  {
    "objectID": "index.html#key-features",
    "href": "index.html#key-features",
    "title": "OpenPipelines",
    "section": "",
    "text": "Reusable components built with Viash for flexible pipeline construction.\n\n\n\n\nLeverage Nextflow for execution on various platforms (local, cloud, HPC).\n\n\n\n\nContainerized components and unit testing ensure reliable analyses.\n\n\n\n\n\n\nA framework for sharing and integrating components to foster teamwork.\n\n\n\n\nAdapts to evolving single-cell analysis by incorporating current best practices and novel methods.\n\n\n\n\nSupports diverse single-cell data types (RNA, protein, VDJ, ATAC) for multi-omics analyses."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "OpenPipelines",
    "section": "Overview",
    "text": "Overview\n\n\n\n\n\nflowchart LR\n  %% Ingestion\n  subgraph ingestion[Step 1: Ingestion]\n    direction LR\n    10x_ingestion[10x Ingestion]:::subwf\n    bd_ingestion[BD Rhapsody\\nIngestion]:::subwf\n    own_h5mu[Own H5MU]:::subwf\n  end\n  ingestion:::info\n\n  %% Process samples\n  subgraph process_samples[Step 2: Process Samples]\n    direction LR\n    gex[GEX]:::subwf\n    atac[ATAC]:::subwf\n    adt[ADT]:::subwf\n    vdj[VDJ]:::subwf\n    other[Other]:::subwf\n  end\n  process_samples:::info\n\n  %% Integration and downstream\n  subgraph integration[Step 3: Integration]\n    direction LR\n    harmony[Harmony]:::subwf\n    scvi[scVI]:::subwf\n    scanvi[scanVI]:::subwf\n    etc[...]:::subwf\n  end\n  integration[Integration]:::info\n  \n  subgraph downstream[Step 4: Downstream]\n    direction LR\n    celltype_annotation[Cell Type\\nAnnotation]:::subwf\n    markergenes[Marker Genes\\nAnalysis]:::subwf\n    differential[Differential\\nExpression]:::subwf\n    gene_signature_analysis[Gene Signature\\nAnalysis]:::subwf\n    ccc[Cell-Cell\\nCommunication]:::subwf\n  end\n\n  ingestion --&gt; process_samples --&gt; integration --&gt; downstream\n\n  classDef wf fill:#f0f0f0,stroke:#525252\n  classDef subwf fill:#d9d9d9,stroke:#525252\n  classDef info fill:#f0f0f0,stroke:#525252,stroke-dasharray: 4 4"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "OpenPipelines",
    "section": "Getting Started",
    "text": "Getting Started\n\n\n\n\n\n\n\n\n  \n  Fundamentals\n  \n    \n  \n    \n        \n  \n  Philosophy\n  \n    \n    \n        \n  \n  Concepts\n  \n    \n    \n        \n  \n  Architecture\n  \n    \n    \n        \n  \n  Roadmap\n  \n    \n    \n  \n    \n\n\nNo matching items\n\n\n\n\n\n\n  \n  User guide\n  \n    \n  \n    \n        \n  \n  Getting started\n  \n    \n    \n        \n  \n  Running pipelines\n  \n    \n    \n        \n  \n  Parameter lists\n  \n    \n    \n        \n  \n  Ingestion\n  \n    \n    \n        \n  \n  Processing\n  \n    \n    \n        \n  \n  Downstream\n  \n    \n    \n        \n  \n  Bug reports\n  \n    \n    \n  \n    \n\n\nNo matching items\n\n\n\n\n\n\n  \n  Contributing\n  \n    \n  \n    \n        \n  \n  Getting started\n  \n    \n    \n        \n  \n  Project structure\n  \n    \n    \n        \n  \n  Creating components\n  \n    \n    \n        \n  \n  Creating pipelines\n  \n    \n    \n        \n  \n  Running tests\n  \n    \n    \n        \n  \n  Publishing your changes\n  \n    \n    \n  \n    \n\n\nNo matching items\n\n\n\n\n\n\n  \n  More information\n  \n    \n  \n    \n        \n  \n  Cheat sheets\n  \n    \n    \n        \n  \n  Code of conduct\n  \n    \n    \n        \n  \n  FAQ\n  \n    \n    \n  \n    \n\n\nNo matching items"
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "OpenPipelines.bio next release",
    "section": "",
    "text": "Add descriptions to all pages and add listings to index pages.\nUpdate documentation on creating components for developers.\nUpdate getting started page for developers\nUpdate project structure.\nUpdate information on running tests.\nUpdate “More information” pages\nWrite getting started page for user guide\nDocument how to run workflows\nDocument parameter lists"
  },
  {
    "objectID": "CHANGELOG.html#major-changes",
    "href": "CHANGELOG.html#major-changes",
    "title": "OpenPipelines.bio next release",
    "section": "",
    "text": "Add descriptions to all pages and add listings to index pages.\nUpdate documentation on creating components for developers.\nUpdate getting started page for developers\nUpdate project structure.\nUpdate information on running tests.\nUpdate “More information” pages\nWrite getting started page for user guide\nDocument how to run workflows\nDocument parameter lists"
  },
  {
    "objectID": "CHANGELOG.html#major-changes-1",
    "href": "CHANGELOG.html#major-changes-1",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.12.1 release."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-2",
    "href": "CHANGELOG.html#major-changes-2",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.12.0 release."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-3",
    "href": "CHANGELOG.html#major-changes-3",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.11.0 release."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-4",
    "href": "CHANGELOG.html#major-changes-4",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.10.0 release.\nAdd documentation for OpenPipelines architecture."
  },
  {
    "objectID": "CHANGELOG.html#minor-changes",
    "href": "CHANGELOG.html#minor-changes",
    "title": "OpenPipelines.bio next release",
    "section": "MINOR CHANGES",
    "text": "MINOR CHANGES\n\nAlso generate documentation for the multiple_sep values of component arguments."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-5",
    "href": "CHANGELOG.html#major-changes-5",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.9.0 release."
  },
  {
    "objectID": "CHANGELOG.html#minor-changes-1",
    "href": "CHANGELOG.html#minor-changes-1",
    "title": "OpenPipelines.bio next release",
    "section": "MINOR CHANGES",
    "text": "MINOR CHANGES\n\nUpdate to Viash actions 0.4.0."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-6",
    "href": "CHANGELOG.html#major-changes-6",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.8.0 release.\nUse git submodule to access openpipeline repo.\nPropose new website structure.\nUpdate author page."
  },
  {
    "objectID": "contributing/index.html",
    "href": "contributing/index.html",
    "title": "Contributing",
    "section": "",
    "text": "Getting started: Install dependencies and fetch test resources\n  \n  \n  \n    Project structure: The structure of OpenPipelines\n  \n  \n  \n    Creating components: A guide on how to create new components\n  \n  \n  \n    Creating pipelines: A guide on how to create new workflows\n  \n  \n  \n    Running tests: How to run component and integration tests.\n  \n  \n  \n    Publishing your changes: How to create a pull request\n  \n  \n\n\nNo matching items",
    "crumbs": [
      "Fundamentals",
      "Contributing"
    ]
  },
  {
    "objectID": "contributing/pull_requests.html",
    "href": "contributing/pull_requests.html",
    "title": "Publishing your changes",
    "section": "",
    "text": "After ensuring that the implemented changes pass all relevant tests and meets the contribution guidelines, you can create a pull request following the steps below.",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Publishing your changes"
    ]
  },
  {
    "objectID": "contributing/pull_requests.html#step-1-merge-upstream-repository",
    "href": "contributing/pull_requests.html#step-1-merge-upstream-repository",
    "title": "Publishing your changes",
    "section": "Step 1: Merge upstream repository",
    "text": "Step 1: Merge upstream repository\nBefore you contribute your changes need to merge the upstream main branch into your fork. This ensures that your changes are based on the latest version of the code.\nTo do this, enter the following commands adapted from Syncing a Fork in your terminal or command prompt:\n# add the upstream repository to your local repository\ngit remote add upstream https://github.com/openpipelines-bio/openpipeline.git\n# download the changes from the openpipelines repo\ngit fetch upstream\n# change your current branch to the branch of the pull request\ngit checkout &lt;feature_branch&gt;\n# merge the changes from upstream into your branch\ngit merge upstream/main\n# push the updates, your pull request will also be updated\ngit push",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Publishing your changes"
    ]
  },
  {
    "objectID": "contributing/pull_requests.html#step-2-edit-changelog",
    "href": "contributing/pull_requests.html#step-2-edit-changelog",
    "title": "Publishing your changes",
    "section": "Step 2: Edit changelog",
    "text": "Step 2: Edit changelog\nAdd an entry to the CHANGELOG.md file describing the proposed changes.",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Publishing your changes"
    ]
  },
  {
    "objectID": "contributing/pull_requests.html#step-3-create-pull-request",
    "href": "contributing/pull_requests.html#step-3-create-pull-request",
    "title": "Publishing your changes",
    "section": "Step 3: Create pull request",
    "text": "Step 3: Create pull request\nThe following steps were adapted from Creating a pull request from a fork\n\nGo to https://github.com/openpipelines-bio/openpipeline/pulls.\nClick on the New pull request button.\nOn the compare page click on the link compare across forks below the title. \nOn the right side in the head section select your fork repo and the correct branch you want to merge.\nClick on Create pull request.\nConstruct your PR by giving it a title and description.\nMake sure you select the box below the description Allow edits from maintainers.\nIf the PR is ready for review click the button Create Pull Request. Otherwise you can click the arrow next to the button and select Create Draft Pull Request and click the button when it changes.",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Publishing your changes"
    ]
  },
  {
    "objectID": "contributing/pull_requests.html#next-steps",
    "href": "contributing/pull_requests.html#next-steps",
    "title": "Publishing your changes",
    "section": "Next steps",
    "text": "Next steps\n\nGithub Actions\nWhenever a Pull Request (including draft) is created a github workflow will perform checks. These checks need to be succesful as a minimum requirement before a merge can be done. When there are errors in the checks, try to fix them while waiting on a review. If it is not possible to fix the error, add a comment to the PR to let the reviewers know.\n\n\nReview\nYour PR will be reviewed by maintainers of OpenPipelines. During the review, you can be asked for changes to the code.",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Publishing your changes"
    ]
  },
  {
    "objectID": "contributing/project_structure.html",
    "href": "contributing/project_structure.html",
    "title": "Project structure",
    "section": "",
    "text": "The root of the repository contains two main folders:\n\nsrc, which contains the source code for components and workflows.\n(optionally) the target folder\n\nEach subfolder from src contains a Viash namespace, a logical grouping of pipeline components that perform a similar function. Within each namespace, subfolders designate individual pipeline components. For example ./src/convert/from_bdrhap_to_h5ad contains the implementation for a component from_bdrhap_to_h5ad which is grouped together with other components such as from_10xmtx_to_h5mu into a namespace convert. In a similar manner as grouping components into namespaces, pipelines are grouped together into folders. However, these are not component namespaces and as such do not interact with viash ns commands.\nAs will become apparent later on, Viash not only provides commands to perform operations on individual components, but also on groups of components in a namespace and all components in a project. As a rule of thumb, the basic Viash commands (like viash test) are designated for running commands on individual components, while ns commands are (viash ns test) are for namespaces. When cloning a fresh repository, there will be no target folder present. This is because the target folder will only be created after components have been build.",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Project structure"
    ]
  },
  {
    "objectID": "contributing/project_structure.html#sec-project-structure",
    "href": "contributing/project_structure.html#sec-project-structure",
    "title": "Project structure",
    "section": "",
    "text": "The root of the repository contains two main folders:\n\nsrc, which contains the source code for components and workflows.\n(optionally) the target folder\n\nEach subfolder from src contains a Viash namespace, a logical grouping of pipeline components that perform a similar function. Within each namespace, subfolders designate individual pipeline components. For example ./src/convert/from_bdrhap_to_h5ad contains the implementation for a component from_bdrhap_to_h5ad which is grouped together with other components such as from_10xmtx_to_h5mu into a namespace convert. In a similar manner as grouping components into namespaces, pipelines are grouped together into folders. However, these are not component namespaces and as such do not interact with viash ns commands.\nAs will become apparent later on, Viash not only provides commands to perform operations on individual components, but also on groups of components in a namespace and all components in a project. As a rule of thumb, the basic Viash commands (like viash test) are designated for running commands on individual components, while ns commands are (viash ns test) are for namespaces. When cloning a fresh repository, there will be no target folder present. This is because the target folder will only be created after components have been build.",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Project structure"
    ]
  },
  {
    "objectID": "contributing/project_structure.html#sec-versioning",
    "href": "contributing/project_structure.html#sec-versioning",
    "title": "Project structure",
    "section": "Versioning and branching strategy",
    "text": "Versioning and branching strategy\nOpenPipeline tries to use of semantic versioning to govern changes between versions. An release of openpipelines uses a version number in the format MAJOR.MINOR.PATCH. Currenly, openpipelines is still at major version 0.x.y, meaning that public-facing breaking changes are possible on MINOR releases. These breaking changes will be documented in a dedicated section of the CHANGELOG that is published with each release. A PATCH release (i.e. a release where the MAJOR and MINOR version number stay the same), is used to resolve bugs with the pipeline but should not introduce breaking changes. Keep in mind that patches might introduce behavioral changes that may look breaking but are actually rectifying changes that were inadvertently introduced previously (and were in fact also ‘breaking changes’). In this case, a bug can also be released without changing the MINOR version, in a PATH release.\nBetween releases, development progress is tracked on Git branches. A git branch represents a snapshot of a codebase in time, to which changes can be added (i.e. committed). Eventually, all new feature or bugfixes must be reconsiled into a single branch so that a new release can be created. This process is called merging and the process of requesting the merging of two branches is called a pull request. Openpipelines follows the convention that the target branch for all pull requests is the main branch. Thus, the main branch contains the latest changes for the code and it can be considered the development branch.\nOnce a pull request has been approved and merged, Github Actions CI will automatically build all components (creating the target directory) and push the result to the main_build branch. In essence, the main_build branch is a copy of the main branch, but also containing the build components. Once it is time to create a openpipelines release, the Github CI release workflow is manually triggered, the components on the main branch will be build and tested. Then, the result will be pushed to the release branch and the integration tests will be run. If all tests succeeded, a new github tag and release can be created manually from the release branch.\n\n\n\n\n\n%%{init: { 'logLevel': 'debug', 'theme': 'default'} } }%%\ngitGraph\n  commit id: \"initial commit\"\n  branch main_build\n  commit id: \"CI build\"\n  checkout main\n  commit\n  checkout main_build\n  merge main\n  checkout main\n  branch feature_a\n  branch feature_b\n  checkout feature_a\n  commit\n  commit\n  checkout main\n  commit id: \"#release 0.1\" type: HIGHLIGHT\n  checkout main_build\n  merge main\n  checkout main\n  branch release\n  commit tag: \"0.1\"\n  checkout main\n  commit\n  checkout feature_b\n  commit\n  commit\n  checkout feature_a\n  commit\n  checkout main\n  merge feature_a\n  checkout main_build\n  merge main\n  checkout main\n  checkout feature_b\n  commit\n  checkout main\n  merge feature_b\n  checkout main_build\n  merge main\n  checkout release\n  merge main tag: \"0.2\"",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Project structure"
    ]
  },
  {
    "objectID": "contributing/getting_started.html",
    "href": "contributing/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "The OpenPipelines code is hosted on GitHub. To start working on OpenPipelines, you should create your own copy of the repository by forking it. Visit the OpenPipelines repository here and use the ‘Fork’ button on the top right hand side of the page. After you are done forking, you can clone the repository to a local directory on your computer using git clone. You can choose between using an SSH key to log in to GitHub or username and password (HTTPS) to connect to github.\n\nHTTPSSSH\n\n\ngit clone https://github.com/&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git\n\n\ngit clone git@github.com:&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Getting started"
    ]
  },
  {
    "objectID": "contributing/getting_started.html#forking-the-code-and-cloning-the-repository",
    "href": "contributing/getting_started.html#forking-the-code-and-cloning-the-repository",
    "title": "Getting started",
    "section": "",
    "text": "The OpenPipelines code is hosted on GitHub. To start working on OpenPipelines, you should create your own copy of the repository by forking it. Visit the OpenPipelines repository here and use the ‘Fork’ button on the top right hand side of the page. After you are done forking, you can clone the repository to a local directory on your computer using git clone. You can choose between using an SSH key to log in to GitHub or username and password (HTTPS) to connect to github.\n\nHTTPSSSH\n\n\ngit clone https://github.com/&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git\n\n\ngit clone git@github.com:&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Getting started"
    ]
  },
  {
    "objectID": "contributing/getting_started.html#sec-install-viash-nextflow",
    "href": "contributing/getting_started.html#sec-install-viash-nextflow",
    "title": "Getting started",
    "section": "Install viash and nextflow",
    "text": "Install viash and nextflow\nTo start contributing to OpenPipelines, you will need at Java 11 (or higher) and Docker installed on your system.\nOpenPipelines is being developed in Viash and Nextflow. If you are unfamiliar with either one of these platforms, you can check out their respective documentation pages.\nYou can check if is installed correctly by running the following commands.\nnextflow run hello -with-docker\nviash --version",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Getting started"
    ]
  },
  {
    "objectID": "contributing/getting_started.html#fetch-test-resources",
    "href": "contributing/getting_started.html#fetch-test-resources",
    "title": "Getting started",
    "section": "Fetch test resources",
    "text": "Fetch test resources\nOpenPipelines uses a number of test resources to test the pipelines. If everything is installed correctly, you should be able to fetch these resources by running the following command.\nviash run src/download/sync_test_resources/config.vsh.yaml",
    "crumbs": [
      "Fundamentals",
      "Contributing",
      "Getting started"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html",
    "href": "fundamentals/architecture.html",
    "title": "Architecture",
    "section": "",
    "text": "OpenPipeline is a pipeline for the processing of multimodal single-cell data that scales to a great many of samples. Covering the architecture requires us to explain many angles, including: what the expected inputs and outputs are for each workflow are, how do the workflows relate to each other, and what the state of the data is at each step of the pipeline. Here is an overview of the general steps involved in processing sequencing data into a single integrated object. We will discuss each of the steps further below.\nflowchart TD  \n  ingest[\"Ingestion\"] --&gt; split --&gt; unimodalsinglesample[\"Unimodal Single Sample Processing\"] --&gt; concat --&gt; unimodalmultisample[\"Unimodal Multi Sample Processing\"] --&gt; merging --&gt; integation_setup[\"Integration Setup\"] --&gt; integration[\"Integration\"]  --&gt; downstreamprocessing[\"Downstream Processing\"]\n\n\n\n\nFigure 1: Overview of the steps included in OpenPipeline for the analysis of single cell multiomics data.\nflowchart TB\n  subgraph ingestion\n    direction TB\n    subgraph cellranger_multi\n      direction TB\n      mapping_10x --&gt; convert_to_h5mu_10x\n      mapping_10x[mapping]\n      convert_to_h5mu_10x[convert_to_h5mu]\n    end\n    subgraph bdrhap_v1\n      direction TB\n      mapping_bd1 --&gt; convert_to_h5mu_bd1\n      mapping_bd1[mapping]\n      convert_to_h5mu_bd1[convert_to_h5mu]\n    end\n    subgraph bdrhap_v2\n      direction TB\n      mapping_bd2 --&gt; convert_to_h5mu_bd2\n      mapping_bd2[mapping]\n      convert_to_h5mu_bd2[convert_to_h5mu]\n    end\n    cellranger_multi:::subwf\n    bdrhap_v1:::subwf\n    bdrhap_v2:::subwf\n  end\n  ingestion:::wf\n  subgraph process_samples\n    split_modalities --&gt; rna_singlesample & prot_singlesample & gdo_singlesample & atac_singlesample & other_modalities --&gt; concat --&gt; process_batches\n    split_modalities\n    rna_singlesample\n    prot_singlesample\n    gdo_singlesample\n    atac_singlesample\n    other_modalities\n    concat\n    subgraph process_batches\n      direction LR\n      split_modalities2 --&gt; rna_multisample & prot_multisample & atac_multisample & other_modalities2 --&gt; merge\n      split_modalities2[split_modalities]\n      other_modalities2[other_modalities]\n      rna_multisample\n      prot_multisample\n      merge\n    end\n    process_batches:::subwf\n    atac_multisample\n  end\n  process_samples:::wf\n  raw_counts --- ingestion --&gt; raw_h5mu\n  raw_h5mu --- process_samples --&gt; processed_h5mu\n  subgraph integration\n    direction LR\n    integration_method --&gt; find_neighbors --&gt; leiden --&gt; umap\n    integration_method -.- intmeth\n    integration_method\n    find_neighbors\n    leiden\n    umap\n    subgraph intmeth [integration_method]\n      bbknn\n      harmony\n      scanorama\n      scvi\n      totalvi\n      scgpt_integration\n    end\n    intmeth:::info\n  end\n  integration:::wf\n  processed_h5mu --- integration ---&gt; integrated_h5mu\n  subgraph celltype_annotation\n    direction TB\n    integration_method2[integration_method]\n    celltypist\n    scanvi\n    scgpt_annotation\n    onclass\n    svm\n    randomforest\n    pynndescent_knn\n    consensus_voting\n    integration_method2 --&gt; pynndescent_knn --&gt; consensus_voting\n    celltypist & scanvi & scgpt_annotation & onclass & svm & randomforest --&gt; consensus_voting\n  end\n  reference_atlas --&gt; celltype_annotation\n  celltype_annotation:::wf\n  integrated_h5mu --- celltype_annotation --&gt; annotated_h5mu\n\n  classDef wf fill:#f0f0f0,stroke:#525252\n  classDef subwf fill:#d9d9d9,stroke:#525252\n  classDef info fill:#f0f0f0,stroke:#525252,stroke-dasharray: 4 4",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#ingestion-workflows",
    "href": "fundamentals/architecture.html#ingestion-workflows",
    "title": "Architecture",
    "section": "Ingestion workflows",
    "text": "Ingestion workflows\nAll of the following workflows from the ingestion namespace have been discussed in more detail in the ingestion section:\n\ningestion/bd_rhapsody\ningestion/cellranger_mapping\ningestion/cellranger_multi\ningestion/demux\ningestion/make_reference",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#multiomics-workflows",
    "href": "fundamentals/architecture.html#multiomics-workflows",
    "title": "Architecture",
    "section": "Multiomics workflows",
    "text": "Multiomics workflows\nThere exists no singlesample workflow. However, the prot_singlesample and rna_singlesample pipelines do exist and they map identically to the functionality described in the single-sample antibody capture processing and single-sample gene expression processing sections respectively. If you would like to process your samples as described in the unimodal single sample processing section, you can execute both workflows in tandem for the two modalities.\nContrary to the workflows for single sample processing, there exists a multiomics/multisample workflow. However this workflow is not just the multiomics/prot_multisample and multiomics/rna_multisample workflows that have been combined. Instead, it combines the multiomics/prot_multisample, multiomics/rna_multisample and multiomics/integration/initialize_integration workflows. The purpose of this pipeline is to provide an extra ‘entrypoint’ into the full pipeline that skips the singlesample processing, allowing reprocessing samples that have already been processed before. A popular usecase is to manually select one or more celltypes which need to be processed again or the integration of observations from multiple experiments into a single dataset. Keep in mind that concatenation is not included in the multisample pipeline, so when multiple input files are specified they are processed in parallel. If you would like to integrate multiple experiments, you need to first concatenate them in a seperate step:",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#the-full-pipeline",
    "href": "fundamentals/architecture.html#the-full-pipeline",
    "title": "Architecture",
    "section": "The “full” pipeline",
    "text": "The “full” pipeline\nThe name of this pipeline is a bit of a misnomer, because it does not include all the steps from ingestion to integration. As will be discussed in the ingestion section, which ingestion strategy you need is dependant on your technology provider and the chosen platform. For integration, there exist many methods and combination of methods, and you may wish to choose which integration methods are applicable for your usecase. As a consequence, these two stages in the analysis of single-cell need to be executed seperatly and not as part of a single unified pipeline. All other steps outlined below on the other hand are included into the “full” pipeline, which can therefore be summarized in the following figure:\n\n\n\n\n\n\nflowchart TD  \n  split --&gt; unimodalsinglesample[\"Unimodal Single Sample Processing\"] --&gt; concat --&gt; unimodalmultisample[\"Unimodal Multi Sample Processing\"] --&gt; merging --&gt; integation_setup\n\n\n\n\nFigure 2: Overview of the steps included in the full pipelines from OpenPipeline.",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#integration-workflows",
    "href": "fundamentals/architecture.html#integration-workflows",
    "title": "Architecture",
    "section": "Integration workflows",
    "text": "Integration workflows\nFor each of the integration methods (and their optional combination with other tools), a seperate pipeline is defined. More information for each of the pipelines is available in the integration methods section.\n\nmultiomics/integration/bbknn_leiden\nmultiomics/integration/harmony_leiden\nmultiomics/integration/scanorama_leiden\nmultiomics/integration/scvi_leiden\nmultiomics/integration/totalvi_leiden\nmultiomics/integration/initialize_integration",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#sec-splitting",
    "href": "fundamentals/architecture.html#sec-splitting",
    "title": "Architecture",
    "section": "Splitting modalities",
    "text": "Splitting modalities\nWe refer to splitting modalities when multimodal MuData file is split into several unimodal MuData files. The number of output files is equal to the number of modalities present in the input file. Splitting the modalities works on MuData files containing data for multiple samples or for single-sample files.",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#sec-merging",
    "href": "fundamentals/architecture.html#sec-merging",
    "title": "Architecture",
    "section": "Merging of modalities",
    "text": "Merging of modalities\nMerging refers to combining multiple files with data for one modality into a single output file that contains all input modalities. It is the inverse operation of splitting the modalities.",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#concatenation-of-samples",
    "href": "fundamentals/architecture.html#concatenation-of-samples",
    "title": "Architecture",
    "section": "Concatenation of samples",
    "text": "Concatenation of samples\nJoining of observations for different samples, stored in their respective MuData file, into a single MuData file for all samples together is called sample concatenation. In practice, this operation is performed for each modality separately. An extra column (with default name sample_id) is added to the annotation of the observations (.obs) to indicate where each observation originated from.\n\nSpecial care must be taken when considering annotations for observations and features while concatenating the samples. Indeed, the data from different samples can contain conflicting information. Openpipeline’s concat component provides an argument other_axis_mode that allows a user to specify what happens when conflicting information is found. The move option for this argument is the default behavior. In this mode, each annotation column (from .obs and .var) is compared across samples. When no conflicts are found or the column is unique for a sample, the column is added output object. When a conflict does occur, all of the columns are gathered from the samples and stored into a dataframe. This dataframe is then stored into .obsm for annotations for the observations and .varm for feature annotations. This way, a user can have a look at the conflicts and decide what to do with them.",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#creating-a-transcriptomics-reference",
    "href": "fundamentals/architecture.html#creating-a-transcriptomics-reference",
    "title": "Architecture",
    "section": "Creating a transcriptomics reference",
    "text": "Creating a transcriptomics reference\nMapping reads from the FASTQ files to features requires a reference that needs to be provided to the mapping component. Depending on the usecase, you might even need to provide references specific for the modalities that you are trying to analyze. For gene expression data, the reference is a reference genome, together with its appropriate gene annotation. A genome reference is often indexed in order to improve the mapping speed. Additionally, some mapping frameworks provided by the single-cell technology providers require extra preprocessing of the reference before they can be used with their worklow. OpenPipelines provides a make_reference that allows you to create references in many formats which can be used to map your reads to.",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#sec-single-sample-gex",
    "href": "fundamentals/architecture.html#sec-single-sample-gex",
    "title": "Architecture",
    "section": "Single-sample Gene Expression Processing",
    "text": "Single-sample Gene Expression Processing\nSingle-sample gene expression processing involves two steps: removing cells based on count statistics and flagging observations originating from doublets.\nThe removal of cells based on basic count statistics is split up into two parts: first, cells are flagged for removal by filter_with_counts. It flags observations based on several thresholds:\n\nThe number of genes that have a least a single count. Both a maximum and minimum number of genes for a cell to be removed can be specified.\nThe percentage of read counts that originated from a mitochodrial genes. Cells can be filtered based on both a maximum or minimum fraction of mitochondrial genes.\nThe minimum or maximum total number of counts captured per cell. Cells with 0 total counts are always removed.\n\nFlagging cells for removal involved adding a boolean column to the .obs dataframe. After the cells have been flagged for removal, the cells are actually filtered using do_filter, which reads the values in .obs and removed the cells labeled True. This applies the general phylosophy of “separation of concerns”: one component is responsible for labeling the cells, another for removing them. This keeps the codebase for a single component small and its functionality testable.\nThe next and final step in the single-sample gene expression processing is doublet detection using filter_with_scrublet. Like filter_with_counts, it will not remove cells but add a column to .obs (which have the name filter_with_scrublet by default). The single-sample GEX workflow will not remove not be removed during the processing (hence no do_filter). However, you can choose to remove them yourself before doing your analyses by applying a filter with the column in .obs yourself.",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#sec-single-sample-adt",
    "href": "fundamentals/architecture.html#sec-single-sample-adt",
    "title": "Architecture",
    "section": "Single-sample Antibody Capture Processing",
    "text": "Single-sample Antibody Capture Processing\nThe process of filtering antibody capture data is similar to the filtering in the single-sample gene-expression processing, but without doublet detection. In some particular cases you can use your ADT data to perform doublet detection using for example cell-type maskers. More information can be found in the single-cell best practices book.",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#multisample-gene-expression-processing",
    "href": "fundamentals/architecture.html#multisample-gene-expression-processing",
    "title": "Architecture",
    "section": "Multisample Gene Expression Processing",
    "text": "Multisample Gene Expression Processing\nProcessing multisample gene expression involved the following steps:\n\nNormalization: Normalization aims to adjust the raw counts in the dataset for variable sampling effects by scaling the observable variance to a specified range. There are different ways to transform the data, but the normalization method is to make sure each observation (cell) has a total count equal to the median of total counts over all genes for observations (cells) before normalization.\nLog transformation: Calculates \\(X = ln(X + 1)\\), which converts multiplicative relative changes to additive differences. This allows for interpreting the gene expression in terms of relative, rather than absolute, abundances of genes.\nHighly variable gene detection: Detects genes that have a large change in expression between samples. By default, OpenPipeline uses the method from Seurat (Satija et al.). As with other “filtering” components, the filter_with_hvg component does not remove features, but rather annotates genes of interest by adding a boolean column to .var.\nQC metric calculations",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#multisample-antibody-capture-processing",
    "href": "fundamentals/architecture.html#multisample-antibody-capture-processing",
    "title": "Architecture",
    "section": "Multisample Antibody Capture Processing",
    "text": "Multisample Antibody Capture Processing\nProcessing the ADT modality for multiple samples",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#sec-dimensionality-reduction",
    "href": "fundamentals/architecture.html#sec-dimensionality-reduction",
    "title": "Architecture",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\nscRNA-seq is a high-throughput sequencing technology that produces datasets with high dimensions in the number of cells and genes. It is true that the data should provide more information, but it also contains more noise and redudant information, making it harder to distill the usefull information. The number of genes and cells can already reduced by gene filtering, but further reduction is a necessity for downstream analysis. Dimensionality reduction projects high-dimensional data into a lower dimensional space (like taking a photo (2D) of some 3D structure). The lower dimensional representation still captures the underlying information of the data, while having fewer dimensions.\nSeveral dimensionality reduction methods have been developed and applied to single-cell data analysis. Two of which are being applied in OpenPipeline:\n\nPrincipal Component Analysis (PCA): PCA reduces the dimension of a dataset by creating a new set of variables (principal components, PCs) from a linear combination of the original features in such a way that they are as uncorrelated as possible. The PCs can be ranked in the order by which they explain the largest variability in the original dataset. By keeping the top n PCs, the PCs with the lowest variance are discarded to effectively reduce the dimensionality of the data without losing information.\nUniform manifold approximation and projection (UMAP): a non-linear dimensionality technique. It constructs a high dimensional graph representation of the dataset and optimizes the low-dimensional graph representation to be structurally as similar as possible to the original graph. In a review by Xiang et al., 2021 it showed the highest stability and separates best the original cell populations.\nt-SNE is another popular non-linear, graph based dimensionality technique which is very similar to UMAP, but it has not yet been implemented in OpenPipeline.",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#sec-initializing-integration",
    "href": "fundamentals/architecture.html#sec-initializing-integration",
    "title": "Architecture",
    "section": "Initializing integration",
    "text": "Initializing integration\nAs will be descibed in more details later on, many integration methods exist and therefore there is no single integration which is executed by default. However, there are common tasks which are run before integration either because they provide required input for many downstream integration methods or because they popular steps that would otherwise be done manually. These operations are executed by default when using the “full pipeline” as part of the initialize_integration subworkflow.\nPCA is used to reduce the dimensionality of the dataset as described previously. Find Neighbors and Leiden Clustering are useful for the identification of cell types or states in the data. Here we apply a popular method to accomplish this is to first calculate a neighborhood graph on a low dimensinonal representation of the data and then cluster the data based on similarity between data points. Finally, UMAP allows us to visualise the clusters by reducing the dimensionality of the data while still providing an accurate representation of the underlying cell population structure.",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/architecture.html#sec-integration-methods",
    "href": "fundamentals/architecture.html#sec-integration-methods",
    "title": "Architecture",
    "section": "Integration Methods",
    "text": "Integration Methods\nIntegration is the alignment of cell types across samples. There exist three different types of integration methods, based on the degree of integration across modalities:\n\nUnimodal integration across batches. For example: scVI, scanorama, harmony\nMultimodal integration across batches and modalities. Can be used to integrate joint-profiling data where multiple modalities are measured. For example: totalVI\nMosaic integration: data integration across batches and modalities where not all cells are profiled in all modalities and it may be the case that no cells contain profiles in all integrated modalities. Mosaic integration methods have not been made available in OpenPipeline yet. An example of a tool that performs mosaic integration is StabMap.\n\nIn either of the three cases, concatenated samples are required, and merged modalities preferred. A plethora of integration methods exist, which in turn interact with other functionality (like clustering and dimensionality reduction methods) to generate a large number of possible usecases which one pipeline cannot cover in an easy manner. Therefore, there is no single integration step that is part of a global pipeline which is executed by default. Instead, a user can choose from the integration workflows provided, and ‘stack’ integration methods by adding the outputs to different output slots of the MuData object. The following sections will descibe the integration workflows that are available in OpenPipeline.\n\nUnimodal integration\nFor unimodal integration, scVI, scanorama and harmony have been added to the scvi_leiden, scanorama_leiden, and harmony_leiden workflows respectively. After executing the integration methods themselves, Find Neighbors and Leiden Clustering are run the results of the integration as wel as UMAP in order to be able to visualise the results. The functioning of these components has already been described here.\n\n\n\nMultimodal Integration\nA single multimodal integration method is currently avaiable in OpenPipeline: totalVI. It allows using information from both the gene-expression data and the antibody-capture data together to integrate the cell types. As with the other integration workflows, after running totalVI, Find Neighbors, Leiden Clustering and UMAP are run on the result. However in this case the three components are executed on both of the integrated modalities.",
    "crumbs": [
      "Fundamentals",
      "Architecture"
    ]
  },
  {
    "objectID": "fundamentals/roadmap.html",
    "href": "fundamentals/roadmap.html",
    "title": "Roadmap",
    "section": "",
    "text": "flowchart LR\n  classDef done fill:#a3f6cf,stroke:#000000;\n  classDef wip fill:#f4cb93,stroke:#000000;\n  classDef unprocessed fill:#afadff,stroke:#000000;\n\n  Raw1[Sample 1] --&gt; Split1[/Split\\nmodalities/]:::done --&gt; ProcGEX1 & ProcRNAV1 & ProcADT1 & ProcATAC1 & ProcVDJ1\n  ProcGEX1[/Process GEX\\nprofile/]:::done --&gt; ConcatGEX[/Concatenate\\nprofiles/]:::done --&gt; ProcGEX[/Process GEX\\nprofiles/]:::done\n  ProcRNAV1[/Process RNAV\\nprofile/]:::wip --&gt; ConcatRNAV[/Concatenate\\nprofiles/]:::done --&gt; ProcRNAV[/Process RNAV\\nprofiles/]:::wip\n  ProcADT1[/Process ADT\\nprofile/]:::done --&gt; ConcatADT[/Concatenate\\nprofiles/]:::done --&gt; ProcADT[/Process ADT\\nprofiles/]:::done\n  ProcATAC1[/Process ATAC\\nprofile/]:::unprocessed --&gt; ConcatATAC[/Concatenate\\nprofiles/]:::done --&gt; ProcATAC[/Process ATAC\\nprofiles/]:::unprocessed\n  ProcVDJ1[/Process VDJ\\nprofile/]:::unprocessed --&gt; ConcatVDJ[/Concatenate\\nprofiles/]:::done --&gt; ProcVDJ[/Process VDJ\\nprofiles/]:::unprocessed\n  ProcGEX & ProcRNAV & ProcADT & ProcATAC & ProcVDJ --&gt; Merge[/Merge\\nmodalities/]:::done --&gt; SetupIntegration[/Setup\\nintegration/]:::done --&gt; Integration[/Integration/]:::done\n\n\n\n\nFigure 1: Status of implemented components. Green: implemented, orange: work in progress, purple: modality included in output but unprocessed,\nGEX: Gene-expression. RNAV: RNA Velocity. ADT: Antibody-Derived Tags. ATAC: Assay for Transposase-Accessible Chromatin.\n\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  subgraph ingestion\n    direction TB\n    subgraph cellranger_multi\n      direction TB\n      mapping_10x --&gt; convert_to_h5mu_10x\n      mapping_10x[mapping]:::done\n      convert_to_h5mu_10x[convert_to_h5mu]:::done\n    end\n    subgraph bdrhap_v1\n      direction TB\n      mapping_bd1 --&gt; convert_to_h5mu_bd1\n      mapping_bd1[mapping]:::done\n      convert_to_h5mu_bd1[convert_to_h5mu]:::done\n    end\n    subgraph bdrhap_v2\n      direction TB\n      mapping_bd2 --&gt; convert_to_h5mu_bd2\n      mapping_bd2[mapping]:::wip\n      convert_to_h5mu_bd2[convert_to_h5mu]:::wip\n    end\n    cellranger_multi:::subwf\n    bdrhap_v1:::subwf\n    bdrhap_v2:::subwf\n  end\n  ingestion:::wf\n  subgraph process_samples\n    split_modalities --&gt; rna_singlesample & prot_singlesample & gdo_singlesample & atac_singlesample & other_modalities --&gt; concat --&gt; process_batches\n    split_modalities:::done\n    rna_singlesample:::done\n    prot_singlesample:::done\n    gdo_singlesample:::done\n    atac_singlesample:::todo\n    other_modalities:::done\n    concat:::done\n    subgraph process_batches\n      direction LR\n      split_modalities2 --&gt; rna_multisample & prot_multisample & atac_multisample & other_modalities2 --&gt; merge\n      split_modalities2[split_modalities]:::done\n      other_modalities2[other_modalities]:::done\n      rna_multisample:::done\n      prot_multisample:::done\n      merge:::done\n    end\n    process_batches:::subwf\n    atac_multisample:::todo\n  end\n  process_samples:::wf\n  raw_counts --- ingestion --&gt; raw_h5mu\n  raw_h5mu --- process_samples --&gt; processed_h5mu\n  subgraph integration\n    direction LR\n    integration_method --&gt; find_neighbors --&gt; leiden --&gt; umap\n    integration_method -.- intmeth\n    integration_method:::done\n    find_neighbors:::done\n    leiden:::done\n    umap:::done\n    subgraph intmeth [integration_method]\n      bbknn:::done\n      harmony:::done\n      scanorama:::done\n      scvi:::done\n      totalvi:::done\n      scgpt_integration:::wip\n    end\n    intmeth:::info\n  end\n  integration:::wf\n  processed_h5mu --- integration ---&gt; integrated_h5mu\n  subgraph celltype_annotation\n    direction TB\n    integration_method2[integration_method]:::done\n    celltypist:::wip\n    scanvi:::wip\n    scgpt_annotation:::wip\n    onclass:::todo\n    svm:::todo\n    randomforest:::todo\n    pynndescent_knn:::wip\n    consensus_voting:::todo\n    integration_method2 --&gt; pynndescent_knn --&gt; consensus_voting\n    celltypist & scanvi & scgpt_annotation & onclass & svm & randomforest --&gt; consensus_voting\n  end\n  reference_atlas --&gt; celltype_annotation\n  celltype_annotation:::wf\n  integrated_h5mu --- celltype_annotation --&gt; annotated_h5mu\n\n  classDef done fill:#ccebc5,stroke:#4daf4a\n  classDef wip fill:#fed9a6,stroke:#ff7f00\n  classDef todo fill:#fbb4ae,stroke:#e41a1c\n  classDef wf fill:#f0f0f0,stroke:#525252\n  classDef subwf fill:#d9d9d9,stroke:#525252\n  classDef info fill:#f0f0f0,stroke:#525252,stroke-dasharray: 4 4\n  \n  subgraph Legend\n    done[Done]:::done\n    wip[Work in progress]:::wip\n    todo[To do]:::todo\n  end\n  Legend:::info\n\n\n\n\nFigure 2",
    "crumbs": [
      "Fundamentals",
      "Roadmap"
    ]
  },
  {
    "objectID": "more_information/index.html",
    "href": "more_information/index.html",
    "title": "More information",
    "section": "",
    "text": "Cheat sheets: Cheat sheets for various tools\n  \n  \n  \n    Code of conduct: Our DEI values\n  \n  \n  \n    FAQ: Frequently Asked Questions\n  \n  \n\n\nNo matching items",
    "crumbs": [
      "Fundamentals",
      "More information"
    ]
  },
  {
    "objectID": "more_information/code_of_conduct.html",
    "href": "more_information/code_of_conduct.html",
    "title": "Code of conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\nOur full Code of Conduct is adapted from the Contributor Covenant, version 2.1.",
    "crumbs": [
      "Fundamentals",
      "More information",
      "Code of conduct"
    ]
  },
  {
    "objectID": "components/index.html",
    "href": "components/index.html",
    "title": "Reference",
    "section": "",
    "text": "Order By\n       Default\n         \n          Name\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nName\n\n\nNamespace\n\n\nDescription\n\n\n\n\n\n\nBD Rhapsody\n\n\nWorkflows/ingestion\n\n\nBD Rhapsody Sequence Analysis CWL pipeline v2.2.1\n\n\n\n\nBbknn leiden\n\n\nWorkflows/integration\n\n\nRun bbknn followed by leiden clustering and run umap on the result.\n\n\n\n\nCell Ranger mapping\n\n\nWorkflows/ingestion\n\n\nA pipeline for running Cell Ranger mapping.\n\n\n\n\nCell Ranger multi\n\n\nWorkflows/ingestion\n\n\nA pipeline for running Cell Ranger multi.\n\n\n\n\nCell Ranger post-processing\n\n\nWorkflows/ingestion\n\n\nPost-processing Cell Ranger datasets.\n\n\n\n\nConvert to MuData\n\n\nWorkflows/ingestion\n\n\nA pipeline to convert different file formats to .h5mu.\n\n\n\n\nDemux\n\n\nWorkflows/ingestion\n\n\nA generic pipeline for running bcl2fastq, bcl-convert or Cell Ranger mkfastq.\n\n\n\n\nDimensionality reduction\n\n\nWorkflows/multiomics\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nGDO Singlesample\n\n\nWorkflows/gdo\n\n\nProcessing unimodal single-sample guide-derived oligonucleotide (GDO) data.\n\n\n\n\nHarmony integration followed by KNN label transfer\n\n\nWorkflows/annotation\n\n\nCell type annotation workflow by performing harmony integration of reference and query dataset followed by KNN label transfer.\n\n\n\n\nHarmony leiden\n\n\nWorkflows/integration\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nMake reference\n\n\nWorkflows/ingestion\n\n\nBuild a transcriptomics reference into one of many formats\n\n\n\n\nNeighbors leiden umap\n\n\nWorkflows/multiomics\n\n\nPerforms neighborhood search, leiden clustering and run umap on an integrated embedding.\n\n\n\n\nProcess batches\n\n\nWorkflows/multiomics\n\n\nThis workflow serves as an entrypoint into the ‘full_pipeline’ in order to re-run the multisample processing and the integration setup.\n\n\n\n\nProcess samples\n\n\nWorkflows/multiomics\n\n\nA pipeline to analyse multiple multiomics samples.\n\n\n\n\nProt multisample\n\n\nWorkflows/prot\n\n\nProcessing unimodal multi-sample ADT data.\n\n\n\n\nProt singlesample\n\n\nWorkflows/prot\n\n\nProcessing unimodal single-sample CITE-seq data.\n\n\n\n\nQc\n\n\nWorkflows/qc\n\n\nA pipeline to add basic qc statistics to a MuData\n\n\n\n\nRna multisample\n\n\nWorkflows/rna\n\n\nProcessing unimodal multi-sample RNA transcriptomics data.\n\n\n\n\nRna singlesample\n\n\nWorkflows/rna\n\n\nProcessing unimodal single-sample RNA transcriptomics data.\n\n\n\n\nScanorama leiden\n\n\nWorkflows/integration\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScgpt leiden\n\n\nWorkflows/integration\n\n\nRun scGPT integration (cell embedding generation) followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScvi leiden\n\n\nWorkflows/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nSplit h5mu\n\n\nWorkflows/multiomics\n\n\nSplit the samples of a single modality from a .h5mu (multimodal) sample into seperate .h5mu files based on the values of an .obs column of this modality\n\n\n\n\nSplit modalities\n\n\nWorkflows/multiomics\n\n\nA pipeline to split a multimodal mudata files into several unimodal mudata files.\n\n\n\n\nTotalvi leiden\n\n\nWorkflows/integration\n\n\nRun totalVI integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nscANVI - scArches workflow\n\n\nWorkflows/annotation\n\n\nCell type annotation workflow using ScanVI with scArches for reference mapping.\n\n\n\n\nscGPT Annotation\n\n\nWorkflows/annotation\n\n\nCell type annotation workflow using scGPT.\n\n\n\n\nscVI Annotation\n\n\nWorkflows/annotation\n\n\nCell type annotation workflow that performs scVI integration of reference and query dataset followed by KNN label transfer.\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Reference"
    ]
  },
  {
    "objectID": "components/index.html#workflows",
    "href": "components/index.html#workflows",
    "title": "Reference",
    "section": "",
    "text": "Order By\n       Default\n         \n          Name\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nName\n\n\nNamespace\n\n\nDescription\n\n\n\n\n\n\nBD Rhapsody\n\n\nWorkflows/ingestion\n\n\nBD Rhapsody Sequence Analysis CWL pipeline v2.2.1\n\n\n\n\nBbknn leiden\n\n\nWorkflows/integration\n\n\nRun bbknn followed by leiden clustering and run umap on the result.\n\n\n\n\nCell Ranger mapping\n\n\nWorkflows/ingestion\n\n\nA pipeline for running Cell Ranger mapping.\n\n\n\n\nCell Ranger multi\n\n\nWorkflows/ingestion\n\n\nA pipeline for running Cell Ranger multi.\n\n\n\n\nCell Ranger post-processing\n\n\nWorkflows/ingestion\n\n\nPost-processing Cell Ranger datasets.\n\n\n\n\nConvert to MuData\n\n\nWorkflows/ingestion\n\n\nA pipeline to convert different file formats to .h5mu.\n\n\n\n\nDemux\n\n\nWorkflows/ingestion\n\n\nA generic pipeline for running bcl2fastq, bcl-convert or Cell Ranger mkfastq.\n\n\n\n\nDimensionality reduction\n\n\nWorkflows/multiomics\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nGDO Singlesample\n\n\nWorkflows/gdo\n\n\nProcessing unimodal single-sample guide-derived oligonucleotide (GDO) data.\n\n\n\n\nHarmony integration followed by KNN label transfer\n\n\nWorkflows/annotation\n\n\nCell type annotation workflow by performing harmony integration of reference and query dataset followed by KNN label transfer.\n\n\n\n\nHarmony leiden\n\n\nWorkflows/integration\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nMake reference\n\n\nWorkflows/ingestion\n\n\nBuild a transcriptomics reference into one of many formats\n\n\n\n\nNeighbors leiden umap\n\n\nWorkflows/multiomics\n\n\nPerforms neighborhood search, leiden clustering and run umap on an integrated embedding.\n\n\n\n\nProcess batches\n\n\nWorkflows/multiomics\n\n\nThis workflow serves as an entrypoint into the ‘full_pipeline’ in order to re-run the multisample processing and the integration setup.\n\n\n\n\nProcess samples\n\n\nWorkflows/multiomics\n\n\nA pipeline to analyse multiple multiomics samples.\n\n\n\n\nProt multisample\n\n\nWorkflows/prot\n\n\nProcessing unimodal multi-sample ADT data.\n\n\n\n\nProt singlesample\n\n\nWorkflows/prot\n\n\nProcessing unimodal single-sample CITE-seq data.\n\n\n\n\nQc\n\n\nWorkflows/qc\n\n\nA pipeline to add basic qc statistics to a MuData\n\n\n\n\nRna multisample\n\n\nWorkflows/rna\n\n\nProcessing unimodal multi-sample RNA transcriptomics data.\n\n\n\n\nRna singlesample\n\n\nWorkflows/rna\n\n\nProcessing unimodal single-sample RNA transcriptomics data.\n\n\n\n\nScanorama leiden\n\n\nWorkflows/integration\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScgpt leiden\n\n\nWorkflows/integration\n\n\nRun scGPT integration (cell embedding generation) followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScvi leiden\n\n\nWorkflows/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nSplit h5mu\n\n\nWorkflows/multiomics\n\n\nSplit the samples of a single modality from a .h5mu (multimodal) sample into seperate .h5mu files based on the values of an .obs column of this modality\n\n\n\n\nSplit modalities\n\n\nWorkflows/multiomics\n\n\nA pipeline to split a multimodal mudata files into several unimodal mudata files.\n\n\n\n\nTotalvi leiden\n\n\nWorkflows/integration\n\n\nRun totalVI integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nscANVI - scArches workflow\n\n\nWorkflows/annotation\n\n\nCell type annotation workflow using ScanVI with scArches for reference mapping.\n\n\n\n\nscGPT Annotation\n\n\nWorkflows/annotation\n\n\nCell type annotation workflow using scGPT.\n\n\n\n\nscVI Annotation\n\n\nWorkflows/annotation\n\n\nCell type annotation workflow that performs scVI integration of reference and query dataset followed by KNN label transfer.\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Reference"
    ]
  },
  {
    "objectID": "components/index.html#modules",
    "href": "components/index.html#modules",
    "title": "Reference",
    "section": "Modules",
    "text": "Modules\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Name\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nName\n\n\nNamespace\n\n\nDescription\n\n\n\n\n\n\nAdd id\n\n\nMetadata\n\n\nAdd id of .obs.\n\n\n\n\nAlign query reference\n\n\nFeature annotation\n\n\nAlignment of a query and reference dataset by: * Alignment of layers * Harmonization of .obs field names for batch and cell type labels * Harmonization of .var field name for gene names * Sanitation of gene names * Cross-checking of genes * Assignment of an id to the query and reference datasets\n\n\n\n\nBbknn\n\n\nNeighbors\n\n\nBBKNN network generation\n\n\n\n\nBcftools\n\n\nGenetic demux\n\n\nFilter the variants called by freebayes or cellSNP\n\n\n\n\nBcl convert\n\n\nDemux\n\n\nConvert bcl files to fastq files using bcl-convert.\n\n\n\n\nBcl2fastq\n\n\nDemux\n\n\nConvert bcl files to fastq files using bcl2fastq\n\n\n\n\nBd rhapsody\n\n\nMapping\n\n\nBD Rhapsody Sequence Analysis CWL pipeline v2.2.1 This pipeline performs analysis of single-cell multiomic sequence read (FASTQ) data.\n\n\n\n\nBinning\n\n\nScgpt\n\n\nConversion of (pre-processed) expression count data into relative values (bins) to address scale differences across sequencing batches\n\n\n\n\nBpcells regress out\n\n\nTransform\n\n\nRegress out the effects of confounding variables using a linear least squares regression model with BPCells\n\n\n\n\nBuild bdrhap reference\n\n\nReference\n\n\nThe Reference Files Generator creates an archive containing Genome Index and Transcriptome annotation files needed for the BD Rhapsody Sequencing Analysis Pipeline.\n\n\n\n\nBuild cellranger arc reference\n\n\nReference\n\n\nBuild a Cell Ranger-arc and -atac compatible reference folder from user-supplied genome FASTA and gene GTF files.\n\n\n\n\nBuild cellranger reference\n\n\nReference\n\n\nBuild a Cell Ranger-compatible reference folder from user-supplied genome FASTA and gene GTF files.\n\n\n\n\nBuild star reference\n\n\nReference\n\n\nCreate a reference for STAR from a set of fasta files.\n\n\n\n\nCalculate atac qc metrics\n\n\nQc\n\n\nAdd basic ATAC quality control metrics to an .h5mu file.\n\n\n\n\nCalculate qc metrics\n\n\nQc\n\n\nAdd basic quality control metrics to an .h5mu file.\n\n\n\n\nCell type annotation\n\n\nScgpt\n\n\nAnnotate gene expression data with cell type classes through the scGPT model\n\n\n\n\nCellbender remove background\n\n\nCorrection\n\n\nEliminating technical artifacts from high-throughput single-cell RNA sequencing data.\n\n\n\n\nCellbender remove background v0 2\n\n\nCorrection\n\n\nEliminating technical artifacts from high-throughput single-cell RNA sequencing data.\n\n\n\n\nCellranger atac count\n\n\nMapping\n\n\nAlign fastq files using Cell Ranger ATAC count.\n\n\n\n\nCellranger atac mkfastq\n\n\nDemux\n\n\nDemultiplex raw sequencing data for ATAC experiments\n\n\n\n\nCellranger count\n\n\nMapping\n\n\nAlign fastq files using Cell Ranger count.\n\n\n\n\nCellranger count split\n\n\nMapping\n\n\nSplit 10x Cell Ranger output directory into separate output fields.\n\n\n\n\nCellranger mkfastq\n\n\nDemux\n\n\nDemultiplex raw sequencing data\n\n\n\n\nCellranger mkgtf\n\n\nReference\n\n\nMake a GTF file - filter by a specific attribute.\n\n\n\n\nCellranger multi\n\n\nMapping\n\n\nAlign fastq files using Cell Ranger multi.\n\n\n\n\nCellsnp\n\n\nGenetic demux\n\n\ncellSNP aims to pileup the expressed alleles in single-cell or bulk RNA-seq data.\n\n\n\n\nCelltypist\n\n\nAnnotate\n\n\nAutomated cell type annotation tool for scRNA-seq datasets on the basis of logistic regression classifiers optimised by the stochastic gradient descent algorithm.\n\n\n\n\nCellxgene census\n\n\nQuery\n\n\nQuery cells from a CellxGene Census or custom TileDBSoma object.\n\n\n\n\nClr\n\n\nTransform\n\n\nPerform CLR normalization on CITE-seq data (Stoeckius et al., 2017)\n\n\n\n\nCompress h5mu\n\n\nCompression\n\n\nCompress a MuData file.\n\n\n\n\nConcatenate h5mu\n\n\nDataflow\n\n\nConcatenate observations from samples in several (uni- and/or multi-modal) MuData files into a single file\n\n\n\n\nCross check genes\n\n\nScgpt\n\n\nCross-check genes with pre-trained scGPT model\n\n\n\n\nDelete layer\n\n\nTransform\n\n\nDelete an anndata layer from one or more modalities\n\n\n\n\nDelimit fraction\n\n\nFilter\n\n\nTurns a column containing values between 0 and 1 into a boolean column based on thresholds\n\n\n\n\nDemuxlet\n\n\nGenetic demux\n\n\nDemuxlet is a software tool to deconvolute sample identity and identify multiplets when multiple samples are pooled by barcoded single cell sequencing.\n\n\n\n\nDensmap\n\n\nDimred\n\n\nA modification of UMAP that adds an extra cost term in order to preserve information about the relative local density of the data.\n\n\n\n\nDo filter\n\n\nFilter\n\n\nRemove observations and variables based on specified .obs and .var columns\n\n\n\n\nDownload file\n\n\nDownload\n\n\nDownload a file\n\n\n\n\nDsc pileup\n\n\nGenetic demux\n\n\nDsc-pileup is a software tool to pileup reads and corresponding base quality for each overlapping SNPs and each barcode.\n\n\n\n\nEmbedding\n\n\nScgpt\n\n\nGeneration of cell embeddings for the integration of single cell transcriptomic count data using scGPT\n\n\n\n\nFastqc\n\n\nQc\n\n\nFastqc component, please see https://www.bioinformatics.babraham.ac.uk/projects/fastqc/.\n\n\n\n\nFilter 10xh5\n\n\nProcess 10xh5\n\n\nFilter a 10x h5 dataset\n\n\n\n\nFilter with counts\n\n\nFilter\n\n\nFilter scRNA-seq data based on the primary QC metrics.\n\n\n\n\nFilter with scrublet\n\n\nFilter\n\n\nDoublet detection using the Scrublet method (Wolock, Lopez and Klein, 2019).\n\n\n\n\nFind neighbors\n\n\nNeighbors\n\n\nCompute a neighborhood graph of observations [McInnes18].\n\n\n\n\nFreebayes\n\n\nGenetic demux\n\n\nFreebayes is a Bayesian genetic variant detector designed to find small polymorphisms, specifically SNPs\n\n\n\n\nFreemuxlet\n\n\nGenetic demux\n\n\nFreemuxlet is a software tool to deconvolute sample identity and identify multiplets when multiple samples are pooled by barcoded single cell sequencing.\n\n\n\n\nFrom 10xh5 to h5mu\n\n\nConvert\n\n\nConverts a 10x h5 into an h5mu file\n\n\n\n\nFrom 10xmtx to h5mu\n\n\nConvert\n\n\nConverts a 10x mtx into an h5mu file\n\n\n\n\nFrom bd to 10x molecular barcode tags\n\n\nConvert\n\n\nConvert the molecular barcode sequence SAM tag from BD format (MA) to 10X format (UB)\n\n\n\n\nFrom bdrhap to h5mu\n\n\nConvert\n\n\nConvert the output of a BD Rhapsody pipeline v2.x to a MuData h5 file\n\n\n\n\nFrom cellranger multi to h5mu\n\n\nConvert\n\n\nConverts the output from cellranger multi to a single .h5mu file.\n\n\n\n\nFrom h5ad to h5mu\n\n\nConvert\n\n\nConverts a single layer h5ad file into a single MuData object\n\n\n\n\nFrom h5ad to seurat\n\n\nConvert\n\n\nConverts an h5ad file into a Seurat file\n\n\n\n\nFrom h5mu to h5ad\n\n\nConvert\n\n\nConverts a h5mu file into a h5ad file\n\n\n\n\nFrom h5mu to seurat\n\n\nConvert\n\n\nConverts an h5mu file into a Seurat file.\n\n\n\n\nGrep annotation column\n\n\nMetadata\n\n\nPerform a regex lookup on a column from the annotation matrices .obs or .var.\n\n\n\n\nHarmonypy\n\n\nIntegrate\n\n\nPerforms Harmony integration based as described in https://github.com/immunogenomics/harmony.\n\n\n\n\nHighly variable features scanpy\n\n\nFeature annotation\n\n\nAnnotate highly variable features [Satija15] [Zheng17] [Stuart19].\n\n\n\n\nHtseq count\n\n\nMapping\n\n\nQuantify gene expression for subsequent testing for differential expression.\n\n\n\n\nHtseq count to h5mu\n\n\nMapping\n\n\nConvert the htseq table to a h5mu\n\n\n\n\nIntersect obs\n\n\nFilter\n\n\nCreate an intersection between two or more modalities.\n\n\n\n\nJoin csv\n\n\nMetadata\n\n\nJoin a csv containing metadata to the .obs or .var field of a mudata file.\n\n\n\n\nJoin uns to obs\n\n\nMetadata\n\n\nJoin a data frame of length 1 (1 row index value) in .uns containing metadata to the .obs of a mudata file.\n\n\n\n\nKnn\n\n\nLabels transfer\n\n\nThis component performs label transfer from reference to query using a K-Neirest Neighbors classifier\n\n\n\n\nLeiden\n\n\nCluster\n\n\nCluster cells using the [Leiden algorithm] [Traag18] implemented in the [Scanpy framework] [Wolf18].\n\n\n\n\nLianapy\n\n\nInterpret\n\n\nPerforms LIANA integration based as described in https://github.com/saezlab/liana-py\n\n\n\n\nLog1p\n\n\nTransform\n\n\nLogarithmize the data matrix.\n\n\n\n\nLsi\n\n\nDimred\n\n\nRuns Latent Semantic Indexing.\n\n\n\n\nMake params\n\n\nFiles\n\n\nLooks for files in a directory and turn it in a params file.\n\n\n\n\nMake reference\n\n\nReference\n\n\nPreprocess and build a transcriptome reference.\n\n\n\n\nMerge\n\n\nDataflow\n\n\nCombine one or more single-modality .h5mu files together into one .h5mu file\n\n\n\n\nMermaid\n\n\nReport\n\n\nGenerates a network from mermaid code\n\n\n\n\nMove layer\n\n\nTransform\n\n\nMove a data matrix stored at the .layers or .X attributes in a MuData object to another layer.\n\n\n\n\nMove obsm to obs\n\n\nMetadata\n\n\nMove a matrix from .obsm to .obs.\n\n\n\n\nMulti star\n\n\nMapping\n\n\nAlign fastq files using STAR.\n\n\n\n\nMulti star to h5mu\n\n\nMapping\n\n\nConvert the output of multi_star to a h5mu\n\n\n\n\nMultiqc\n\n\nQc\n\n\nMultiQC aggregates results from bioinformatics analyses across many samples into a single report.\n\n\n\n\nNormalize total\n\n\nTransform\n\n\nNormalize counts per cell.\n\n\n\n\nOnclass\n\n\nAnnotate\n\n\nOnClass is a python package for single-cell cell type annotation.\n\n\n\n\nPad tokenize\n\n\nScgpt\n\n\nTokenize and pad a batch of data for scGPT integration zero-shot inference or fine-tuning\n\n\n\n\nPca\n\n\nDimred\n\n\nComputes PCA coordinates, loadings and variance decomposition.\n\n\n\n\nPopv\n\n\nAnnotate\n\n\nPerforms popular major vote cell typing on single cell sequence data using multiple algorithms.\n\n\n\n\nPublish\n\n\nTransfer\n\n\nPublish an artifact and optionally rename with parameters\n\n\n\n\nRandom forest annotation\n\n\nAnnotate\n\n\nAutomated cell type annotation tool for scRNA-seq datasets on the basis of random forest.\n\n\n\n\nRegress out\n\n\nTransform\n\n\nRegress out (mostly) unwanted sources of variation.\n\n\n\n\nRemove modality\n\n\nFilter\n\n\nRemove a modality from a .h5mu file\n\n\n\n\nSamtools\n\n\nGenetic demux\n\n\nFilter the BAM according to the instruction of scSplit via Samtools.\n\n\n\n\nSamtools sort\n\n\nMapping\n\n\nSort and (optionally) index alignments.\n\n\n\n\nScale\n\n\nTransform\n\n\nScale data to unit variance and zero mean\n\n\n\n\nScanorama\n\n\nIntegrate\n\n\nUse Scanorama to integrate different experiments\n\n\n\n\nScanvi\n\n\nAnnotate\n\n\nscANVI () is a semi-supervised model for single-cell transcriptomics data.\n\n\n\n\nScarches\n\n\nIntegrate\n\n\nPerforms reference mapping with scArches\n\n\n\n\nScore genes cell cycle scanpy\n\n\nFeature annotation\n\n\nCalculates the score associated to S phase and G2M phase and annotates the cell cycle phase for each cell, as implemented by scanpy.\n\n\n\n\nScsplit\n\n\nGenetic demux\n\n\nscsplit is a genotype-free demultiplexing methode of pooled single-cell RNA-seq, using a hidden state model for identifying genetically distinct samples within a mixed population.\n\n\n\n\nScvelo\n\n\nVelocity\n\n\n\n\n\n\n\nScvi\n\n\nIntegrate\n\n\nPerforms scvi integration as done in the human lung cell atlas https://github.com/LungCellAtlas/HLCA\n\n\n\n\nSouporcell\n\n\nGenetic demux\n\n\nsouporcell is a method for clustering mixed-genotype scRNAseq experiments by individual.\n\n\n\n\nSplit h5mu\n\n\nDataflow\n\n\nSplit the samples of a single modality from a .h5mu (multimodal) sample into seperate .h5mu files based on the values of an .obs column of this modality.\n\n\n\n\nSplit h5mu train test\n\n\nDataflow\n\n\nSplit mudata object into training and testing (and validation) datasets based on observations into separate mudata objects.\n\n\n\n\nSplit modalities\n\n\nDataflow\n\n\nSplit the modalities from a single .h5mu multimodal sample into seperate .h5mu files.\n\n\n\n\nStar align\n\n\nMapping\n\n\nAlign fastq files using STAR.\n\n\n\n\nStar align v273a\n\n\nMapping\n\n\nAlign fastq files using STAR.\n\n\n\n\nSubset h5mu\n\n\nFilter\n\n\nCreate a subset of a mudata file by selecting the first number of observations\n\n\n\n\nSubset obsp\n\n\nFilter\n\n\nCreate a subset of an .obsp field in a mudata file, by filtering the columns based on the values of an .obs column.\n\n\n\n\nSvm annotation\n\n\nAnnotate\n\n\nAutomated cell type annotation tool for scRNA-seq datasets on the basis of SVMs.\n\n\n\n\nSync test resources\n\n\nDownload\n\n\nSync test resources to the local filesystem\n\n\n\n\nTar extract\n\n\nCompression\n\n\nExtract files from a tar archive\n\n\n\n\nTfidf\n\n\nTransform\n\n\nPerform TF-IDF normalization of the data (typically, ATAC).\n\n\n\n\nTotalvi\n\n\nIntegrate\n\n\nPerforms mapping to the reference by totalvi model: https://docs.scvi-tools.org/en/stable/tutorials/notebooks/scarches_scvi_tools.html#Reference-mapping-with-TOTALVI\n\n\n\n\nTsne\n\n\nDimred\n\n\nt-SNE (t-Distributed Stochastic Neighbor Embedding) is a dimensionality reduction technique used to visualize high-dimensional data in a low-dimensional space, revealing patterns and clusters by preserving local data similarities\n\n\n\n\nUmap\n\n\nDimred\n\n\nUMAP (Uniform Manifold Approximation and Projection) is a manifold learning technique suitable for visualizing high-dimensional data.\n\n\n\n\nVelocyto\n\n\nVelocity\n\n\nRuns the velocity analysis on a BAM file, outputting a loom file.\n\n\n\n\nVelocyto to h5mu\n\n\nConvert\n\n\nConvert a velocyto loom file to a h5mu file.\n\n\n\n\nVireo\n\n\nGenetic demux\n\n\nVireo is primarily designed for demultiplexing cells into donors by modelling of expressed alleles.\n\n\n\n\nXgboost\n\n\nLabels transfer\n\n\nPerforms label transfer from reference to query using XGBoost classifier\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Reference"
    ]
  },
  {
    "objectID": "components/workflows/rna/rna_multisample.html",
    "href": "components/workflows/rna/rna_multisample.html",
    "title": "Rna multisample",
    "section": "",
    "text": "ID: rna_multisample\nNamespace: workflows/rna\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Rna",
      "Rna multisample"
    ]
  },
  {
    "objectID": "components/workflows/rna/rna_multisample.html#example-commands",
    "href": "components/workflows/rna/rna_multisample.html#example-commands",
    "title": "Rna multisample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/rna/rna_multisample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"concatenated\"\ninput: # please fill in - example: \"dataset.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering highly variable features\nhighly_variable_features_var_output: \"filter_with_hvg\"\nhighly_variable_features_obs_batch_key: \"sample_id\"\nhighly_variable_features_flavor: \"seurat\"\n# highly_variable_features_n_top_features: 123\n\n# QC metrics calculation options\nvar_qc_metrics: [\"filter_with_hvg\"]\ntop_n_vars: [50, 100, 200, 500]\noutput_obs_num_nonzero_vars: \"num_nonzero_vars\"\noutput_obs_total_counts_vars: \"total_counts\"\noutput_var_num_nonzero_obs: \"num_nonzero_obs\"\noutput_var_total_counts_obs: \"total_counts\"\noutput_var_obs_mean: \"obs_mean\"\noutput_var_pct_dropout: \"pct_dropout\"\n\n# RNA Scaling options\nenable_scaling: false\nscaling_output_layer: \"scaled\"\n# scaling_max_value: 123.0\nscaling_zero_center: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/rna/rna_multisample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Rna",
      "Rna multisample"
    ]
  },
  {
    "objectID": "components/workflows/rna/rna_multisample.html#argument-groups",
    "href": "components/workflows/rna/rna_multisample.html#argument-groups",
    "title": "Rna multisample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the concatenated file\nstring, required, example: \"concatenated\"\n\n\n--input\nPath to the samples.\nfile, required, example: \"dataset.h5mu\"\n\n\n--modality\nModality to process.\nstring, default: \"rna\"\n\n\n--layer\nInput layer to use. If not specified, .X is used.\nstring\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering highly variable features\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--highly_variable_features_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable features.\nstring, default: \"filter_with_hvg\"\n\n\n--highly_variable_features_obs_batch_key\nIf specified, highly-variable features are selected within each batch separately and merged. This simple process avoids the selection of batch-specific features and acts as a lightweight batch correction method. For all flavors, featues are first sorted by how many batches they are highly variable. For dispersion-based flavors ties are broken by normalized dispersion. If flavor = ‘seurat_v3’, ties are broken by the median (across batches) rank based on within-batch normalized variance.\nstring, default: \"sample_id\"\n\n\n--highly_variable_features_flavor\nChoose the flavor for identifying highly variable features. For the dispersion based methods in their default workflows, Seurat passes the cutoffs whereas Cell Ranger passes n_top_features.\nstring, default: \"seurat\"\n\n\n--highly_variable_features_n_top_features\nNumber of highly-variable features to keep. Mandatory if filter_with_hvg_flavor is set to ‘seurat_v3’.\ninteger\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes.\nList of string, default: \"filter_with_hvg\", example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n--output_obs_num_nonzero_vars\nName of column in .obs describing, for each observation, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each row the number of columns that contain data.\nstring, default: \"num_nonzero_vars\"\n\n\n--output_obs_total_counts_vars\nName of the column for .obs describing, for each observation (row), the sum of the stored values in the columns.\nstring, default: \"total_counts\"\n\n\n--output_var_num_nonzero_obs\nName of column describing, for each feature, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each column the number of rows that contain data.\nstring, default: \"num_nonzero_obs\"\n\n\n--output_var_total_counts_obs\nName of the column in .var describing, for each feature (column), the sum of the stored values in the rows.\nstring, default: \"total_counts\"\n\n\n--output_var_obs_mean\nName of the column in .obs providing the mean of the values in each row.\nstring, default: \"obs_mean\"\n\n\n--output_var_pct_dropout\nName of the column in .obs providing for each feature the percentage of observations the feature does not appear on (i.e. is missing). Same as --num_nonzero_obs but percentage based.\nstring, default: \"pct_dropout\"\n\n\n\n\n\nRNA Scaling options\nOptions for enabling scaling of the log-normalized data to unit variance and zero mean. The scaled data will be output a different layer and representation with reduced dimensions will be created and stored in addition to the non-scaled data.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--enable_scaling\nEnable scaling for the RNA modality.\nboolean_true\n\n\n--scaling_output_layer\nOutput layer where the scaled log-normalized data will be stored.\nstring, default: \"scaled\"\n\n\n--scaling_max_value\nClip (truncate) data to this value after scaling. If not specified, do not clip.\ndouble\n\n\n--scaling_zero_center\nIf set, omit zero-centering variables, which allows to handle sparse input efficiently.”\nboolean_false",
    "crumbs": [
      "Reference",
      "Workflows",
      "Rna",
      "Rna multisample"
    ]
  },
  {
    "objectID": "components/workflows/rna/rna_multisample.html#authors",
    "href": "components/workflows/rna/rna_multisample.html#authors",
    "title": "Rna multisample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Rna",
      "Rna multisample"
    ]
  },
  {
    "objectID": "components/workflows/rna/rna_multisample.html#visualisation",
    "href": "components/workflows/rna/rna_multisample.html#visualisation",
    "title": "Rna multisample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(normalize_total)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v49(log1p)\n    v56(cross)\n    v66(cross)\n    v72(filter)\n    v80(delete_layer)\n    v87(cross)\n    v97(cross)\n    v106(branch)\n    v133(concat)\n    v111(scale)\n    v118(cross)\n    v128(cross)\n    v134(filter)\n    v142(highly_variable_features_scanpy)\n    v149(cross)\n    v159(cross)\n    v165(filter)\n    v288(concat)\n    v177(branch)\n    v204(concat)\n    v189(cross)\n    v199(cross)\n    v208(branch)\n    v235(concat)\n    v220(cross)\n    v230(cross)\n    v236(filter)\n    v266(concat)\n    v251(cross)\n    v261(cross)\n    v273(cross)\n    v283(cross)\n    v295(cross)\n    v302(cross)\n    v314(cross)\n    v321(cross)\n    v325(Output)\n    subgraph group_rna_qc [rna_qc]\n        v182(grep_mitochondrial_genes)\n        v213(grep_ribosomal_genes)\n        v244(calculate_qc_metrics)\n    end\n    v106--&gt;v133\n    v133--&gt;v134\n    v177--&gt;v204\n    v208--&gt;v235\n    v235--&gt;v236\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v49\n    v49--&gt;v56\n    v41--&gt;v56\n    v41--&gt;v66\n    v72--&gt;v80\n    v80--&gt;v87\n    v72--&gt;v87\n    v72--&gt;v97\n    v106--&gt;v111\n    v111--&gt;v118\n    v106--&gt;v118\n    v106--&gt;v128\n    v128--&gt;v133\n    v134--&gt;v142\n    v142--&gt;v149\n    v134--&gt;v149\n    v134--&gt;v159\n    v177--&gt;v182\n    v182--&gt;v189\n    v177--&gt;v189\n    v177--&gt;v199\n    v199--&gt;v204\n    v208--&gt;v213\n    v213--&gt;v220\n    v208--&gt;v220\n    v208--&gt;v230\n    v230--&gt;v235\n    v236--&gt;v244\n    v244--&gt;v251\n    v236--&gt;v251\n    v236--&gt;v261\n    v261--&gt;v266\n    v266--&gt;v273\n    v165--&gt;v273\n    v165--&gt;v283\n    v283--&gt;v288\n    v288--&gt;v295\n    v2--&gt;v295\n    v295--&gt;v302\n    v2--&gt;v302\n    v2--&gt;v314\n    v314--&gt;v321\n    v2--&gt;v321\n    v321--&gt;v325\n    v35--&gt;v41\n    v18--&gt;v35\n    v66--&gt;v72\n    v49--&gt;v66\n    v80--&gt;v97\n    v97--&gt;v106\n    v111--&gt;v128\n    v159--&gt;v165\n    v142--&gt;v159\n    v165--&gt;v177\n    v182--&gt;v199\n    v204--&gt;v208\n    v213--&gt;v230\n    v244--&gt;v261\n    v266--&gt;v283\n    v288--&gt;v314\n    style group_rna_qc fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v49 fill:#e3dcea,stroke:#7a4baa;\n    style v56 fill:#e3dcea,stroke:#7a4baa;\n    style v66 fill:#e3dcea,stroke:#7a4baa;\n    style v72 fill:#e3dcea,stroke:#7a4baa;\n    style v80 fill:#e3dcea,stroke:#7a4baa;\n    style v87 fill:#e3dcea,stroke:#7a4baa;\n    style v97 fill:#e3dcea,stroke:#7a4baa;\n    style v106 fill:#e3dcea,stroke:#7a4baa;\n    style v133 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v118 fill:#e3dcea,stroke:#7a4baa;\n    style v128 fill:#e3dcea,stroke:#7a4baa;\n    style v134 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v149 fill:#e3dcea,stroke:#7a4baa;\n    style v159 fill:#e3dcea,stroke:#7a4baa;\n    style v165 fill:#e3dcea,stroke:#7a4baa;\n    style v288 fill:#e3dcea,stroke:#7a4baa;\n    style v177 fill:#e3dcea,stroke:#7a4baa;\n    style v204 fill:#e3dcea,stroke:#7a4baa;\n    style v182 fill:#e3dcea,stroke:#7a4baa;\n    style v189 fill:#e3dcea,stroke:#7a4baa;\n    style v199 fill:#e3dcea,stroke:#7a4baa;\n    style v208 fill:#e3dcea,stroke:#7a4baa;\n    style v235 fill:#e3dcea,stroke:#7a4baa;\n    style v213 fill:#e3dcea,stroke:#7a4baa;\n    style v220 fill:#e3dcea,stroke:#7a4baa;\n    style v230 fill:#e3dcea,stroke:#7a4baa;\n    style v236 fill:#e3dcea,stroke:#7a4baa;\n    style v266 fill:#e3dcea,stroke:#7a4baa;\n    style v244 fill:#e3dcea,stroke:#7a4baa;\n    style v251 fill:#e3dcea,stroke:#7a4baa;\n    style v261 fill:#e3dcea,stroke:#7a4baa;\n    style v273 fill:#e3dcea,stroke:#7a4baa;\n    style v283 fill:#e3dcea,stroke:#7a4baa;\n    style v295 fill:#e3dcea,stroke:#7a4baa;\n    style v302 fill:#e3dcea,stroke:#7a4baa;\n    style v314 fill:#e3dcea,stroke:#7a4baa;\n    style v321 fill:#e3dcea,stroke:#7a4baa;\n    style v325 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Rna",
      "Rna multisample"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/neighbors_leiden_umap.html",
    "href": "components/workflows/multiomics/neighbors_leiden_umap.html",
    "title": "Neighbors leiden umap",
    "section": "",
    "text": "ID: neighbors_leiden_umap\nNamespace: workflows/multiomics\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Neighbors leiden umap"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/neighbors_leiden_umap.html#example-commands",
    "href": "components/workflows/multiomics/neighbors_leiden_umap.html#example-commands",
    "title": "Neighbors leiden umap",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/multiomics/neighbors_leiden_umap/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"dataset.h5mu\"\nobsm_input: # please fill in - example: \"foo\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: # please fill in - example: \"foo\"\nobsp_neighbor_distances: # please fill in - example: \"foo\"\nobsp_neighbor_connectivities: # please fill in - example: \"foo\"\n\n# Clustering options\n# obs_cluster: \"foo\"\nleiden_resolution: [1.0]\n\n# Umap options\n# obsm_umap: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/multiomics/neighbors_leiden_umap/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Neighbors leiden umap"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/neighbors_leiden_umap.html#argument-groups",
    "href": "components/workflows/multiomics/neighbors_leiden_umap.html#argument-groups",
    "title": "Neighbors leiden umap",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--obsm_input\nThe key of the embedding to use as input.\nstring, required\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, required\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, required\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, required\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding. When not specified, UMAP will not be executed.\nstring",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Neighbors leiden umap"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/neighbors_leiden_umap.html#authors",
    "href": "components/workflows/multiomics/neighbors_leiden_umap.html#authors",
    "title": "Neighbors leiden umap",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Neighbors leiden umap"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/neighbors_leiden_umap.html#visualisation",
    "href": "components/workflows/multiomics/neighbors_leiden_umap.html#visualisation",
    "title": "Neighbors leiden umap",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v11(filter)\n    v19(find_neighbors)\n    v26(cross)\n    v36(cross)\n    v45(branch)\n    v72(concat)\n    v50(leiden)\n    v57(cross)\n    v67(cross)\n    v76(branch)\n    v103(concat)\n    v81(move_obsm_to_obs)\n    v88(cross)\n    v98(cross)\n    v107(branch)\n    v134(concat)\n    v112(umap)\n    v119(cross)\n    v129(cross)\n    v141(cross)\n    v148(cross)\n    v160(cross)\n    v167(cross)\n    v171(Output)\n    v45--&gt;v72\n    v76--&gt;v103\n    v107--&gt;v134\n    v0--&gt;v2\n    v2--&gt;v11\n    v11--&gt;v19\n    v19--&gt;v26\n    v11--&gt;v26\n    v11--&gt;v36\n    v45--&gt;v50\n    v50--&gt;v57\n    v45--&gt;v57\n    v45--&gt;v67\n    v67--&gt;v72\n    v76--&gt;v81\n    v81--&gt;v88\n    v76--&gt;v88\n    v76--&gt;v98\n    v98--&gt;v103\n    v107--&gt;v112\n    v112--&gt;v119\n    v107--&gt;v119\n    v107--&gt;v129\n    v129--&gt;v134\n    v134--&gt;v141\n    v2--&gt;v141\n    v141--&gt;v148\n    v2--&gt;v148\n    v2--&gt;v160\n    v160--&gt;v167\n    v2--&gt;v167\n    v167--&gt;v171\n    v19--&gt;v36\n    v36--&gt;v45\n    v50--&gt;v67\n    v72--&gt;v76\n    v81--&gt;v98\n    v103--&gt;v107\n    v112--&gt;v129\n    v134--&gt;v160\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v11 fill:#e3dcea,stroke:#7a4baa;\n    style v19 fill:#e3dcea,stroke:#7a4baa;\n    style v26 fill:#e3dcea,stroke:#7a4baa;\n    style v36 fill:#e3dcea,stroke:#7a4baa;\n    style v45 fill:#e3dcea,stroke:#7a4baa;\n    style v72 fill:#e3dcea,stroke:#7a4baa;\n    style v50 fill:#e3dcea,stroke:#7a4baa;\n    style v57 fill:#e3dcea,stroke:#7a4baa;\n    style v67 fill:#e3dcea,stroke:#7a4baa;\n    style v76 fill:#e3dcea,stroke:#7a4baa;\n    style v103 fill:#e3dcea,stroke:#7a4baa;\n    style v81 fill:#e3dcea,stroke:#7a4baa;\n    style v88 fill:#e3dcea,stroke:#7a4baa;\n    style v98 fill:#e3dcea,stroke:#7a4baa;\n    style v107 fill:#e3dcea,stroke:#7a4baa;\n    style v134 fill:#e3dcea,stroke:#7a4baa;\n    style v112 fill:#e3dcea,stroke:#7a4baa;\n    style v119 fill:#e3dcea,stroke:#7a4baa;\n    style v129 fill:#e3dcea,stroke:#7a4baa;\n    style v141 fill:#e3dcea,stroke:#7a4baa;\n    style v148 fill:#e3dcea,stroke:#7a4baa;\n    style v160 fill:#e3dcea,stroke:#7a4baa;\n    style v167 fill:#e3dcea,stroke:#7a4baa;\n    style v171 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Neighbors leiden umap"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/dimensionality_reduction.html",
    "href": "components/workflows/multiomics/dimensionality_reduction.html",
    "title": "Dimensionality reduction",
    "section": "",
    "text": "ID: dimensionality_reduction\nNamespace: workflows/multiomics\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Dimensionality reduction"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/dimensionality_reduction.html#example-commands",
    "href": "components/workflows/multiomics/dimensionality_reduction.html#example-commands",
    "title": "Dimensionality reduction",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/multiomics/dimensionality_reduction/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# PCA options\nobsm_pca: \"X_pca\"\n# var_pca_feature_selection: \"foo\"\n# pca_loadings_varm_output: \"foo\"\n# pca_variance_uns_output: \"foo\"\npca_overwrite: false\n\n# Neighbour calculation\nuns_neighbors: \"neighbors\"\nobsp_neighbor_distances: \"distances\"\nobsp_neighbor_connectivities: \"connectivities\"\n\n# Umap options\nobsm_umap: \"X_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/multiomics/dimensionality_reduction/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Dimensionality reduction"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/dimensionality_reduction.html#argument-groups",
    "href": "components/workflows/multiomics/dimensionality_reduction.html#argument-groups",
    "title": "Dimensionality reduction",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_pca\nIn which .obsm slot to store the resulting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--var_pca_feature_selection\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring\n\n\n--pca_loadings_varm_output\nName of the .varm key where the PCA loadings are stored.\nstring\n\n\n--pca_variance_uns_output\nName of the .uns key where the variance and variance ratio will be stored as a map. The map will contain two keys: variance and variance_ratio respectively.\nstring\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_umap\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Dimensionality reduction"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/dimensionality_reduction.html#authors",
    "href": "components/workflows/multiomics/dimensionality_reduction.html#authors",
    "title": "Dimensionality reduction",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Dimensionality reduction"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/dimensionality_reduction.html#visualisation",
    "href": "components/workflows/multiomics/dimensionality_reduction.html#visualisation",
    "title": "Dimensionality reduction",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(pca)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v195(concat)\n    v50(filter)\n    v65(cross)\n    v75(cross)\n    v84(branch)\n    v111(concat)\n    v96(cross)\n    v106(cross)\n    v115(branch)\n    v142(concat)\n    v127(cross)\n    v137(cross)\n    v146(branch)\n    v173(concat)\n    v158(cross)\n    v168(cross)\n    v180(cross)\n    v190(cross)\n    v202(cross)\n    v209(cross)\n    v221(cross)\n    v228(cross)\n    v232(Output)\n    subgraph group_neighbors_leiden_umap [neighbors_leiden_umap]\n        v58(find_neighbors)\n        v89(leiden)\n        v120(move_obsm_to_obs)\n        v151(umap)\n    end\n    v84--&gt;v111\n    v115--&gt;v142\n    v146--&gt;v173\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v50\n    v50--&gt;v58\n    v58--&gt;v65\n    v50--&gt;v65\n    v50--&gt;v75\n    v84--&gt;v89\n    v89--&gt;v96\n    v84--&gt;v96\n    v84--&gt;v106\n    v106--&gt;v111\n    v115--&gt;v120\n    v120--&gt;v127\n    v115--&gt;v127\n    v115--&gt;v137\n    v137--&gt;v142\n    v146--&gt;v151\n    v151--&gt;v158\n    v146--&gt;v158\n    v146--&gt;v168\n    v168--&gt;v173\n    v173--&gt;v180\n    v41--&gt;v180\n    v41--&gt;v190\n    v190--&gt;v195\n    v195--&gt;v202\n    v2--&gt;v202\n    v202--&gt;v209\n    v2--&gt;v209\n    v2--&gt;v221\n    v221--&gt;v228\n    v2--&gt;v228\n    v228--&gt;v232\n    v35--&gt;v41\n    v18--&gt;v35\n    v58--&gt;v75\n    v75--&gt;v84\n    v89--&gt;v106\n    v111--&gt;v115\n    v120--&gt;v137\n    v142--&gt;v146\n    v151--&gt;v168\n    v173--&gt;v190\n    v195--&gt;v221\n    style group_neighbors_leiden_umap fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v195 fill:#e3dcea,stroke:#7a4baa;\n    style v50 fill:#e3dcea,stroke:#7a4baa;\n    style v58 fill:#e3dcea,stroke:#7a4baa;\n    style v65 fill:#e3dcea,stroke:#7a4baa;\n    style v75 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v89 fill:#e3dcea,stroke:#7a4baa;\n    style v96 fill:#e3dcea,stroke:#7a4baa;\n    style v106 fill:#e3dcea,stroke:#7a4baa;\n    style v115 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v120 fill:#e3dcea,stroke:#7a4baa;\n    style v127 fill:#e3dcea,stroke:#7a4baa;\n    style v137 fill:#e3dcea,stroke:#7a4baa;\n    style v146 fill:#e3dcea,stroke:#7a4baa;\n    style v173 fill:#e3dcea,stroke:#7a4baa;\n    style v151 fill:#e3dcea,stroke:#7a4baa;\n    style v158 fill:#e3dcea,stroke:#7a4baa;\n    style v168 fill:#e3dcea,stroke:#7a4baa;\n    style v180 fill:#e3dcea,stroke:#7a4baa;\n    style v190 fill:#e3dcea,stroke:#7a4baa;\n    style v202 fill:#e3dcea,stroke:#7a4baa;\n    style v209 fill:#e3dcea,stroke:#7a4baa;\n    style v221 fill:#e3dcea,stroke:#7a4baa;\n    style v228 fill:#e3dcea,stroke:#7a4baa;\n    style v232 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Dimensionality reduction"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/process_batches.html",
    "href": "components/workflows/multiomics/process_batches.html",
    "title": "Process batches",
    "section": "",
    "text": "ID: process_batches\nNamespace: workflows/multiomics\n\n\n\nSource\nAn input .h5mu file will first be split in order to run the multisample processing per modality. Next, the modalities are merged again and the integration setup pipeline is executed. Please note that this workflow assumes that samples from multiple pipelines are already concatenated.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Process batches"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/process_batches.html#example-commands",
    "href": "components/workflows/multiomics/process_batches.html#example-commands",
    "title": "Process batches",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/multiomics/process_batches/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"input.h5mu\"]\n# rna_layer: \"foo\"\n# prot_layer: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Highly variable features detection\nhighly_variable_features_var_output: \"filter_with_hvg\"\nhighly_variable_features_obs_batch_key: \"sample_id\"\n\n# QC metrics calculation options\nvar_qc_metrics: [\"filter_with_hvg\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# PCA options\npca_overwrite: false\n\n# CLR options\nclr_axis: 0\n\n# RNA Scaling options\nrna_enable_scaling: false\nrna_scaling_output_layer: \"scaled\"\nrna_scaling_pca_obsm_output: \"scaled_pca\"\nrna_scaling_pca_loadings_varm_output: \"scaled_pca_loadings\"\nrna_scaling_pca_variance_uns_output: \"scaled_pca_variance\"\nrna_scaling_umap_obsm_output: \"scaled_umap\"\n# rna_scaling_max_value: 123.0\nrna_scaling_zero_center: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/multiomics/process_batches/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Process batches"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/process_batches.html#argument-groups",
    "href": "components/workflows/multiomics/process_batches.html#argument-groups",
    "title": "Process batches",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nList of file, required, example: \"input.h5mu\", multiple_sep: \";\"\n\n\n--rna_layer\nInput layer for the gene expression modality. If not specified, .X is used.\nstring\n\n\n--prot_layer\nInput layer for the antibody capture modality. If not specified, .X is used.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nHighly variable features detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--highly_variable_features_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable genes.\nstring, default: \"filter_with_hvg\"\n\n\n--highly_variable_features_obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method.\nstring, default: \"sample_id\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes.\nList of string, default: \"filter_with_hvg\", example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true\n\n\n\n\n\nCLR options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clr_axis\nAxis to perform the CLR transformation on.\ninteger, default: 0\n\n\n\n\n\nRNA Scaling options\nOptions for enabling scaling of the log-normalized data to unit variance and zero mean. The scaled data will be output a different layer and representation with reduced dimensions will be created and stored in addition to the non-scaled data.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_enable_scaling\nEnable scaling for the RNA modality.\nboolean_true\n\n\n--rna_scaling_output_layer\nOutput layer where the scaled log-normalized data will be stored.\nstring, default: \"scaled\"\n\n\n--rna_scaling_pca_obsm_output\nName of the .obsm key where the PCA representation of the log-normalized and scaled data is stored.\nstring, default: \"scaled_pca\"\n\n\n--rna_scaling_pca_loadings_varm_output\nName of the .varm key where the PCA loadings of the log-normalized and scaled data is stored.\nstring, default: \"scaled_pca_loadings\"\n\n\n--rna_scaling_pca_variance_uns_output\nName of the .uns key where the variance and variance ratio will be stored as a map. The map will contain two keys: variance and variance_ratio respectively.\nstring, default: \"scaled_pca_variance\"\n\n\n--rna_scaling_umap_obsm_output\nName of the .obsm key where the UMAP representation of the log-normalized and scaled data is stored.\nstring, default: \"scaled_umap\"\n\n\n--rna_scaling_max_value\nClip (truncate) data to this value after scaling. If not specified, do not clip.\ndouble\n\n\n--rna_scaling_zero_center\nIf set, omit zero-centering variables, which allows to handle sparse input efficiently.”\nboolean_false",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Process batches"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/process_batches.html#authors",
    "href": "components/workflows/multiomics/process_batches.html#authors",
    "title": "Process batches",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Process batches"
    ]
  },
  {
    "objectID": "components/workflows/multiomics/process_batches.html#visualisation",
    "href": "components/workflows/multiomics/process_batches.html#visualisation",
    "title": "Process batches",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v11(filter)\n    v22(filter)\n    v34(cross)\n    v44(cross)\n    v54(concat)\n    v61(cross)\n    v71(cross)\n    v77(flatMap)\n    v85(filter)\n    v93(filter)\n    v108(cross)\n    v118(cross)\n    v124(filter)\n    v139(cross)\n    v149(cross)\n    v155(filter)\n    v170(cross)\n    v180(cross)\n    v189(branch)\n    v216(concat)\n    v201(cross)\n    v211(cross)\n    v217(filter)\n    v232(cross)\n    v242(cross)\n    v248(filter)\n    v371(concat)\n    v260(branch)\n    v287(concat)\n    v272(cross)\n    v282(cross)\n    v291(branch)\n    v318(concat)\n    v303(cross)\n    v313(cross)\n    v319(filter)\n    v349(concat)\n    v334(cross)\n    v344(cross)\n    v356(cross)\n    v366(cross)\n    v378(cross)\n    v388(cross)\n    v586(mix)\n    v399(filter)\n    v407(filter)\n    v422(cross)\n    v432(cross)\n    v438(filter)\n    v561(concat)\n    v450(branch)\n    v477(concat)\n    v462(cross)\n    v472(cross)\n    v481(branch)\n    v508(concat)\n    v493(cross)\n    v503(cross)\n    v509(filter)\n    v539(concat)\n    v524(cross)\n    v534(cross)\n    v546(cross)\n    v556(cross)\n    v568(cross)\n    v578(cross)\n    v588(mix)\n    v596(filter)\n    v604(merge)\n    v611(cross)\n    v621(cross)\n    v631(branch)\n    v843(concat)\n    v636(filter)\n    v651(cross)\n    v661(cross)\n    v667(filter)\n    v821(concat)\n    v676(filter)\n    v691(cross)\n    v701(cross)\n    v710(branch)\n    v737(concat)\n    v722(cross)\n    v732(cross)\n    v741(branch)\n    v768(concat)\n    v753(cross)\n    v763(cross)\n    v772(branch)\n    v799(concat)\n    v784(cross)\n    v794(cross)\n    v806(cross)\n    v816(cross)\n    v828(cross)\n    v838(cross)\n    v847(branch)\n    v1059(concat)\n    v852(filter)\n    v867(cross)\n    v877(cross)\n    v883(filter)\n    v1037(concat)\n    v892(filter)\n    v907(cross)\n    v917(cross)\n    v926(branch)\n    v953(concat)\n    v938(cross)\n    v948(cross)\n    v957(branch)\n    v984(concat)\n    v969(cross)\n    v979(cross)\n    v988(branch)\n    v1015(concat)\n    v1000(cross)\n    v1010(cross)\n    v1022(cross)\n    v1032(cross)\n    v1044(cross)\n    v1054(cross)\n    v1063(branch)\n    v1275(concat)\n    v1068(filter)\n    v1083(cross)\n    v1093(cross)\n    v1099(filter)\n    v1253(concat)\n    v1108(filter)\n    v1123(cross)\n    v1133(cross)\n    v1142(branch)\n    v1169(concat)\n    v1154(cross)\n    v1164(cross)\n    v1173(branch)\n    v1200(concat)\n    v1185(cross)\n    v1195(cross)\n    v1204(branch)\n    v1231(concat)\n    v1216(cross)\n    v1226(cross)\n    v1238(cross)\n    v1248(cross)\n    v1260(cross)\n    v1270(cross)\n    v1282(cross)\n    v1289(cross)\n    v1301(cross)\n    v1308(cross)\n    v1312(Output)\n    subgraph group_split_modalities_workflow [split_modalities_workflow]\n        v27(split_modalities_component)\n    end\n    subgraph group_rna_multisample [rna_multisample]\n        v101(normalize_total)\n        v132(log1p)\n        v163(delete_layer)\n        v194(scale)\n        v225(highly_variable_features_scanpy)\n        v265(grep_mitochondrial_genes)\n        v296(grep_ribosomal_genes)\n        v327(calculate_qc_metrics)\n    end\n    subgraph group_prot_multisample [prot_multisample]\n        v415(clr)\n        v455(grep_mitochondrial_genes)\n        v486(grep_ribosomal_genes)\n        v517(calculate_qc_metrics)\n    end\n    subgraph group_dimensionality_reduction_rna [dimensionality_reduction_rna]\n        v644(pca)\n        v684(find_neighbors)\n        v715(leiden)\n        v746(move_obsm_to_obs)\n        v777(umap)\n    end\n    subgraph group_dimensionality_reduction_scaling_rna [dimensionality_reduction_scaling_rna]\n        v860(pca)\n        v900(find_neighbors)\n        v931(leiden)\n        v962(move_obsm_to_obs)\n        v993(umap)\n    end\n    subgraph group_dimensionality_reduction_prot [dimensionality_reduction_prot]\n        v1076(pca)\n        v1116(find_neighbors)\n        v1147(leiden)\n        v1178(move_obsm_to_obs)\n        v1209(umap)\n    end\n    v189--&gt;v216\n    v216--&gt;v217\n    v260--&gt;v287\n    v291--&gt;v318\n    v318--&gt;v319\n    v450--&gt;v477\n    v481--&gt;v508\n    v508--&gt;v509\n    v586--&gt;v588\n    v631--&gt;v843\n    v710--&gt;v737\n    v741--&gt;v768\n    v772--&gt;v799\n    v847--&gt;v1059\n    v926--&gt;v953\n    v957--&gt;v984\n    v988--&gt;v1015\n    v1063--&gt;v1275\n    v1142--&gt;v1169\n    v1173--&gt;v1200\n    v1204--&gt;v1231\n    v0--&gt;v2\n    v22--&gt;v27\n    v27--&gt;v34\n    v22--&gt;v34\n    v22--&gt;v44\n    v54--&gt;v61\n    v11--&gt;v61\n    v11--&gt;v71\n    v85--&gt;v93\n    v93--&gt;v101\n    v101--&gt;v108\n    v93--&gt;v108\n    v93--&gt;v118\n    v124--&gt;v132\n    v132--&gt;v139\n    v124--&gt;v139\n    v124--&gt;v149\n    v155--&gt;v163\n    v163--&gt;v170\n    v155--&gt;v170\n    v155--&gt;v180\n    v189--&gt;v194\n    v194--&gt;v201\n    v189--&gt;v201\n    v189--&gt;v211\n    v211--&gt;v216\n    v217--&gt;v225\n    v225--&gt;v232\n    v217--&gt;v232\n    v217--&gt;v242\n    v260--&gt;v265\n    v265--&gt;v272\n    v260--&gt;v272\n    v260--&gt;v282\n    v282--&gt;v287\n    v291--&gt;v296\n    v296--&gt;v303\n    v291--&gt;v303\n    v291--&gt;v313\n    v313--&gt;v318\n    v319--&gt;v327\n    v327--&gt;v334\n    v319--&gt;v334\n    v319--&gt;v344\n    v344--&gt;v349\n    v349--&gt;v356\n    v248--&gt;v356\n    v248--&gt;v366\n    v366--&gt;v371\n    v371--&gt;v378\n    v85--&gt;v378\n    v85--&gt;v388\n    v399--&gt;v407\n    v407--&gt;v415\n    v415--&gt;v422\n    v407--&gt;v422\n    v407--&gt;v432\n    v450--&gt;v455\n    v455--&gt;v462\n    v450--&gt;v462\n    v450--&gt;v472\n    v472--&gt;v477\n    v481--&gt;v486\n    v486--&gt;v493\n    v481--&gt;v493\n    v481--&gt;v503\n    v503--&gt;v508\n    v509--&gt;v517\n    v517--&gt;v524\n    v509--&gt;v524\n    v509--&gt;v534\n    v534--&gt;v539\n    v539--&gt;v546\n    v438--&gt;v546\n    v438--&gt;v556\n    v556--&gt;v561\n    v561--&gt;v568\n    v399--&gt;v568\n    v399--&gt;v578\n    v596--&gt;v604\n    v604--&gt;v611\n    v596--&gt;v611\n    v596--&gt;v621\n    v631--&gt;v636\n    v636--&gt;v644\n    v644--&gt;v651\n    v636--&gt;v651\n    v636--&gt;v661\n    v667--&gt;v676\n    v676--&gt;v684\n    v684--&gt;v691\n    v676--&gt;v691\n    v676--&gt;v701\n    v710--&gt;v715\n    v715--&gt;v722\n    v710--&gt;v722\n    v710--&gt;v732\n    v732--&gt;v737\n    v741--&gt;v746\n    v746--&gt;v753\n    v741--&gt;v753\n    v741--&gt;v763\n    v763--&gt;v768\n    v772--&gt;v777\n    v777--&gt;v784\n    v772--&gt;v784\n    v772--&gt;v794\n    v794--&gt;v799\n    v799--&gt;v806\n    v667--&gt;v806\n    v667--&gt;v816\n    v816--&gt;v821\n    v821--&gt;v828\n    v631--&gt;v828\n    v631--&gt;v838\n    v838--&gt;v843\n    v847--&gt;v852\n    v852--&gt;v860\n    v860--&gt;v867\n    v852--&gt;v867\n    v852--&gt;v877\n    v883--&gt;v892\n    v892--&gt;v900\n    v900--&gt;v907\n    v892--&gt;v907\n    v892--&gt;v917\n    v926--&gt;v931\n    v931--&gt;v938\n    v926--&gt;v938\n    v926--&gt;v948\n    v948--&gt;v953\n    v957--&gt;v962\n    v962--&gt;v969\n    v957--&gt;v969\n    v957--&gt;v979\n    v979--&gt;v984\n    v988--&gt;v993\n    v993--&gt;v1000\n    v988--&gt;v1000\n    v988--&gt;v1010\n    v1010--&gt;v1015\n    v1015--&gt;v1022\n    v883--&gt;v1022\n    v883--&gt;v1032\n    v1032--&gt;v1037\n    v1037--&gt;v1044\n    v847--&gt;v1044\n    v847--&gt;v1054\n    v1054--&gt;v1059\n    v1063--&gt;v1068\n    v1068--&gt;v1076\n    v1076--&gt;v1083\n    v1068--&gt;v1083\n    v1068--&gt;v1093\n    v1099--&gt;v1108\n    v1108--&gt;v1116\n    v1116--&gt;v1123\n    v1108--&gt;v1123\n    v1108--&gt;v1133\n    v1142--&gt;v1147\n    v1147--&gt;v1154\n    v1142--&gt;v1154\n    v1142--&gt;v1164\n    v1164--&gt;v1169\n    v1173--&gt;v1178\n    v1178--&gt;v1185\n    v1173--&gt;v1185\n    v1173--&gt;v1195\n    v1195--&gt;v1200\n    v1204--&gt;v1209\n    v1209--&gt;v1216\n    v1204--&gt;v1216\n    v1204--&gt;v1226\n    v1226--&gt;v1231\n    v1231--&gt;v1238\n    v1099--&gt;v1238\n    v1099--&gt;v1248\n    v1248--&gt;v1253\n    v1253--&gt;v1260\n    v1063--&gt;v1260\n    v1063--&gt;v1270\n    v1270--&gt;v1275\n    v1275--&gt;v1282\n    v2--&gt;v1282\n    v1282--&gt;v1289\n    v2--&gt;v1289\n    v2--&gt;v1301\n    v1301--&gt;v1308\n    v2--&gt;v1308\n    v1308--&gt;v1312\n    v2--&gt;v11\n    v71--&gt;v77\n    v11--&gt;v22\n    v44--&gt;v54\n    v27--&gt;v44\n    v54--&gt;v71\n    v77--&gt;v85\n    v388--&gt;v586\n    v118--&gt;v124\n    v101--&gt;v118\n    v149--&gt;v155\n    v132--&gt;v149\n    v163--&gt;v180\n    v180--&gt;v189\n    v194--&gt;v211\n    v242--&gt;v248\n    v225--&gt;v242\n    v248--&gt;v260\n    v265--&gt;v282\n    v287--&gt;v291\n    v296--&gt;v313\n    v327--&gt;v344\n    v349--&gt;v366\n    v371--&gt;v388\n    v77--&gt;v399\n    v578--&gt;v586\n    v432--&gt;v438\n    v415--&gt;v432\n    v438--&gt;v450\n    v455--&gt;v472\n    v477--&gt;v481\n    v486--&gt;v503\n    v517--&gt;v534\n    v539--&gt;v556\n    v561--&gt;v578\n    v77--&gt;v588\n    v588--&gt;v596\n    v604--&gt;v621\n    v621--&gt;v631\n    v661--&gt;v667\n    v644--&gt;v661\n    v684--&gt;v701\n    v701--&gt;v710\n    v715--&gt;v732\n    v737--&gt;v741\n    v746--&gt;v763\n    v768--&gt;v772\n    v777--&gt;v794\n    v799--&gt;v816\n    v821--&gt;v838\n    v843--&gt;v847\n    v877--&gt;v883\n    v860--&gt;v877\n    v900--&gt;v917\n    v917--&gt;v926\n    v931--&gt;v948\n    v953--&gt;v957\n    v962--&gt;v979\n    v984--&gt;v988\n    v993--&gt;v1010\n    v1015--&gt;v1032\n    v1037--&gt;v1054\n    v1059--&gt;v1063\n    v1093--&gt;v1099\n    v1076--&gt;v1093\n    v1116--&gt;v1133\n    v1133--&gt;v1142\n    v1147--&gt;v1164\n    v1169--&gt;v1173\n    v1178--&gt;v1195\n    v1200--&gt;v1204\n    v1209--&gt;v1226\n    v1231--&gt;v1248\n    v1253--&gt;v1270\n    v1275--&gt;v1301\n    style group_split_modalities_workflow fill:#F0F0F0,stroke:#969696;\n    style group_rna_multisample fill:#F0F0F0,stroke:#969696;\n    style group_prot_multisample fill:#F0F0F0,stroke:#969696;\n    style group_dimensionality_reduction_rna fill:#F0F0F0,stroke:#969696;\n    style group_dimensionality_reduction_scaling_rna fill:#F0F0F0,stroke:#969696;\n    style group_dimensionality_reduction_prot fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v11 fill:#e3dcea,stroke:#7a4baa;\n    style v22 fill:#e3dcea,stroke:#7a4baa;\n    style v27 fill:#e3dcea,stroke:#7a4baa;\n    style v34 fill:#e3dcea,stroke:#7a4baa;\n    style v44 fill:#e3dcea,stroke:#7a4baa;\n    style v54 fill:#e3dcea,stroke:#7a4baa;\n    style v61 fill:#e3dcea,stroke:#7a4baa;\n    style v71 fill:#e3dcea,stroke:#7a4baa;\n    style v77 fill:#e3dcea,stroke:#7a4baa;\n    style v85 fill:#e3dcea,stroke:#7a4baa;\n    style v93 fill:#e3dcea,stroke:#7a4baa;\n    style v101 fill:#e3dcea,stroke:#7a4baa;\n    style v108 fill:#e3dcea,stroke:#7a4baa;\n    style v118 fill:#e3dcea,stroke:#7a4baa;\n    style v124 fill:#e3dcea,stroke:#7a4baa;\n    style v132 fill:#e3dcea,stroke:#7a4baa;\n    style v139 fill:#e3dcea,stroke:#7a4baa;\n    style v149 fill:#e3dcea,stroke:#7a4baa;\n    style v155 fill:#e3dcea,stroke:#7a4baa;\n    style v163 fill:#e3dcea,stroke:#7a4baa;\n    style v170 fill:#e3dcea,stroke:#7a4baa;\n    style v180 fill:#e3dcea,stroke:#7a4baa;\n    style v189 fill:#e3dcea,stroke:#7a4baa;\n    style v216 fill:#e3dcea,stroke:#7a4baa;\n    style v194 fill:#e3dcea,stroke:#7a4baa;\n    style v201 fill:#e3dcea,stroke:#7a4baa;\n    style v211 fill:#e3dcea,stroke:#7a4baa;\n    style v217 fill:#e3dcea,stroke:#7a4baa;\n    style v225 fill:#e3dcea,stroke:#7a4baa;\n    style v232 fill:#e3dcea,stroke:#7a4baa;\n    style v242 fill:#e3dcea,stroke:#7a4baa;\n    style v248 fill:#e3dcea,stroke:#7a4baa;\n    style v371 fill:#e3dcea,stroke:#7a4baa;\n    style v260 fill:#e3dcea,stroke:#7a4baa;\n    style v287 fill:#e3dcea,stroke:#7a4baa;\n    style v265 fill:#e3dcea,stroke:#7a4baa;\n    style v272 fill:#e3dcea,stroke:#7a4baa;\n    style v282 fill:#e3dcea,stroke:#7a4baa;\n    style v291 fill:#e3dcea,stroke:#7a4baa;\n    style v318 fill:#e3dcea,stroke:#7a4baa;\n    style v296 fill:#e3dcea,stroke:#7a4baa;\n    style v303 fill:#e3dcea,stroke:#7a4baa;\n    style v313 fill:#e3dcea,stroke:#7a4baa;\n    style v319 fill:#e3dcea,stroke:#7a4baa;\n    style v349 fill:#e3dcea,stroke:#7a4baa;\n    style v327 fill:#e3dcea,stroke:#7a4baa;\n    style v334 fill:#e3dcea,stroke:#7a4baa;\n    style v344 fill:#e3dcea,stroke:#7a4baa;\n    style v356 fill:#e3dcea,stroke:#7a4baa;\n    style v366 fill:#e3dcea,stroke:#7a4baa;\n    style v378 fill:#e3dcea,stroke:#7a4baa;\n    style v388 fill:#e3dcea,stroke:#7a4baa;\n    style v586 fill:#e3dcea,stroke:#7a4baa;\n    style v399 fill:#e3dcea,stroke:#7a4baa;\n    style v407 fill:#e3dcea,stroke:#7a4baa;\n    style v415 fill:#e3dcea,stroke:#7a4baa;\n    style v422 fill:#e3dcea,stroke:#7a4baa;\n    style v432 fill:#e3dcea,stroke:#7a4baa;\n    style v438 fill:#e3dcea,stroke:#7a4baa;\n    style v561 fill:#e3dcea,stroke:#7a4baa;\n    style v450 fill:#e3dcea,stroke:#7a4baa;\n    style v477 fill:#e3dcea,stroke:#7a4baa;\n    style v455 fill:#e3dcea,stroke:#7a4baa;\n    style v462 fill:#e3dcea,stroke:#7a4baa;\n    style v472 fill:#e3dcea,stroke:#7a4baa;\n    style v481 fill:#e3dcea,stroke:#7a4baa;\n    style v508 fill:#e3dcea,stroke:#7a4baa;\n    style v486 fill:#e3dcea,stroke:#7a4baa;\n    style v493 fill:#e3dcea,stroke:#7a4baa;\n    style v503 fill:#e3dcea,stroke:#7a4baa;\n    style v509 fill:#e3dcea,stroke:#7a4baa;\n    style v539 fill:#e3dcea,stroke:#7a4baa;\n    style v517 fill:#e3dcea,stroke:#7a4baa;\n    style v524 fill:#e3dcea,stroke:#7a4baa;\n    style v534 fill:#e3dcea,stroke:#7a4baa;\n    style v546 fill:#e3dcea,stroke:#7a4baa;\n    style v556 fill:#e3dcea,stroke:#7a4baa;\n    style v568 fill:#e3dcea,stroke:#7a4baa;\n    style v578 fill:#e3dcea,stroke:#7a4baa;\n    style v588 fill:#e3dcea,stroke:#7a4baa;\n    style v596 fill:#e3dcea,stroke:#7a4baa;\n    style v604 fill:#e3dcea,stroke:#7a4baa;\n    style v611 fill:#e3dcea,stroke:#7a4baa;\n    style v621 fill:#e3dcea,stroke:#7a4baa;\n    style v631 fill:#e3dcea,stroke:#7a4baa;\n    style v843 fill:#e3dcea,stroke:#7a4baa;\n    style v636 fill:#e3dcea,stroke:#7a4baa;\n    style v644 fill:#e3dcea,stroke:#7a4baa;\n    style v651 fill:#e3dcea,stroke:#7a4baa;\n    style v661 fill:#e3dcea,stroke:#7a4baa;\n    style v667 fill:#e3dcea,stroke:#7a4baa;\n    style v821 fill:#e3dcea,stroke:#7a4baa;\n    style v676 fill:#e3dcea,stroke:#7a4baa;\n    style v684 fill:#e3dcea,stroke:#7a4baa;\n    style v691 fill:#e3dcea,stroke:#7a4baa;\n    style v701 fill:#e3dcea,stroke:#7a4baa;\n    style v710 fill:#e3dcea,stroke:#7a4baa;\n    style v737 fill:#e3dcea,stroke:#7a4baa;\n    style v715 fill:#e3dcea,stroke:#7a4baa;\n    style v722 fill:#e3dcea,stroke:#7a4baa;\n    style v732 fill:#e3dcea,stroke:#7a4baa;\n    style v741 fill:#e3dcea,stroke:#7a4baa;\n    style v768 fill:#e3dcea,stroke:#7a4baa;\n    style v746 fill:#e3dcea,stroke:#7a4baa;\n    style v753 fill:#e3dcea,stroke:#7a4baa;\n    style v763 fill:#e3dcea,stroke:#7a4baa;\n    style v772 fill:#e3dcea,stroke:#7a4baa;\n    style v799 fill:#e3dcea,stroke:#7a4baa;\n    style v777 fill:#e3dcea,stroke:#7a4baa;\n    style v784 fill:#e3dcea,stroke:#7a4baa;\n    style v794 fill:#e3dcea,stroke:#7a4baa;\n    style v806 fill:#e3dcea,stroke:#7a4baa;\n    style v816 fill:#e3dcea,stroke:#7a4baa;\n    style v828 fill:#e3dcea,stroke:#7a4baa;\n    style v838 fill:#e3dcea,stroke:#7a4baa;\n    style v847 fill:#e3dcea,stroke:#7a4baa;\n    style v1059 fill:#e3dcea,stroke:#7a4baa;\n    style v852 fill:#e3dcea,stroke:#7a4baa;\n    style v860 fill:#e3dcea,stroke:#7a4baa;\n    style v867 fill:#e3dcea,stroke:#7a4baa;\n    style v877 fill:#e3dcea,stroke:#7a4baa;\n    style v883 fill:#e3dcea,stroke:#7a4baa;\n    style v1037 fill:#e3dcea,stroke:#7a4baa;\n    style v892 fill:#e3dcea,stroke:#7a4baa;\n    style v900 fill:#e3dcea,stroke:#7a4baa;\n    style v907 fill:#e3dcea,stroke:#7a4baa;\n    style v917 fill:#e3dcea,stroke:#7a4baa;\n    style v926 fill:#e3dcea,stroke:#7a4baa;\n    style v953 fill:#e3dcea,stroke:#7a4baa;\n    style v931 fill:#e3dcea,stroke:#7a4baa;\n    style v938 fill:#e3dcea,stroke:#7a4baa;\n    style v948 fill:#e3dcea,stroke:#7a4baa;\n    style v957 fill:#e3dcea,stroke:#7a4baa;\n    style v984 fill:#e3dcea,stroke:#7a4baa;\n    style v962 fill:#e3dcea,stroke:#7a4baa;\n    style v969 fill:#e3dcea,stroke:#7a4baa;\n    style v979 fill:#e3dcea,stroke:#7a4baa;\n    style v988 fill:#e3dcea,stroke:#7a4baa;\n    style v1015 fill:#e3dcea,stroke:#7a4baa;\n    style v993 fill:#e3dcea,stroke:#7a4baa;\n    style v1000 fill:#e3dcea,stroke:#7a4baa;\n    style v1010 fill:#e3dcea,stroke:#7a4baa;\n    style v1022 fill:#e3dcea,stroke:#7a4baa;\n    style v1032 fill:#e3dcea,stroke:#7a4baa;\n    style v1044 fill:#e3dcea,stroke:#7a4baa;\n    style v1054 fill:#e3dcea,stroke:#7a4baa;\n    style v1063 fill:#e3dcea,stroke:#7a4baa;\n    style v1275 fill:#e3dcea,stroke:#7a4baa;\n    style v1068 fill:#e3dcea,stroke:#7a4baa;\n    style v1076 fill:#e3dcea,stroke:#7a4baa;\n    style v1083 fill:#e3dcea,stroke:#7a4baa;\n    style v1093 fill:#e3dcea,stroke:#7a4baa;\n    style v1099 fill:#e3dcea,stroke:#7a4baa;\n    style v1253 fill:#e3dcea,stroke:#7a4baa;\n    style v1108 fill:#e3dcea,stroke:#7a4baa;\n    style v1116 fill:#e3dcea,stroke:#7a4baa;\n    style v1123 fill:#e3dcea,stroke:#7a4baa;\n    style v1133 fill:#e3dcea,stroke:#7a4baa;\n    style v1142 fill:#e3dcea,stroke:#7a4baa;\n    style v1169 fill:#e3dcea,stroke:#7a4baa;\n    style v1147 fill:#e3dcea,stroke:#7a4baa;\n    style v1154 fill:#e3dcea,stroke:#7a4baa;\n    style v1164 fill:#e3dcea,stroke:#7a4baa;\n    style v1173 fill:#e3dcea,stroke:#7a4baa;\n    style v1200 fill:#e3dcea,stroke:#7a4baa;\n    style v1178 fill:#e3dcea,stroke:#7a4baa;\n    style v1185 fill:#e3dcea,stroke:#7a4baa;\n    style v1195 fill:#e3dcea,stroke:#7a4baa;\n    style v1204 fill:#e3dcea,stroke:#7a4baa;\n    style v1231 fill:#e3dcea,stroke:#7a4baa;\n    style v1209 fill:#e3dcea,stroke:#7a4baa;\n    style v1216 fill:#e3dcea,stroke:#7a4baa;\n    style v1226 fill:#e3dcea,stroke:#7a4baa;\n    style v1238 fill:#e3dcea,stroke:#7a4baa;\n    style v1248 fill:#e3dcea,stroke:#7a4baa;\n    style v1260 fill:#e3dcea,stroke:#7a4baa;\n    style v1270 fill:#e3dcea,stroke:#7a4baa;\n    style v1282 fill:#e3dcea,stroke:#7a4baa;\n    style v1289 fill:#e3dcea,stroke:#7a4baa;\n    style v1301 fill:#e3dcea,stroke:#7a4baa;\n    style v1308 fill:#e3dcea,stroke:#7a4baa;\n    style v1312 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Multiomics",
      "Process batches"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scanvi_scarches.html",
    "href": "components/workflows/annotation/scanvi_scarches.html",
    "title": "scANVI - scArches workflow",
    "section": "",
    "text": "ID: scanvi_scarches\nNamespace: workflows/annotation\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scANVI - scArches workflow"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scanvi_scarches.html#example-commands",
    "href": "components/workflows/annotation/scanvi_scarches.html#example-commands",
    "title": "scANVI - scArches workflow",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/annotation/scanvi_scarches/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Query Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\ninput_obs_batch_label: # please fill in - example: \"sample\"\n# input_obs_size_factor: \"foo\"\n# input_var_gene_names: \"foo\"\n\n# Reference input\nreference: # please fill in - example: \"reference.h5mu\"\nreference_obs_target: # please fill in - example: \"cell_type\"\nreference_obs_batch_label: # please fill in - example: \"sample\"\n# reference_obs_size_factor: \"foo\"\nunlabeled_category: \"Unknown\"\n# reference_var_hvg: \"foo\"\n# reference_var_gene_names: \"foo\"\n\n# scVI, scANVI and scArches training options\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30.0\n\n# Leiden clustering options\nleiden_resolution: [1.0]\n\n# Neighbor classifier arguments\nknn_weights: \"uniform\"\nknn_n_neighbors: 15\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\noutput_obs_predictions: \"scanvi_pred\"\noutput_obs_probability: \"scanvi_probabilities\"\noutput_obsm_integrated: \"X_integrated_scanvi\"\n# output_compression: \"gzip\"\n# output_model: \"$id.$key.output_model\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/annotation/scanvi_scarches/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scANVI - scArches workflow"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scanvi_scarches.html#argument-groups",
    "href": "components/workflows/annotation/scanvi_scarches.html#argument-groups",
    "title": "scANVI - scArches workflow",
    "section": "Argument groups",
    "text": "Argument groups\n\nQuery Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput dataset consisting of the (unlabeled) query observations. The dataset is expected to be pre-processed in the same way as –reference.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process. Should match the modality of the –reference dataset.\nstring, default: \"rna\"\n\n\n--layer\nWhich layer to use for integration if .X is not to be used. Should match the layer of the –reference dataset.\nstring\n\n\n--input_obs_batch_label\nThe .obs field in the input (query) dataset containing the batch labels.\nstring, required, example: \"sample\"\n\n\n--input_obs_size_factor\nKey in adata.obs for size factor information. Instead of using library size as a size factor, the provided size factor column will be used as offset in the mean of the likelihood. Assumed to be on linear scale.\nstring\n\n\n--input_var_gene_names\n.var column containing gene names. By default, use the index.\nstring\n\n\n\n\n\nReference input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nReference dataset consisting of the labeled observations to train the KNN classifier on. The dataset is expected to be pre-processed in the same way as the –input query dataset.\nfile, required, example: \"reference.h5mu\"\n\n\n--reference_obs_target\nThe .obs key containing the target labels.\nstring, required, example: \"cell_type\"\n\n\n--reference_obs_batch_label\nThe .obs field in the reference dataset containing the batch labels.\nstring, required, example: \"sample\"\n\n\n--reference_obs_size_factor\nKey in adata.obs for size factor information. Instead of using library size as a size factor, the provided size factor column will be used as offset in the mean of the likelihood. Assumed to be on linear scale.\nstring\n\n\n--unlabeled_category\nValue in the –reference_obs_batch_label field that indicates unlabeled observations\nstring, default: \"Unknown\"\n\n\n--reference_var_hvg\n.var column containing highly variable genes. If not provided, genes will not be subset.\nstring\n\n\n--reference_var_gene_names\n.var column containing gene names. By default, use the index.\nstring\n\n\n\n\n\nscVI, scANVI and scArches training options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nLeiden clustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nNeighbor classifier arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--knn_weights\nWeight function used in prediction. Possible values are: uniform (all points in each neighborhood are weighted equally) or distance (weight points by the inverse of their distance)\nstring, default: \"uniform\"\n\n\n--knn_n_neighbors\nThe number of neighbors to use in k-neighbor graph structure used for fast approximate nearest neighbor search with PyNNDescent. Larger values will result in more accurate search results at the cost of computation time.\ninteger, default: 15\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe query data in .h5mu format with predicted labels predicted from the classifier trained on the reference.\nfile, required, example: \"output.h5mu\"\n\n\n--output_obs_predictions\nIn which .obs slot to store the predicted labels.\nstring, default: \"scanvi_pred\"\n\n\n--output_obs_probability\nIn which. obs slot to store the probabilities of the predicted labels.\nstring, default: \"scanvi_probabilities\"\n\n\n--output_obsm_integrated\nIn which .obsm slot to store the integrated embedding.\nstring, default: \"X_integrated_scanvi\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_model\nPath to the resulting scANVI model that was updated with query data.\nfile",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scANVI - scArches workflow"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scanvi_scarches.html#authors",
    "href": "components/workflows/annotation/scanvi_scarches.html#authors",
    "title": "scANVI - scArches workflow",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (author, maintainer)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scANVI - scArches workflow"
    ]
  },
  {
    "objectID": "components/workflows/annotation/scanvi_scarches.html#visualisation",
    "href": "components/workflows/annotation/scanvi_scarches.html#visualisation",
    "title": "scANVI - scArches workflow",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(scvi)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v49(scanvi)\n    v56(cross)\n    v66(cross)\n    v72(filter)\n    v80(scarches)\n    v87(cross)\n    v97(cross)\n    v104(filter)\n    v258(concat)\n    v113(filter)\n    v128(cross)\n    v138(cross)\n    v147(branch)\n    v174(concat)\n    v159(cross)\n    v169(cross)\n    v178(branch)\n    v205(concat)\n    v190(cross)\n    v200(cross)\n    v209(branch)\n    v236(concat)\n    v221(cross)\n    v231(cross)\n    v243(cross)\n    v253(cross)\n    v265(cross)\n    v272(cross)\n    v284(cross)\n    v291(cross)\n    v295(Output)\n    subgraph group_neighbors_leiden_umap [neighbors_leiden_umap]\n        v121(find_neighbors)\n        v152(leiden)\n        v183(move_obsm_to_obs)\n        v214(umap)\n    end\n    v147--&gt;v174\n    v178--&gt;v205\n    v209--&gt;v236\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v49\n    v49--&gt;v56\n    v41--&gt;v56\n    v41--&gt;v66\n    v72--&gt;v80\n    v80--&gt;v87\n    v72--&gt;v87\n    v72--&gt;v97\n    v104--&gt;v113\n    v113--&gt;v121\n    v121--&gt;v128\n    v113--&gt;v128\n    v113--&gt;v138\n    v147--&gt;v152\n    v152--&gt;v159\n    v147--&gt;v159\n    v147--&gt;v169\n    v169--&gt;v174\n    v178--&gt;v183\n    v183--&gt;v190\n    v178--&gt;v190\n    v178--&gt;v200\n    v200--&gt;v205\n    v209--&gt;v214\n    v214--&gt;v221\n    v209--&gt;v221\n    v209--&gt;v231\n    v231--&gt;v236\n    v236--&gt;v243\n    v104--&gt;v243\n    v104--&gt;v253\n    v253--&gt;v258\n    v258--&gt;v265\n    v2--&gt;v265\n    v265--&gt;v272\n    v2--&gt;v272\n    v2--&gt;v284\n    v284--&gt;v291\n    v2--&gt;v291\n    v291--&gt;v295\n    v35--&gt;v41\n    v18--&gt;v35\n    v66--&gt;v72\n    v49--&gt;v66\n    v97--&gt;v104\n    v80--&gt;v97\n    v121--&gt;v138\n    v138--&gt;v147\n    v152--&gt;v169\n    v174--&gt;v178\n    v183--&gt;v200\n    v205--&gt;v209\n    v214--&gt;v231\n    v236--&gt;v253\n    v258--&gt;v284\n    style group_neighbors_leiden_umap fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v49 fill:#e3dcea,stroke:#7a4baa;\n    style v56 fill:#e3dcea,stroke:#7a4baa;\n    style v66 fill:#e3dcea,stroke:#7a4baa;\n    style v72 fill:#e3dcea,stroke:#7a4baa;\n    style v80 fill:#e3dcea,stroke:#7a4baa;\n    style v87 fill:#e3dcea,stroke:#7a4baa;\n    style v97 fill:#e3dcea,stroke:#7a4baa;\n    style v104 fill:#e3dcea,stroke:#7a4baa;\n    style v258 fill:#e3dcea,stroke:#7a4baa;\n    style v113 fill:#e3dcea,stroke:#7a4baa;\n    style v121 fill:#e3dcea,stroke:#7a4baa;\n    style v128 fill:#e3dcea,stroke:#7a4baa;\n    style v138 fill:#e3dcea,stroke:#7a4baa;\n    style v147 fill:#e3dcea,stroke:#7a4baa;\n    style v174 fill:#e3dcea,stroke:#7a4baa;\n    style v152 fill:#e3dcea,stroke:#7a4baa;\n    style v159 fill:#e3dcea,stroke:#7a4baa;\n    style v169 fill:#e3dcea,stroke:#7a4baa;\n    style v178 fill:#e3dcea,stroke:#7a4baa;\n    style v205 fill:#e3dcea,stroke:#7a4baa;\n    style v183 fill:#e3dcea,stroke:#7a4baa;\n    style v190 fill:#e3dcea,stroke:#7a4baa;\n    style v200 fill:#e3dcea,stroke:#7a4baa;\n    style v209 fill:#e3dcea,stroke:#7a4baa;\n    style v236 fill:#e3dcea,stroke:#7a4baa;\n    style v214 fill:#e3dcea,stroke:#7a4baa;\n    style v221 fill:#e3dcea,stroke:#7a4baa;\n    style v231 fill:#e3dcea,stroke:#7a4baa;\n    style v243 fill:#e3dcea,stroke:#7a4baa;\n    style v253 fill:#e3dcea,stroke:#7a4baa;\n    style v265 fill:#e3dcea,stroke:#7a4baa;\n    style v272 fill:#e3dcea,stroke:#7a4baa;\n    style v284 fill:#e3dcea,stroke:#7a4baa;\n    style v291 fill:#e3dcea,stroke:#7a4baa;\n    style v295 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "scANVI - scArches workflow"
    ]
  },
  {
    "objectID": "components/workflows/annotation/harmony_knn.html",
    "href": "components/workflows/annotation/harmony_knn.html",
    "title": "Harmony integration followed by KNN label transfer",
    "section": "",
    "text": "ID: harmony_knn\nNamespace: workflows/annotation\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "Harmony integration followed by KNN label transfer"
    ]
  },
  {
    "objectID": "components/workflows/annotation/harmony_knn.html#example-commands",
    "href": "components/workflows/annotation/harmony_knn.html#example-commands",
    "title": "Harmony integration followed by KNN label transfer",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/annotation/harmony_knn/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Query Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\ninput_obs_batch_label: # please fill in - example: \"sample\"\n# input_var_gene_names: \"foo\"\ninput_reference_gene_overlap: 100\noverwrite_existing_key: false\n\n# Reference input\nreference: # please fill in - example: \"reference.h5mu\"\n# reference_layer: \"foo\"\nreference_obs_target: # please fill in - example: \"cell_type\"\n# reference_var_gene_names: \"foo\"\nreference_obs_batch_label: # please fill in - example: \"sample\"\n\n# HVG subset arguments\nn_hvg: 2000\n\n# PCA options\n# pca_num_components: 25\n\n# Harmony integration options\nharmony_theta: [2.0]\n\n# Leiden clustering options\nleiden_resolution: [1.0]\n\n# Neighbor classifier arguments\nknn_weights: \"uniform\"\nknn_n_neighbors: 15\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_obs_predictions: [\"foo\"]\n# output_obs_probability: [\"foo\"]\noutput_obsm_integrated: \"X_integrated_harmony\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/annotation/harmony_knn/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "Harmony integration followed by KNN label transfer"
    ]
  },
  {
    "objectID": "components/workflows/annotation/harmony_knn.html#argument-groups",
    "href": "components/workflows/annotation/harmony_knn.html#argument-groups",
    "title": "Harmony integration followed by KNN label transfer",
    "section": "Argument groups",
    "text": "Argument groups\n\nQuery Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput dataset consisting of the (unlabeled) query observations. The dataset is expected to be pre-processed in the same way as –reference.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process. Should match the modality of the –reference dataset.\nstring, default: \"rna\"\n\n\n--input_layer\nThe layer of the input dataset to process if .X is not to be used. Should contain log normalized counts.\nstring\n\n\n--input_obs_batch_label\nThe .obs field in the input (query) dataset containing the batch labels.\nstring, required, example: \"sample\"\n\n\n--input_var_gene_names\nThe .var field in the input (query) dataset containing gene names; if not provided, the .var index will be used.\nstring\n\n\n--input_reference_gene_overlap\nThe minimum number of genes present in both the reference and query datasets.\ninteger, default: 100\n\n\n--overwrite_existing_key\nIf provided, will overwrite existing fields in the input dataset when data are copied during the reference alignment process.\nboolean_true\n\n\n\n\n\nReference input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nReference dataset consisting of the labeled observations to train the KNN classifier on. The dataset is expected to be pre-processed in the same way as the –input query dataset.\nfile, required, example: \"reference.h5mu\"\n\n\n--reference_layer\nThe layer of the reference dataset to process if .X is not to be used. Should contain log normalized counts.\nstring\n\n\n--reference_obs_target\nThe .obs key of the target cell type labels to transfer.\nstring, required, example: \"cell_type\"\n\n\n--reference_var_gene_names\nThe .var field in the reference dataset containing gene names; if not provided, the .var index will be used.\nstring\n\n\n--reference_obs_batch_label\nThe .obs field in the reference dataset containing the batch labels.\nstring, required, example: \"sample\"\n\n\n\n\n\nHVG subset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_hvg\nNumber of highly variable genes to subset for.\ninteger, default: 2000\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pca_num_components\nNumber of principal components to compute. Defaults to 50, or 1 - minimum dimension size of selected representation.\ninteger, example: 25\n\n\n\n\n\nHarmony integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--harmony_theta\nDiversity clustering penalty parameter. Can be set as a single value for all batch observations or as multiple values, one for each observation in the batches defined by –input_obs_batch_label. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.”\nList of double, default: 2, multiple_sep: \";\"\n\n\n\n\n\nLeiden clustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nNeighbor classifier arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--knn_weights\nWeight function used in prediction. Possible values are: uniform (all points in each neighborhood are weighted equally) or distance (weight points by the inverse of their distance)\nstring, default: \"uniform\"\n\n\n--knn_n_neighbors\nThe number of neighbors to use in k-neighbor graph structure used for fast approximate nearest neighbor search with PyNNDescent. Larger values will result in more accurate search results at the cost of computation time.\ninteger, default: 15\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe query data in .h5mu format with predicted labels predicted from the classifier trained on the reference.\nfile, required, example: \"output.h5mu\"\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted cell labels. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_pred\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_obs_probability\nIn which .obs slots to store the probability of the predictions. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_probability\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_obsm_integrated\nIn which .obsm slot to store the integrated embedding.\nstring, default: \"X_integrated_harmony\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "Harmony integration followed by KNN label transfer"
    ]
  },
  {
    "objectID": "components/workflows/annotation/harmony_knn.html#authors",
    "href": "components/workflows/annotation/harmony_knn.html#authors",
    "title": "Harmony integration followed by KNN label transfer",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (author, maintainer)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "Harmony integration followed by KNN label transfer"
    ]
  },
  {
    "objectID": "components/workflows/annotation/harmony_knn.html#visualisation",
    "href": "components/workflows/annotation/harmony_knn.html#visualisation",
    "title": "Harmony integration followed by KNN label transfer",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(align_query_reference)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v52(filter)\n    v64(cross)\n    v74(cross)\n    v84(concat)\n    v91(cross)\n    v101(cross)\n    v107(flatMap)\n    v111(filter)\n    v119(concatenate_h5mu)\n    v126(cross)\n    v136(cross)\n    v143(filter)\n    v151(highly_variable_features_scanpy)\n    v158(cross)\n    v168(cross)\n    v174(filter)\n    v182(pca)\n    v189(cross)\n    v199(cross)\n    v205(filter)\n    v213(delete_aligned_lognormalized_counts_layer)\n    v220(cross)\n    v230(cross)\n    v236(filter)\n    v244(filter)\n    v259(cross)\n    v269(cross)\n    v275(filter)\n    v429(concat)\n    v284(filter)\n    v299(cross)\n    v309(cross)\n    v318(branch)\n    v345(concat)\n    v330(cross)\n    v340(cross)\n    v349(branch)\n    v376(concat)\n    v361(cross)\n    v371(cross)\n    v380(branch)\n    v407(concat)\n    v392(cross)\n    v402(cross)\n    v414(cross)\n    v424(cross)\n    v436(cross)\n    v446(cross)\n    v453(filter)\n    v464(filter)\n    v476(cross)\n    v486(cross)\n    v496(concat)\n    v503(cross)\n    v513(cross)\n    v522(filter)\n    v530(knn)\n    v537(cross)\n    v547(cross)\n    v555(mix)\n    v558(filter)\n    v588(concat)\n    v566(merge)\n    v573(cross)\n    v583(cross)\n    v595(cross)\n    v602(cross)\n    v614(cross)\n    v621(cross)\n    v625(Output)\n    subgraph group_split_modalities [split_modalities]\n        v57(split_modalities_component)\n    end\n    subgraph group_harmony_leiden_workflow [harmony_leiden_workflow]\n        v252(harmonypy)\n        v292(find_neighbors)\n        v323(leiden)\n        v354(move_obsm_to_obs)\n        v385(umap)\n    end\n    subgraph group_split_h5mu [split_h5mu]\n        v469(split_h5mu_component)\n    end\n    v318--&gt;v345\n    v349--&gt;v376\n    v380--&gt;v407\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v52--&gt;v57\n    v57--&gt;v64\n    v52--&gt;v64\n    v52--&gt;v74\n    v84--&gt;v91\n    v41--&gt;v91\n    v41--&gt;v101\n    v111--&gt;v119\n    v119--&gt;v126\n    v111--&gt;v126\n    v111--&gt;v136\n    v143--&gt;v151\n    v151--&gt;v158\n    v143--&gt;v158\n    v143--&gt;v168\n    v174--&gt;v182\n    v182--&gt;v189\n    v174--&gt;v189\n    v174--&gt;v199\n    v205--&gt;v213\n    v213--&gt;v220\n    v205--&gt;v220\n    v205--&gt;v230\n    v236--&gt;v244\n    v244--&gt;v252\n    v252--&gt;v259\n    v244--&gt;v259\n    v244--&gt;v269\n    v275--&gt;v284\n    v284--&gt;v292\n    v292--&gt;v299\n    v284--&gt;v299\n    v284--&gt;v309\n    v318--&gt;v323\n    v323--&gt;v330\n    v318--&gt;v330\n    v318--&gt;v340\n    v340--&gt;v345\n    v349--&gt;v354\n    v354--&gt;v361\n    v349--&gt;v361\n    v349--&gt;v371\n    v371--&gt;v376\n    v380--&gt;v385\n    v385--&gt;v392\n    v380--&gt;v392\n    v380--&gt;v402\n    v402--&gt;v407\n    v407--&gt;v414\n    v275--&gt;v414\n    v275--&gt;v424\n    v424--&gt;v429\n    v429--&gt;v436\n    v236--&gt;v436\n    v236--&gt;v446\n    v464--&gt;v469\n    v469--&gt;v476\n    v464--&gt;v476\n    v464--&gt;v486\n    v496--&gt;v503\n    v453--&gt;v503\n    v453--&gt;v513\n    v522--&gt;v530\n    v530--&gt;v537\n    v522--&gt;v537\n    v522--&gt;v547\n    v558--&gt;v566\n    v566--&gt;v573\n    v558--&gt;v573\n    v558--&gt;v583\n    v583--&gt;v588\n    v588--&gt;v595\n    v2--&gt;v595\n    v595--&gt;v602\n    v2--&gt;v602\n    v2--&gt;v614\n    v614--&gt;v621\n    v2--&gt;v621\n    v621--&gt;v625\n    v35--&gt;v41\n    v18--&gt;v35\n    v101--&gt;v107\n    v41--&gt;v52\n    v74--&gt;v84\n    v57--&gt;v74\n    v84--&gt;v101\n    v107--&gt;v111\n    v136--&gt;v143\n    v119--&gt;v136\n    v168--&gt;v174\n    v151--&gt;v168\n    v199--&gt;v205\n    v182--&gt;v199\n    v230--&gt;v236\n    v213--&gt;v230\n    v446--&gt;v453\n    v269--&gt;v275\n    v252--&gt;v269\n    v292--&gt;v309\n    v309--&gt;v318\n    v323--&gt;v340\n    v345--&gt;v349\n    v354--&gt;v371\n    v376--&gt;v380\n    v385--&gt;v402\n    v407--&gt;v424\n    v429--&gt;v446\n    v513--&gt;v522\n    v453--&gt;v464\n    v486--&gt;v496\n    v469--&gt;v486\n    v496--&gt;v513\n    v547--&gt;v555\n    v530--&gt;v547\n    v107--&gt;v555\n    v555--&gt;v558\n    v566--&gt;v583\n    v588--&gt;v614\n    style group_split_modalities fill:#F0F0F0,stroke:#969696;\n    style group_harmony_leiden_workflow fill:#F0F0F0,stroke:#969696;\n    style group_split_h5mu fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v52 fill:#e3dcea,stroke:#7a4baa;\n    style v57 fill:#e3dcea,stroke:#7a4baa;\n    style v64 fill:#e3dcea,stroke:#7a4baa;\n    style v74 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v91 fill:#e3dcea,stroke:#7a4baa;\n    style v101 fill:#e3dcea,stroke:#7a4baa;\n    style v107 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v119 fill:#e3dcea,stroke:#7a4baa;\n    style v126 fill:#e3dcea,stroke:#7a4baa;\n    style v136 fill:#e3dcea,stroke:#7a4baa;\n    style v143 fill:#e3dcea,stroke:#7a4baa;\n    style v151 fill:#e3dcea,stroke:#7a4baa;\n    style v158 fill:#e3dcea,stroke:#7a4baa;\n    style v168 fill:#e3dcea,stroke:#7a4baa;\n    style v174 fill:#e3dcea,stroke:#7a4baa;\n    style v182 fill:#e3dcea,stroke:#7a4baa;\n    style v189 fill:#e3dcea,stroke:#7a4baa;\n    style v199 fill:#e3dcea,stroke:#7a4baa;\n    style v205 fill:#e3dcea,stroke:#7a4baa;\n    style v213 fill:#e3dcea,stroke:#7a4baa;\n    style v220 fill:#e3dcea,stroke:#7a4baa;\n    style v230 fill:#e3dcea,stroke:#7a4baa;\n    style v236 fill:#e3dcea,stroke:#7a4baa;\n    style v244 fill:#e3dcea,stroke:#7a4baa;\n    style v252 fill:#e3dcea,stroke:#7a4baa;\n    style v259 fill:#e3dcea,stroke:#7a4baa;\n    style v269 fill:#e3dcea,stroke:#7a4baa;\n    style v275 fill:#e3dcea,stroke:#7a4baa;\n    style v429 fill:#e3dcea,stroke:#7a4baa;\n    style v284 fill:#e3dcea,stroke:#7a4baa;\n    style v292 fill:#e3dcea,stroke:#7a4baa;\n    style v299 fill:#e3dcea,stroke:#7a4baa;\n    style v309 fill:#e3dcea,stroke:#7a4baa;\n    style v318 fill:#e3dcea,stroke:#7a4baa;\n    style v345 fill:#e3dcea,stroke:#7a4baa;\n    style v323 fill:#e3dcea,stroke:#7a4baa;\n    style v330 fill:#e3dcea,stroke:#7a4baa;\n    style v340 fill:#e3dcea,stroke:#7a4baa;\n    style v349 fill:#e3dcea,stroke:#7a4baa;\n    style v376 fill:#e3dcea,stroke:#7a4baa;\n    style v354 fill:#e3dcea,stroke:#7a4baa;\n    style v361 fill:#e3dcea,stroke:#7a4baa;\n    style v371 fill:#e3dcea,stroke:#7a4baa;\n    style v380 fill:#e3dcea,stroke:#7a4baa;\n    style v407 fill:#e3dcea,stroke:#7a4baa;\n    style v385 fill:#e3dcea,stroke:#7a4baa;\n    style v392 fill:#e3dcea,stroke:#7a4baa;\n    style v402 fill:#e3dcea,stroke:#7a4baa;\n    style v414 fill:#e3dcea,stroke:#7a4baa;\n    style v424 fill:#e3dcea,stroke:#7a4baa;\n    style v436 fill:#e3dcea,stroke:#7a4baa;\n    style v446 fill:#e3dcea,stroke:#7a4baa;\n    style v453 fill:#e3dcea,stroke:#7a4baa;\n    style v464 fill:#e3dcea,stroke:#7a4baa;\n    style v469 fill:#e3dcea,stroke:#7a4baa;\n    style v476 fill:#e3dcea,stroke:#7a4baa;\n    style v486 fill:#e3dcea,stroke:#7a4baa;\n    style v496 fill:#e3dcea,stroke:#7a4baa;\n    style v503 fill:#e3dcea,stroke:#7a4baa;\n    style v513 fill:#e3dcea,stroke:#7a4baa;\n    style v522 fill:#e3dcea,stroke:#7a4baa;\n    style v530 fill:#e3dcea,stroke:#7a4baa;\n    style v537 fill:#e3dcea,stroke:#7a4baa;\n    style v547 fill:#e3dcea,stroke:#7a4baa;\n    style v555 fill:#e3dcea,stroke:#7a4baa;\n    style v558 fill:#e3dcea,stroke:#7a4baa;\n    style v588 fill:#e3dcea,stroke:#7a4baa;\n    style v566 fill:#e3dcea,stroke:#7a4baa;\n    style v573 fill:#e3dcea,stroke:#7a4baa;\n    style v583 fill:#e3dcea,stroke:#7a4baa;\n    style v595 fill:#e3dcea,stroke:#7a4baa;\n    style v602 fill:#e3dcea,stroke:#7a4baa;\n    style v614 fill:#e3dcea,stroke:#7a4baa;\n    style v621 fill:#e3dcea,stroke:#7a4baa;\n    style v625 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Annotation",
      "Harmony integration followed by KNN label transfer"
    ]
  },
  {
    "objectID": "components/workflows/integration/bbknn_leiden.html",
    "href": "components/workflows/integration/bbknn_leiden.html",
    "title": "Bbknn leiden",
    "section": "",
    "text": "ID: bbknn_leiden\nNamespace: workflows/integration\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Bbknn leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/bbknn_leiden.html#example-commands",
    "href": "components/workflows/integration/bbknn_leiden.html#example-commands",
    "title": "Bbknn leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/integration/bbknn_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Bbknn\nobsm_input: \"X_pca\"\nobs_batch: \"sample_id\"\nuns_output: \"bbknn_integration_neighbors\"\nobsp_distances: \"bbknn_integration_distances\"\nobsp_connectivities: \"bbknn_integration_connectivities\"\nn_neighbors_within_batch: 3\nn_pcs: 50\n# n_trim: 123\n\n# Clustering options\nobs_cluster: \"bbknn_integration_leiden\"\nleiden_resolution: [1.0]\n\n# UMAP options\nobsm_umap: \"X_leiden_bbknn_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/integration/bbknn_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Bbknn leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/bbknn_leiden.html#argument-groups",
    "href": "components/workflows/integration/bbknn_leiden.html#argument-groups",
    "title": "Bbknn leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nBbknn\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_input\nThe dimensionality reduction in .obsm to use for neighbour detection. Defaults to X_pca.\nstring, default: \"X_pca\"\n\n\n--obs_batch\n.obs column name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--uns_output\nMandatory .uns slot to store various neighbor output objects.\nstring, default: \"bbknn_integration_neighbors\"\n\n\n--obsp_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"bbknn_integration_distances\"\n\n\n--obsp_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"bbknn_integration_connectivities\"\n\n\n--n_neighbors_within_batch\nHow many top neighbours to report for each batch; total number of neighbours in the initial k-nearest-neighbours computation will be this number times the number of batches.\ninteger, default: 3\n\n\n--n_pcs\nHow many dimensions (in case of PCA, principal components) to use in the analysis.\ninteger, default: 50\n\n\n--n_trim\nTrim the neighbours of each cell to these many top connectivities. May help with population independence and improve the tidiness of clustering. The lower the value the more independent the individual populations, at the cost of more conserved batch effect. If None (default), sets the parameter value automatically to 10 times neighbors_within_batch times the number of batches. Set to 0 to skip.\ninteger\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"bbknn_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUMAP options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_bbknn_umap\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Bbknn leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/bbknn_leiden.html#authors",
    "href": "components/workflows/integration/bbknn_leiden.html#authors",
    "title": "Bbknn leiden",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Bbknn leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/bbknn_leiden.html#visualisation",
    "href": "components/workflows/integration/bbknn_leiden.html#visualisation",
    "title": "Bbknn leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v40(concat)\n    v18(bbknn)\n    v25(cross)\n    v35(cross)\n    v42(filter)\n    v50(leiden)\n    v57(cross)\n    v67(cross)\n    v73(filter)\n    v81(move_obsm_to_obs)\n    v88(cross)\n    v98(cross)\n    v105(mix)\n    v106(filter)\n    v136(concat)\n    v114(umap)\n    v121(cross)\n    v131(cross)\n    v143(cross)\n    v150(cross)\n    v162(cross)\n    v169(cross)\n    v173(Output)\n    v105--&gt;v106\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v35--&gt;v40\n    v42--&gt;v50\n    v50--&gt;v57\n    v42--&gt;v57\n    v42--&gt;v67\n    v73--&gt;v81\n    v81--&gt;v88\n    v73--&gt;v88\n    v73--&gt;v98\n    v106--&gt;v114\n    v114--&gt;v121\n    v106--&gt;v121\n    v106--&gt;v131\n    v131--&gt;v136\n    v136--&gt;v143\n    v2--&gt;v143\n    v143--&gt;v150\n    v2--&gt;v150\n    v2--&gt;v162\n    v162--&gt;v169\n    v2--&gt;v169\n    v169--&gt;v173\n    v18--&gt;v35\n    v40--&gt;v42\n    v67--&gt;v73\n    v50--&gt;v67\n    v98--&gt;v105\n    v81--&gt;v98\n    v40--&gt;v105\n    v114--&gt;v131\n    v136--&gt;v162\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v40 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v42 fill:#e3dcea,stroke:#7a4baa;\n    style v50 fill:#e3dcea,stroke:#7a4baa;\n    style v57 fill:#e3dcea,stroke:#7a4baa;\n    style v67 fill:#e3dcea,stroke:#7a4baa;\n    style v73 fill:#e3dcea,stroke:#7a4baa;\n    style v81 fill:#e3dcea,stroke:#7a4baa;\n    style v88 fill:#e3dcea,stroke:#7a4baa;\n    style v98 fill:#e3dcea,stroke:#7a4baa;\n    style v105 fill:#e3dcea,stroke:#7a4baa;\n    style v106 fill:#e3dcea,stroke:#7a4baa;\n    style v136 fill:#e3dcea,stroke:#7a4baa;\n    style v114 fill:#e3dcea,stroke:#7a4baa;\n    style v121 fill:#e3dcea,stroke:#7a4baa;\n    style v131 fill:#e3dcea,stroke:#7a4baa;\n    style v143 fill:#e3dcea,stroke:#7a4baa;\n    style v150 fill:#e3dcea,stroke:#7a4baa;\n    style v162 fill:#e3dcea,stroke:#7a4baa;\n    style v169 fill:#e3dcea,stroke:#7a4baa;\n    style v173 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Bbknn leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scvi_leiden.html",
    "href": "components/workflows/integration/scvi_leiden.html",
    "title": "Scvi leiden",
    "section": "",
    "text": "ID: scvi_leiden\nNamespace: workflows/integration\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scvi leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scvi_leiden.html#example-commands",
    "href": "components/workflows/integration/scvi_leiden.html#example-commands",
    "title": "Scvi leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/integration/scvi_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n# layer: \"foo\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_model: \"$id.$key.output_model\"\n\n# Neighbour calculation\nuns_neighbors: \"scvi_integration_neighbors\"\nobsp_neighbor_distances: \"scvi_integration_distances\"\nobsp_neighbor_connectivities: \"scvi_integration_connectivities\"\n\n# Scvi integration options\nobs_batch: # please fill in - example: \"foo\"\nobsm_output: \"X_scvi_integrated\"\n# var_input: \"foo\"\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30.0\n\n# Clustering options\nobs_cluster: \"scvi_integration_leiden\"\nleiden_resolution: [1.0]\n\n# Umap options\nobsm_umap: \"X_scvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/integration/scvi_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scvi leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scvi_leiden.html#argument-groups",
    "href": "components/workflows/integration/scvi_leiden.html#argument-groups",
    "title": "Scvi leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scvi_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scvi_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scvi_integration_connectivities\"\n\n\n\n\n\nScvi integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n--var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"scvi_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_scvi_umap\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scvi leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scvi_leiden.html#authors",
    "href": "components/workflows/integration/scvi_leiden.html#authors",
    "title": "Scvi leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scvi leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/scvi_leiden.html#visualisation",
    "href": "components/workflows/integration/scvi_leiden.html#visualisation",
    "title": "Scvi leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(scvi)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v195(concat)\n    v50(filter)\n    v65(cross)\n    v75(cross)\n    v84(branch)\n    v111(concat)\n    v96(cross)\n    v106(cross)\n    v115(branch)\n    v142(concat)\n    v127(cross)\n    v137(cross)\n    v146(branch)\n    v173(concat)\n    v158(cross)\n    v168(cross)\n    v180(cross)\n    v190(cross)\n    v202(cross)\n    v209(cross)\n    v221(cross)\n    v228(cross)\n    v232(Output)\n    subgraph group_neighbors_leiden_umap [neighbors_leiden_umap]\n        v58(find_neighbors)\n        v89(leiden)\n        v120(move_obsm_to_obs)\n        v151(umap)\n    end\n    v84--&gt;v111\n    v115--&gt;v142\n    v146--&gt;v173\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v50\n    v50--&gt;v58\n    v58--&gt;v65\n    v50--&gt;v65\n    v50--&gt;v75\n    v84--&gt;v89\n    v89--&gt;v96\n    v84--&gt;v96\n    v84--&gt;v106\n    v106--&gt;v111\n    v115--&gt;v120\n    v120--&gt;v127\n    v115--&gt;v127\n    v115--&gt;v137\n    v137--&gt;v142\n    v146--&gt;v151\n    v151--&gt;v158\n    v146--&gt;v158\n    v146--&gt;v168\n    v168--&gt;v173\n    v173--&gt;v180\n    v41--&gt;v180\n    v41--&gt;v190\n    v190--&gt;v195\n    v195--&gt;v202\n    v2--&gt;v202\n    v202--&gt;v209\n    v2--&gt;v209\n    v2--&gt;v221\n    v221--&gt;v228\n    v2--&gt;v228\n    v228--&gt;v232\n    v35--&gt;v41\n    v18--&gt;v35\n    v58--&gt;v75\n    v75--&gt;v84\n    v89--&gt;v106\n    v111--&gt;v115\n    v120--&gt;v137\n    v142--&gt;v146\n    v151--&gt;v168\n    v173--&gt;v190\n    v195--&gt;v221\n    style group_neighbors_leiden_umap fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v195 fill:#e3dcea,stroke:#7a4baa;\n    style v50 fill:#e3dcea,stroke:#7a4baa;\n    style v58 fill:#e3dcea,stroke:#7a4baa;\n    style v65 fill:#e3dcea,stroke:#7a4baa;\n    style v75 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v89 fill:#e3dcea,stroke:#7a4baa;\n    style v96 fill:#e3dcea,stroke:#7a4baa;\n    style v106 fill:#e3dcea,stroke:#7a4baa;\n    style v115 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v120 fill:#e3dcea,stroke:#7a4baa;\n    style v127 fill:#e3dcea,stroke:#7a4baa;\n    style v137 fill:#e3dcea,stroke:#7a4baa;\n    style v146 fill:#e3dcea,stroke:#7a4baa;\n    style v173 fill:#e3dcea,stroke:#7a4baa;\n    style v151 fill:#e3dcea,stroke:#7a4baa;\n    style v158 fill:#e3dcea,stroke:#7a4baa;\n    style v168 fill:#e3dcea,stroke:#7a4baa;\n    style v180 fill:#e3dcea,stroke:#7a4baa;\n    style v190 fill:#e3dcea,stroke:#7a4baa;\n    style v202 fill:#e3dcea,stroke:#7a4baa;\n    style v209 fill:#e3dcea,stroke:#7a4baa;\n    style v221 fill:#e3dcea,stroke:#7a4baa;\n    style v228 fill:#e3dcea,stroke:#7a4baa;\n    style v232 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Scvi leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/harmony_leiden.html",
    "href": "components/workflows/integration/harmony_leiden.html",
    "title": "Harmony leiden",
    "section": "",
    "text": "ID: harmony_leiden\nNamespace: workflows/integration\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Harmony leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/harmony_leiden.html#example-commands",
    "href": "components/workflows/integration/harmony_leiden.html#example-commands",
    "title": "Harmony leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/integration/harmony_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"harmonypy_integration_neighbors\"\nobsp_neighbor_distances: \"harmonypy_integration_distances\"\nobsp_neighbor_connectivities: \"harmonypy_integration_connectivities\"\n\n# Harmony integration options\nembedding: \"X_pca\"\nobsm_integrated: \"X_pca_integrated\"\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\ntheta: [2.0]\n\n# Clustering options\nobs_cluster: \"harmony_integration_leiden\"\nleiden_resolution: [1.0]\n\n# Umap options\nobsm_umap: \"X_leiden_harmony_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/integration/harmony_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Harmony leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/harmony_leiden.html#argument-groups",
    "href": "components/workflows/integration/harmony_leiden.html#argument-groups",
    "title": "Harmony leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"harmonypy_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_connectivities\"\n\n\n\n\n\nHarmony integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--embedding\nEmbedding to use as input\nstring, default: \"X_pca\"\n\n\n--obsm_integrated\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nList of string, required, example: \"batch\", \"sample\", multiple_sep: \";\"\n\n\n--theta\nDiversity clustering penalty parameter. Can be set as a single value for all batch observations or as multiple values, one for each observation in the batches defined by –obs_covariates. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.”\nList of double, default: 2, multiple_sep: \";\"\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"harmony_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_harmony_umap\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Harmony leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/harmony_leiden.html#authors",
    "href": "components/workflows/integration/harmony_leiden.html#authors",
    "title": "Harmony leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Harmony leiden"
    ]
  },
  {
    "objectID": "components/workflows/integration/harmony_leiden.html#visualisation",
    "href": "components/workflows/integration/harmony_leiden.html#visualisation",
    "title": "Harmony leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(harmonypy)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v195(concat)\n    v50(filter)\n    v65(cross)\n    v75(cross)\n    v84(branch)\n    v111(concat)\n    v96(cross)\n    v106(cross)\n    v115(branch)\n    v142(concat)\n    v127(cross)\n    v137(cross)\n    v146(branch)\n    v173(concat)\n    v158(cross)\n    v168(cross)\n    v180(cross)\n    v190(cross)\n    v202(cross)\n    v209(cross)\n    v221(cross)\n    v228(cross)\n    v232(Output)\n    subgraph group_neighbors_leiden_umap [neighbors_leiden_umap]\n        v58(find_neighbors)\n        v89(leiden)\n        v120(move_obsm_to_obs)\n        v151(umap)\n    end\n    v84--&gt;v111\n    v115--&gt;v142\n    v146--&gt;v173\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v41--&gt;v50\n    v50--&gt;v58\n    v58--&gt;v65\n    v50--&gt;v65\n    v50--&gt;v75\n    v84--&gt;v89\n    v89--&gt;v96\n    v84--&gt;v96\n    v84--&gt;v106\n    v106--&gt;v111\n    v115--&gt;v120\n    v120--&gt;v127\n    v115--&gt;v127\n    v115--&gt;v137\n    v137--&gt;v142\n    v146--&gt;v151\n    v151--&gt;v158\n    v146--&gt;v158\n    v146--&gt;v168\n    v168--&gt;v173\n    v173--&gt;v180\n    v41--&gt;v180\n    v41--&gt;v190\n    v190--&gt;v195\n    v195--&gt;v202\n    v2--&gt;v202\n    v202--&gt;v209\n    v2--&gt;v209\n    v2--&gt;v221\n    v221--&gt;v228\n    v2--&gt;v228\n    v228--&gt;v232\n    v35--&gt;v41\n    v18--&gt;v35\n    v58--&gt;v75\n    v75--&gt;v84\n    v89--&gt;v106\n    v111--&gt;v115\n    v120--&gt;v137\n    v142--&gt;v146\n    v151--&gt;v168\n    v173--&gt;v190\n    v195--&gt;v221\n    style group_neighbors_leiden_umap fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v195 fill:#e3dcea,stroke:#7a4baa;\n    style v50 fill:#e3dcea,stroke:#7a4baa;\n    style v58 fill:#e3dcea,stroke:#7a4baa;\n    style v65 fill:#e3dcea,stroke:#7a4baa;\n    style v75 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v89 fill:#e3dcea,stroke:#7a4baa;\n    style v96 fill:#e3dcea,stroke:#7a4baa;\n    style v106 fill:#e3dcea,stroke:#7a4baa;\n    style v115 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v120 fill:#e3dcea,stroke:#7a4baa;\n    style v127 fill:#e3dcea,stroke:#7a4baa;\n    style v137 fill:#e3dcea,stroke:#7a4baa;\n    style v146 fill:#e3dcea,stroke:#7a4baa;\n    style v173 fill:#e3dcea,stroke:#7a4baa;\n    style v151 fill:#e3dcea,stroke:#7a4baa;\n    style v158 fill:#e3dcea,stroke:#7a4baa;\n    style v168 fill:#e3dcea,stroke:#7a4baa;\n    style v180 fill:#e3dcea,stroke:#7a4baa;\n    style v190 fill:#e3dcea,stroke:#7a4baa;\n    style v202 fill:#e3dcea,stroke:#7a4baa;\n    style v209 fill:#e3dcea,stroke:#7a4baa;\n    style v221 fill:#e3dcea,stroke:#7a4baa;\n    style v228 fill:#e3dcea,stroke:#7a4baa;\n    style v232 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Integration",
      "Harmony leiden"
    ]
  },
  {
    "objectID": "components/workflows/prot/prot_multisample.html",
    "href": "components/workflows/prot/prot_multisample.html",
    "title": "Prot multisample",
    "section": "",
    "text": "ID: prot_multisample\nNamespace: workflows/prot\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Prot",
      "Prot multisample"
    ]
  },
  {
    "objectID": "components/workflows/prot/prot_multisample.html#example-commands",
    "href": "components/workflows/prot/prot_multisample.html#example-commands",
    "title": "Prot multisample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/prot/prot_multisample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"concatenated\"\ninput: # please fill in - example: \"dataset.h5mu\"\n# layer: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc,highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\noutput_obs_num_nonzero_vars: \"num_nonzero_vars\"\noutput_obs_total_counts_vars: \"total_counts\"\noutput_var_num_nonzero_obs: \"num_nonzero_obs\"\noutput_var_total_counts_obs: \"total_counts\"\noutput_var_obs_mean: \"obs_mean\"\noutput_var_pct_dropout: \"pct_dropout\"\n\n# CLR arguments\nclr_axis: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/prot/prot_multisample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Prot",
      "Prot multisample"
    ]
  },
  {
    "objectID": "components/workflows/prot/prot_multisample.html#argument-groups",
    "href": "components/workflows/prot/prot_multisample.html#argument-groups",
    "title": "Prot multisample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the concatenated file\nstring, required, example: \"concatenated\"\n\n\n--input\nPath to the samples.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nInput layer to use. If not specified, .X is used.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes. Defaults to the value from –var_name_mitochondrial_genes.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n--output_obs_num_nonzero_vars\nName of column in .obs describing, for each observation, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each row the number of columns that contain data.\nstring, default: \"num_nonzero_vars\"\n\n\n--output_obs_total_counts_vars\nName of the column for .obs describing, for each observation (row), the sum of the stored values in the columns.\nstring, default: \"total_counts\"\n\n\n--output_var_num_nonzero_obs\nName of column describing, for each feature, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each column the number of rows that contain data.\nstring, default: \"num_nonzero_obs\"\n\n\n--output_var_total_counts_obs\nName of the column in .var describing, for each feature (column), the sum of the stored values in the rows.\nstring, default: \"total_counts\"\n\n\n--output_var_obs_mean\nName of the column in .obs providing the mean of the values in each row.\nstring, default: \"obs_mean\"\n\n\n--output_var_pct_dropout\nName of the column in .obs providing for each feature the percentage of observations the feature does not appear on (i.e. is missing). Same as --output_var_num_nonzero_obs but percentage based.\nstring, default: \"pct_dropout\"\n\n\n\n\n\nCLR arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clr_axis\nAxis across which CLR is performed.\ninteger, default: 0",
    "crumbs": [
      "Reference",
      "Workflows",
      "Prot",
      "Prot multisample"
    ]
  },
  {
    "objectID": "components/workflows/prot/prot_multisample.html#authors",
    "href": "components/workflows/prot/prot_multisample.html#authors",
    "title": "Prot multisample",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Prot",
      "Prot multisample"
    ]
  },
  {
    "objectID": "components/workflows/prot/prot_multisample.html#visualisation",
    "href": "components/workflows/prot/prot_multisample.html#visualisation",
    "title": "Prot multisample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v10(filter)\n    v18(clr)\n    v25(cross)\n    v35(cross)\n    v41(filter)\n    v164(concat)\n    v53(branch)\n    v80(concat)\n    v65(cross)\n    v75(cross)\n    v84(branch)\n    v111(concat)\n    v96(cross)\n    v106(cross)\n    v112(filter)\n    v142(concat)\n    v127(cross)\n    v137(cross)\n    v149(cross)\n    v159(cross)\n    v171(cross)\n    v178(cross)\n    v190(cross)\n    v197(cross)\n    v201(Output)\n    subgraph group_prot_qc [prot_qc]\n        v58(grep_mitochondrial_genes)\n        v89(grep_ribosomal_genes)\n        v120(calculate_qc_metrics)\n    end\n    v53--&gt;v80\n    v84--&gt;v111\n    v111--&gt;v112\n    v0--&gt;v2\n    v2--&gt;v10\n    v10--&gt;v18\n    v18--&gt;v25\n    v10--&gt;v25\n    v10--&gt;v35\n    v53--&gt;v58\n    v58--&gt;v65\n    v53--&gt;v65\n    v53--&gt;v75\n    v75--&gt;v80\n    v84--&gt;v89\n    v89--&gt;v96\n    v84--&gt;v96\n    v84--&gt;v106\n    v106--&gt;v111\n    v112--&gt;v120\n    v120--&gt;v127\n    v112--&gt;v127\n    v112--&gt;v137\n    v137--&gt;v142\n    v142--&gt;v149\n    v41--&gt;v149\n    v41--&gt;v159\n    v159--&gt;v164\n    v164--&gt;v171\n    v2--&gt;v171\n    v171--&gt;v178\n    v2--&gt;v178\n    v2--&gt;v190\n    v190--&gt;v197\n    v2--&gt;v197\n    v197--&gt;v201\n    v35--&gt;v41\n    v18--&gt;v35\n    v41--&gt;v53\n    v58--&gt;v75\n    v80--&gt;v84\n    v89--&gt;v106\n    v120--&gt;v137\n    v142--&gt;v159\n    v164--&gt;v190\n    style group_prot_qc fill:#F0F0F0,stroke:#969696;\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v10 fill:#e3dcea,stroke:#7a4baa;\n    style v18 fill:#e3dcea,stroke:#7a4baa;\n    style v25 fill:#e3dcea,stroke:#7a4baa;\n    style v35 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v164 fill:#e3dcea,stroke:#7a4baa;\n    style v53 fill:#e3dcea,stroke:#7a4baa;\n    style v80 fill:#e3dcea,stroke:#7a4baa;\n    style v58 fill:#e3dcea,stroke:#7a4baa;\n    style v65 fill:#e3dcea,stroke:#7a4baa;\n    style v75 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v111 fill:#e3dcea,stroke:#7a4baa;\n    style v89 fill:#e3dcea,stroke:#7a4baa;\n    style v96 fill:#e3dcea,stroke:#7a4baa;\n    style v106 fill:#e3dcea,stroke:#7a4baa;\n    style v112 fill:#e3dcea,stroke:#7a4baa;\n    style v142 fill:#e3dcea,stroke:#7a4baa;\n    style v120 fill:#e3dcea,stroke:#7a4baa;\n    style v127 fill:#e3dcea,stroke:#7a4baa;\n    style v137 fill:#e3dcea,stroke:#7a4baa;\n    style v149 fill:#e3dcea,stroke:#7a4baa;\n    style v159 fill:#e3dcea,stroke:#7a4baa;\n    style v171 fill:#e3dcea,stroke:#7a4baa;\n    style v178 fill:#e3dcea,stroke:#7a4baa;\n    style v190 fill:#e3dcea,stroke:#7a4baa;\n    style v197 fill:#e3dcea,stroke:#7a4baa;\n    style v201 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Prot",
      "Prot multisample"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html",
    "title": "Cell Ranger post-processing",
    "section": "",
    "text": "ID: cellranger_postprocessing\nNamespace: workflows/ingestion\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger post-processing"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#example-commands",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#example-commands",
    "title": "Cell Ranger post-processing",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/ingestion/cellranger_postprocessing/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output\"\n\n# Correction arguments\nperform_correction: false\ncellbender_epochs: 150\n\n# Filtering arguments\n# min_genes: 100\n# min_counts: 1000\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/ingestion/cellranger_postprocessing/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger post-processing"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#argument-groups",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#argument-groups",
    "title": "Cell Ranger post-processing",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput h5mu file created by running Cell Ranger and converting its output to h5mu.\nfile, required, example: \"input.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe converted h5mu file.\nfile\n\n\n\n\n\nCorrection arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--perform_correction\nWhether or not to run CellBender to perform count correction.\nboolean_true\n\n\n--cellbender_epochs\nNumber of epochs to run CellBender for.\ninteger, default: 150\n\n\n\n\n\nFiltering arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_genes\nMinimum number of counts required for a cell to pass filtering.\ninteger, example: 100\n\n\n--min_counts\nMinimum number of genes expressed required for a cell to pass filtering.\ninteger, example: 1000",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger post-processing"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#authors",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#authors",
    "title": "Cell Ranger post-processing",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger post-processing"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#visualisation",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#visualisation",
    "title": "Cell Ranger post-processing",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v14(branch)\n    v41(concat)\n    v19(cellbender_remove_background)\n    v26(cross)\n    v36(cross)\n    v45(branch)\n    v72(concat)\n    v50(filter_with_counts)\n    v57(cross)\n    v67(cross)\n    v79(cross)\n    v86(cross)\n    v98(cross)\n    v105(cross)\n    v109(Output)\n    v14--&gt;v41\n    v45--&gt;v72\n    v0--&gt;v2\n    v14--&gt;v19\n    v19--&gt;v26\n    v14--&gt;v26\n    v14--&gt;v36\n    v36--&gt;v41\n    v45--&gt;v50\n    v50--&gt;v57\n    v45--&gt;v57\n    v45--&gt;v67\n    v67--&gt;v72\n    v72--&gt;v79\n    v2--&gt;v79\n    v79--&gt;v86\n    v2--&gt;v86\n    v2--&gt;v98\n    v98--&gt;v105\n    v2--&gt;v105\n    v105--&gt;v109\n    v2--&gt;v14\n    v19--&gt;v36\n    v41--&gt;v45\n    v50--&gt;v67\n    v72--&gt;v98\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v14 fill:#e3dcea,stroke:#7a4baa;\n    style v41 fill:#e3dcea,stroke:#7a4baa;\n    style v19 fill:#e3dcea,stroke:#7a4baa;\n    style v26 fill:#e3dcea,stroke:#7a4baa;\n    style v36 fill:#e3dcea,stroke:#7a4baa;\n    style v45 fill:#e3dcea,stroke:#7a4baa;\n    style v72 fill:#e3dcea,stroke:#7a4baa;\n    style v50 fill:#e3dcea,stroke:#7a4baa;\n    style v57 fill:#e3dcea,stroke:#7a4baa;\n    style v67 fill:#e3dcea,stroke:#7a4baa;\n    style v79 fill:#e3dcea,stroke:#7a4baa;\n    style v86 fill:#e3dcea,stroke:#7a4baa;\n    style v98 fill:#e3dcea,stroke:#7a4baa;\n    style v105 fill:#e3dcea,stroke:#7a4baa;\n    style v109 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger post-processing"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html",
    "href": "components/workflows/ingestion/cellranger_multi.html",
    "title": "Cell Ranger multi",
    "section": "",
    "text": "ID: cellranger_multi\nNamespace: workflows/ingestion\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger multi"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#example-commands",
    "href": "components/workflows/ingestion/cellranger_multi.html#example-commands",
    "title": "Cell Ranger multi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/ingestion/cellranger_multi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input files\n# input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n\n# Feature type-specific input files\n# gex_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# abc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# cgc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# mux_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_t_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_t_gd_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_b_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# agc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n\n# Library arguments\n# library_id: [\"mysample1\"]\n# library_type: [\"Gene Expression\"]\n# library_subsample: [\"0.5\"]\n# library_lanes: [\"1-4\"]\n# library_chemistry: \"foo\"\n\n# Sample parameters\n# sample_ids: [\"foo\"]\n# sample_description: [\"foo\"]\n# sample_expect_cells: [3000]\n# sample_force_cells: [3000]\n\n# Feature Barcode library specific arguments\n# feature_reference: \"feature_reference.csv\"\n# feature_r1_length: 123\n# feature_r2_length: 123\n# min_crispr_umi: 123\n\n# Gene expression arguments\ngex_reference: # please fill in - example: \"reference_genome.tar.gz\"\ngex_secondary_analysis: false\ngex_generate_bam: false\n# gex_expect_cells: 3000\n# gex_force_cells: 3000\ngex_include_introns: true\n# gex_r1_length: 123\n# gex_r2_length: 123\ngex_chemistry: \"auto\"\n\n# VDJ related parameters\n# vdj_reference: \"reference_vdj.tar.gz\"\n# vdj_inner_enrichment_primers: \"enrichment_primers.txt\"\n# vdj_r1_length: 123\n# vdj_r2_length: 123\n\n# Cell multiplexing parameters\n# cell_multiplex_oligo_ids: [\"foo\"]\n# min_assignment_confidence: 123.0\n# cmo_set: \"path/to/file\"\n# barcode_sample_assignment: \"path/to/file\"\n\n# Fixed RNA profiling paramaters\n# probe_set: \"path/to/file\"\n# filter_probes: true\n# probe_barcode_ids: [\"foo\"]\n\n# Antigen Capture (BEAM) libary arguments\n# control_id: [\"foo\"]\n# mhc_allele: [\"foo\"]\n\n# General arguments\ncheck_library_compatibility: true\n\n# Outputs\n# output_raw: \"$id.$key.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\nuns_metrics: \"metrics_cellranger\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/ingestion/cellranger_multi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger multi"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#argument-groups",
    "href": "components/workflows/ingestion/cellranger_multi.html#argument-groups",
    "title": "Cell Ranger multi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput files\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe FASTQ files to be analyzed. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n\n\n\nFeature type-specific input files\nHelper functionality to allow feature type-specific input files, without the need to specify library_type or library_id. The library_id will be inferred from the input paths.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_input\nThe FASTQ files to be analyzed for Gene Expression. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--abc_input\nThe FASTQ files to be analyzed for Antibody Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--cgc_input\nThe FASTQ files to be analyzed for CRISPR Guide Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--mux_input\nThe FASTQ files to be analyzed for Multiplexing Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_input\nThe FASTQ files to be analyzed for VDJ. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_t_input\nThe FASTQ files to be analyzed for VDJ-T. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_t_gd_input\nThe FASTQ files to be analyzed for VDJ-T-GD. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_b_input\nThe FASTQ files to be analyzed for VDJ-B. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--agc_input\nThe FASTQ files to be analyzed for Antigen Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n\n\n\nLibrary arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--library_id\nThe Illumina sample name to analyze. This must exactly match the ’Sample Name’part of the FASTQ files specified in the --input argument.\nList of string, example: \"mysample1\", multiple_sep: \";\"\n\n\n--library_type\nThe underlying feature type of the library.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--library_subsample\nThe rate at which reads from the provided FASTQ files are sampled. Must be strictly greater than 0 and less than or equal to 1.\nList of string, example: \"0.5\", multiple_sep: \";\"\n\n\n--library_lanes\nLanes associated with this sample. Defaults to using all lanes.\nList of string, example: \"1-4\", multiple_sep: \";\"\n\n\n--library_chemistry\nOnly applicable to FRP. Library-specific assay configuration. By default, the assay configuration is detected automatically. Typically, users will not need to specify a chemistry.\nstring\n\n\n\n\n\nSample parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sample_ids\nA name to identify a multiplexed sample. Must be alphanumeric with hyphens and/or underscores, and less than 64 characters. Required for Cell Multiplexing libraries.\nList of string, multiple_sep: \";\"\n\n\n--sample_description\nA description for the sample.\nList of string, multiple_sep: \";\"\n\n\n--sample_expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\nList of integer, example: 3000, multiple_sep: \";\"\n\n\n--sample_force_cells\nForce pipeline to use this number of cells, bypassing cell detection.\nList of integer, example: 3000, multiple_sep: \";\"\n\n\n\n\n\nFeature Barcode library specific arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--feature_reference\nPath to the Feature reference CSV file, declaring Feature Barcode constructs and associated barcodes. Required only for Antibody Capture or CRISPR Guide Capture libraries. See https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/feature-bc-analysis#feature-ref for more information.”\nfile, example: \"feature_reference.csv\"\n\n\n--feature_r1_length\nLimit the length of the input Read 1 sequence of V(D)J libraries to the first N bases, where N is the user-supplied value. Note that the length includes the Barcode and UMI sequences so do not set this below 26.\ninteger\n\n\n--feature_r2_length\nLimit the length of the input Read 2 sequence of V(D)J libraries to the first N bases, where N is a user-supplied value. Trimming occurs before sequencing metrics are computed and therefore, limiting the length of Read 2 may affect Q30 scores.\ninteger\n\n\n--min_crispr_umi\nSet the minimum number of CRISPR guide RNA UMIs required for protospacer detection. If a lower or higher sensitivity is desired for detection, this value can be customized according to specific experimental needs. Applicable only to datasets that include a CRISPR Guide Capture library.\ninteger\n\n\n\n\n\nGene expression arguments\nArguments relevant to the analysis of gene expression data.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_reference\nGenome refence index built by Cell Ranger mkref.\nfile, required, example: \"reference_genome.tar.gz\"\n\n\n--gex_secondary_analysis\nWhether or not to run the secondary analysis e.g. clustering.\nboolean, default: FALSE\n\n\n--gex_generate_bam\nWhether to generate a BAM file.\nboolean, default: FALSE\n\n\n--gex_expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--gex_force_cells\nForce pipeline to use this number of cells, bypassing cell detection.\ninteger, example: 3000\n\n\n--gex_include_introns\nWhether or not to include intronic reads in counts. This option does not apply to Fixed RNA Profiling analysis.\nboolean, default: TRUE\n\n\n--gex_r1_length\nLimit the length of the input Read 1 sequence of V(D)J libraries to the first N bases, where N is the user-supplied value. Note that the length includes the Barcode and UMI sequences so do not set this below 26.\ninteger\n\n\n--gex_r2_length\nLimit the length of the input Read 2 sequence of V(D)J libraries to the first N bases, where N is a user-supplied value. Trimming occurs before sequencing metrics are computed and therefore, limiting the length of Read 2 may affect Q30 scores.\ninteger\n\n\n--gex_chemistry\nAssay configuration. Either specify a single value which will be applied to all libraries, or a number of values that is equal to the number of libararies. The latter is only applicable to only applicable to Fixed RNA Profiling. - auto: Chemistry autodetection (default) - threeprime: Single Cell 3’ - SC3Pv1, SC3Pv2, SC3Pv3, SC3Pv4: Single Cell 3’ v1, v2, v3, or v4 - SC3Pv3HT: Single Cell 3’ v3.1 HT - SC-FB: Single Cell Antibody-only 3’ v2 or 5’ - fiveprime: Single Cell 5’ - SC5P-PE: Paired-end Single Cell 5’ - SC5P-R2: R2-only Single Cell 5’ - SC5P-R2-v3: R2-only Single Cell 5’ v3 - SCP5-PE-v3: Single Cell 5’ paired-end v3 (GEM-X) - SC5PHT : Single Cell 5’ v2 HT - SFRP: Fixed RNA Profiling (Singleplex) - MFRP: Fixed RNA Profiling (Multiplex, Probe Barcode on R2) - MFRP-R1: Fixed RNA Profiling (Multiplex, Probe Barcode on R1) - MFRP-RNA: Fixed RNA Profiling (Multiplex, RNA, Probe Barcode on R2) - MFRP-Ab: Fixed RNA Profiling (Multiplex, Antibody, Probe Barcode at R2:69) - MFRP-Ab-R2pos50: Fixed RNA Profiling (Multiplex, Antibody, Probe Barcode at R2:50) - MFRP-RNA-R1: Fixed RNA Profiling (Multiplex, RNA, Probe Barcode on R1) - MFRP-Ab-R1: Fixed RNA Profiling (Multiplex, Antibody, Probe Barcode on R1) - ARC-v1 for analyzing the Gene Expression portion of Multiome data. If Cell Ranger auto-detects ARC-v1 chemistry, an error is triggered. See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n\n\n\nVDJ related parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vdj_reference\nVDJ refence index built by Cell Ranger mkref.\nfile, example: \"reference_vdj.tar.gz\"\n\n\n--vdj_inner_enrichment_primers\nV(D)J Immune Profiling libraries: if inner enrichment primers other than those provided in the 10x Genomics kits are used, they need to be specified here as a text file with one primer per line.\nfile, example: \"enrichment_primers.txt\"\n\n\n--vdj_r1_length\nLimit the length of the input Read 1 sequence of V(D)J libraries to the first N bases, where N is the user-supplied value. Note that the length includes the Barcode and UMI sequences so do not set this below 26.\ninteger\n\n\n--vdj_r2_length\nLimit the length of the input Read 2 sequence of V(D)J libraries to the first N bases, where N is a user-supplied value. Trimming occurs before sequencing metrics are computed and therefore, limiting the length of Read 2 may affect Q30 scores\ninteger\n\n\n\n\n\nCell multiplexing parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_multiplex_oligo_ids\nThe Cell Multiplexing oligo IDs used to multiplex this sample. If multiple CMOs were used for a sample, separate IDs with a pipe (e.g., CMO301|CMO302). Required for Cell Multiplexing libraries.\nList of string, multiple_sep: \";\"\n\n\n--min_assignment_confidence\nThe minimum estimated likelihood to call a sample as tagged with a Cell Multiplexing Oligo (CMO) instead of “Unassigned”. Users may wish to tolerate a higher rate of mis-assignment in order to obtain more singlets to include in their analysis, or a lower rate of mis-assignment at the cost of obtaining fewer singlets.\ndouble\n\n\n--cmo_set\nPath to a custom CMO set CSV file, declaring CMO constructs and associated barcodes. If the default CMO reference IDs that are built into the Cell Ranger software are required, this option does not need to be used.\nfile\n\n\n--barcode_sample_assignment\nPath to a barcode-sample assignment CSV file that specifies the barcodes that belong to each sample.\nfile\n\n\n\n\n\nFixed RNA profiling paramaters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--probe_set\nA probe set reference CSV file. It specifies the sequences used as a reference for probe alignment and the gene ID associated with each probe. It must include 4 columns (probe file format 1.0.0): gene_id,probe_seq,probe_id,included,region and an optional 5th column (probe file format 1.0.1). - gene_id: The Ensembl gene identifier targeted by the probe. - probe_seq: The nucleotide sequence of the probe, which is complementary to the transcript sequence. - probe_id: The probe identifier, whose format is described in Probe identifiers. - included: A TRUE or FALSE flag specifying whether the probe is included in the filtered counts matrix output or excluded by the probe filter. See filter-probes option of cellranger multi. All probes of a gene must be marked TRUE in the included column for that gene to be included. - region: Present only in v1.0.1 probe set reference CSV. The gene boundary targeted by the probe. Accepted values are spliced or unspliced. The file also contains a number of required metadata fields in the header in the format #key=value: - panel_name: The name of the probe set. - panel_type: Always predesigned for predesigned probe sets. - reference_genome: The reference genome build used for probe design. - reference_version: The version of the Cell Ranger reference transcriptome used for probe design. - probe_set_file_format: The version of the probe set file format specification that this file conforms to.\nfile\n\n\n--filter_probes\nIf ‘false’, include all non-deprecated probes listed in the probe set reference CSV file. If ‘true’ or not set, probes that are predicted to have off-target activity to homologous genes are excluded from analysis. Not filtering will result in UMI counts from all non-deprecated probes, including those with predicted off-target activity, to be used in the analysis. Probes whose ID is prefixed with DEPRECATED are always excluded from the analysis.\nboolean\n\n\n--probe_barcode_ids\nThe Fixed RNA Probe Barcode ID used for this sample, and for multiplex GEX + Antibody Capture libraries, the corresponding Antibody Multiplexing Barcode IDs. 10x recommends specifying both barcodes (e.g., BC001+AB001) when an Antibody Capture library is present. The barcode pair order is BC+AB and they are separated with a “+” (no spaces). Alternatively, you can specify the Probe Barcode ID alone and Cell Ranger’s barcode pairing auto-detection algorithm will automatically match to the corresponding Antibody Multiplexing Barcode.\nList of string, multiple_sep: \";\"\n\n\n\n\n\nAntigen Capture (BEAM) libary arguments\nThese arguments are recommended if an Antigen Capture (BEAM) library is present. It is needed to calculate the antigen specificity score.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--control_id\nA user-defined ID for any negative controls used in the T/BCR Antigen Capture assay. Must match id specified in the feature reference CSV. May only include ASCII characters and must not use whitespace, slash, quote, or comma characters. Each ID must be unique and must not collide with a gene identifier from the transcriptome.\nList of string, multiple_sep: \";\"\n\n\n--mhc_allele\nThe MHC allele for TCR Antigen Capture libraries. Must match mhc_allele name specified in the Feature Reference CSV.\nList of string, multiple_sep: \";\"\n\n\n\n\n\nGeneral arguments\nThese arguments are applicable to all library types.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--check_library_compatibility\nOptional. This option allows users to disable the check that evaluates 10x Barcode overlap between ibraries when multiple libraries are specified (e.g., Gene Expression + Antibody Capture). Setting this option to false will disable the check across all library combinations. We recommend running this check (default), however if the pipeline errors out, users can bypass the check to generate outputs for troubleshooting.\nboolean, default: TRUE\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nThe raw output folder.\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nLocations for the output files. Must contain a wildcard (*) character, which will be replaced with the sample name.\nfile, required, example: \"*.h5mu\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_cellranger\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger multi"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#authors",
    "href": "components/workflows/ingestion/cellranger_multi.html#authors",
    "title": "Cell Ranger multi",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger multi"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#visualisation",
    "href": "components/workflows/ingestion/cellranger_multi.html#visualisation",
    "title": "Cell Ranger multi",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v9(filter)\n    v39(concat)\n    v17(cellranger_multi_component)\n    v24(cross)\n    v34(cross)\n    v44(filter)\n    v49(from_cellranger_multi_to_h5mu)\n    v56(cross)\n    v66(cross)\n    v77(flatMap)\n    v83(cross)\n    v90(cross)\n    v102(cross)\n    v109(cross)\n    v113(Output)\n    v0--&gt;v2\n    v2--&gt;v9\n    v9--&gt;v17\n    v17--&gt;v24\n    v9--&gt;v24\n    v9--&gt;v34\n    v34--&gt;v39\n    v44--&gt;v49\n    v49--&gt;v56\n    v44--&gt;v56\n    v44--&gt;v66\n    v77--&gt;v83\n    v2--&gt;v83\n    v83--&gt;v90\n    v2--&gt;v90\n    v2--&gt;v102\n    v102--&gt;v109\n    v2--&gt;v109\n    v109--&gt;v113\n    v17--&gt;v34\n    v39--&gt;v44\n    v49--&gt;v66\n    v66--&gt;v77\n    v77--&gt;v102\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v9 fill:#e3dcea,stroke:#7a4baa;\n    style v39 fill:#e3dcea,stroke:#7a4baa;\n    style v17 fill:#e3dcea,stroke:#7a4baa;\n    style v24 fill:#e3dcea,stroke:#7a4baa;\n    style v34 fill:#e3dcea,stroke:#7a4baa;\n    style v44 fill:#e3dcea,stroke:#7a4baa;\n    style v49 fill:#e3dcea,stroke:#7a4baa;\n    style v56 fill:#e3dcea,stroke:#7a4baa;\n    style v66 fill:#e3dcea,stroke:#7a4baa;\n    style v77 fill:#e3dcea,stroke:#7a4baa;\n    style v83 fill:#e3dcea,stroke:#7a4baa;\n    style v90 fill:#e3dcea,stroke:#7a4baa;\n    style v102 fill:#e3dcea,stroke:#7a4baa;\n    style v109 fill:#e3dcea,stroke:#7a4baa;\n    style v113 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Cell Ranger multi"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html",
    "href": "components/workflows/ingestion/bd_rhapsody.html",
    "title": "BD Rhapsody",
    "section": "",
    "text": "ID: bd_rhapsody\nNamespace: workflows/ingestion\n\n\n\nSource\nThis pipeline performs analysis of single-cell multiomic sequence read (FASTQ) data. The supported sequencing libraries are those generated by the BD Rhapsody assay kits, including: Whole Transcriptome mRNA, Targeted mRNA, AbSeq Antibody-Oligonucleotides, Single-Cell Multiplexing, TCR/BCR, and ATAC-Seq\nThe CWL pipeline file is obtained by cloning ‘https://bitbucket.org/CRSwDev/cwl’ and removing all objects with class ‘DockerRequirement’ from the YAML.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "BD Rhapsody"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#example-commands",
    "href": "components/workflows/ingestion/bd_rhapsody.html#example-commands",
    "title": "BD Rhapsody",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/ingestion/bd_rhapsody/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\n# reads: [\"WTALibrary_S1_L001_R1_001.fastq.gz\", \"WTALibrary_S1_L001_R2_001.fastq.gz\"]\n# reads_atac: [\"ATACLibrary_S2_L001_R1_001.fastq.gz\", \"ATACLibrary_S2_L001_R2_001.fastq.gz\", \"ATACLibrary_S2_L001_I2_001.fastq.gz\"]\n\n# References\n# reference_archive: \"RhapRef_Human_WTA_2023-02.tar.gz\"\n# targeted_reference: [\"BD_Rhapsody_Immune_Response_Panel_Hs.fasta\"]\n# abseq_reference: [\"AbSeq_reference.fasta\"]\n# supplemental_reference: [\"supplemental_reference.fasta\"]\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_raw: \"$id.$key.output_raw\"\n\n# Putative Cell Calling Settings\n# cell_calling_data: \"mRNA\"\n# cell_calling_bioproduct_algorithm: \"Basic\"\n# cell_calling_atac_algorithm: \"Basic\"\n# exact_cell_count: 10000\n# expected_cell_count: 20000\n\n# Intronic Reads Settings\n# exclude_intronic_reads: false\n\n# Multiplex Settings\n# sample_tags_version: \"human\"\n# tag_names: [\"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\"]\n\n# VDJ arguments\n# vdj_version: \"human\"\n\n# ATAC options\n# predefined_atac_peaks: \"predefined_peaks.bed\"\n\n# Additional options\nrun_name: \"sample\"\ngenerate_bam: false\n# long_reads: true\n\n# Advanced options\n# custom_star_params: \"--alignIntronMax 6000 --outFilterScoreMinOverLread 0.1 --limitOutSJcollapsed 2000000\"\n# custom_bwa_mem2_params: \"-k 16 -w 200 -r\"\n\n# CWL-runner arguments\nparallel: true\ntimestamps: false\n\n# Undocumented arguments\n# abseq_umi: 123\n# target_analysis: true\n# vdj_jgene_evalue: 123.0\n# vdj_vgene_evalue: 123.0\n# write_filtered_reads: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/ingestion/bd_rhapsody/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "BD Rhapsody"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#argument-groups",
    "href": "components/workflows/ingestion/bd_rhapsody.html#argument-groups",
    "title": "BD Rhapsody",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reads\nReads (optional) - Path to your FASTQ.GZ formatted read files from libraries that may include: - WTA mRNA - Targeted mRNA - AbSeq - Sample Multiplexing - VDJ You may specify as many R1/R2 read pairs as you want.\nList of file, example: \"WTALibrary_S1_L001_R1_001.fastq.gz\", \"WTALibrary_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reads_atac\nPath to your FASTQ.GZ formatted read files from ATAC-Seq libraries. You may specify as many R1/R2/I2 files as you want.\nList of file, example: \"ATACLibrary_S2_L001_R1_001.fastq.gz\", \"ATACLibrary_S2_L001_R2_001.fastq.gz\", \"ATACLibrary_S2_L001_I2_001.fastq.gz\", multiple_sep: \";\"\n\n\n\n\n\nReferences\nAssay type will be inferred from the provided reference(s). Do not provide both reference_archive and targeted_reference at the same time.\nValid reference input combinations: - reference_archive: WTA only - reference_archive & abseq_reference: WTA + AbSeq - reference_archive & supplemental_reference: WTA + extra transgenes - reference_archive & abseq_reference & supplemental_reference: WTA + AbSeq + extra transgenes - reference_archive: WTA + ATAC or ATAC only - reference_archive & supplemental_reference: WTA + ATAC + extra transgenes - targeted_reference: Targeted only - targeted_reference & abseq_reference: Targeted + AbSeq - abseq_reference: AbSeq only\nThe reference_archive can be generated with the reference/build_bdrhap_reference component. Alternatively, BD also provides standard references which can be downloaded from these locations:\n\nHuman: https://bd-rhapsody-public.s3.amazonaws.com/Rhapsody-WTA/Pipeline-version2.x_WTA_references/RhapRef_Human_WTA_2023-02.tar.gz\nMouse: https://bd-rhapsody-public.s3.amazonaws.com/Rhapsody-WTA/Pipeline-version2.x_WTA_references/RhapRef_Mouse_WTA_2023-02.tar.gz\n\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference_archive\nPath to Rhapsody WTA Reference in the tar.gz format. Structure of the reference archive: - BD_Rhapsody_Reference_Files/: top level folder - star_index/: sub-folder containing STAR index, that is files created with STAR --runMode genomeGenerate - GTF for gene-transcript-annotation e.g. “gencode.v43.primary_assembly.annotation.gtf”\nfile, example: \"RhapRef_Human_WTA_2023-02.tar.gz\"\n\n\n--targeted_reference\nPath to the targeted reference file in FASTA format.\nList of file, example: \"BD_Rhapsody_Immune_Response_Panel_Hs.fasta\", multiple_sep: \";\"\n\n\n--abseq_reference\nPath to the AbSeq reference file in FASTA format. Only needed if BD AbSeq Ab-Oligos are used.\nList of file, example: \"AbSeq_reference.fasta\", multiple_sep: \";\"\n\n\n--supplemental_reference\nPath to the supplemental reference file in FASTA format. Only needed if there are additional transgene sequences to be aligned against in a WTA assay experiment.\nList of file, example: \"supplemental_reference.fasta\", multiple_sep: \";\"\n\n\n\n\n\nOutputs\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe processed output file in h5mu format.\nfile, required, example: \"output.h5mu\"\n\n\n--output_raw\nThe unprocessed output directory containing all the outputs from the pipeline.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nPutative Cell Calling Settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_calling_data\nSpecify the dataset to be used for putative cell calling: mRNA, AbSeq, ATAC, mRNA_and_ATAC For putative cell calling using an AbSeq dataset, please provide an AbSeq_Reference fasta file above. For putative cell calling using an ATAC dataset, please provide a WTA+ATAC-Seq Reference_Archive file above. The default data for putative cell calling, will be determined the following way: - If mRNA Reads and ATAC Reads exist: mRNA_and_ATAC - If only ATAC Reads exist: ATAC - Otherwise: mRNA\nstring, example: \"mRNA\"\n\n\n--cell_calling_bioproduct_algorithm\nSpecify the bioproduct algorithm to be used for putative cell calling: Basic or Refined By default, the Basic algorithm will be used for putative cell calling.\nstring, example: \"Basic\"\n\n\n--cell_calling_atac_algorithm\nSpecify the ATAC-seq algorithm to be used for putative cell calling: Basic or Refined By default, the Basic algorithm will be used for putative cell calling.\nstring, example: \"Basic\"\n\n\n--exact_cell_count\nSet a specific number of cells as putative, based on those with the highest error-corrected read count\ninteger, example: 10000\n\n\n--expected_cell_count\nGuide the basic putative cell calling algorithm by providing an estimate of the number of cells expected. Usually this can be the number of cells loaded into the Rhapsody cartridge. If there are multiple inflection points on the second derivative cumulative curve, this will ensure the one selected is near the expected.\ninteger, example: 20000\n\n\n\n\n\nIntronic Reads Settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--exclude_intronic_reads\nBy default, the flag is false, and reads aligned to exons and introns are considered and represented in molecule counts. When the flag is set to true, intronic reads will be excluded. The value can be true or false.\nboolean, example: FALSE\n\n\n\n\n\nMultiplex Settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sample_tags_version\nSpecify the version of the Sample Tags used in the run: * If Sample Tag Multiplexing was done, specify the appropriate version: human, mouse, flex, nuclei_includes_mrna, nuclei_atac_only * If this is an SMK + Nuclei mRNA run or an SMK + Multiomic ATAC-Seq (WTA+ATAC-Seq) run (and not an SMK + ATAC-Seq only run), choose the “nuclei_includes_mrna” option. * If this is an SMK + ATAC-Seq only run (and not SMK + Multiomic ATAC-Seq (WTA+ATAC-Seq)), choose the “nuclei_atac_only” option.\nstring, example: \"human\"\n\n\n--tag_names\nSpecify the tag number followed by ‘-’ and the desired sample name to appear in Sample_Tag_Metrics.csv Do not use the special characters.\nList of string, example: \"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\", multiple_sep: \";\"\n\n\n\n\n\nVDJ arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vdj_version\nIf VDJ was done, specify the appropriate option: human, mouse, humanBCR, humanTCR, mouseBCR, mouseTCR\nstring, example: \"human\"\n\n\n\n\n\nATAC options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--predefined_atac_peaks\nAn optional BED file containing pre-established chromatin accessibility peak regions for generating the ATAC cell-by-peak matrix.\nfile, example: \"predefined_peaks.bed\"\n\n\n\n\n\nAdditional options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--run_name\nSpecify a run name to use as the output file base name. Use only letters, numbers, or hyphens. Do not use special characters or spaces.\nstring, default: \"sample\"\n\n\n--generate_bam\nSpecify whether to create the BAM file output\nboolean, default: FALSE\n\n\n--long_reads\nUse STARlong (default: undefined - i.e. autodetects based on read lengths) - Specify if the STARlong aligner should be used instead of STAR. Set to true if the reads are longer than 650bp.\nboolean\n\n\n\n\n\nAdvanced options\nNOTE: Only change these if you are really sure about what you are doing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--custom_star_params\nModify STAR alignment parameters - Set this parameter to fully override default STAR mapping parameters used in the pipeline. For reference this is the default that is used: Short Reads: --outFilterScoreMinOverLread 0 --outFilterMatchNminOverLread 0 --outFilterMultimapScoreRange 0 --clip3pAdapterSeq AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA --seedSearchStartLmax 50 --outFilterMatchNmin 25 --limitOutSJcollapsed 2000000 Long Reads: Same as Short Reads + --seedPerReadNmax 10000 This applies to fastqs provided in the Reads user input Do NOT set any non-mapping related params like --genomeDir, --outSAMtype, --outSAMunmapped, --readFilesIn, --runThreadN, etc. We use STAR version 2.7.10b\nstring, example: \"--alignIntronMax 6000 --outFilterScoreMinOverLread 0.1 --limitOutSJcollapsed 2000000\"\n\n\n--custom_bwa_mem2_params\nModify bwa-mem2 alignment parameters - Set this parameter to fully override bwa-mem2 mapping parameters used in the pipeline The pipeline does not specify any custom mapping params to bwa-mem2 so program default values are used This applies to fastqs provided in the Reads_ATAC user input Do NOT set any non-mapping related params like -C, -t, etc. We use bwa-mem2 version 2.2.1\nstring, example: \"-k 16 -w 200 -r\"\n\n\n\n\n\nCWL-runner arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--parallel\nRun jobs in parallel.\nboolean, default: TRUE\n\n\n--timestamps\nAdd timestamps to the errors, warnings, and notifications.\nboolean_true\n\n\n\n\n\nUndocumented arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--abseq_umi\n\ninteger\n\n\n--target_analysis\n\nboolean\n\n\n--vdj_jgene_evalue\ne-value threshold for J gene. The e-value threshold for J gene call by IgBlast/PyIR, default is set as 0.001\ndouble\n\n\n--vdj_vgene_evalue\ne-value threshold for V gene. The e-value threshold for V gene call by IgBlast/PyIR, default is set as 0.001\ndouble\n\n\n--write_filtered_reads\n\nboolean",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "BD Rhapsody"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#authors",
    "href": "components/workflows/ingestion/bd_rhapsody.html#authors",
    "title": "BD Rhapsody",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)\nDorien Roosen   (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "BD Rhapsody"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#visualisation",
    "href": "components/workflows/ingestion/bd_rhapsody.html#visualisation",
    "title": "BD Rhapsody",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v9(filter)\n    v17(bd_rhapsody_component)\n    v24(cross)\n    v34(cross)\n    v40(filter)\n    v70(concat)\n    v48(from_bdrhap_to_h5mu)\n    v55(cross)\n    v65(cross)\n    v77(cross)\n    v84(cross)\n    v96(cross)\n    v103(cross)\n    v107(Output)\n    v0--&gt;v2\n    v2--&gt;v9\n    v9--&gt;v17\n    v17--&gt;v24\n    v9--&gt;v24\n    v9--&gt;v34\n    v40--&gt;v48\n    v48--&gt;v55\n    v40--&gt;v55\n    v40--&gt;v65\n    v65--&gt;v70\n    v70--&gt;v77\n    v2--&gt;v77\n    v77--&gt;v84\n    v2--&gt;v84\n    v2--&gt;v96\n    v96--&gt;v103\n    v2--&gt;v103\n    v103--&gt;v107\n    v34--&gt;v40\n    v17--&gt;v34\n    v48--&gt;v65\n    v70--&gt;v96\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v9 fill:#e3dcea,stroke:#7a4baa;\n    style v17 fill:#e3dcea,stroke:#7a4baa;\n    style v24 fill:#e3dcea,stroke:#7a4baa;\n    style v34 fill:#e3dcea,stroke:#7a4baa;\n    style v40 fill:#e3dcea,stroke:#7a4baa;\n    style v70 fill:#e3dcea,stroke:#7a4baa;\n    style v48 fill:#e3dcea,stroke:#7a4baa;\n    style v55 fill:#e3dcea,stroke:#7a4baa;\n    style v65 fill:#e3dcea,stroke:#7a4baa;\n    style v77 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v96 fill:#e3dcea,stroke:#7a4baa;\n    style v103 fill:#e3dcea,stroke:#7a4baa;\n    style v107 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "BD Rhapsody"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html",
    "href": "components/workflows/ingestion/conversion.html",
    "title": "Convert to MuData",
    "section": "",
    "text": "ID: conversion\nNamespace: workflows/ingestion\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Convert to MuData"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#example-commands",
    "href": "components/workflows/ingestion/conversion.html#example-commands",
    "title": "Convert to MuData",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/workflows/ingestion/conversion/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\ninput_type: # please fill in - example: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Conversion from h5ad\n# modality: [\"foo\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/workflows/ingestion/conversion/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Convert to MuData"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#argument-groups",
    "href": "components/workflows/ingestion/conversion.html#argument-groups",
    "title": "Convert to MuData",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n--input_type\nType of the input file\nstring, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nName or template for the output files.\nfile, example: \"output.h5mu\"\n\n\n\n\n\nConversion from h5ad\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--modality\nName of the modality where the h5ad is stored in the h5mu object.\nList of string, multiple_sep: \";\"",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Convert to MuData"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#authors",
    "href": "components/workflows/ingestion/conversion.html#authors",
    "title": "Convert to MuData",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)\nDries De Maeyer   (author)",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Convert to MuData"
    ]
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#visualisation",
    "href": "components/workflows/ingestion/conversion.html#visualisation",
    "title": "Convert to MuData",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\n\nflowchart TB\n    v0(Channel.fromList)\n    v2(filter)\n    v12(filter)\n    v20(from_10xh5_to_h5mu)\n    v27(cross)\n    v37(cross)\n    v117(mix)\n    v48(filter)\n    v56(from_h5ad_to_h5mu)\n    v63(cross)\n    v73(cross)\n    v84(filter)\n    v92(from_10xmtx_to_h5mu)\n    v99(cross)\n    v109(cross)\n    v124(cross)\n    v131(cross)\n    v143(cross)\n    v150(cross)\n    v154(Output)\n    v0--&gt;v2\n    v12--&gt;v20\n    v20--&gt;v27\n    v12--&gt;v27\n    v12--&gt;v37\n    v48--&gt;v56\n    v56--&gt;v63\n    v48--&gt;v63\n    v48--&gt;v73\n    v84--&gt;v92\n    v92--&gt;v99\n    v84--&gt;v99\n    v84--&gt;v109\n    v117--&gt;v124\n    v2--&gt;v124\n    v124--&gt;v131\n    v2--&gt;v131\n    v2--&gt;v143\n    v143--&gt;v150\n    v2--&gt;v150\n    v150--&gt;v154\n    v2--&gt;v12\n    v37--&gt;v117\n    v20--&gt;v37\n    v2--&gt;v48\n    v73--&gt;v117\n    v56--&gt;v73\n    v2--&gt;v84\n    v109--&gt;v117\n    v92--&gt;v109\n    v117--&gt;v143\n    style v0 fill:#e3dcea,stroke:#7a4baa;\n    style v2 fill:#e3dcea,stroke:#7a4baa;\n    style v12 fill:#e3dcea,stroke:#7a4baa;\n    style v20 fill:#e3dcea,stroke:#7a4baa;\n    style v27 fill:#e3dcea,stroke:#7a4baa;\n    style v37 fill:#e3dcea,stroke:#7a4baa;\n    style v117 fill:#e3dcea,stroke:#7a4baa;\n    style v48 fill:#e3dcea,stroke:#7a4baa;\n    style v56 fill:#e3dcea,stroke:#7a4baa;\n    style v63 fill:#e3dcea,stroke:#7a4baa;\n    style v73 fill:#e3dcea,stroke:#7a4baa;\n    style v84 fill:#e3dcea,stroke:#7a4baa;\n    style v92 fill:#e3dcea,stroke:#7a4baa;\n    style v99 fill:#e3dcea,stroke:#7a4baa;\n    style v109 fill:#e3dcea,stroke:#7a4baa;\n    style v124 fill:#e3dcea,stroke:#7a4baa;\n    style v131 fill:#e3dcea,stroke:#7a4baa;\n    style v143 fill:#e3dcea,stroke:#7a4baa;\n    style v150 fill:#e3dcea,stroke:#7a4baa;\n    style v154 fill:#e3dcea,stroke:#7a4baa;",
    "crumbs": [
      "Reference",
      "Workflows",
      "Ingestion",
      "Convert to MuData"
    ]
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html",
    "href": "components/modules/query/cellxgene_census.html",
    "title": "Cellxgene census",
    "section": "",
    "text": "ID: cellxgene_census\nNamespace: query\n\n\n\nSource\nAside from fetching the cells’ RNA counts (.X), cell metadata (.obs) and gene metadata (.var), this component also fetches the dataset metadata and joins it into the cell metadata",
    "crumbs": [
      "Reference",
      "Modules",
      "Query",
      "Cellxgene census"
    ]
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html#example-commands",
    "href": "components/modules/query/cellxgene_census.html#example-commands",
    "title": "Cellxgene census",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/query/cellxgene_census/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input database\n# input_uri: \"s3://bucket/path\"\n# census_version: \"stable\"\nadd_dataset_metadata: false\n\n# Cell query\nspecies: # please fill in - example: \"homo_sapiens\"\nobs_value_filter: # please fill in - example: \"is_primary_data == True and cell_type_ontology_term_id in ['CL:0000136', 'CL:1000311', 'CL:0002616'] and suspension_type == 'cell'\"\n\n# Filter cells by grouping\n# cell_filter_grouping: [\"dataset_id\", \"tissue\", \"assay\", \"disease\", \"cell_type\"]\n# cell_filter_minimum_count: 100\n\n# Count filtering\ncell_filter_min_genes: 50\ncell_filter_min_counts: 0\ngene_filter_min_cells: 5\ngene_filter_min_counts: 0\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_modality: \"rna\"\n# output_layer_counts: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/query/cellxgene_census/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Query",
      "Cellxgene census"
    ]
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html#argument-groups",
    "href": "components/modules/query/cellxgene_census.html#argument-groups",
    "title": "Cellxgene census",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput database\nOpen CellxGene Census by version or URI.\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_uri\nIf specified, a URI containing the Census SOMA objects. If specified, will take precedence over the --census_version argument.\nstring, example: \"s3://bucket/path\"\n\n\n--census_version\nWhich release of CellxGene census to use. Possible values are “latest”, “stable”, or the date of one of the releases (e.g. “2023-07-25”). For more information, check the documentation on Census data releases.\nstring, example: \"stable\"\n\n\n--add_dataset_metadata\nIf true, the experiment metadata will be added to the cell metadata. More specifically: collection_id, collection_name, collection_doi, dataset_title.\nboolean_true\n\n\n\n\n\nCell query\nArguments related to the query.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--species\nThe organism to query, usually one of Homo sapiens or Mus musculus.\nstring, required, example: \"homo_sapiens\"\n\n\n--obs_value_filter\nFilter for selecting the obs metadata (i.e. cells). Value is a filter query written in the SOMA value_filter syntax.\nstring, required, example: \"is_primary_data == True and cell_type_ontology_term_id in ['CL:0000136', 'CL:1000311', 'CL:0002616'] and suspension_type == 'cell'\"\n\n\n\n\n\nFilter cells by grouping\nFilter groups with fewer than X number of cells.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_filter_grouping\nA subset of ‘obs’ columns by which to group the cells for filtering. Only groups surpassing or equal to the --cell_filter_minimum_count threshold will be retained. Take care not to introduce a selection bias against cells with more fine-grained ontology annotations.\nList of string, example: \"dataset_id\", \"tissue\", \"assay\", \"disease\", \"cell_type\", multiple_sep: \";\"\n\n\n--cell_filter_minimum_count\nA minimum number of cells per group to retain. If --cell_filter_grouping is defined, this parameter should also be provided and vice versa.\ninteger, example: 100\n\n\n\n\n\nCount filtering\nArguments related to filtering cells and genes by counts.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_filter_min_genes\nRemove cells with less than this number of genes.\ninteger, default: 50\n\n\n--cell_filter_min_counts\nRemove cells with less than this number of counts.\ninteger, default: 0\n\n\n--gene_filter_min_cells\nRemove genes expressed in less than this number of cells.\ninteger, default: 5\n\n\n--gene_filter_min_counts\nRemove genes with less than this number of counts.\ninteger, default: 0\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--output_modality\nWhich modality to store the output in.\nstring, default: \"rna\"\n\n\n--output_layer_counts\nWhich layer to store the raw counts in. If not provided, the .X layer will be used.\nstring",
    "crumbs": [
      "Reference",
      "Modules",
      "Query",
      "Cellxgene census"
    ]
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html#authors",
    "href": "components/modules/query/cellxgene_census.html#authors",
    "title": "Cellxgene census",
    "section": "Authors",
    "text": "Authors\n\nMatthias Beyens    (maintainer, author)\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author)\nKai Waldrant    (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Query",
      "Cellxgene census"
    ]
  },
  {
    "objectID": "components/modules/integrate/scanorama.html",
    "href": "components/modules/integrate/scanorama.html",
    "title": "Scanorama",
    "section": "",
    "text": "ID: scanorama\nNamespace: integrate\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scanorama"
    ]
  },
  {
    "objectID": "components/modules/integrate/scanorama.html#example-commands",
    "href": "components/modules/integrate/scanorama.html#example-commands",
    "title": "Scanorama",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/integrate/scanorama/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\n# output: \"output.h5ad\"\n# output_compression: \"gzip\"\nobs_batch: \"batch\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_scanorama\"\nknn: 20\nbatch_size: 5000\nsigma: 15.0\napprox: true\nalpha: 0.1\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/scanorama/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scanorama"
    ]
  },
  {
    "objectID": "components/modules/integrate/scanorama.html#argument-group",
    "href": "components/modules/integrate/scanorama.html#argument-group",
    "title": "Scanorama",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--output\nOutput .h5mu file\nfile, required, default: \"output.h5ad\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"batch\"\n\n\n--obsm_input\nBasis obsm slot to run scanorama on.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nThe name of the field in adata.obsm where the integrated embeddings will be stored after running this function. Defaults to X_scanorama.\nstring, default: \"X_scanorama\"\n\n\n--knn\nNumber of nearest neighbors to use for matching.\ninteger, default: 20\n\n\n--batch_size\nThe batch size used in the alignment vector computation. Useful when integrating very large (&gt;100k samples) datasets. Set to large value that runs within available memory.\ninteger, default: 5000\n\n\n--sigma\nCorrection smoothing parameter on Gaussian kernel.\ndouble, default: 15\n\n\n--approx\nUse approximate nearest neighbors with Python annoy; greatly speeds up matching runtime.\nboolean, default: TRUE\n\n\n--alpha\nAlignment score minimum cutoff\ndouble, default: 0.1",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scanorama"
    ]
  },
  {
    "objectID": "components/modules/integrate/scanorama.html#authors",
    "href": "components/modules/integrate/scanorama.html#authors",
    "title": "Scanorama",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Scanorama"
    ]
  },
  {
    "objectID": "components/modules/integrate/totalvi.html",
    "href": "components/modules/integrate/totalvi.html",
    "title": "Totalvi",
    "section": "",
    "text": "ID: totalvi\nNamespace: integrate\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Totalvi"
    ]
  },
  {
    "objectID": "components/modules/integrate/totalvi.html#example-commands",
    "href": "components/modules/integrate/totalvi.html#example-commands",
    "title": "Totalvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/integrate/totalvi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\nreference: # please fill in - example: \"path/to/file\"\nforce_retrain: false\nquery_modality: \"rna\"\n# query_proteins_modality: \"foo\"\nreference_modality: \"rna\"\nreference_proteins_modality: \"prot\"\n# input_layer: \"foo\"\nobs_batch: \"sample_id\"\n# var_input: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output\"\nobsm_output: \"X_integrated_totalvi\"\nobsm_normalized_rna_output: \"X_totalvi_normalized_rna\"\nobsm_normalized_protein_output: \"X_totalvi_normalized_protein\"\n# reference_model_path: \"totalvi_model_reference\"\n# query_model_path: \"totalvi_model_query\"\n\n# Learning parameters\nmax_epochs: 400\nmax_query_epochs: 200\nweight_decay: 0.0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/totalvi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Totalvi"
    ]
  },
  {
    "objectID": "components/modules/integrate/totalvi.html#argument-groups",
    "href": "components/modules/integrate/totalvi.html#argument-groups",
    "title": "Totalvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file with query data to integrate with reference.\nfile, required\n\n\n--reference\nInput h5mu file with reference data to train the TOTALVI model.\nfile, required\n\n\n--force_retrain\nIf true, retrain the model and save it to reference_model_path\nboolean_true\n\n\n--query_modality\n\nstring, default: \"rna\"\n\n\n--query_proteins_modality\nName of the modality in the input (query) h5mu file containing protein data\nstring\n\n\n--reference_modality\n\nstring, default: \"rna\"\n\n\n--reference_proteins_modality\nName of the modality containing proteins in the reference\nstring, default: \"prot\"\n\n\n--input_layer\nInput layer to use. If None, X is used\nstring\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_integrated_totalvi\"\n\n\n--obsm_normalized_rna_output\nIn which .obsm slot to store the normalized RNA from TOTALVI.\nstring, default: \"X_totalvi_normalized_rna\"\n\n\n--obsm_normalized_protein_output\nIn which .obsm slot to store the normalized protein data from TOTALVI.\nstring, default: \"X_totalvi_normalized_protein\"\n\n\n--reference_model_path\nDirectory with the reference model. If not exists, trained model will be saved there\nfile, default: \"totalvi_model_reference\"\n\n\n--query_model_path\nDirectory, where the query model will be saved\nfile, default: \"totalvi_model_query\"\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_epochs\nNumber of passes through the dataset\ninteger, default: 400\n\n\n--max_query_epochs\nNumber of passes through the dataset, when fine-tuning model for query\ninteger, default: 200\n\n\n--weight_decay\nWeight decay, when fine-tuning model for query\ndouble, default: 0",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Totalvi"
    ]
  },
  {
    "objectID": "components/modules/integrate/totalvi.html#authors",
    "href": "components/modules/integrate/totalvi.html#authors",
    "title": "Totalvi",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov",
    "crumbs": [
      "Reference",
      "Modules",
      "Integrate",
      "Totalvi"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/score_genes_cell_cycle_scanpy.html",
    "href": "components/modules/feature_annotation/score_genes_cell_cycle_scanpy.html",
    "title": "Score genes cell cycle scanpy",
    "section": "",
    "text": "ID: score_genes_cell_cycle_scanpy\nNamespace: feature_annotation\n\n\n\nSource\nThe score is the average expression of a set of genes subtracted with the average expression of a reference set of genes",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Score genes cell cycle scanpy"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/score_genes_cell_cycle_scanpy.html#example-commands",
    "href": "components/modules/feature_annotation/score_genes_cell_cycle_scanpy.html#example-commands",
    "title": "Score genes cell cycle scanpy",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/feature_annotation/score_genes_cell_cycle_scanpy/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input_file.h5mu\"\nmodality: \"rna\"\n# input_layer: \"log_normalized\"\n# var_gene_names: \"gene_names\"\n\n# Gene list inputs\n# s_genes: [\"gene1\", \"gene2\", \"gene3\"]\n# s_genes_file: \"s_gene_list.txt\"\n# g2m_genes: [\"gene1\", \"gene2\", \"gene3\"]\n# g2m_genes_file: \"g2m_gene_list.txt\"\n# gene_pool: [\"gene1\", \"gene2\", \"gene3\"]\n# gene_pool_file: \"gene_pool.txt\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_phase: \"phase\"\nobs_s_score: \"S_score\"\nobs_g2m_score: \"G2M_score\"\n\n# Arguments\nn_bins: 25\nrandom_state: 0\nallow_missing_genes: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/feature_annotation/score_genes_cell_cycle_scanpy/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Score genes cell cycle scanpy"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/score_genes_cell_cycle_scanpy.html#argument-groups",
    "href": "components/modules/feature_annotation/score_genes_cell_cycle_scanpy.html#argument-groups",
    "title": "Score genes cell cycle scanpy",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input_file.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nThe layer of the adata object containing normalized expression values. If not provided, the X attribute of the adata object will be used.\nstring, example: \"log_normalized\"\n\n\n--var_gene_names\nThe name of the column in the var attribute of the adata object that contains the gene names (symbols). If not provided, the index of the var attribute will be used.\nstring, example: \"gene_names\"\n\n\n\n\n\nGene list inputs\nThe gene list inputs can be provided as a list of gene symbols or as a file containing a list of gene symbols. The gene list file should be formatted as a single column with gene symbols.\nMake sure that the gene list inputs are consistent with the gene names in the adata object as provided by the –var_gene_names argument.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--s_genes\nList of gene symbols for scoring s phase genes.\nList of string, example: \"gene1\", \"gene2\", \"gene3\", multiple_sep: \";\"\n\n\n--s_genes_file\nPath to a .txt file containing the gene list of s phase genes to be scored. The gene list file should be formatted as a single column with gene symbols.\nfile, example: \"s_gene_list.txt\"\n\n\n--g2m_genes\nList of gene symbols for scoring g2m phase genes.\nList of string, example: \"gene1\", \"gene2\", \"gene3\", multiple_sep: \";\"\n\n\n--g2m_genes_file\nPath to a .txt file containing the gene list of g2m phase genes to be scored. The gene list file should be formatted as a single column with gene symbols.\nfile, example: \"g2m_gene_list.txt\"\n\n\n--gene_pool\nList of gene symbols for sampling the reference set. Default is all genes.\nList of string, example: \"gene1\", \"gene2\", \"gene3\", multiple_sep: \";\"\n\n\n--gene_pool_file\nFile with genes for sampling the reference set. Default is all genes. The gene pool file should be formatted as a single column with gene symbols.\nfile, example: \"gene_pool.txt\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file\nfile, required, example: \"output_file.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_phase\nThe name of the column in the obs attribute of the adata object that will store the cell cycle phase annotation.\nstring, default: \"phase\"\n\n\n--obs_s_score\nThe name of the column in the obs attribute of the adata object that will store the s phase score.\nstring, default: \"S_score\"\n\n\n--obs_g2m_score\nThe name of the column in the obs attribute of the adata object that will store the g2m phase score.\nstring, default: \"G2M_score\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_bins\nNumber of expression level bins for sampling.\ninteger, default: 25\n\n\n--random_state\nThe random seed for sampling.\ninteger, default: 0\n\n\n--allow_missing_genes\nIf true, missing genes in the gene list will be ignored.\nboolean, default: FALSE",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Score genes cell cycle scanpy"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/score_genes_cell_cycle_scanpy.html#authors",
    "href": "components/modules/feature_annotation/score_genes_cell_cycle_scanpy.html#authors",
    "title": "Score genes cell cycle scanpy",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author)\nDorien Roosen   (author)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Score genes cell cycle scanpy"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/align_query_reference.html",
    "href": "components/modules/feature_annotation/align_query_reference.html",
    "title": "Align query reference",
    "section": "",
    "text": "ID: align_query_reference\nNamespace: feature_annotation\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Align query reference"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/align_query_reference.html#example-commands",
    "href": "components/modules/feature_annotation/align_query_reference.html#example-commands",
    "title": "Align query reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/feature_annotation/align_query_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# input_layer_lognormalized: \"foo\"\n# input_var_gene_names: \"foo\"\ninput_obs_batch: # please fill in - example: \"sample_id\"\n# input_obs_label: \"cell_type\"\ninput_id: \"query\"\n\n# Reference\n# reference: \"reference.h5mu\"\n# reference_layer: \"foo\"\n# reference_layer_lognormalized: \"foo\"\n# reference_var_gene_names: \"foo\"\nreference_obs_batch: # please fill in - example: \"sample_id\"\n# reference_obs_label: \"cell_type\"\nreference_id: \"reference\"\n\n# Outputs\n# output_query: \"$id.$key.output_query.h5mu\"\n# output_reference: \"$id.$key.output_reference.h5mu\"\n# output_compression: \"gzip\"\noutput_layer: \"_counts\"\noutput_layer_lognormalized: \"_log_normalized\"\noutput_var_gene_names: \"_gene_names\"\noutput_obs_batch: \"_sample_id\"\noutput_obs_label: \"_cell_type\"\noutput_obs_id: \"_dataset\"\noutput_var_index: \"_ori_var_index\"\noutput_var_common_genes: \"_common_vars\"\n\n# Arguments\ninput_reference_gene_overlap: 100\nalign_layers_raw_counts: true\nalign_layers_lognormalized_counts: false\nunkown_celltype_label: \"Unknown\"\noverwrite_existing_key: false\npreserve_var_index: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/feature_annotation/align_query_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Align query reference"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/align_query_reference.html#argument-groups",
    "href": "components/modules/feature_annotation/align_query_reference.html#argument-groups",
    "title": "Align query reference",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe input (query) data to be labeled. Should be a .h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process. Note that the query and reference modalities should be the same.\nstring, default: \"rna\"\n\n\n--input_layer\nThe layer in the input (query) data containing raw counts if .X is not to be used.\nstring\n\n\n--input_layer_lognormalized\nThe layer in the input (query) data containing log normalized counts if .X is not to be used.\nstring\n\n\n--input_var_gene_names\nThe name of the .var column in the input (query) data containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--input_obs_batch\nThe name of the .obs column in the input (query) data containing batch information.\nstring, required, example: \"sample_id\"\n\n\n--input_obs_label\nThe name of the .obs column in the input (query) data containing cell type labels. If not provided, the –unkown_celltype_label will be assigned to all observations.\nstring, example: \"cell_type\"\n\n\n--input_id\nMeta id value to be assigned to the –output_obs_id .obs field of the aligned input (query) data.\nstring, default: \"query\"\n\n\n\n\n\nReference\nArguments related to the reference dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train the CellTypist classifiers on. Only required if a pre-trained –model is not provided.\nfile, example: \"reference.h5mu\"\n\n\n--reference_layer\nThe layer in the reference data containing raw counts if .X is not to be used. Data are expected to be processed in the same way as the –input query dataset.\nstring\n\n\n--reference_layer_lognormalized\nThe layer in the reference data containing log normalized counts if .X is not to be used. Data are expected to be processed in the same way as the –input query dataset.\nstring\n\n\n--reference_var_gene_names\nThe name of the .var column in the reference data containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--reference_obs_batch\nThe name of the .obs column in the reference data containing batch information.\nstring, required, example: \"sample_id\"\n\n\n--reference_obs_label\nThe name of the .obs column in the reference data containing cell type labels. If not provided, the –unkown_celltype_label will be assigned to all observations.\nstring, example: \"cell_type\"\n\n\n--reference_id\nMeta id value to be assigned to the –output_obs_id .obs field of the aligned reference data.\nstring, default: \"reference\"\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_query\nAligned query data.\nfile, example: \"output_query.h5mu\"\n\n\n--output_reference\nAligned reference data.\nfile, example: \"output_reference.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--output_layer\nName of the aligned layer containing raw counts in the output query and reference datasets.\nstring, default: \"_counts\"\n\n\n--output_layer_lognormalized\nName of the aligned layer containing log normalized counts in the output query and reference datasets.\nstring, default: \"_log_normalized\"\n\n\n--output_var_gene_names\nName of the .var column in the output query and reference datasets containing the gene names.\nstring, default: \"_gene_names\"\n\n\n--output_obs_batch\nName of the .obs column in the output query and reference datasets containing the batch information.\nstring, default: \"_sample_id\"\n\n\n--output_obs_label\nName of the .obs column in the output query and reference datasets containing the cell type labels.\nstring, default: \"_cell_type\"\n\n\n--output_obs_id\nName of the .obs column in the output query and reference datasets containing the dataset id.\nstring, default: \"_dataset\"\n\n\n--output_var_index\nName of the .var column to which the .var index of the –input and –reference datasets is stored. Only relevant if “–preserve_var_index” is False.\nstring, default: \"_ori_var_index\"\n\n\n--output_var_common_genes\nName of the .var column in the output query and reference datasets containing the boolean array indicating the common variables.\nstring, default: \"_common_vars\"\n\n\n\n\n\nArguments\nArguments related to the alignment of the input and reference datasets.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_reference_gene_overlap\nThe minimum number of genes present in both the reference and query datasets.\ninteger, default: 100\n\n\n--align_layers_raw_counts\nWhether to align the query and reference layers containing raw counts.\nboolean, default: TRUE\n\n\n--align_layers_lognormalized_counts\nWhether to align the query and reference layers containing log normalized counts.\nboolean_true\n\n\n--unkown_celltype_label\nThe label to assign to cells with an unknown cell type.\nstring, default: \"Unknown\"\n\n\n--overwrite_existing_key\nIf set to true and the layer, obs or var key already exists in the query/reference file, the key will be overwritten.\nboolean_true\n\n\n--preserve_var_index\nIf set to true, the .var index of the –input and –reference datasets will be preserved. If set to false (default behavior), the original .var index will be stored in the –output_var_index .var column and the .var index will be replaced with the sanitized & aligned gene names.\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Align query reference"
    ]
  },
  {
    "objectID": "components/modules/feature_annotation/align_query_reference.html#authors",
    "href": "components/modules/feature_annotation/align_query_reference.html#authors",
    "title": "Align query reference",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Feature Annotation",
      "Align query reference"
    ]
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html",
    "href": "components/modules/filter/filter_with_scrublet.html",
    "title": "Filter with scrublet",
    "section": "",
    "text": "ID: filter_with_scrublet\nNamespace: filter\n\n\n\nSource\nThe method tests for potential doublets by using the expression profiles of cells to generate synthetic potential doubles which are tested against cells. The method returns a “doublet score” on which it calls for potential doublets.\nFor the source code please visit https://github.com/AllonKleinLab/scrublet.\nFor 10x we expect the doublet rates to be: Multiplet Rate (%) - # of Cells Loaded - # of Cells Recovered ~0.4% ~800 ~500 ~0.8% ~1,600 ~1,000 ~1.6% ~3,200 ~2,000 ~2.3% ~4,800 ~3,000 ~3.1% ~6,400 ~4,000 ~3.9% ~8,000 ~5,000 ~4.6% ~9,600 ~6,000 ~5.4% ~11,200 ~7,000 ~6.1% ~12,800 ~8,000 ~6.9% ~14,400 ~9,000 ~7.6% ~16,000 ~10,000",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Filter with scrublet"
    ]
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html#example-commands",
    "href": "components/modules/filter/filter_with_scrublet.html#example-commands",
    "title": "Filter with scrublet",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/filter/filter_with_scrublet/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_name_filter: \"filter_with_scrublet\"\ndo_subset: false\nobs_name_doublet_score: \"scrublet_doublet_score\"\n# expected_doublet_rate: 123.0\n# stdev_doublet_rate: 123.0\n# n_neighbors: 123\n# sim_doublet_ratio: 123.0\nmin_counts: 2\nmin_cells: 3\nmin_gene_variablity_percent: 85.0\nnum_pca_components: 30\ndistance_metric: \"euclidean\"\nallow_automatic_threshold_detection_fail: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/filter_with_scrublet/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Filter with scrublet"
    ]
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html#argument-group",
    "href": "components/modules/filter/filter_with_scrublet.html#argument-group",
    "title": "Filter with scrublet",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nInput layer to use as data for calculating doublets. .X is used not specified.\nstring\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_name_filter\nIn which .obs slot to store a boolean array corresponding to which observations should be filtered out.\nstring, default: \"filter_with_scrublet\"\n\n\n--do_subset\nWhether to subset before storing the output.\nboolean_true\n\n\n--obs_name_doublet_score\nName of the doublet scores column in the obs slot of the returned object.\nstring, default: \"scrublet_doublet_score\"\n\n\n--expected_doublet_rate\nThe estimated fraction of doublets as from the experimental setup.\ndouble\n\n\n--stdev_doublet_rate\nUncertainty in the expected doublet rate.\ndouble\n\n\n--n_neighbors\nNumber of neighbors used to construct the KNN classifier of observed transcriptomes and simulated doublets.\ninteger\n\n\n--sim_doublet_ratio\nNumber of doublets to simulate relative to the number of observed transcriptomes.\ndouble\n\n\n--min_counts\nThe number of minimal UMI counts per cell that have to be present for initial cell detection.\ninteger, default: 2\n\n\n--min_cells\nThe number of cells in which UMIs for a gene were detected.\ninteger, default: 3\n\n\n--min_gene_variablity_percent\nUsed for gene filtering prior to PCA. Keep the most highly variable genes (in the top min_gene_variability_pctl percentile), as measured by the v-statistic [Klein et al., Cell 2015].\ndouble, default: 85\n\n\n--num_pca_components\nNumber of principal components to use during PCA dimensionality reduction.\ninteger, default: 30\n\n\n--distance_metric\nThe distance metric used for computing similarities.\nstring, default: \"euclidean\"\n\n\n--allow_automatic_threshold_detection_fail\nWhen scrublet fails to automatically determine the double score threshold, allow the component to continue and set the output columns to NA.\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Filter with scrublet"
    ]
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html#authors",
    "href": "components/modules/filter/filter_with_scrublet.html#authors",
    "title": "Filter with scrublet",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (contributor)\nRobrecht Cannoodt    (maintainer, contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Filter with scrublet"
    ]
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html",
    "href": "components/modules/filter/filter_with_counts.html",
    "title": "Filter with counts",
    "section": "",
    "text": "ID: filter_with_counts\nNamespace: filter\n\n\n\nSource\nThis is based on both the UMI counts, the gene counts and the mitochondrial genes (genes starting with mt/MT)",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Filter with counts"
    ]
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html#example-commands",
    "href": "components/modules/filter/filter_with_counts.html#example-commands",
    "title": "Filter with counts",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/filter/filter_with_counts/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\ndo_subset: false\nobs_name_filter: \"filter_with_counts\"\nvar_name_filter: \"filter_with_counts\"\n\n# Arguments\n# min_counts: 200\n# max_counts: 5000000\n# min_genes_per_cell: 200\n# max_genes_per_cell: 1500000\n# min_cells_per_gene: 3\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/filter_with_counts/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Filter with counts"
    ]
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html#argument-groups",
    "href": "components/modules/filter/filter_with_counts.html#argument-groups",
    "title": "Filter with counts",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\n\nstring, example: \"raw_counts\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--do_subset\nWhether to subset before storing the output.\nboolean_true\n\n\n--obs_name_filter\nIn which .obs slot to store a boolean array corresponding to which observations should be removed.\nstring, default: \"filter_with_counts\"\n\n\n--var_name_filter\nIn which .var slot to store a boolean array corresponding to which variables should be removed.\nstring, default: \"filter_with_counts\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Filter with counts"
    ]
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html#authors",
    "href": "components/modules/filter/filter_with_counts.html#authors",
    "title": "Filter with counts",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (maintainer, author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Filter with counts"
    ]
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html",
    "href": "components/modules/filter/delimit_fraction.html",
    "title": "Delimit fraction",
    "section": "",
    "text": "ID: delimit_fraction\nNamespace: filter\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Delimit fraction"
    ]
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html#example-commands",
    "href": "components/modules/filter/delimit_fraction.html#example-commands",
    "title": "Delimit fraction",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/filter/delimit_fraction/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\nobs_fraction_column: # please fill in - example: \"fraction_mitochondrial\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_name_filter: # please fill in - example: \"foo\"\n\n# Arguments\nmin_fraction: 0.0\nmax_fraction: 1.0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/delimit_fraction/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Delimit fraction"
    ]
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html#argument-groups",
    "href": "components/modules/filter/delimit_fraction.html#argument-groups",
    "title": "Delimit fraction",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\n\nstring, example: \"raw_counts\"\n\n\n--obs_fraction_column\nName of column from .var dataframe selecting a column that contains floating point values between 0 and 1.\nstring, required, example: \"fraction_mitochondrial\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_name_filter\nIn which .obs slot to store a boolean array corresponding to which observations should be removed.\nstring, required\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_fraction\nMin fraction for an observation to be retained (True in output).\ndouble, default: 0\n\n\n--max_fraction\nMax fraction for an observation to be retained (True in output).\ndouble, default: 1",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Delimit fraction"
    ]
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html#authors",
    "href": "components/modules/filter/delimit_fraction.html#authors",
    "title": "Delimit fraction",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Delimit fraction"
    ]
  },
  {
    "objectID": "components/modules/filter/do_filter.html",
    "href": "components/modules/filter/do_filter.html",
    "title": "Do filter",
    "section": "",
    "text": "ID: do_filter\nNamespace: filter\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Do filter"
    ]
  },
  {
    "objectID": "components/modules/filter/do_filter.html#example-commands",
    "href": "components/modules/filter/do_filter.html#example-commands",
    "title": "Do filter",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/filter/do_filter/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# obs_filter: [\"filter_with_x\"]\n# var_filter: [\"filter_with_x\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/do_filter/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Do filter"
    ]
  },
  {
    "objectID": "components/modules/filter/do_filter.html#argument-group",
    "href": "components/modules/filter/do_filter.html#argument-group",
    "title": "Do filter",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obs_filter\nWhich .obs columns to use to filter the observations by.\nList of string, example: \"filter_with_x\", multiple_sep: \";\"\n\n\n--var_filter\nWhich .var columns to use to filter the observations by.\nList of string, example: \"filter_with_x\", multiple_sep: \";\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Do filter"
    ]
  },
  {
    "objectID": "components/modules/filter/do_filter.html#authors",
    "href": "components/modules/filter/do_filter.html#authors",
    "title": "Do filter",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer, contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Filter",
      "Do filter"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/vireo.html",
    "href": "components/modules/genetic_demux/vireo.html",
    "title": "Vireo",
    "section": "",
    "text": "ID: vireo\nNamespace: genetic_demux\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Vireo"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/vireo.html#example-commands",
    "href": "components/modules/genetic_demux/vireo.html#example-commands",
    "title": "Vireo",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/genetic_demux/vireo/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# cell_data: \"path/to/file\"\nn_donor: 2\n# vartrix_data: \"path/to/file\"\n# donor_file: \"path/to/file\"\ngeno_tag: \"PL\"\nno_doublet: false\nn_init: 50\nextra_donor: 0\n# extra_donorMode: \"foo\"\nforce_learn_gt: false\nase_mode: false\nno_plot: false\n# rand_seed: 123\n# cell_range: \"foo\"\ncall_ambient_rnas: false\n\n# Output\n# output: \"$id.$key.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/vireo/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Vireo"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/vireo.html#argument-groups",
    "href": "components/modules/genetic_demux/vireo.html#argument-groups",
    "title": "Vireo",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_data\nThe cell genotype file in VCF format or cellSNP folder with sparse matrices.\nfile\n\n\n--n_donor\nNumber of donors to demultiplex; can be larger than provided in donor_file.\ninteger, default: 2\n\n\n--vartrix_data\nThe cell genotype files in vartrix outputs.\nfile\n\n\n--donor_file\nThe donor genotype file in VCF format. Please filter the sample and region with bcftools first!\nfile\n\n\n--geno_tag\nThe tag for donor genotype.\nstring, default: \"PL\"\n\n\n--no_doublet\nIf use, not checking doublets.\nboolean, default: FALSE\n\n\n--n_init\nNumber of random initializations, when GT needs to learn.\ninteger, default: 50\n\n\n--extra_donor\nNumber of extra donor in pre-cluster, when GT needs to learn.\ninteger, default: 0\n\n\n--extra_donorMode\nMethod for searching from extra donors. size: n_cell per donor; distance: GT distance between donors\nstring\n\n\n--force_learn_gt\nIf use, treat donor GT as prior only.\nboolean, default: FALSE\n\n\n--ase_mode\nIf use, turn on SNP specific allelic ratio.\nboolean, default: FALSE\n\n\n--no_plot\nIf use, turn off plotting GT distance.\nboolean, default: FALSE\n\n\n--rand_seed\nSeed for random initialization\ninteger\n\n\n--cell_range\nRange of cells to process.\nstring\n\n\n--call_ambient_rnas\nIf use, detect ambient RNAs in each cell.\nboolean, default: FALSE\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"vireo\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Vireo"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/vireo.html#authors",
    "href": "components/modules/genetic_demux/vireo.html#authors",
    "title": "Vireo",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Vireo"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/dsc_pileup.html",
    "href": "components/modules/genetic_demux/dsc_pileup.html",
    "title": "Dsc pileup",
    "section": "",
    "text": "ID: dsc_pileup\nNamespace: genetic_demux\n\n\n\nSource\nBy using pileup files, it would allow us to run demuxlet/freemuxlet pretty fast multiple times without going over the BAM file again",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Dsc pileup"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/dsc_pileup.html#example-commands",
    "href": "components/modules/genetic_demux/dsc_pileup.html#example-commands",
    "title": "Dsc pileup",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/genetic_demux/dsc_pileup/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# sam: \"path/to/file\"\ntag_group: \"CB\"\ntag_umi: \"UB\"\nexclude_flag: 1796\n# vcf: \"path/to/file\"\n# sm: \"foo\"\n# sm_list: \"foo\"\nsam_verbose: 1000000\nvcf_verbose: 1000\nskip_umi: false\ncap_bq: 40\nmin_bq: 13\nmin_mq: 20\nmin_td: 0\nexcl_flag: 3844\n# group_list: \"foo\"\nmin_total: 0\nmin_uniq: 0\nmin_snp: 0\n\n# Output\n# output: \"$id.$key.output\"\n# out: \"demuxlet_dsc\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/dsc_pileup/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Dsc pileup"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/dsc_pileup.html#argument-groups",
    "href": "components/modules/genetic_demux/dsc_pileup.html#argument-groups",
    "title": "Dsc pileup",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sam\nInput SAM/BAM/CRAM file. Must be sorted by coordinates and indexed.\nfile\n\n\n--tag_group\nTag representing readgroup or cell barcodes, in the case to partition the BAM file into multiple groups. For 10x genomics, use CB.\nstring, default: \"CB\"\n\n\n--tag_umi\nTag representing UMIs. For 10x genomiucs, use UB.\nstring, default: \"UB\"\n\n\n--exclude_flag\nSAM/BAM FLAGs to be excluded.\ninteger, default: 1796\n\n\n--vcf\nInput VCF/BCF file for dsc-pileup, containing the AC and AN field.\nfile\n\n\n--sm\nList of sample IDs to compare to (default: use all).\nstring\n\n\n--sm_list\nFile containing the list of sample IDs to compare.\nstring\n\n\n--sam_verbose\nVerbose message frequency for SAM/BAM/CRAM.\ninteger, default: 1000000\n\n\n--vcf_verbose\nVerbose message frequency for VCF/BCF.\ninteger, default: 1000\n\n\n--skip_umi\nDo not generate [prefix].umi.gz file, which stores the regions covered by each barcode/UMI pair.\nboolean_true\n\n\n--cap_bq\nMaximum base quality (higher BQ will be capped).\ninteger, default: 40\n\n\n--min_bq\nMinimum base quality to consider (lower BQ will be skipped).\ninteger, default: 13\n\n\n--min_mq\nMinimum mapping quality to consider (lower MQ will be ignored).\ninteger, default: 20\n\n\n--min_td\nMinimum distance to the tail (lower will be ignored).\ninteger, default: 0\n\n\n--excl_flag\nSAM/BAM FLAGs to be excluded for SNP overlapping Read filtering Options.\ninteger, default: 3844\n\n\n--group_list\nList of tag readgroup/cell barcode to consider in this run. All other barcodes will be ignored. This is useful for parallelized run.\nstring\n\n\n--min_total\nMinimum number of total reads for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_uniq\nMinimum number of unique reads (determined by UMI/SNP pair) for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_snp\nMinimum number of SNPs with coverage for a droplet/cell to be considered.\ninteger, default: 0\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"demux\"\n\n\n--out\ndsc-pileup output file prefix\nstring, example: \"demuxlet_dsc\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Dsc pileup"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/dsc_pileup.html#authors",
    "href": "components/modules/genetic_demux/dsc_pileup.html#authors",
    "title": "Dsc pileup",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Dsc pileup"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/cellsnp.html",
    "href": "components/modules/genetic_demux/cellsnp.html",
    "title": "Cellsnp",
    "section": "",
    "text": "ID: cellsnp\nNamespace: genetic_demux\n\n\n\nSource\nIt can be directly used for donor deconvolution in multiplexed single-cell RNA-seq data, particularly with vireo.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Cellsnp"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/cellsnp.html#example-commands",
    "href": "components/modules/genetic_demux/cellsnp.html#example-commands",
    "title": "Cellsnp",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/genetic_demux/cellsnp/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# sam_file: \"path/to/file\"\n# sam_index_file: \"path/to/file\"\n# sam_fileList: \"path/to/file\"\n# regions_vcf: \"path/to/file\"\n# targets_vcf: \"path/to/file\"\n# barcode_file: \"path/to/file\"\n# sample_list: \"path/to/file\"\n# sample_ids: \"foo\"\ngenotype: false\ngzip: false\nprint_skip_snps: false\n# chrom: \"foo\"\ncell_tag: \"CB\"\numi_tag: \"Auto\"\nmin_count: 20\nmin_maf: 0.0\ndoublet_gl: false\n# incl_flag: \"foo\"\n# excl_flag: \"foo\"\ncount_orphan: false\nmin_mapq: 20\nmin_len: 30\n\n# Output\n# output: \"$id.$key.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/cellsnp/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Cellsnp"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/cellsnp.html#argument-groups",
    "href": "components/modules/genetic_demux/cellsnp.html#argument-groups",
    "title": "Cellsnp",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sam_file\nIndexed sam/bam file(s), comma separated multiple samples. Mode 1a & 2a: one sam/bam file with single cell. Mode 1b & 2b: one or multiple bulk sam/bam files, no barcodes needed, but sample ids and regionsVCF.\nfile\n\n\n--sam_index_file\nInput SAM/BAM Index file, problem with samFileList.\nfile\n\n\n--sam_fileList\nA list file containing bam files, each per line, for Mode 1b & 2b.\nfile\n\n\n--regions_vcf\nA vcf file listing all candidate SNPs, for fetch each variants. If None, pileup the genome. Needed for bulk samples.\nfile\n\n\n--targets_vcf\nSimilar as –regions_vcf, but the next position is accessed by streaming rather than indexing/jumping (like -T in samtools/bcftools mpileup).\nfile\n\n\n--barcode_file\nA plain file listing all effective cell barcode.\nfile\n\n\n--sample_list\nA list file containing sample IDs, each per line.\nfile\n\n\n--sample_ids\nComma separated sample ids.\nstring\n\n\n--genotype\nIf use, do genotyping in addition to counting.\nboolean_true\n\n\n--gzip\nIf use, the output files will be zipped into BGZF format.\nboolean_true\n\n\n--print_skip_snps\nIf use, the SNPs skipped when loading VCF will be printed.\nboolean_true\n\n\n--chrom\nThe chromosomes to use in integer format 1-22, comma separated\nstring\n\n\n--cell_tag\nTag for cell barcodes, turn off with None.\nstring, default: \"CB\"\n\n\n--umi_tag\nTag for UMI: UR, Auto, None. For Auto mode, use UR if barcodes is inputted, otherwise use None. None mode means no UMI but read counts.\nstring, default: \"Auto\"\n\n\n--min_count\nMinimum aggragated count.\ninteger, default: 20\n\n\n--min_maf\nMinimum minor allele frequency.\ndouble, default: 0\n\n\n--doublet_gl\nIf use, keep doublet GT likelihood, i.e., GT=0.5 and GT=1.5.\nboolean_true\n\n\n--incl_flag\nRequired flags: skip reads with all mask bits unset.\nstring\n\n\n--excl_flag\nFilter flags: skip reads with any mask bits set [UNMAP,SECONDARY,QCFAIL (when use UMI) or UNMAP,SECONDARY,QCFAIL,DUP (otherwise)]\nstring\n\n\n--count_orphan\nIf use, do not skip anomalous read pairs.\nboolean_true\n\n\n--min_mapq\nMinimum MAPQ for read filtering.\ninteger, default: 20\n\n\n--min_len\nMinimum mapped length for read filtering.\ninteger, default: 30\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory for VCF and sparse matrices.\nfile, example: \"cellsnp_out\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Cellsnp"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/cellsnp.html#authors",
    "href": "components/modules/genetic_demux/cellsnp.html#authors",
    "title": "Cellsnp",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Cellsnp"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/scsplit.html",
    "href": "components/modules/genetic_demux/scsplit.html",
    "title": "Scsplit",
    "section": "",
    "text": "ID: scsplit\nNamespace: genetic_demux\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Scsplit"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/scsplit.html#example-commands",
    "href": "components/modules/genetic_demux/scsplit.html#example-commands",
    "title": "Scsplit",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/genetic_demux/scsplit/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# vcf: \"path/to/file\"\n# bam: \"path/to/file\"\n# bar: \"path/to/file\"\ntag: \"CB\"\n# com: \"path/to/file\"\n# num: 123\nsub: 10\nems: 30\n# dbl: 123.0\n# vcf_known: \"path/to/file\"\ngeno: false\n\n# Output\n# output: \"$id.$key.output\"\n# ref: \"foo\"\n# alt: \"foo\"\n# psc: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/scsplit/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Scsplit"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/scsplit.html#argument-groups",
    "href": "components/modules/genetic_demux/scsplit.html#argument-groups",
    "title": "Scsplit",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vcf\nVCF from mixed BAM\nfile\n\n\n--bam\nmixed sample BAM\nfile\n\n\n--bar\nbarcodes whitelist\nfile\n\n\n--tag\ntag for barcode\nstring, default: \"CB\"\n\n\n--com\ncommon SNVs\nfile\n\n\n--num\nexpected number of mixed samples\ninteger\n\n\n--sub\nmaximum number of subpopulations in autodetect mode\ninteger, default: 10\n\n\n--ems\nnumber of EM repeats to avoid local maximum\ninteger, default: 30\n\n\n--dbl\ncorrection for doublets. There will be no refinement on the results if this optional parameter is not specified or specified percentage is less than doublet rates detected during the run.\ndouble\n\n\n--vcf_known\nknown individual genotypes to limit distinguishing variants to available variants, so that users do not need to redo genotyping on selected variants, otherwise any variants could be selected as distinguishing variants.\nfile\n\n\n--geno\ngenerate sample genotypes based on the split result.\nboolean_true\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"scSplit_out\"\n\n\n--ref\noutput Ref count matrix\nstring\n\n\n--alt\noutput Alt count matrix\nstring\n\n\n--psc\ngenerated P(S|C)\nstring",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Scsplit"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/scsplit.html#authors",
    "href": "components/modules/genetic_demux/scsplit.html#authors",
    "title": "Scsplit",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Scsplit"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/bcftools.html",
    "href": "components/modules/genetic_demux/bcftools.html",
    "title": "Bcftools",
    "section": "",
    "text": "ID: bcftools\nNamespace: genetic_demux\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Bcftools"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/bcftools.html#example-commands",
    "href": "components/modules/genetic_demux/bcftools.html#example-commands",
    "title": "Bcftools",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/genetic_demux/bcftools/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nvcf: # please fill in - example: [\"path/to/file\"]\nconcat: false\nfilter: false\nfilter_qual: 30\n# output: \"$id.$key.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/bcftools/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Bcftools"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/bcftools.html#argument-group",
    "href": "components/modules/genetic_demux/bcftools.html#argument-group",
    "title": "Bcftools",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vcf\nVCF files, must have the same sample columns appearing in the same order.\nList of file, required, multiple_sep: \";\"\n\n\n--concat\nConcatenate or combine VCFs and sort them.\nboolean_true\n\n\n--filter\nFilter VCFs.\nboolean_true\n\n\n--filter_qual\nFilter VCFs with specified QUAL threshold.\ninteger, default: 30\n\n\n--output\nbcftools output directory\nfile, example: \"bcftools_out\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Bcftools"
    ]
  },
  {
    "objectID": "components/modules/genetic_demux/bcftools.html#authors",
    "href": "components/modules/genetic_demux/bcftools.html#authors",
    "title": "Bcftools",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Genetic Demux",
      "Bcftools"
    ]
  },
  {
    "objectID": "components/modules/velocity/scvelo.html",
    "href": "components/modules/velocity/scvelo.html",
    "title": "Scvelo",
    "section": "",
    "text": "ID: scvelo\nNamespace: velocity\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Velocity",
      "Scvelo"
    ]
  },
  {
    "objectID": "components/modules/velocity/scvelo.html#example-commands",
    "href": "components/modules/velocity/scvelo.html#example-commands",
    "title": "Scvelo",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/velocity/scvelo/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\n# counts_layer: \"foo\"\nmodality: # please fill in - example: \"foo\"\nlayer_spliced: \"spliced\"\nlayer_unspliced: \"unspliced\"\nlayer_ambiguous: \"ambiguous\"\n\n# Outputs\n# output: \"$id.$key.output\"\n# output_h5mu: \"$id.$key.output_h5mu\"\n# output_compression: \"gzip\"\n\n# Filtering and normalization\n# min_counts: 123\n# min_counts_u: 123\n# min_cells: 123\n# min_cells_u: 123\n# min_shared_counts: 123\n# min_shared_cells: 123\n# n_top_genes: 123\nlog_transform: true\n\n# Fitting parameters\n# n_principal_components: 123\nn_neighbors: 30\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/velocity/scvelo/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Velocity",
      "Scvelo"
    ]
  },
  {
    "objectID": "components/modules/velocity/scvelo.html#argument-groups",
    "href": "components/modules/velocity/scvelo.html#argument-groups",
    "title": "Scvelo",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput MuData file\nfile, required\n\n\n--counts_layer\nName of the counts layer, if not specified, X is used.\nstring\n\n\n--modality\nInput modality\nstring, required\n\n\n--layer_spliced\n\nstring, default: \"spliced\"\n\n\n--layer_unspliced\n\nstring, default: \"unspliced\"\n\n\n--layer_ambiguous\n\nstring, default: \"ambiguous\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory. If it does not exist, will be created.\nfile, required\n\n\n--output_h5mu\nOutput mudata file.\nfile, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n\n\n\nFiltering and normalization\nArguments for filtering, normalization an log transform (see scvelo.pp.filter_and_normalize function)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts required for a gene to pass filtering (spliced).\ninteger\n\n\n--min_counts_u\nMinimum number of counts required for a gene to pass filtering (unspliced).\ninteger\n\n\n--min_cells\nMinimum number of cells expressed required to pass filtering (spliced).\ninteger\n\n\n--min_cells_u\nMinimum number of cells expressed required to pass filtering (unspliced).\ninteger\n\n\n--min_shared_counts\nMinimum number of counts (both unspliced and spliced) required for a gene.\ninteger\n\n\n--min_shared_cells\nMinimum number of cells required to be expressed (both unspliced and spliced).\ninteger\n\n\n--n_top_genes\nNumber of genes to keep.\ninteger\n\n\n--log_transform\nDo not log transform counts.\nboolean, default: TRUE\n\n\n\n\n\nFitting parameters\nArguments for fitting the data\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_principal_components\nNumber of principal components to use for calculating moments.\ninteger\n\n\n--n_neighbors\nNumber of neighbors to use. First/second-order moments are computed for each cell across its nearest neighbors, where the neighbor graph is obtained from euclidean distances in PCA space.\ninteger, default: 30",
    "crumbs": [
      "Reference",
      "Modules",
      "Velocity",
      "Scvelo"
    ]
  },
  {
    "objectID": "components/modules/velocity/scvelo.html#authors",
    "href": "components/modules/velocity/scvelo.html#authors",
    "title": "Scvelo",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Velocity",
      "Scvelo"
    ]
  },
  {
    "objectID": "components/modules/demux/cellranger_atac_mkfastq.html",
    "href": "components/modules/demux/cellranger_atac_mkfastq.html",
    "title": "Cellranger atac mkfastq",
    "section": "",
    "text": "ID: cellranger_atac_mkfastq\nNamespace: demux\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Cellranger atac mkfastq"
    ]
  },
  {
    "objectID": "components/modules/demux/cellranger_atac_mkfastq.html#example-commands",
    "href": "components/modules/demux/cellranger_atac_mkfastq.html#example-commands",
    "title": "Cellranger atac mkfastq",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/demux/cellranger_atac_mkfastq/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"/path/to/bcl\"\ncsv: # please fill in - example: \"SampleSheet.csv\"\n# lanes: [\"1,3\"]\n# use_bases_mask: [\"y50n,I6n,Y50n\"]\ndelete_undetermined: false\nbarcode_mismatches: 1\n# output: \"fastqs\"\n# reports: \"$id.$key.reports\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/demux/cellranger_atac_mkfastq/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Cellranger atac mkfastq"
    ]
  },
  {
    "objectID": "components/modules/demux/cellranger_atac_mkfastq.html#argument-group",
    "href": "components/modules/demux/cellranger_atac_mkfastq.html#argument-group",
    "title": "Cellranger atac mkfastq",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath of Illumina BCL run folder.\nfile, required, example: \"/path/to/bcl\"\n\n\n--csv\nThe path to the simple layout sample sheet.\nfile, required, example: \"SampleSheet.csv\"\n\n\n--lanes\nbcl2fastq option. Semicolon-delimited series of lanes to demultiplex. Use this if you have a sample sheet for an entire flow cell but only want to generate a few lanes for further 10x Genomics analysis.\nList of string, example: \"1,3\", multiple_sep: \",\"\n\n\n--use_bases_mask\nbcl2fastq option. Use to clip extra bases off a read if you ran extra cycles for QC.\nList of string, example: \"y50n,I6n,Y50n\", multiple_sep: \",\"\n\n\n--delete_undetermined\nbcl2fastq option. Delete the Undetermined FASTQs generated by bcl2fastq. Useful if you are demultiplexing a small number of samples from a large flow cell.\nboolean_true\n\n\n--barcode_mismatches\nbcl2fastq option. Use this option to change the number of allowed mismatches per index adapter (0, 1, 2).\ninteger, default: 1\n\n\n--output\nThe folder to store the demux results\nfile, required, default: \"fastqs\", example: \"/path/to/output\"\n\n\n--reports\nReports directory\nfile, example: \"reports_dir\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Cellranger atac mkfastq"
    ]
  },
  {
    "objectID": "components/modules/demux/cellranger_atac_mkfastq.html#authors",
    "href": "components/modules/demux/cellranger_atac_mkfastq.html#authors",
    "title": "Cellranger atac mkfastq",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Cellranger atac mkfastq"
    ]
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html",
    "href": "components/modules/demux/bcl_convert.html",
    "title": "Bcl convert",
    "section": "",
    "text": "ID: bcl_convert\nNamespace: demux\n\n\n\nSource\nInformation about upgrading from bcl2fastq via https://emea.support.illumina.com/bulletins/2020/10/upgrading-from-bcl2fastq-to-bcl-convert.html and https://support.illumina.com/sequencing/sequencing_software/bcl-convert/compatibility.html",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Bcl convert"
    ]
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html#example-commands",
    "href": "components/modules/demux/bcl_convert.html#example-commands",
    "title": "Bcl convert",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/demux/bcl_convert/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"bcl_dir\"\nsample_sheet: # please fill in - example: \"bcl_dir\"\n# output: \"$id.$key.output\"\n# reports: \"$id.$key.reports\"\ntest_mode: false\nstrict_mode: false\n# tiles: \"foo\"\n# exclude_tiles: \"foo\"\n# no_lane_splitting: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/demux/bcl_convert/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Bcl convert"
    ]
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html#argument-group",
    "href": "components/modules/demux/bcl_convert.html#argument-group",
    "title": "Bcl convert",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput run directory\nfile, required, example: \"bcl_dir\"\n\n\n--sample_sheet\nPointer to the sample sheet\nfile, required, example: \"bcl_dir\"\n\n\n--output\nOutput directory containig fastq files\nfile, required, example: \"fastq_dir\"\n\n\n--reports\nReports directory\nfile, example: \"reports_dir\"\n\n\n--test_mode\nShould bcl-convert be run in test mode (using –first-tile-only)?\nboolean, default: FALSE\n\n\n--strict_mode\nAbort if any files are missing.\nboolean, default: FALSE\n\n\n--tiles\nProcess only a subset of tiles by a regular expression.\nstring\n\n\n--exclude_tiles\nExclude set of tiles by a regular expression\nstring\n\n\n--no_lane_splitting\nWheter to avoid splitting FASTQ file by lane.\nboolean",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Bcl convert"
    ]
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html#authors",
    "href": "components/modules/demux/bcl_convert.html#authors",
    "title": "Bcl convert",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (author, maintainer)\nMarijke Van Moerbeke    (author)\nWeiwei Schultz (contributor)\nDorien Roosen   (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Demux",
      "Bcl convert"
    ]
  },
  {
    "objectID": "components/modules/transform/clr.html",
    "href": "components/modules/transform/clr.html",
    "title": "Clr",
    "section": "",
    "text": "ID: clr\nNamespace: transform\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Clr"
    ]
  },
  {
    "objectID": "components/modules/transform/clr.html#example-commands",
    "href": "components/modules/transform/clr.html#example-commands",
    "title": "Clr",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/transform/clr/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"prot\"\n# output: \"output.h5mu\"\n# output_compression: \"gzip\"\n# input_layer: \"foo\"\n# output_layer: \"foo\"\naxis: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/clr/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Clr"
    ]
  },
  {
    "objectID": "components/modules/transform/clr.html#argument-group",
    "href": "components/modules/transform/clr.html#argument-group",
    "title": "Clr",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"prot\"\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--input_layer\nInput layer to use. By default, .X is used.\nstring\n\n\n--output_layer\nOutput layer to use. By default, use X.\nstring\n\n\n--axis\nAxis across which CLR is performed. If set to 0, CLR is performed across observations (cells). If set to 1, CLR is performed across features (genes).\ninteger, default: 0",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Clr"
    ]
  },
  {
    "objectID": "components/modules/transform/clr.html#authors",
    "href": "components/modules/transform/clr.html#authors",
    "title": "Clr",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Clr"
    ]
  },
  {
    "objectID": "components/modules/transform/move_layer.html",
    "href": "components/modules/transform/move_layer.html",
    "title": "Move layer",
    "section": "",
    "text": "ID: move_layer\nNamespace: transform\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Move layer"
    ]
  },
  {
    "objectID": "components/modules/transform/move_layer.html#example-commands",
    "href": "components/modules/transform/move_layer.html#example-commands",
    "title": "Move layer",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/transform/move_layer/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_layer: \"foo\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/move_layer/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Move layer"
    ]
  },
  {
    "objectID": "components/modules/transform/move_layer.html#argument-group",
    "href": "components/modules/transform/move_layer.html#argument-group",
    "title": "Move layer",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\n\nstring\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_layer\n\nstring\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Move layer"
    ]
  },
  {
    "objectID": "components/modules/transform/regress_out.html",
    "href": "components/modules/transform/regress_out.html",
    "title": "Regress out",
    "section": "",
    "text": "ID: regress_out\nNamespace: transform\n\n\n\nSource\nUses simple linear regression. This is inspired by Seurat’s regressOut function in R [Satija15]. Note that this function tends to overcorrect in certain circumstances as described in issue theislab/scanpy#526. See https://github.com/theislab/scanpy/issues/526",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Regress out"
    ]
  },
  {
    "objectID": "components/modules/transform/regress_out.html#example-commands",
    "href": "components/modules/transform/regress_out.html#example-commands",
    "title": "Regress out",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/transform/regress_out/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\n# output: \"output.h5mu\"\n# output_compression: \"gzip\"\nmodality: \"rna\"\n# obs_keys: [\"foo\"]\n# input_layer: \"X_normalized\"\n# output_layer: \"X_regressed\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/regress_out/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Regress out"
    ]
  },
  {
    "objectID": "components/modules/transform/regress_out.html#argument-group",
    "href": "components/modules/transform/regress_out.html#argument-group",
    "title": "Regress out",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--modality\nWhich modality (one or more) to run this component on.\nstring, default: \"rna\"\n\n\n--obs_keys\nWhich .obs keys to regress on.\nList of string, multiple_sep: \";\"\n\n\n--input_layer\nThe layer of the adata object to regress on. If not provided, the X attribute of the adata object will be used.\nstring, example: \"X_normalized\"\n\n\n--output_layer\nThe layer of the adata object containing the regressed count data. If not provided, the X attribute of the adata object will be used.\nstring, example: \"X_regressed\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Regress out"
    ]
  },
  {
    "objectID": "components/modules/transform/regress_out.html#authors",
    "href": "components/modules/transform/regress_out.html#authors",
    "title": "Regress out",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer, contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Regress out"
    ]
  },
  {
    "objectID": "components/modules/transform/tfidf.html",
    "href": "components/modules/transform/tfidf.html",
    "title": "Tfidf",
    "section": "",
    "text": "ID: tfidf\nNamespace: transform\n\n\n\nSource\nTF-IDF stands for “term frequency - inverse document frequency”. It is a technique from natural language processing analysis. In the context of ATAC data, “terms” are the features (genes) and “documents” are the observations (cells). TF-IDF normalization is applied to single-cell ATAC-seq data to highlight the importance of specific genomic regions (typically peaks) across different cells while down-weighting regions that are commonly accessible across many cells.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Tfidf"
    ]
  },
  {
    "objectID": "components/modules/transform/tfidf.html#example-commands",
    "href": "components/modules/transform/tfidf.html#example-commands",
    "title": "Tfidf",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/transform/tfidf/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"atac\"\n# input_layer: \"foo\"\n# output: \"$id.$key.output\"\n# output_compression: \"gzip\"\noutput_layer: \"tfidf\"\nscale_factor: 10000\nlog_idf: true\nlog_tf: true\nlog_tfidf: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/tfidf/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Tfidf"
    ]
  },
  {
    "objectID": "components/modules/transform/tfidf.html#argument-group",
    "href": "components/modules/transform/tfidf.html#argument-group",
    "title": "Tfidf",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"atac\"\n\n\n--input_layer\nInput layer to use. By default, X is normalized\nstring\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_layer\nOutput layer to use.\nstring, default: \"tfidf\"\n\n\n--scale_factor\nScale factor to multiply the TF-IDF matrix by.\ninteger, default: 10000\n\n\n--log_idf\nWhether to log-transform IDF term.\nboolean, default: TRUE\n\n\n--log_tf\nWhether to log-transform TF term.\nboolean, default: TRUE\n\n\n--log_tfidf\nWhether to log-transform TF*IDF term (False by default). Can only be used when log_tf and log_idf are False.\nboolean, default: FALSE",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Tfidf"
    ]
  },
  {
    "objectID": "components/modules/transform/tfidf.html#authors",
    "href": "components/modules/transform/tfidf.html#authors",
    "title": "Tfidf",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Transform",
      "Tfidf"
    ]
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html",
    "href": "components/modules/neighbors/bbknn.html",
    "title": "Bbknn",
    "section": "",
    "text": "ID: bbknn\nNamespace: neighbors\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Neighbors",
      "Bbknn"
    ]
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html#example-commands",
    "href": "components/modules/neighbors/bbknn.html#example-commands",
    "title": "Bbknn",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/neighbors/bbknn/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\nobsm_input: \"X_pca\"\nobs_batch: \"batch\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_output: \"neighbors\"\nobsp_distances: \"distances\"\nobsp_connectivities: \"connectivities\"\nn_neighbors_within_batch: 3\nn_pcs: 50\n# n_trim: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/neighbors/bbknn/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Neighbors",
      "Bbknn"
    ]
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html#argument-group",
    "href": "components/modules/neighbors/bbknn.html#argument-group",
    "title": "Bbknn",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_input\nThe dimensionality reduction in .obsm to use for neighbour detection. Defaults to X_pca.\nstring, default: \"X_pca\"\n\n\n--obs_batch\n.obs column name discriminating between your batches.\nstring, default: \"batch\"\n\n\n--output\nOutput .h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--uns_output\nMandatory .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n--n_neighbors_within_batch\nHow many top neighbours to report for each batch; total number of neighbours in the initial k-nearest-neighbours computation will be this number times the number of batches.\ninteger, default: 3\n\n\n--n_pcs\nHow many dimensions (in case of PCA, principal components) to use in the analysis.\ninteger, default: 50\n\n\n--n_trim\nTrim the neighbours of each cell to these many top connectivities. May help with population independence and improve the tidiness of clustering. The lower the value the more independent the individual populations, at the cost of more conserved batch effect. If None (default), sets the parameter value automatically to 10 times neighbors_within_batch times the number of batches. Set to 0 to skip.\ninteger",
    "crumbs": [
      "Reference",
      "Modules",
      "Neighbors",
      "Bbknn"
    ]
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html#authors",
    "href": "components/modules/neighbors/bbknn.html#authors",
    "title": "Bbknn",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Neighbors",
      "Bbknn"
    ]
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html",
    "href": "components/modules/compression/compress_h5mu.html",
    "title": "Compress h5mu",
    "section": "",
    "text": "ID: compress_h5mu\nNamespace: compression\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Compression",
      "Compress h5mu"
    ]
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html#example-commands",
    "href": "components/modules/compression/compress_h5mu.html#example-commands",
    "title": "Compress h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/compression/compress_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"sample_path\"\n# output: \"$id.$key.output\"\ncompression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/compression/compress_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Compression",
      "Compress h5mu"
    ]
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html#argument-group",
    "href": "components/modules/compression/compress_h5mu.html#argument-group",
    "title": "Compress h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the input .h5mu.\nfile, required, example: \"sample_path\"\n\n\n--output\nlocation of output file.\nfile, required\n\n\n--compression\nCompression type.\nstring, default: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Compression",
      "Compress h5mu"
    ]
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html#authors",
    "href": "components/modules/compression/compress_h5mu.html#authors",
    "title": "Compress h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Compression",
      "Compress h5mu"
    ]
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background.html",
    "href": "components/modules/correction/cellbender_remove_background.html",
    "title": "Cellbender remove background",
    "section": "",
    "text": "ID: cellbender_remove_background\nNamespace: correction\n\n\n\nSource\nThis module removes counts due to ambient RNA molecules and random barcode swapping from (raw) UMI-based scRNA-seq count matrices. At the moment, only the count matrices produced by the CellRanger count pipeline is supported. Support for additional tools and protocols will be added in the future. A quick start tutorial can be found here.\nFleming et al. 2022, bioRxiv.",
    "crumbs": [
      "Reference",
      "Modules",
      "Correction",
      "Cellbender remove background"
    ]
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background.html#example-commands",
    "href": "components/modules/correction/cellbender_remove_background.html#example-commands",
    "title": "Cellbender remove background",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/correction/cellbender_remove_background/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nlayer_output: \"cellbender_corrected\"\nobs_background_fraction: \"cellbender_background_fraction\"\nobs_cell_probability: \"cellbender_cell_probability\"\nobs_cell_size: \"cellbender_cell_size\"\nobs_droplet_efficiency: \"cellbender_droplet_efficiency\"\nobs_latent_scale: \"cellbender_latent_scale\"\nvar_ambient_expression: \"cellbender_ambient_expression\"\nobsm_gene_expression_encoding: \"cellbender_gene_expression_encoding\"\n\n# Arguments\nexpected_cells_from_qc: false\n# expected_cells: 1000\n# total_droplets_included: 25000\n# force_cell_umi_prior: 123\n# force_empty_umi_prior: 123\nmodel: \"full\"\nepochs: 150\nlow_count_threshold: 5\nz_dim: 64\nz_layers: [512]\ntraining_fraction: 0.9\nempty_drop_training_fraction: 0.2\n# ignore_features: [123]\nfpr: [0.01]\n# exclude_feature_types: [\"foo\"]\nprojected_ambient_count_threshold: 0.1\nlearning_rate: 1.0E-4\n# final_elbo_fail_fraction: 123.0\n# epoch_elbo_fail_fraction: 123.0\nnum_training_tries: 1\nlearning_rate_retry_mult: 0.2\nposterior_batch_size: 128\n# posterior_regulation: \"foo\"\n# alpha: 123.0\n# q: 123.0\nestimator: \"mckp\"\nestimator_multiple_cpu: false\n# constant_learning_rate: true\ndebug: false\ncuda: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/correction/cellbender_remove_background/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Correction",
      "Cellbender remove background"
    ]
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background.html#argument-groups",
    "href": "components/modules/correction/cellbender_remove_background.html#argument-groups",
    "title": "Cellbender remove background",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file. Data file on which to run tool. Data must be un-filtered: it should include empty droplets.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nList of modalities to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nFull count matrix as an h5mu file, with background RNA removed. This file contains all the original droplet barcodes.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--layer_output\nOutput layer\nstring, default: \"cellbender_corrected\"\n\n\n--obs_background_fraction\n\nstring, default: \"cellbender_background_fraction\"\n\n\n--obs_cell_probability\n\nstring, default: \"cellbender_cell_probability\"\n\n\n--obs_cell_size\n\nstring, default: \"cellbender_cell_size\"\n\n\n--obs_droplet_efficiency\n\nstring, default: \"cellbender_droplet_efficiency\"\n\n\n--obs_latent_scale\n\nstring, default: \"cellbender_latent_scale\"\n\n\n--var_ambient_expression\n\nstring, default: \"cellbender_ambient_expression\"\n\n\n--obsm_gene_expression_encoding\n\nstring, default: \"cellbender_gene_expression_encoding\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expected_cells_from_qc\nWill use the Cell Ranger QC to determine the estimated number of cells\nboolean, default: FALSE\n\n\n--expected_cells\nNumber of cells expected in the dataset (a rough estimate within a factor of 2 is sufficient).\ninteger, example: 1000\n\n\n--total_droplets_included\nThe number of droplets from the rank-ordered UMI plot that will have their cell probabilities inferred as an output. Include the droplets which might contain cells. Droplets beyond TOTAL_DROPLETS_INCLUDED should be ‘surely empty’ droplets.\ninteger, example: 25000\n\n\n--force_cell_umi_prior\nIgnore CellBender’s heuristic prior estimation, and use this prior for UMI counts in cells.\ninteger\n\n\n--force_empty_umi_prior\nIgnore CellBender’s heuristic prior estimation, and use this prior for UMI counts in empty droplets.\ninteger\n\n\n--model\nWhich model is being used for count data. * ‘naive’ subtracts the estimated ambient profile. * ‘simple’ does not model either ambient RNA or random barcode swapping (for debugging purposes – not recommended). * ‘ambient’ assumes background RNA is incorporated into droplets. * ‘swapping’ assumes background RNA comes from random barcode swapping (via PCR chimeras). * ‘full’ uses a combined ambient and swapping model.\nstring, default: \"full\"\n\n\n--epochs\nNumber of epochs to train.\ninteger, default: 150\n\n\n--low_count_threshold\nDroplets with UMI counts below this number are completely excluded from the analysis. This can help identify the correct prior for empty droplet counts in the rare case where empty counts are extremely high (over 200).\ninteger, default: 5\n\n\n--z_dim\nDimension of latent variable z.\ninteger, default: 64\n\n\n--z_layers\nDimension of hidden layers in the encoder for z.\nList of integer, default: 512, multiple_sep: \";\"\n\n\n--training_fraction\nTraining detail: the fraction of the data used for training. The rest is never seen by the inference algorithm. Speeds up learning.\ndouble, default: 0.9\n\n\n--empty_drop_training_fraction\nTraining detail: the fraction of the training data each epoch that is drawn (randomly sampled) from surely empty droplets.\ndouble, default: 0.2\n\n\n--ignore_features\nInteger indices of features to ignore entirely. In the output count matrix, the counts for these features will be unchanged.\nList of integer, multiple_sep: \";\"\n\n\n--fpr\nTarget ‘delta’ false positive rate in [0, 1). Use 0 for a cohort of samples which will be jointly analyzed for differential expression. A false positive is a true signal count that is erroneously removed. More background removal is accompanied by more signal removal at high values of FPR. You can specify multiple values, which will create multiple output files.\nList of double, default: 0.01, multiple_sep: \";\"\n\n\n--exclude_feature_types\nFeature types to ignore during the analysis. These features will be left unchanged in the output file.\nList of string, multiple_sep: \";\"\n\n\n--projected_ambient_count_threshold\nControls how many features are included in the analysis, which can lead to a large speedup. If a feature is expected to have less than PROJECTED_AMBIENT_COUNT_THRESHOLD counts total in all cells (summed), then that gene is excluded, and it will be unchanged in the output count matrix. For example, PROJECTED_AMBIENT_COUNT_THRESHOLD = 0 will include all features which have even a single count in any empty droplet.\ndouble, default: 0.1\n\n\n--learning_rate\nTraining detail: lower learning rate for inference. A OneCycle learning rate schedule is used, where the upper learning rate is ten times this value. (For this value, probably do not exceed 1e-3).\ndouble, default: 1e-04\n\n\n--final_elbo_fail_fraction\nTraining is considered to have failed if (best_test_ELBO - final_test_ELBO)/(best_test_ELBO - initial_test_ELBO) &gt; FINAL_ELBO_FAIL_FRACTION. Training will automatically re-run if –num-training-tries &gt; 1. By default, will not fail training based on final_training_ELBO.\ndouble\n\n\n--epoch_elbo_fail_fraction\nTraining is considered to have failed if (previous_epoch_test_ELBO - current_epoch_test_ELBO)/(previous_epoch_test_ELBO - initial_train_ELBO) &gt; EPOCH_ELBO_FAIL_FRACTION. Training will automatically re-run if –num-training-tries &gt; 1. By default, will not fail training based on epoch_training_ELBO.\ndouble\n\n\n--num_training_tries\nNumber of times to attempt to train the model. At each subsequent attempt, the learning rate is multiplied by LEARNING_RATE_RETRY_MULT.\ninteger, default: 1\n\n\n--learning_rate_retry_mult\nLearning rate is multiplied by this amount each time a new training attempt is made. (This parameter is only used if training fails based on EPOCH_ELBO_FAIL_FRACTION or FINAL_ELBO_FAIL_FRACTION and NUM_TRAINING_TRIES is &gt; 1.)\ndouble, default: 0.2\n\n\n--posterior_batch_size\nTraining detail: size of batches when creating the posterior. Reduce this to avoid running out of GPU memory creating the posterior (will be slower).\ninteger, default: 128\n\n\n--posterior_regulation\nPosterior regularization method. (For experts: not required for normal usage, see documentation). * PRq is approximate quantile-targeting. * PRmu is approximate mean-targeting aggregated over genes (behavior of v0.2.0). * PRmu_gene is approximate mean-targeting per gene.\nstring\n\n\n--alpha\nTunable parameter alpha for the PRq posterior regularization method (not normally used: see documentation).\ndouble\n\n\n--q\nTunable parameter q for the CDF threshold estimation method (not normally used: see documentation).\ndouble\n\n\n--estimator\nOutput denoised count estimation method. (For experts: not required for normal usage, see documentation).\nstring, default: \"mckp\"\n\n\n--estimator_multiple_cpu\nIncluding the flag –estimator-multiple-cpu will use more than one CPU to compute the MCKP output count estimator in parallel (does nothing for other estimators).\nboolean_true\n\n\n--constant_learning_rate\nIncluding the flag –constant-learning-rate will use the ClippedAdam optimizer instead of the OneCycleLR learning rate schedule, which is the default. Learning is faster with the OneCycleLR schedule. However, training can easily be continued from a checkpoint for more epochs than the initial command specified when using ClippedAdam. On the other hand, if using the OneCycleLR schedule with 150 epochs specified, it is not possible to pick up from that final checkpoint and continue training until 250 epochs.\nboolean\n\n\n--debug\nIncluding the flag –debug will log extra messages useful for debugging.\nboolean_true\n\n\n--cuda\nIncluding the flag –cuda will run the inference on a GPU.\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Correction",
      "Cellbender remove background"
    ]
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html",
    "href": "components/modules/download/sync_test_resources.html",
    "title": "Sync test resources",
    "section": "",
    "text": "ID: sync_test_resources\nNamespace: download\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Download",
      "Sync test resources"
    ]
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html#example-commands",
    "href": "components/modules/download/sync_test_resources.html#example-commands",
    "title": "Sync test resources",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/download/sync_test_resources/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: \"_viash.yaml\"\n\n# Outputs\n# output: \".\"\n\n# Arguments\nquiet: false\ndryrun: false\ndelete: false\n# exclude: [\"foo\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/download/sync_test_resources/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Download",
      "Sync test resources"
    ]
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html#argument-groups",
    "href": "components/modules/download/sync_test_resources.html#argument-groups",
    "title": "Sync test resources",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the _viash.yaml project configuration file.\nfile, default: \"_viash.yaml\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nPath to the directory where the resources will be synced to.\nfile, default: \".\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--quiet\nDisplays the operations that would be performed using the specified command without actually running them.\nboolean_true\n\n\n--dryrun\nDoes not display the operations performed from the specified command.\nboolean_true\n\n\n--delete\nFiles that exist in the destination but not in the source are deleted during sync.\nboolean_true\n\n\n--exclude\nExclude all files or objects from the command that matches the specified pattern.\nList of string, multiple_sep: \";\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Download",
      "Sync test resources"
    ]
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html#authors",
    "href": "components/modules/download/sync_test_resources.html#authors",
    "title": "Sync test resources",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Download",
      "Sync test resources"
    ]
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html",
    "href": "components/modules/process_10xh5/filter_10xh5.html",
    "title": "Filter 10xh5",
    "section": "",
    "text": "ID: filter_10xh5\nNamespace: process_10xh5\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Process 10xh5",
      "Filter 10xh5"
    ]
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html#example-commands",
    "href": "components/modules/process_10xh5/filter_10xh5.html#example-commands",
    "title": "Filter 10xh5",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/process_10xh5/filter_10xh5/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n# output: \"$id.$key.output.h5\"\nmin_library_size: 0\nmin_cells_per_gene: 0\n# keep_feature_types: [\"Antibody Capture\"]\nverbose: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/process_10xh5/filter_10xh5/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Process 10xh5",
      "Filter 10xh5"
    ]
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html#argument-group",
    "href": "components/modules/process_10xh5/filter_10xh5.html#argument-group",
    "title": "Filter 10xh5",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nAn h5 file from the 10x genomics website.\nfile, required, example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n\n\n--output\nOutput h5 file.\nfile, required, example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix_filtered.h5\"\n\n\n--min_library_size\nMinimum library size.\ninteger, default: 0\n\n\n--min_cells_per_gene\nMinimum number of cells per gene.\ninteger, default: 0\n\n\n--keep_feature_types\nSpecify which feature types will never be filtered out\nList of string, example: \"Antibody Capture\", multiple_sep: \";\"\n\n\n--verbose\nIncrease verbosity\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Process 10xh5",
      "Filter 10xh5"
    ]
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html#authors",
    "href": "components/modules/process_10xh5/filter_10xh5.html#authors",
    "title": "Filter 10xh5",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Process 10xh5",
      "Filter 10xh5"
    ]
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html",
    "href": "components/modules/labels_transfer/knn.html",
    "title": "Knn",
    "section": "",
    "text": "ID: knn\nNamespace: labels_transfer\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Labels Transfer",
      "Knn"
    ]
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html#example-commands",
    "href": "components/modules/labels_transfer/knn.html#example-commands",
    "title": "Knn",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/labels_transfer/knn/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input dataset (query) arguments\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\n# input_obsm_features: \"X_scvi\"\n\n# Reference dataset arguments\n# reference: \"reference.h5mu\"\n# reference_obsm_features: \"X_scvi\"\nreference_obs_targets: [\"ann_level_1\", \"ann_level_2\", \"ann_level_3\", \"ann_level_4\", \"ann_level_5\", \"ann_finest_level\"]\n\n# Outputs\n# output: \"$id.$key.output\"\n# output_obs_predictions: [\"foo\"]\n# output_obs_probability: [\"foo\"]\n# output_compression: \"gzip\"\n\n# Input dataset (query) arguments\n# input_obsm_distances: \"bbknn_distances\"\n\n# Reference dataset arguments\n# reference_obsm_distances: \"bbknn_distances\"\n\n# KNN label transfer arguments\nweights: \"uniform\"\nn_neighbors: 15\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/labels_transfer/knn/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Labels Transfer",
      "Knn"
    ]
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html#argument-groups",
    "href": "components/modules/labels_transfer/knn.html#argument-groups",
    "title": "Knn",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe query data to transfer the labels to. Should be a .h5mu file.\nfile, required\n\n\n--modality\nWhich modality to use.\nstring, default: \"rna\"\n\n\n--input_obsm_features\nThe .obsm key of the embedding to use for the classifier’s inference. If not provided, the .X slot will be used instead. Make sure that embedding was obtained in the same way as the reference embedding (e.g. by the same model or preprocessing).\nstring, example: \"X_scvi\"\n\n\n\n\n\nReference dataset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train classifiers on.\nfile, example: \"reference.h5mu\"\n\n\n--reference_obsm_features\nThe .obsm key of the embedding to use for the classifier’s training. If not provided, the .X slot will be used instead. Make sure that embedding was obtained in the same way as the query embedding (e.g. by the same model or preprocessing).\nstring, example: \"X_scvi\"\n\n\n--reference_obs_targets\nThe .obs key(s) of the target labels to tranfer.\nList of string, default: \"ann_level_1\", \"ann_level_2\", \"ann_level_3\", \"ann_level_4\", \"ann_level_5\", \"ann_finest_level\", multiple_sep: \";\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe query data in .h5mu format with predicted labels transfered from the reference.\nfile, required\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted information. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_pred\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_obs_probability\nIn which .obs slots to store the probability of the predictions. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_probability\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n\n\n\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_obsm_distances\nThe .obsm key of the input (query) dataset containing pre-calculated distances. If not provided, the distances will be calculated using PyNNDescent. Make sure the distance matrix contains distances relative to the reference dataset and were obtained in the same way as the reference embedding.\nstring, example: \"bbknn_distances\"\n\n\n\n\n\nReference dataset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference_obsm_distances\nThe .obsm key of the reference dataset containing pre-calculated distances. If not provided, the distances will be calculated using PyNNDescent.\nstring, example: \"bbknn_distances\"\n\n\n\n\n\nKNN label transfer arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--weights\nWeight function used in prediction. Possible values are: - uniform - all points in each neighborhood are weighted equally - distance - weight points by the inverse of their distance - gaussian - weight points by the sum of their Gaussian kernel similarities to each sample\nstring, default: \"uniform\"\n\n\n--n_neighbors\nThe number of neighbors to use in k-neighbor graph structure used for fast approximate nearest neighbor search with PyNNDescent. Larger values will result in more accurate search results at the cost of computation time.\ninteger, default: 15",
    "crumbs": [
      "Reference",
      "Modules",
      "Labels Transfer",
      "Knn"
    ]
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html#authors",
    "href": "components/modules/labels_transfer/knn.html#authors",
    "title": "Knn",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (maintainer, author)\nVladimir Shitov    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Labels Transfer",
      "Knn"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html",
    "href": "components/modules/dataflow/split_modalities.html",
    "title": "Split modalities",
    "section": "",
    "text": "ID: split_modalities\nNamespace: dataflow\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split modalities"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html#example-commands",
    "href": "components/modules/dataflow/split_modalities.html#example-commands",
    "title": "Split modalities",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/dataflow/split_modalities/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"sample_path\"\n# output: \"$id.$key.output\"\n# output_compression: \"gzip\"\n# output_types: \"$id.$key.output_types.csv\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/split_modalities/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split modalities"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html#argument-group",
    "href": "components/modules/dataflow/split_modalities.html#argument-group",
    "title": "Split modalities",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to a single .h5mu file.\nfile, required, default: \"sample_path\"\n\n\n--output\nOutput directory containing multiple h5mu files.\nfile, required, example: \"/path/to/output\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_types\nA csv containing the base filename and modality type per output file.\nfile, required, example: \"types.csv\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split modalities"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html#authors",
    "href": "components/modules/dataflow/split_modalities.html#authors",
    "title": "Split modalities",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)\nRobrecht Cannoodt    (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split modalities"
    ]
  },
  {
    "objectID": "components/modules/dataflow/concatenate_h5mu.html",
    "href": "components/modules/dataflow/concatenate_h5mu.html",
    "title": "Concatenate h5mu",
    "section": "",
    "text": "ID: concatenate_h5mu\nNamespace: dataflow\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Concatenate h5mu"
    ]
  },
  {
    "objectID": "components/modules/dataflow/concatenate_h5mu.html#example-commands",
    "href": "components/modules/dataflow/concatenate_h5mu.html#example-commands",
    "title": "Concatenate h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/dataflow/concatenate_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"sample_paths\"]\n# modality: [\"foo\"]\n# input_id: [\"foo\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_sample_name: \"sample_id\"\nother_axis_mode: \"move\"\nuns_merge_mode: \"make_unique\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/concatenate_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Concatenate h5mu"
    ]
  },
  {
    "objectID": "components/modules/dataflow/concatenate_h5mu.html#argument-group",
    "href": "components/modules/dataflow/concatenate_h5mu.html#argument-group",
    "title": "Concatenate h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPaths to the different samples to be concatenated.\nList of file, required, example: \"sample_paths\", multiple_sep: \";\"\n\n\n--modality\nOnly output concatenated objects for the provided modalities. Outputs all modalities by default.\nList of string, multiple_sep: \";\"\n\n\n--input_id\nNames of the different samples that have to be concatenated. Must be specified when using ‘–mode move’. In this case, the ids will be used for the columns names of the dataframes registring the conflicts. If specified, must be of same length as --input.\nList of string, multiple_sep: \";\"\n\n\n--output\n\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_sample_name\nName of the .obs key under which to add the sample names.\nstring, default: \"sample_id\"\n\n\n--other_axis_mode\nHow to handle the merging of other axis (var, obs, …). - None: keep no data - same: only keep elements of the matrices which are the same in each of the samples - unique: only keep elements for which there is only 1 possible value (1 value that can occur in multiple samples) - first: keep the annotation from the first sample - only: keep elements that show up in only one of the objects (1 unique element in only 1 sample) - move: identical to ‘same’, but moving the conflicting values to .varm or .obsm\nstring, default: \"move\"\n\n\n--uns_merge_mode\nHow to handle the merging of .uns across modalities - None: keep no data - same: only keep elements of the matrices which are the same in each of the samples - unique: only keep elements for which there is only 1 possible value (1 value that can occur in multiple samples) - first: keep the annotation from the first sample - only: keep elements that show up in only one of the objects (1 unique element in only 1 sample) - make_unique: identical to ‘unique’, but keys which are not unique are made unique by prefixing them with the sample id.\nstring, default: \"make_unique\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Concatenate h5mu"
    ]
  },
  {
    "objectID": "components/modules/dataflow/concatenate_h5mu.html#authors",
    "href": "components/modules/dataflow/concatenate_h5mu.html#authors",
    "title": "Concatenate h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Concatenate h5mu"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_h5mu.html",
    "href": "components/modules/dataflow/split_h5mu.html",
    "title": "Split h5mu",
    "section": "",
    "text": "ID: split_h5mu\nNamespace: dataflow\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split h5mu"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_h5mu.html#example-commands",
    "href": "components/modules/dataflow/split_h5mu.html#example-commands",
    "title": "Split h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/dataflow/split_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input & specifications\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\nobs_feature: # please fill in - example: \"celltype\"\ndrop_obs_nan: false\nensure_unique_filenames: false\n\n# Outputs\n# output: \"$id.$key.output\"\n# output_compression: \"gzip\"\n# output_files: \"$id.$key.output_files.csv\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/split_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split h5mu"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_h5mu.html#argument-groups",
    "href": "components/modules/dataflow/split_h5mu.html#argument-groups",
    "title": "Split h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput & specifications\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to a single .h5mu file.\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obs_feature\nThe .obs column to split the mudata on.\nstring, required, example: \"celltype\"\n\n\n--drop_obs_nan\nWhether to drop all .obs columns that contain only nan values after splitting.\nboolean_true\n\n\n--ensure_unique_filenames\nAppend number suffixes to ensure unique filenames after sanitizing obs feature values.\nboolean_true\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory containing multiple h5mu files.\nfile, required, example: \"/path/to/output\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_files\nA csv containing the base filename and obs feature by which it was split.\nfile, required, example: \"sample_files.csv\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split h5mu"
    ]
  },
  {
    "objectID": "components/modules/dataflow/split_h5mu.html#authors",
    "href": "components/modules/dataflow/split_h5mu.html#authors",
    "title": "Split h5mu",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Dataflow",
      "Split h5mu"
    ]
  },
  {
    "objectID": "components/modules/annotate/random_forest_annotation.html",
    "href": "components/modules/annotate/random_forest_annotation.html",
    "title": "Random forest annotation",
    "section": "",
    "text": "ID: random_forest_annotation\nNamespace: annotate\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Random forest annotation"
    ]
  },
  {
    "objectID": "components/modules/annotate/random_forest_annotation.html#example-commands",
    "href": "components/modules/annotate/random_forest_annotation.html#example-commands",
    "title": "Random forest annotation",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/annotate/random_forest_annotation/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# input_var_gene_names: \"foo\"\ninput_reference_gene_overlap: 100\n\n# Reference\n# reference: \"reference.h5mu\"\n# reference_layer: \"foo\"\nreference_obs_target: # please fill in - example: \"foo\"\n# reference_var_gene_names: \"foo\"\n# reference_var_input: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_obs_predictions: \"random_forest_pred\"\noutput_obs_probability: \"random_forest_probability\"\n\n# Model arguments\n# model: \"pretrained_model.pkl\"\nn_estimators: 100\n# max_depth: 123\ncriterion: \"gini\"\nclass_weight: \"balanced_subsample\"\nmax_features: \"200\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/annotate/random_forest_annotation/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Random forest annotation"
    ]
  },
  {
    "objectID": "components/modules/annotate/random_forest_annotation.html#argument-groups",
    "href": "components/modules/annotate/random_forest_annotation.html#argument-groups",
    "title": "Random forest annotation",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe input (query) data to be labeled. Should be a .h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--input_layer\nThe layer in the input data to be used for cell type annotation if .X is not to be used.\nstring\n\n\n--input_var_gene_names\nThe name of the adata var column in the input data containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--input_reference_gene_overlap\nThe minimum number of genes present in both the reference and query datasets.\ninteger, default: 100\n\n\n\n\n\nReference\nArguments related to the reference dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train the CellTypist classifiers on. Only required if a pre-trained –model is not provided.\nfile, example: \"reference.h5mu\"\n\n\n--reference_layer\nThe layer in the reference data to be used for cell type annotation if .X is not to be used. Data are expected to be processed in the same way as the –input query dataset.\nstring\n\n\n--reference_obs_target\nKey in obs field of reference modality with cell-type information.\nstring, required\n\n\n--reference_var_gene_names\nThe name of the adata var column in the reference data containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--reference_var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted information.\nstring, default: \"random_forest_pred\"\n\n\n--output_obs_probability\nIn which .obs slots to store the probability of the predictions.\nstring, default: \"random_forest_probability\"\n\n\n\n\n\nModel arguments\nModel arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--model\nPretrained model in pkl format. If not provided, the model will be trained on the reference data and –reference should be provided.\nfile, example: \"pretrained_model.pkl\"\n\n\n--n_estimators\nNumber of trees in the random forest.\ninteger, default: 100\n\n\n--max_depth\nMaximum depth of the trees in the random forest. If not provided, the nodes are expanded until all leaves only contain a single sample.\ninteger\n\n\n--criterion\nThe function to measure the quality of a split.\nstring, default: \"gini\"\n\n\n--class_weight\nWeights associated with classes. The balanced mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data. The balanced_subsample mode is the same as balanced except that weights are computed based on the bootstrap sample for every tree grown. The uniform mode gives all classes a weight of one.\nstring, default: \"balanced_subsample\"\n\n\n--max_features\nThe number of features to consider when looking for the best split. The value can either be a positive integer or one of sqrt, log2 or all. If integer: consider max_features features at each split. If sqrt: max_features is the squareroot of all input features. If log2: max_features is the log2 of all input features. If all: max features equals all input features.\nstring, default: \"200\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Random forest annotation"
    ]
  },
  {
    "objectID": "components/modules/annotate/random_forest_annotation.html#authors",
    "href": "components/modules/annotate/random_forest_annotation.html#authors",
    "title": "Random forest annotation",
    "section": "Authors",
    "text": "Authors\n\nJakub Majercik   (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Random forest annotation"
    ]
  },
  {
    "objectID": "components/modules/annotate/onclass.html",
    "href": "components/modules/annotate/onclass.html",
    "title": "Onclass",
    "section": "",
    "text": "ID: onclass\nNamespace: annotate\n\n\n\nSource\nIt uses the Cell Ontology to capture the cell type similarity. These similarities enable OnClass to annotate cell types that are never seen in the training data",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Onclass"
    ]
  },
  {
    "objectID": "components/modules/annotate/onclass.html#example-commands",
    "href": "components/modules/annotate/onclass.html#example-commands",
    "title": "Onclass",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/annotate/onclass/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# input_var_gene_names: \"foo\"\ninput_reference_gene_overlap: 100\n\n# Ongoloty\ncl_nlp_emb_file: # please fill in - example: \"path/to/file\"\ncl_ontology_file: # please fill in - example: \"path/to/file\"\ncl_obo_file: # please fill in - example: \"path/to/file\"\n\n# Reference\n# reference: \"reference.h5mu\"\n# reference_layer: \"foo\"\nreference_obs_target: # please fill in - example: \"cell_ontology_class\"\n# reference_var_gene_names: \"foo\"\n# reference_var_input: \"foo\"\nunknown_celltype: \"Unknown\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_obs_predictions: \"onclass_pred\"\noutput_obs_probability: \"onclass_prob\"\n\n# Model arguments\n# model: \"foo\"\nmax_iter: 30\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/annotate/onclass/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Onclass"
    ]
  },
  {
    "objectID": "components/modules/annotate/onclass.html#argument-groups",
    "href": "components/modules/annotate/onclass.html#argument-groups",
    "title": "Onclass",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe input (query) data to be labeled. Should be a .h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--input_layer\nThe layer in the input data to be used for cell type annotation if .X is not to be used.\nstring\n\n\n--input_var_gene_names\nThe name of the adata var column in the input data containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--input_reference_gene_overlap\nThe minimum number of genes present in both the reference and query datasets.\ninteger, default: 100\n\n\n\n\n\nOngoloty\nOntology input files\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cl_nlp_emb_file\nThe .nlp.emb file with the cell type embeddings.\nfile, required\n\n\n--cl_ontology_file\nThe .ontology file with the cell type ontology.\nfile, required\n\n\n--cl_obo_file\nThe .obo file with the cell type ontology.\nfile, required\n\n\n\n\n\nReference\nArguments related to the reference dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train the CellTypist classifiers on. Only required if a pre-trained –model is not provided.\nfile, example: \"reference.h5mu\"\n\n\n--reference_layer\nThe layer in the reference data to be used for cell type annotation if .X is not to be used.\nstring\n\n\n--reference_obs_target\nThe name of the adata obs column in the reference data containing cell type annotations.\nstring, required, example: \"cell_ontology_class\"\n\n\n--reference_var_gene_names\nThe name of the adata var column in the reference data containing gene names; when no gene_name_layer is provided, the var index will be used.\nstring\n\n\n--reference_var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n--unknown_celltype\nLabel for unknown cell types.\nstring, default: \"Unknown\"\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted information.\nstring, default: \"onclass_pred\"\n\n\n--output_obs_probability\nIn which .obs slots to store the probability of the predictions.\nstring, default: \"onclass_prob\"\n\n\n\n\n\nModel arguments\nModel arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--model\n“Pretrained model path without a file extension. If not provided, the model will be trained on the reference data and –reference should be provided. The path namespace should contain: - a .npz or .pkl file - a .data file - a .meta file - a .index file e.g. /path/to/model/pretrained_model_target1 as saved by OnClass.”\nstring\n\n\n--max_iter\nMaximum number of iterations for training the model.\ninteger, default: 30",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Onclass"
    ]
  },
  {
    "objectID": "components/modules/annotate/onclass.html#authors",
    "href": "components/modules/annotate/onclass.html#authors",
    "title": "Onclass",
    "section": "Authors",
    "text": "Authors\n\nJakub Majercik   (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Onclass"
    ]
  },
  {
    "objectID": "components/modules/annotate/popv.html",
    "href": "components/modules/annotate/popv.html",
    "title": "Popv",
    "section": "",
    "text": "ID: popv\nNamespace: annotate\n\n\n\nSource\nNote that this is a one-shot version of PopV.",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Popv"
    ]
  },
  {
    "objectID": "components/modules/annotate/popv.html#example-commands",
    "href": "components/modules/annotate/popv.html#example-commands",
    "title": "Popv",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/annotate/popv/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# input_obs_batch: \"foo\"\n# input_var_subset: \"foo\"\n# input_obs_label: \"foo\"\nunknown_celltype_label: \"unknown\"\n\n# Reference\nreference: # please fill in - example: \"TS_Bladder_filtered.h5ad\"\n# reference_layer: \"foo\"\nreference_obs_label: \"cell_ontology_class\"\nreference_obs_batch: \"donor_assay\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Arguments\nmethods: # please fill in - example: [\"knn_on_scvi\", \"scanvi\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/annotate/popv/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Popv"
    ]
  },
  {
    "objectID": "components/modules/annotate/popv.html#argument-groups",
    "href": "components/modules/annotate/popv.html#argument-groups",
    "title": "Popv",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nArguments related to the input (aka query) dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--input_layer\nWhich layer to use. If no value is provided, the counts are assumed to be in the .X slot. Otherwise, count data is expected to be in .layers[input_layer].\nstring\n\n\n--input_obs_batch\nKey in obs field of input adata for batch information. If no value is provided, batch label is assumed to be unknown.\nstring\n\n\n--input_var_subset\nSubset the input object with this column.\nstring\n\n\n--input_obs_label\nKey in obs field of input adata for label information. This is only used for training scANVI. Unlabelled cells should be set to \"unknown_celltype_label\".\nstring\n\n\n--unknown_celltype_label\nIf input_obs_label is specified, cells with this value will be treated as unknown and will be predicted by the model.\nstring, default: \"unknown\"\n\n\n\n\n\nReference\nArguments related to the reference dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nUser-provided reference tissue. The data that will be used as reference to call cell types.\nfile, required, example: \"TS_Bladder_filtered.h5ad\"\n\n\n--reference_layer\nWhich layer to use. If no value is provided, the counts are assumed to be in the .X slot. Otherwise, count data is expected to be in .layers[reference_layer].\nstring\n\n\n--reference_obs_label\nKey in obs field of reference AnnData with cell-type information.\nstring, default: \"cell_ontology_class\"\n\n\n--reference_obs_batch\nKey in obs field of input adata for batch information.\nstring, default: \"donor_assay\"\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n\n\n\nArguments\nOther arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--methods\nMethods to call cell types. By default, runs to knn_on_scvi and scanvi.\nList of string, required, example: \"knn_on_scvi\", \"scanvi\", multiple_sep: \";\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Popv"
    ]
  },
  {
    "objectID": "components/modules/annotate/popv.html#authors",
    "href": "components/modules/annotate/popv.html#authors",
    "title": "Popv",
    "section": "Authors",
    "text": "Authors\n\nMatthias Beyens    (author)\nRobrecht Cannoodt    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Annotate",
      "Popv"
    ]
  },
  {
    "objectID": "components/modules/reference/build_cellranger_arc_reference.html",
    "href": "components/modules/reference/build_cellranger_arc_reference.html",
    "title": "Build cellranger arc reference",
    "section": "",
    "text": "ID: build_cellranger_arc_reference\nNamespace: reference\n\n\n\nSource\nCreates a new folder named after the genome.",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build cellranger arc reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_cellranger_arc_reference.html#example-commands",
    "href": "components/modules/reference/build_cellranger_arc_reference.html#example-commands",
    "title": "Build cellranger arc reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/reference/build_cellranger_arc_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ngenome_fasta: # please fill in - example: \"genome_sequence.fa.gz\"\nannotation_gtf: # please fill in - example: \"annotation.gtf.gz\"\n# motifs_file: \"JASPAR2024_CORE_non-redundant_pfms_jaspar.txt.modified\"\nnon_nuclear_contigs: [\"chrM\"]\n# output: \"$id.$key.output\"\ngenome: # please fill in - example: \"output\"\n# organism: \"foo\"\n# subset_regex: \"(ERCC-00002|chr1)\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/build_cellranger_arc_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build cellranger arc reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_cellranger_arc_reference.html#argument-group",
    "href": "components/modules/reference/build_cellranger_arc_reference.html#argument-group",
    "title": "Build cellranger arc reference",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nReference genome fasta.\nfile, required, example: \"genome_sequence.fa.gz\"\n\n\n--annotation_gtf\nReference annotation.\nfile, required, example: \"annotation.gtf.gz\"\n\n\n--motifs_file\nTranscription factor motifs in JASPAR format. See https://support.10xgenomics.com/single-cell-multiome-atac-gex/software/pipelines/latest/advanced/references\nfile, example: \"JASPAR2024_CORE_non-redundant_pfms_jaspar.txt.modified\"\n\n\n--non_nuclear_contigs\nName(s) of contig(s) that do not have any chromatin structure, for example, mitochondria or plastids. These contigs are excluded from peak calling since the entire contig will be “open” due to a lack of chromatin structure. Leave empty if there are no such contigs.\nList of string, default: \"chrM\", example: \"chrM\", multiple_sep: \";\"\n\n\n--output\nOutput folder\nfile, required, example: \"cellranger_reference\"\n\n\n--genome\nName of the genome. This will be the name of the intermediate output folder\nstring, required, default: \"output\", example: \"GRCh38\"\n\n\n--organism\nName of the organism. This is displayed in the web summary but is otherwise not used in the analysis.\nstring\n\n\n--subset_regex\nWill subset the reference chromosomes using the given regex.\nstring, example: \"(ERCC-00002&#124;chr1)\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build cellranger arc reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_cellranger_arc_reference.html#authors",
    "href": "components/modules/reference/build_cellranger_arc_reference.html#authors",
    "title": "Build cellranger arc reference",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build cellranger arc reference"
    ]
  },
  {
    "objectID": "components/modules/reference/cellranger_mkgtf.html",
    "href": "components/modules/reference/cellranger_mkgtf.html",
    "title": "Cellranger mkgtf",
    "section": "",
    "text": "ID: cellranger_mkgtf\nNamespace: reference\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Cellranger mkgtf"
    ]
  },
  {
    "objectID": "components/modules/reference/cellranger_mkgtf.html#example-commands",
    "href": "components/modules/reference/cellranger_mkgtf.html#example-commands",
    "title": "Cellranger mkgtf",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/reference/cellranger_mkgtf/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput_gtf: # please fill in - example: \"transcriptome_annotation.gtf.gz\"\n# output_gtf: \"$id.$key.output_gtf.gz\"\nattribute: # please fill in - example: [\"gene_type:transcribed_unprocessed_pseudogene\", \"gene_type:miRNA\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/cellranger_mkgtf/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Cellranger mkgtf"
    ]
  },
  {
    "objectID": "components/modules/reference/cellranger_mkgtf.html#argument-group",
    "href": "components/modules/reference/cellranger_mkgtf.html#argument-group",
    "title": "Cellranger mkgtf",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_gtf\nReference GTF annotation.\nfile, required, example: \"transcriptome_annotation.gtf.gz\"\n\n\n--output_gtf\nOutput GTF file.\nfile, required, example: \"output.gtf.gz\"\n\n\n--attribute\nKey-value pair in attributes field to be kept in the GTF file of the format attribute:attribute_value.\nList of string, required, example: \"gene_type:transcribed_unprocessed_pseudogene\", \"gene_type:miRNA\", multiple_sep: \";\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Cellranger mkgtf"
    ]
  },
  {
    "objectID": "components/modules/reference/cellranger_mkgtf.html#authors",
    "href": "components/modules/reference/cellranger_mkgtf.html#authors",
    "title": "Cellranger mkgtf",
    "section": "Authors",
    "text": "Authors\n\nJakub Majercik   (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Cellranger mkgtf"
    ]
  },
  {
    "objectID": "components/modules/reference/build_star_reference.html",
    "href": "components/modules/reference/build_star_reference.html",
    "title": "Build star reference",
    "section": "",
    "text": "ID: build_star_reference\nNamespace: reference\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build star reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_star_reference.html#example-commands",
    "href": "components/modules/reference/build_star_reference.html#example-commands",
    "title": "Build star reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/reference/build_star_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ngenome_fasta: # please fill in - example: [\"chr1.fasta\", \"chr2.fasta\"]\n# transcriptome_gtf: \"path/to/file\"\n# output: \"$id.$key.output\"\n\n# Genome indexing arguments\ngenomeSAindexNbases: 14\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/build_star_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build star reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_star_reference.html#argument-groups",
    "href": "components/modules/reference/build_star_reference.html#argument-groups",
    "title": "Build star reference",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nThe fasta files to be included in the reference. Corresponds to the –genomeFastaFiles argument in the STAR command.\nList of file, required, example: \"chr1.fasta\", \"chr2.fasta\", multiple_sep: \";\"\n\n\n--transcriptome_gtf\nSpecifies the path to the file with annotated transcripts in the standard GTF format. STAR will extract splice junctions from this file and use them to greatly improve accuracy of the mapping. Corresponds to the –sjdbGTFfile argument in the STAR command.\nfile\n\n\n--output\nPath to output directory. Corresponds to the –genomeDir argument in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nGenome indexing arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeSAindexNbases\nLength (bases) of the SA pre-indexing string. Typically between 10 and 15. Longer strings will use much more memory, but allow faster searches. For small genomes, the parameter {genomeSAindexNbases must be scaled down to min(14, log2(GenomeLength)/2 - 1).\ninteger, default: 14",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build star reference"
    ]
  },
  {
    "objectID": "components/modules/reference/build_star_reference.html#authors",
    "href": "components/modules/reference/build_star_reference.html#authors",
    "title": "Build star reference",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Reference",
      "Build star reference"
    ]
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html",
    "href": "components/modules/metadata/grep_annotation_column.html",
    "title": "Grep annotation column",
    "section": "",
    "text": "ID: grep_annotation_column\nNamespace: metadata\n\n\n\nSource\nThe annotation matrix can originate from either a modality, or all modalities (global .var or .obs)",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Grep annotation column"
    ]
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html#example-commands",
    "href": "components/modules/metadata/grep_annotation_column.html#example-commands",
    "title": "Grep annotation column",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/metadata/grep_annotation_column/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"sample_path\"\n# input_column: \"foo\"\n# input_layer: \"foo\"\nmodality: # please fill in - example: \"rna\"\n# matrix: \"var\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_match_column: # please fill in - example: \"foo\"\n# output_fraction_column: \"foo\"\n\n# Query options\nregex_pattern: # please fill in - example: \"^[mM][tT]-\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/grep_annotation_column/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Grep annotation column"
    ]
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html#argument-groups",
    "href": "components/modules/metadata/grep_annotation_column.html#argument-groups",
    "title": "Grep annotation column",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nArguments related to the input dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the input .h5mu.\nfile, required, example: \"sample_path\"\n\n\n--input_column\nColumn to query. If not specified, use .var_names or .obs_names, depending on the value of –matrix\nstring\n\n\n--input_layer\nInput data to use when calculating fraction of observations that match with the query. Only used when –output_fraction_column is provided. If not specified, .X is used.\nstring\n\n\n--modality\nWhich modality to get the annotation matrix from.\nstring, required, example: \"rna\"\n\n\n--matrix\nMatrix to fetch the column from that will be searched.\nstring, example: \"var\"\n\n\n\n\n\nOutputs\nArguments related to how the output will be written.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\n\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_match_column\nName of the column to write the result to.\nstring, required\n\n\n--output_fraction_column\nFor the opposite axis, name of the column to write the fraction of observations that matches to the pattern.\nstring\n\n\n\n\n\nQuery options\nOptions related to the query\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--regex_pattern\nRegex to use to match with the input column.\nstring, required, example: \"^[mM][tT]-\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Grep annotation column"
    ]
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html#authors",
    "href": "components/modules/metadata/grep_annotation_column.html#authors",
    "title": "Grep annotation column",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Grep annotation column"
    ]
  },
  {
    "objectID": "components/modules/metadata/join_csv.html",
    "href": "components/modules/metadata/join_csv.html",
    "title": "Join csv",
    "section": "",
    "text": "ID: join_csv\nNamespace: metadata\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Join csv"
    ]
  },
  {
    "objectID": "components/modules/metadata/join_csv.html#example-commands",
    "href": "components/modules/metadata/join_csv.html#example-commands",
    "title": "Join csv",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/metadata/join_csv/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# MuData Input\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# obs_key: \"foo\"\n# var_key: \"foo\"\n\n# MuData Output\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Metadata Input\ninput_csv: # please fill in - example: \"metadata.csv\"\ncsv_key: \"id\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/join_csv/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Join csv"
    ]
  },
  {
    "objectID": "components/modules/metadata/join_csv.html#argument-groups",
    "href": "components/modules/metadata/join_csv.html#argument-groups",
    "title": "Join csv",
    "section": "Argument groups",
    "text": "Argument groups\n\nMuData Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obs_key\nObs column name where the sample id can be found for each observation to join on. Useful when adding metadata to concatenated samples. Mutually exclusive with --var_key.”\nstring\n\n\n--var_key\nVar column name where the sample id can be found for each variable to join on. Mutually exclusive with --obs_key.”\nstring\n\n\n\n\n\nMuData Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n\n\n\nMetadata Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_csv\n.csv file containing metadata\nfile, required, example: \"metadata.csv\"\n\n\n--csv_key\ncolumn of the the csv that corresponds to the sample id.\nstring, default: \"id\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Join csv"
    ]
  },
  {
    "objectID": "components/modules/metadata/join_csv.html#authors",
    "href": "components/modules/metadata/join_csv.html#authors",
    "title": "Join csv",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Metadata",
      "Join csv"
    ]
  },
  {
    "objectID": "components/modules/transfer/publish.html",
    "href": "components/modules/transfer/publish.html",
    "title": "Publish",
    "section": "",
    "text": "ID: publish\nNamespace: transfer\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Transfer",
      "Publish"
    ]
  },
  {
    "objectID": "components/modules/transfer/publish.html#example-commands",
    "href": "components/modules/transfer/publish.html#example-commands",
    "title": "Publish",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/transfer/publish/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transfer/publish/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Transfer",
      "Publish"
    ]
  },
  {
    "objectID": "components/modules/transfer/publish.html#argument-group",
    "href": "components/modules/transfer/publish.html#argument-group",
    "title": "Publish",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput filename\nfile, required\n\n\n--output\nOutput filename\nfile, required",
    "crumbs": [
      "Reference",
      "Modules",
      "Transfer",
      "Publish"
    ]
  },
  {
    "objectID": "components/modules/transfer/publish.html#authors",
    "href": "components/modules/transfer/publish.html#authors",
    "title": "Publish",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Transfer",
      "Publish"
    ]
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html",
    "title": "From bd to 10x molecular barcode tags",
    "section": "",
    "text": "ID: from_bd_to_10x_molecular_barcode_tags\nNamespace: convert\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From bd to 10x molecular barcode tags"
    ]
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#example-commands",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#example-commands",
    "title": "From bd to 10x molecular barcode tags",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/convert/from_bd_to_10x_molecular_barcode_tags/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.bam\"\n# output: \"$id.$key.output.sam\"\nbam: false\n# threads: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_bd_to_10x_molecular_barcode_tags/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From bd to 10x molecular barcode tags"
    ]
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#argument-group",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#argument-group",
    "title": "From bd to 10x molecular barcode tags",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput SAM or BAM file.\nfile, required, example: \"input.bam\"\n\n\n--output\nOutput alignment file.\nfile, example: \"output.sam\"\n\n\n--bam\nOutput a BAM file.\nboolean_true\n\n\n--threads\nNumber of threads\ninteger",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From bd to 10x molecular barcode tags"
    ]
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#authors",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#authors",
    "title": "From bd to 10x molecular barcode tags",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From bd to 10x molecular barcode tags"
    ]
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html",
    "href": "components/modules/convert/velocyto_to_h5mu.html",
    "title": "Velocyto to h5mu",
    "section": "",
    "text": "ID: velocyto_to_h5mu\nNamespace: convert\n\n\n\nSource\nIf an input h5mu file is also provided, the velocity h5ad object will get added to that h5mu instead.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "Velocyto to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html#example-commands",
    "href": "components/modules/convert/velocyto_to_h5mu.html#example-commands",
    "title": "Velocyto to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/convert/velocyto_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput_loom: # please fill in - example: \"input.loom\"\n# input_h5mu: \"input.h5mu\"\nmodality: \"rna_velocity\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nlayer_spliced: \"velo_spliced\"\nlayer_unspliced: \"velo_unspliced\"\nlayer_ambiguous: \"velo_ambiguous\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/velocyto_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "Velocyto to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html#argument-groups",
    "href": "components/modules/convert/velocyto_to_h5mu.html#argument-groups",
    "title": "Velocyto to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_loom\nPath to the input loom file.\nfile, required, example: \"input.loom\"\n\n\n--input_h5mu\nIf a MuData file is provided,\nfile, example: \"input.h5mu\"\n\n\n--modality\nThe name of the modality to operate on.\nstring, default: \"rna_velocity\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nPath to the output MuData file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--layer_spliced\nOutput layer for the spliced reads.\nstring, default: \"velo_spliced\"\n\n\n--layer_unspliced\nOutput layer for the unspliced reads.\nstring, default: \"velo_unspliced\"\n\n\n--layer_ambiguous\nOutput layer for the ambiguous reads.\nstring, default: \"velo_ambiguous\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "Velocyto to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html#authors",
    "href": "components/modules/convert/velocyto_to_h5mu.html#authors",
    "title": "Velocyto to h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer, author)\nRobrecht Cannoodt    (author)\nAngela Oliveira Pisco    (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "Velocyto to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html",
    "title": "From 10xmtx to h5mu",
    "section": "",
    "text": "ID: from_10xmtx_to_h5mu\nNamespace: convert\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From 10xmtx to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html#example-commands",
    "title": "From 10xmtx to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/convert/from_10xmtx_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input_dir_containing_gz_files\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_10xmtx_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From 10xmtx to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html#argument-group",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html#argument-group",
    "title": "From 10xmtx to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput mtx folder\nfile, required, example: \"input_dir_containing_gz_files\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From 10xmtx to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html#authors",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html#authors",
    "title": "From 10xmtx to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From 10xmtx to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html",
    "title": "From 10xh5 to h5mu",
    "section": "",
    "text": "ID: from_10xh5_to_h5mu\nNamespace: convert\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From 10xh5 to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html#example-commands",
    "title": "From 10xh5 to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/convert/from_10xh5_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"raw_feature_bc_matrix.h5\"\n# input_metrics_summary: \"metrics_cellranger.h5\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_metrics: \"metrics_cellranger\"\n\n# Arguments\n# min_genes: 100\n# min_counts: 1000\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_10xh5_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From 10xh5 to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html#argument-groups",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html#argument-groups",
    "title": "From 10xh5 to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nA 10x h5 file as generated by Cell Ranger.\nfile, required, example: \"raw_feature_bc_matrix.h5\"\n\n\n--input_metrics_summary\nA metrics summary csv file as generated by Cell Ranger.\nfile, example: \"metrics_cellranger.h5\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_cellranger\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_genes\nMinimum number of counts required for a cell to pass filtering.\ninteger, example: 100\n\n\n--min_counts\nMinimum number of genes expressed required for a cell to pass filtering.\ninteger, example: 1000",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From 10xh5 to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html#authors",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html#authors",
    "title": "From 10xh5 to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From 10xh5 to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html",
    "title": "From bdrhap to h5mu",
    "section": "",
    "text": "ID: from_bdrhap_to_h5mu\nNamespace: convert\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From bdrhap to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html#example-commands",
    "title": "From bdrhap to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/convert/from_bdrhap_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"my_id\"\ninput: # please fill in - example: \"sample.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_bdrhap_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From bdrhap to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html#argument-groups",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html#argument-groups",
    "title": "From bdrhap to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nA sample ID.\nstring, required, example: \"my_id\"\n\n\n--input\nThe output h5mu of a BD Rhapsody workflow.\nfile, required, example: \"sample.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From bdrhap to h5mu"
    ]
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html#authors",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html#authors",
    "title": "From bdrhap to h5mu",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (author, maintainer)\nRobrecht Cannoodt    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Convert",
      "From bdrhap to h5mu"
    ]
  },
  {
    "objectID": "components/modules/scgpt/pad_tokenize.html",
    "href": "components/modules/scgpt/pad_tokenize.html",
    "title": "Pad tokenize",
    "section": "",
    "text": "ID: pad_tokenize\nNamespace: scgpt\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Pad tokenize"
    ]
  },
  {
    "objectID": "components/modules/scgpt/pad_tokenize.html#example-commands",
    "href": "components/modules/scgpt/pad_tokenize.html#example-commands",
    "title": "Pad tokenize",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/scgpt/pad_tokenize/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nmodel_vocab: # please fill in - example: \"vocab.json\"\n# var_gene_names: \"foo\"\nvar_input: \"id_in_vocab\"\ninput_obsm_binned_counts: \"binned_counts\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_gene_tokens: \"gene_id_tokens\"\nobsm_tokenized_values: \"values_tokenized\"\nobsm_padding_mask: \"padding_mask\"\n\n# Arguments\npad_token: \"&lt;pad&gt;\"\npad_value: -2\n# max_seq_len: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/scgpt/pad_tokenize/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Pad tokenize"
    ]
  },
  {
    "objectID": "components/modules/scgpt/pad_tokenize.html#argument-groups",
    "href": "components/modules/scgpt/pad_tokenize.html#argument-groups",
    "title": "Pad tokenize",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe input h5mu file of pre-processed data.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--model_vocab\nPath to model vocabulary file.\nfile, required, example: \"vocab.json\"\n\n\n--var_gene_names\nThe name of the .var column containing gene names. When no gene_name_layer is provided, the .var index will be used.\nstring\n\n\n--var_input\nThe name of the adata.var column containing boolean mask for vocabulary-cross checked and/or highly variable genes.\nstring, default: \"id_in_vocab\"\n\n\n--input_obsm_binned_counts\nThe name of the .obsm field containing the binned counts to be padded and tokenized.\nstring, default: \"binned_counts\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe output h5mu file containing obsm arrays for gene tokens, tokenized data and padding mask.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression type for the output file.\nstring, example: \"gzip\"\n\n\n--obsm_gene_tokens\nThe key of the .obsm array containing the gene token ids\nstring, default: \"gene_id_tokens\", example: \"values.pt\"\n\n\n--obsm_tokenized_values\nThe key of the .obsm array containing the count values of the tokenized genes\nstring, default: \"values_tokenized\"\n\n\n--obsm_padding_mask\nThe key of the .obsm array containing the padding mask.\nstring, default: \"padding_mask\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pad_token\nToken used for padding.\nstring, default: \"&lt;pad&gt;\"\n\n\n--pad_value\nThe value of the padding token.\ninteger, default: -2\n\n\n--max_seq_len\nThe maximum sequence length of the tokenized data. Defaults to the number of features if not provided.\ninteger",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Pad tokenize"
    ]
  },
  {
    "objectID": "components/modules/scgpt/pad_tokenize.html#authors",
    "href": "components/modules/scgpt/pad_tokenize.html#authors",
    "title": "Pad tokenize",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (maintainer, author)\nElizabeth Mlynarski (author)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Pad tokenize"
    ]
  },
  {
    "objectID": "components/modules/scgpt/cell_type_annotation.html",
    "href": "components/modules/scgpt/cell_type_annotation.html",
    "title": "Cell type annotation",
    "section": "",
    "text": "ID: cell_type_annotation\nNamespace: scgpt\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Cell type annotation"
    ]
  },
  {
    "objectID": "components/modules/scgpt/cell_type_annotation.html#example-commands",
    "href": "components/modules/scgpt/cell_type_annotation.html#example-commands",
    "title": "Cell type annotation",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/scgpt/cell_type_annotation/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Model input\nmodel: # please fill in - example: \"best_model.pt\"\nmodel_config: # please fill in - example: \"args.json\"\nmodel_vocab: # please fill in - example: \"vocab.json\"\nfinetuned_checkpoints_key: \"model_state_dict\"\nlabel_mapper_key: \"id_to_class\"\n\n# Query input\ninput: # please fill in - example: \"scgpt_preprocess_ouput.h5mu\"\nmodality: \"rna\"\n# obs_batch_label: \"foo\"\nobsm_gene_tokens: \"gene_id_tokens\"\nobsm_tokenized_values: \"values_tokenized\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\noutput_compression: \"gzip\"\noutput_obs_predictions: \"scgpt_pred\"\noutput_obs_probability: \"scgpt_probability\"\n\n# Arguments\npad_token: \"&lt;pad&gt;\"\npad_value: -2\nn_input_bins: 51\nbatch_size: 64\ndsbn: true\n# seed: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/scgpt/cell_type_annotation/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Cell type annotation"
    ]
  },
  {
    "objectID": "components/modules/scgpt/cell_type_annotation.html#argument-groups",
    "href": "components/modules/scgpt/cell_type_annotation.html#argument-groups",
    "title": "Cell type annotation",
    "section": "Argument groups",
    "text": "Argument groups\n\nModel input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--model\nThe model file containing checkpoints and cell type label mapper.\nfile, required, example: \"best_model.pt\"\n\n\n--model_config\nThe model configuration file.\nfile, required, example: \"args.json\"\n\n\n--model_vocab\nModel vocabulary file directory.\nfile, required, example: \"vocab.json\"\n\n\n--finetuned_checkpoints_key\nKey in the model file containing the pretrained checkpoints.\nstring, default: \"model_state_dict\"\n\n\n--label_mapper_key\nKey in the model file containing the cell type class to label mapper dictionary.\nstring, default: \"id_to_class\"\n\n\n\n\n\nQuery input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe input h5mu file containing of data that have been pre-processed (normalized, binned, genes cross-checked and tokenized).\nfile, required, example: \"scgpt_preprocess_ouput.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obs_batch_label\nThe name of the adata.obs column containing the batch labels. Required if dsbn is set to true.\nstring\n\n\n--obsm_gene_tokens\nThe key of the .obsm array containing the gene token ids\nstring, default: \"gene_id_tokens\"\n\n\n--obsm_tokenized_values\nThe key of the .obsm array containing the count values of the tokenized genes\nstring, default: \"values_tokenized\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe output mudata file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression algorithm to use for the output h5mu file.\nstring, default: \"gzip\", example: \"gzip\"\n\n\n--output_obs_predictions\nThe name of the adata.obs column to write predicted cell type labels to.\nstring, default: \"scgpt_pred\"\n\n\n--output_obs_probability\nThe name of the adata.obs column to write the probabilities of the predicted cell type labels to.\nstring, default: \"scgpt_probability\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pad_token\nThe padding token used in the model.\nstring, default: \"&lt;pad&gt;\"\n\n\n--pad_value\nThe value of the padding.\ninteger, default: -2\n\n\n--n_input_bins\nThe number of input bins.\ninteger, default: 51\n\n\n--batch_size\nThe batch size.\ninteger, default: 64\n\n\n--dsbn\nWhether to use domain-specific batch normalization.\nboolean, default: TRUE\n\n\n--seed\nSeed for random number generation. If not specified, no seed is used.\ninteger",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Cell type annotation"
    ]
  },
  {
    "objectID": "components/modules/scgpt/cell_type_annotation.html#authors",
    "href": "components/modules/scgpt/cell_type_annotation.html#authors",
    "title": "Cell type annotation",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (maintainer, author)\nJakub Majercik   (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Cell type annotation"
    ]
  },
  {
    "objectID": "components/modules/scgpt/binning.html",
    "href": "components/modules/scgpt/binning.html",
    "title": "Binning",
    "section": "",
    "text": "ID: binning\nNamespace: scgpt\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Binning"
    ]
  },
  {
    "objectID": "components/modules/scgpt/binning.html#example-commands",
    "href": "components/modules/scgpt/binning.html#example-commands",
    "title": "Binning",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/scgpt/binning/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\nvar_input: \"id_in_vocab\"\nn_input_bins: 51\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_obsm_binned_counts: \"binned_counts\"\n# seed: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/scgpt/binning/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Binning"
    ]
  },
  {
    "objectID": "components/modules/scgpt/binning.html#argument-groups",
    "href": "components/modules/scgpt/binning.html#argument-groups",
    "title": "Binning",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nMudata layer (key from .layers) to use as input data for binning. If not specified, .X is used.\nstring\n\n\n--var_input\nThe name of the adata.var column containing boolean mask for vocabulary-cross checked and/or highly variable genes.\nstring, default: \"id_in_vocab\"\n\n\n--n_input_bins\nThe number of bins to discretize the data into. When no value is provided, data won’t be binned.\ninteger, default: 51\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe output h5mu file containing the binned data.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression algorithm to use for the output h5mu file.\nstring, example: \"gzip\"\n\n\n--output_obsm_binned_counts\nThe name of the adata layer to write the binned data to.\nstring, default: \"binned_counts\"\n\n\n--seed\nSeed for random number generation.\ninteger",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Binning"
    ]
  },
  {
    "objectID": "components/modules/scgpt/binning.html#authors",
    "href": "components/modules/scgpt/binning.html#authors",
    "title": "Binning",
    "section": "Authors",
    "text": "Authors\n\nDorien Roosen   (maintainer, author)\nElizabeth Mlynarski (author)\nWeiwei Schultz (contributor)",
    "crumbs": [
      "Reference",
      "Modules",
      "Scgpt",
      "Binning"
    ]
  },
  {
    "objectID": "components/modules/report/mermaid.html",
    "href": "components/modules/report/mermaid.html",
    "title": "Mermaid",
    "section": "",
    "text": "ID: mermaid\nNamespace: report\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Report",
      "Mermaid"
    ]
  },
  {
    "objectID": "components/modules/report/mermaid.html#example-commands",
    "href": "components/modules/report/mermaid.html#example-commands",
    "title": "Mermaid",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/report/mermaid/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output\"\n# output_format: \"foo\"\nwidth: 800\nheight: 600\nbackground_color: \"white\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/report/mermaid/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Report",
      "Mermaid"
    ]
  },
  {
    "objectID": "components/modules/report/mermaid.html#argument-group",
    "href": "components/modules/report/mermaid.html#argument-group",
    "title": "Mermaid",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput directory\nfile, required\n\n\n--output\nGenerated network as output.\nfile, required\n\n\n--output_format\nOutput format for the generated image. By default will be inferred from the extension of the file specified with –output.\nstring\n\n\n--width\nWidth of the page\ninteger, default: 800\n\n\n--height\nHeight of the page\ninteger, default: 600\n\n\n--background_color\nBackground color for pngs/svgs (not pdfs)\nstring, default: \"white\", example: \"#F0F0F0\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Report",
      "Mermaid"
    ]
  },
  {
    "objectID": "components/modules/report/mermaid.html#authors",
    "href": "components/modules/report/mermaid.html#authors",
    "title": "Mermaid",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Report",
      "Mermaid"
    ]
  },
  {
    "objectID": "components/modules/qc/multiqc.html",
    "href": "components/modules/qc/multiqc.html",
    "title": "Multiqc",
    "section": "",
    "text": "ID: multiqc\nNamespace: qc\n\n\n\nSource\nIt searches a given directory for analysis logs and compiles a HTML report. It’s a general use tool, perfect for summarising the output from numerous bioinformatics tools",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Multiqc"
    ]
  },
  {
    "objectID": "components/modules/qc/multiqc.html#example-commands",
    "href": "components/modules/qc/multiqc.html#example-commands",
    "title": "Multiqc",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/qc/multiqc/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"input.txt\"]\n# output: \"$id.$key.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/qc/multiqc/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Multiqc"
    ]
  },
  {
    "objectID": "components/modules/qc/multiqc.html#argument-group",
    "href": "components/modules/qc/multiqc.html#argument-group",
    "title": "Multiqc",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInputs for MultiQC.\nList of file, required, example: \"input.txt\", multiple_sep: \";\"\n\n\n--output\nCreate report in the specified output directory.\nfile, required, example: \"report\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Multiqc"
    ]
  },
  {
    "objectID": "components/modules/qc/calculate_atac_qc_metrics.html",
    "href": "components/modules/qc/calculate_atac_qc_metrics.html",
    "title": "Calculate atac qc metrics",
    "section": "",
    "text": "ID: calculate_atac_qc_metrics\nNamespace: qc\n\n\n\nSource\nThe metrics are comparable to what scanpy.pp.calculate_qc_metrics output, although they have slightly different names:\nObs metrics (name in this component -&gt; name in scanpy): - n_features_per_cell -&gt; n_genes_by_counts - total_fragment_counts -&gt; total_counts",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Calculate atac qc metrics"
    ]
  },
  {
    "objectID": "components/modules/qc/calculate_atac_qc_metrics.html#example-commands",
    "href": "components/modules/qc/calculate_atac_qc_metrics.html#example-commands",
    "title": "Calculate atac qc metrics",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/qc/calculate_atac_qc_metrics/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\n# fragments_path: \"fragments.tsv.gz\"\nmodality: \"atac\"\n# layer: \"raw_counts\"\nn_fragments_for_nucleosome_signal: 100000\nnuc_signal_threshold: 2.0\nn_tss: 3000\ntss_threshold: 1.5\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/qc/calculate_atac_qc_metrics/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Calculate atac qc metrics"
    ]
  },
  {
    "objectID": "components/modules/qc/calculate_atac_qc_metrics.html#argument-groups",
    "href": "components/modules/qc/calculate_atac_qc_metrics.html#argument-groups",
    "title": "Calculate atac qc metrics",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--fragments_path\nPath to the fragments file. If not provided and not present in the input h5mu file, the nucleosome signal and TSS enrichment score will not be calculated.\nfile, example: \"fragments.tsv.gz\"\n\n\n--modality\n\nstring, default: \"atac\"\n\n\n--layer\nLayer at .layers to use for the calculation. If not provided, .X is used.\nstring, example: \"raw_counts\"\n\n\n--n_fragments_for_nucleosome_signal\nNumber of fragments to use per cell for nucleosome signal calculation. Takes very long to calculate, for a test run lower value (e.g. 10e3) is recommended. See https://www.sc-best-practices.org/chromatin_accessibility/quality_control.html#nucleosome-signal for more information\ninteger, default: 100000\n\n\n--nuc_signal_threshold\nThreshold for nucleosome signal. Cells with nucleosome signal above this threshold will be marked as low quality (“NS_FAIL”), otherwise they will be marked “NS_PASS”.\ndouble, default: 2\n\n\n--n_tss\nNumber of the transcription start sites to calculate TSS enrichment score. See https://www.sc-best-practices.org/chromatin_accessibility/quality_control.html#tss-enrichment for more information\ninteger, default: 3000\n\n\n--tss_threshold\nThreshold for TSS enrichment score. Cells with TSS enrichment score below this threshold will be marked as low quality (“TSS_FAIL”) otherwise they will be marked as “TSS_PASS”.\ndouble, default: 1.5\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Calculate atac qc metrics"
    ]
  },
  {
    "objectID": "components/modules/qc/calculate_atac_qc_metrics.html#authors",
    "href": "components/modules/qc/calculate_atac_qc_metrics.html#authors",
    "title": "Calculate atac qc metrics",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Qc",
      "Calculate atac qc metrics"
    ]
  },
  {
    "objectID": "components/modules/dimred/densmap.html",
    "href": "components/modules/dimred/densmap.html",
    "title": "Densmap",
    "section": "",
    "text": "ID: densmap\nNamespace: dimred\n\n\n\nSource\nIt is performed on the same inputs as UMAP",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Densmap"
    ]
  },
  {
    "objectID": "components/modules/dimred/densmap.html#example-commands",
    "href": "components/modules/dimred/densmap.html#example-commands",
    "title": "Densmap",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/dimred/densmap/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nuns_neighbors: \"neighbors\"\nobsm_pca: # please fill in - example: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_output: \"X_densmap\"\n\n# Arguments UMAP\nmin_dist: 0.5\nspread: 1.0\nnum_components: 2\nmax_iter: 0\nalpha: 1.0\ngamma: 1.0\nnegative_sample_rate: 5\ninit_pos: \"spectral\"\n\n# Arguments densMAP\nlambda: 2.0\nfraction: 0.3\nvar_shift: 0.1\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dimred/densmap/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Densmap"
    ]
  },
  {
    "objectID": "components/modules/dimred/densmap.html#argument-groups",
    "href": "components/modules/dimred/densmap.html#argument-groups",
    "title": "Densmap",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--uns_neighbors\nThe .uns neighbors slot as output by the find_neighbors component.\nstring, default: \"neighbors\"\n\n\n--obsm_pca\nThe slot in .obsm where the PCA results are stored.\nstring, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nThe .obsm key to use for storing the densMAP results..\nstring, default: \"X_densmap\"\n\n\n\n\n\nArguments UMAP\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_dist\nThe effective minimum distance between embedded points. Smaller values will result in a more clustered/clumped embedding where nearby points on the manifold are drawn closer together, while larger values will result on a more even dispersal of points. The value should be set relative to the spread value, which determines the scale at which embedded points will be spread out.\ndouble, default: 0.5\n\n\n--spread\nThe effective scale of embedded points. In combination with min_dist this determines how clustered/clumped the embedded points are.\ndouble, default: 1\n\n\n--num_components\nThe number of dimensions of the embedding.\ninteger, default: 2\n\n\n--max_iter\nThe number of iterations (epochs) of the optimization. Called n_epochs in the original UMAP. Default is set to 500 if neighbors[‘connectivities’].shape[0] &lt;= 10000, else 200.\ninteger, default: 0\n\n\n--alpha\nThe initial learning rate for the embedding optimization.\ndouble, default: 1\n\n\n--gamma\nWeighting applied to negative samples in low dimensional embedding optimization. Values higher than one will result in greater weight being given to negative samples.\ndouble, default: 1\n\n\n--negative_sample_rate\nThe number of negative samples to select per positive sample in the optimization process. Increasing this value will result in greater repulsive force being applied, greater optimization cost, but slightly more accuracy.\ninteger, default: 5\n\n\n--init_pos\nHow to initialize the low dimensional embedding. Called init in the original UMAP. Options are: * Any key from .obsm * 'paga': positions from paga() * 'spectral': use a spectral embedding of the graph * 'random': assign initial embedding positions at random.\nstring, default: \"spectral\"\n\n\n\n\n\nArguments densMAP\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--lambda\nControls the regularization weight of the density correlation term in densMAP. Higher values prioritize density preservation over the UMAP objective, and vice versa for values closer to zero. Setting this parameter to zero is equivalent to running the original UMAP algorithm.\ndouble, default: 2\n\n\n--fraction\nControls the fraction of epochs (between 0 and 1) where the density-augmented objective is used in densMAP. The first (1 - dens_frac) fraction of epochs optimize the original UMAP objective before introducing the density correlation term.\ndouble, default: 0.3\n\n\n--var_shift\nA small constant added to the variance of local radii in the embedding when calculating the density correlation objective to prevent numerical instability from dividing by a small number.\ndouble, default: 0.1",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Densmap"
    ]
  },
  {
    "objectID": "components/modules/dimred/densmap.html#authors",
    "href": "components/modules/dimred/densmap.html#authors",
    "title": "Densmap",
    "section": "Authors",
    "text": "Authors\n\nJakub Majercik   (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Densmap"
    ]
  },
  {
    "objectID": "components/modules/dimred/umap.html",
    "href": "components/modules/dimred/umap.html",
    "title": "Umap",
    "section": "",
    "text": "ID: umap\nNamespace: dimred\n\n\n\nSource\nBesides tending to be faster than tSNE, it optimizes the embedding such that it best reflects the topology of the data, which we represent throughout Scanpy using a neighborhood graph. tSNE, by contrast, optimizes the distribution of nearest-neighbor distances in the embedding such that these best match the distribution of distances in the high-dimensional space. We use the implementation of umap-learn [McInnes18]. For a few comparisons of UMAP with tSNE, see this preprint",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Umap"
    ]
  },
  {
    "objectID": "components/modules/dimred/umap.html#example-commands",
    "href": "components/modules/dimred/umap.html#example-commands",
    "title": "Umap",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/dimred/umap/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nuns_neighbors: \"neighbors\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_output: \"umap\"\n\n# Arguments\nmin_dist: 0.5\nspread: 1.0\nnum_components: 2\n# max_iter: 123\nalpha: 1.0\ngamma: 1.0\nnegative_sample_rate: 5\ninit_pos: \"spectral\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dimred/umap/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Umap"
    ]
  },
  {
    "objectID": "components/modules/dimred/umap.html#argument-groups",
    "href": "components/modules/dimred/umap.html#argument-groups",
    "title": "Umap",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--uns_neighbors\nThe .uns neighbors slot as output by the find_neighbors component.\nstring, default: \"neighbors\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nThe pre/postfix under which to store the UMAP results.\nstring, default: \"umap\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_dist\nThe effective minimum distance between embedded points. Smaller values will result in a more clustered/clumped embedding where nearby points on the manifold are drawn closer together, while larger values will result on a more even dispersal of points. The value should be set relative to the spread value, which determines the scale at which embedded points will be spread out.\ndouble, default: 0.5\n\n\n--spread\nThe effective scale of embedded points. In combination with min_dist this determines how clustered/clumped the embedded points are.\ndouble, default: 1\n\n\n--num_components\nThe number of dimensions of the embedding.\ninteger, default: 2\n\n\n--max_iter\nThe number of iterations (epochs) of the optimization. Called n_epochs in the original UMAP. Default is set to 500 if neighbors[‘connectivities’].shape[0] &lt;= 10000, else 200.\ninteger\n\n\n--alpha\nThe initial learning rate for the embedding optimization.\ndouble, default: 1\n\n\n--gamma\nWeighting applied to negative samples in low dimensional embedding optimization. Values higher than one will result in greater weight being given to negative samples.\ndouble, default: 1\n\n\n--negative_sample_rate\nThe number of negative edge/1-simplex samples to use per positive edge/1-simplex sample in optimizing the low dimensional embedding.\ninteger, default: 5\n\n\n--init_pos\nHow to initialize the low dimensional embedding. Called init in the original UMAP. Options are: * Any key from .obsm * 'paga': positions from paga() * 'spectral': use a spectral embedding of the graph * 'random': assign initial embedding positions at random.\nstring, default: \"spectral\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Umap"
    ]
  },
  {
    "objectID": "components/modules/dimred/umap.html#authors",
    "href": "components/modules/dimred/umap.html#authors",
    "title": "Umap",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Dimred",
      "Umap"
    ]
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html",
    "title": "Htseq count to h5mu",
    "section": "",
    "text": "ID: htseq_count_to_h5mu\nNamespace: mapping\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Htseq count to h5mu"
    ]
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html#example-commands",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html#example-commands",
    "title": "Htseq count to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/htseq_count_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\ninput_id: # please fill in - example: [\"foo\"]\ninput_counts: # please fill in - example: [\"counts.tsv\"]\nreference: # please fill in - example: \"gencode_v41_star\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/htseq_count_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Htseq count to h5mu"
    ]
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html#argument-groups",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html#argument-groups",
    "title": "Htseq count to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_id\nThe obs index for the counts\nList of string, required, example: \"foo\", multiple_sep: \";\"\n\n\n--input_counts\nThe counts as a TSV file as output by HTSeq.\nList of file, required, example: \"counts.tsv\", multiple_sep: \";\"\n\n\n--reference\nThe GTF file.\nfile, required, example: \"gencode_v41_star\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Htseq count to h5mu"
    ]
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html#authors",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html#authors",
    "title": "Htseq count to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Htseq count to h5mu"
    ]
  },
  {
    "objectID": "components/modules/mapping/star_align.html",
    "href": "components/modules/mapping/star_align.html",
    "title": "Star align",
    "section": "",
    "text": "ID: star_align\nNamespace: mapping\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Star align"
    ]
  },
  {
    "objectID": "components/modules/mapping/star_align.html#example-commands",
    "href": "components/modules/mapping/star_align.html#example-commands",
    "title": "Star align",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/star_align/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ninput: # please fill in - example: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"/path/to/reference\"\n# output: \"$id.$key.output\"\n\n# Run Parameters\n# runRNGseed: 777\n\n# Genome Parameters\n# genomeLoad: \"NoSharedMemory\"\n# genomeFastaFiles: [\"path/to/file\"]\n# genomeFileSizes: [0]\n# genomeTransformOutput: [\"foo\"]\n# genomeChrSetMitochondrial: [\"chrM\", \"M\", \"MT\"]\n\n# Splice Junctions Database\n# sjdbFileChrStartEnd: [\"foo\"]\n# sjdbGTFfile: \"path/to/file\"\n# sjdbGTFchrPrefix: \"foo\"\n# sjdbGTFfeatureExon: \"exon\"\n# sjdbGTFtagExonParentTranscript: \"transcript_id\"\n# sjdbGTFtagExonParentGene: \"gene_id\"\n# sjdbGTFtagExonParentGeneName: [\"gene_name\"]\n# sjdbGTFtagExonParentGeneType: [\"gene_type\", \"gene_biotype\"]\n# sjdbOverhang: 100\n# sjdbScore: 2\n# sjdbInsertSave: \"Basic\"\n\n# Variation parameters\n# varVCFfile: \"foo\"\n\n# Read Parameters\n# readFilesType: \"Fastx\"\n# readFilesSAMattrKeep: [\"All\"]\n# readFilesManifest: \"path/to/file\"\n# readFilesPrefix: \"foo\"\n# readFilesCommand: [\"foo\"]\n# readMapNumber: -1\n# readMatesLengthsIn: \"NotEqual\"\n# readNameSeparator: [\"/\"]\n# readQualityScoreBase: 33\n\n# Read Clipping\n# clipAdapterType: \"Hamming\"\n# clip3pNbases: [0]\n# clip3pAdapterSeq: [\"foo\"]\n# clip3pAdapterMMp: [0.1]\n# clip3pAfterAdapterNbases: [0]\n# clip5pNbases: [0]\n\n# Limits\n# limitGenomeGenerateRAM: 31000000000\n# limitIObufferSize: [30000000, 50000000]\n# limitOutSAMoneReadBytes: 100000\n# limitOutSJoneRead: 1000\n# limitOutSJcollapsed: 1000000\n# limitBAMsortRAM: 0\n# limitSjdbInsertNsj: 1000000\n# limitNreadsSoft: -1\n\n# Output: general\n# outTmpKeep: \"foo\"\n# outStd: \"Log\"\n# outReadsUnmapped: \"foo\"\n# outQSconversionAdd: 0\n# outMultimapperOrder: \"Old_2.4\"\n\n# Output: SAM and BAM\n# outSAMtype: [\"SAM\"]\n# outSAMmode: \"Full\"\n# outSAMstrandField: \"foo\"\n# outSAMattributes: [\"Standard\"]\n# outSAMattrIHstart: 1\n# outSAMunmapped: [\"foo\"]\n# outSAMorder: \"Paired\"\n# outSAMprimaryFlag: \"OneBestScore\"\n# outSAMreadID: \"Standard\"\n# outSAMmapqUnique: 255\n# outSAMflagOR: 0\n# outSAMflagAND: 65535\n# outSAMattrRGline: [\"foo\"]\n# outSAMheaderHD: [\"foo\"]\n# outSAMheaderPG: [\"foo\"]\n# outSAMheaderCommentFile: \"foo\"\n# outSAMfilter: [\"foo\"]\n# outSAMmultNmax: -1\n# outSAMtlen: 1\n# outBAMcompression: 1\n# outBAMsortingThreadN: 0\n# outBAMsortingBinsN: 50\n\n# BAM processing\n# bamRemoveDuplicatesType: \"foo\"\n# bamRemoveDuplicatesMate2basesN: 0\n\n# Output Wiggle\n# outWigType: [\"foo\"]\n# outWigStrand: \"Stranded\"\n# outWigReferencesPrefix: \"foo\"\n# outWigNorm: \"RPM\"\n\n# Output Filtering\n# outFilterType: \"Normal\"\n# outFilterMultimapScoreRange: 1\n# outFilterMultimapNmax: 10\n# outFilterMismatchNmax: 10\n# outFilterMismatchNoverLmax: 0.3\n# outFilterMismatchNoverReadLmax: 1.0\n# outFilterScoreMin: 0\n# outFilterScoreMinOverLread: 0.66\n# outFilterMatchNmin: 0\n# outFilterMatchNminOverLread: 0.66\n# outFilterIntronMotifs: \"foo\"\n# outFilterIntronStrands: \"RemoveInconsistentStrands\"\n\n# Output splice junctions (SJ.out.tab)\n# outSJtype: \"Standard\"\n\n# Output Filtering: Splice Junctions\n# outSJfilterReads: \"All\"\n# outSJfilterOverhangMin: [30, 12, 12, 12]\n# outSJfilterCountUniqueMin: [3, 1, 1, 1]\n# outSJfilterCountTotalMin: [3, 1, 1, 1]\n# outSJfilterDistToOtherSJmin: [10, 0, 5, 10]\n# outSJfilterIntronMaxVsReadN: [50000, 100000, 200000]\n\n# Scoring\n# scoreGap: 0\n# scoreGapNoncan: -8\n# scoreGapGCAG: -4\n# scoreGapATAC: -8\n# scoreGenomicLengthLog2scale: 0\n# scoreDelOpen: -2\n# scoreDelBase: -2\n# scoreInsOpen: -2\n# scoreInsBase: -2\n# scoreStitchSJshift: 1\n\n# Alignments and Seeding\n# seedSearchStartLmax: 50\n# seedSearchStartLmaxOverLread: 1.0\n# seedSearchLmax: 0\n# seedMultimapNmax: 10000\n# seedPerReadNmax: 1000\n# seedPerWindowNmax: 50\n# seedNoneLociPerWindow: 10\n# seedSplitMin: 12\n# seedMapMin: 5\n# alignIntronMin: 21\n# alignIntronMax: 0\n# alignMatesGapMax: 0\n# alignSJoverhangMin: 5\n# alignSJstitchMismatchNmax: [0, -1, 0, 0]\n# alignSJDBoverhangMin: 3\n# alignSplicedMateMapLmin: 0\n# alignSplicedMateMapLminOverLmate: 0.66\n# alignWindowsPerReadNmax: 10000\n# alignTranscriptsPerWindowNmax: 100\n# alignTranscriptsPerReadNmax: 10000\n# alignEndsType: \"Local\"\n# alignEndsProtrude: \"0    ConcordantPair\"\n# alignSoftClipAtReferenceEnds: \"Yes\"\n# alignInsertionFlush: \"foo\"\n\n# Paired-End reads\n# peOverlapNbasesMin: 0\n# peOverlapMMp: 0.01\n\n# Windows, Anchors, Binning\n# winAnchorMultimapNmax: 50\n# winBinNbits: 16\n# winAnchorDistNbins: 9\n# winFlankNbins: 4\n# winReadCoverageRelativeMin: 0.5\n# winReadCoverageBasesMin: 0\n\n# Chimeric Alignments\n# chimOutType: [\"Junctions\"]\n# chimSegmentMin: 0\n# chimScoreMin: 0\n# chimScoreDropMax: 20\n# chimScoreSeparation: 10\n# chimScoreJunctionNonGTAG: -1\n# chimJunctionOverhangMin: 20\n# chimSegmentReadGapMax: 0\n# chimFilter: [\"banGenomicN\"]\n# chimMainSegmentMultNmax: 10\n# chimMultimapNmax: 0\n# chimMultimapScoreRange: 1\n# chimNonchimScoreDropMin: 20\n# chimOutJunctionFormat: 0\n\n# Quantification of Annotations\n# quantMode: [\"foo\"]\n# quantTranscriptomeBAMcompression: 1\n# quantTranscriptomeBan: \"IndelSoftclipSingleend\"\n\n# 2-pass Mapping\n# twopassMode: \"foo\"\n# twopass1readsN: -1\n\n# WASP parameters\n# waspOutputMode: \"foo\"\n\n# STARsolo (single cell RNA-seq) parameters\n# soloType: [\"foo\"]\n# soloCBwhitelist: [\"foo\"]\n# soloCBstart: 1\n# soloCBlen: 16\n# soloUMIstart: 17\n# soloUMIlen: 10\n# soloBarcodeReadLength: 1\n# soloBarcodeMate: 0\n# soloCBposition: [\"foo\"]\n# soloUMIposition: \"foo\"\n# soloAdapterSequence: \"foo\"\n# soloAdapterMismatchesNmax: 1\n# soloCBmatchWLtype: \"1MM_multi\"\n# soloInputSAMattrBarcodeSeq: [\"foo\"]\n# soloInputSAMattrBarcodeQual: [\"foo\"]\n# soloStrand: \"Forward\"\n# soloFeatures: [\"Gene\"]\n# soloMultiMappers: [\"Unique\"]\n# soloUMIdedup: [\"1MM_All\"]\n# soloUMIfiltering: [\"foo\"]\n# soloOutFileNames: [\"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\"]\n# soloCellFilter: [\"CellRanger2.2\", \"3000\", \"0.99\", \"10\"]\n# soloOutFormatFeaturesGeneField3: [\"Gene Expression\"]\n# soloCellReadStats: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/star_align/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Star align"
    ]
  },
  {
    "objectID": "components/modules/mapping/star_align.html#argument-groups",
    "href": "components/modules/mapping/star_align.html#argument-groups",
    "title": "Star align",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe FASTQ files to be analyzed. Corresponds to the –readFilesIn argument in the STAR command.\nList of file, required, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nPath to the reference built by star_build_reference. Corresponds to the –genomeDir argument in the STAR command.\nfile, required, example: \"/path/to/reference\"\n\n\n--output\nPath to output directory. Corresponds to the –outFileNamePrefix argument in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nRun Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--runRNGseed\nrandom number generator seed.\ninteger, example: 777\n\n\n\n\n\nGenome Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeLoad\nmode of shared memory usage for the genome files. Only used with –runMode alignReads. - LoadAndKeep … load genome into shared and keep it in memory after run - LoadAndRemove … load genome into shared but remove it after run - LoadAndExit … load genome into shared memory and exit, keeping the genome in memory for future runs - Remove … do not map anything, just remove loaded genome from memory - NoSharedMemory … do not use shared memory, each job will have its own private copy of the genome\nstring, example: \"NoSharedMemory\"\n\n\n--genomeFastaFiles\npath(s) to the fasta files with the genome sequences, separated by spaces. These files should be plain text FASTA files, they cannot be zipped. Required for the genome generation (–runMode genomeGenerate). Can also be used in the mapping (–runMode alignReads) to add extra (new) sequences to the genome (e.g. spike-ins).\nList of file, multiple_sep: \";\"\n\n\n--genomeFileSizes\ngenome files exact sizes in bytes. Typically, this should not be defined by the user.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--genomeTransformOutput\nwhich output to transform back to original genome - SAM … SAM/BAM alignments - SJ … splice junctions (SJ.out.tab) - None … no transformation of the output\nList of string, multiple_sep: \";\"\n\n\n--genomeChrSetMitochondrial\nnames of the mitochondrial chromosomes. Presently only used for STARsolo statistics output/\nList of string, example: \"chrM\", \"M\", \"MT\", multiple_sep: \";\"\n\n\n\n\n\nSplice Junctions Database\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sjdbFileChrStartEnd\npath to the files with genomic coordinates (chr  start  end  strand) for the splice junction introns. Multiple files can be supplied and will be concatenated.\nList of string, multiple_sep: \";\"\n\n\n--sjdbGTFfile\npath to the GTF file with annotations\nfile\n\n\n--sjdbGTFchrPrefix\nprefix for chromosome names in a GTF file (e.g. ‘chr’ for using ENSMEBL annotations with UCSC genomes)\nstring\n\n\n--sjdbGTFfeatureExon\nfeature type in GTF file to be used as exons for building transcripts\nstring, example: \"exon\"\n\n\n--sjdbGTFtagExonParentTranscript\nGTF attribute name for parent transcript ID (default “transcript_id” works for GTF files)\nstring, example: \"transcript_id\"\n\n\n--sjdbGTFtagExonParentGene\nGTF attribute name for parent gene ID (default “gene_id” works for GTF files)\nstring, example: \"gene_id\"\n\n\n--sjdbGTFtagExonParentGeneName\nGTF attribute name for parent gene name\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--sjdbGTFtagExonParentGeneType\nGTF attribute name for parent gene type\nList of string, example: \"gene_type\", \"gene_biotype\", multiple_sep: \";\"\n\n\n--sjdbOverhang\nlength of the donor/acceptor sequence on each side of the junctions, ideally = (mate_length - 1)\ninteger, example: 100\n\n\n--sjdbScore\nextra alignment score for alignments that cross database junctions\ninteger, example: 2\n\n\n--sjdbInsertSave\nwhich files to save when sjdb junctions are inserted on the fly at the mapping step - Basic … only small junction / transcript files - All … all files including big Genome, SA and SAindex - this will create a complete genome directory\nstring, example: \"Basic\"\n\n\n\n\n\nVariation parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--varVCFfile\npath to the VCF file that contains variation data. The 10th column should contain the genotype information, e.g. 0/1\nstring\n\n\n\n\n\nRead Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--readFilesType\nformat of input read files - Fastx … FASTA or FASTQ - SAM SE … SAM or BAM single-end reads; for BAM use –readFilesCommand samtools view - SAM PE … SAM or BAM paired-end reads; for BAM use –readFilesCommand samtools view\nstring, example: \"Fastx\"\n\n\n--readFilesSAMattrKeep\nfor –readFilesType SAM SE/PE, which SAM tags to keep in the output BAM, e.g.: –readFilesSAMtagsKeep RG PL - All … keep all tags - None … do not keep any tags\nList of string, example: \"All\", multiple_sep: \";\"\n\n\n--readFilesManifest\npath to the “manifest” file with the names of read files. The manifest file should contain 3 tab-separated columns: paired-end reads: read1_file_name \\(tab\\) read2_file_name \\(tab\\) read_group_line. single-end reads: read1_file_name \\(tab\\) - \\(tab\\) read_group_line. Spaces, but not tabs are allowed in file names. If read_group_line does not start with ID:, it can only contain one ID field, and ID: will be added to it. If read_group_line starts with ID:, it can contain several fields separated by \\(tab\\), and all fields will be be copied verbatim into SAM @RG header line.\nfile\n\n\n--readFilesPrefix\nprefix for the read files names, i.e. it will be added in front of the strings in –readFilesIn\nstring\n\n\n--readFilesCommand\ncommand line to execute for each of the input file. This command should generate FASTA or FASTQ text and send it to stdout For example: zcat - to uncompress .gz files, bzcat - to uncompress .bz2 files, etc.\nList of string, multiple_sep: \";\"\n\n\n--readMapNumber\nnumber of reads to map from the beginning of the file -1: map all reads\ninteger, example: -1\n\n\n--readMatesLengthsIn\nEqual/NotEqual - lengths of names,sequences,qualities for both mates are the same / not the same. NotEqual is safe in all situations.\nstring, example: \"NotEqual\"\n\n\n--readNameSeparator\ncharacter(s) separating the part of the read names that will be trimmed in output (read name after space is always trimmed)\nList of string, example: \"/\", multiple_sep: \";\"\n\n\n--readQualityScoreBase\nnumber to be subtracted from the ASCII code to get Phred quality score\ninteger, example: 33\n\n\n\n\n\nRead Clipping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clipAdapterType\nadapter clipping type - Hamming … adapter clipping based on Hamming distance, with the number of mismatches controlled by –clip5pAdapterMMp - CellRanger4 … 5p and 3p adapter clipping similar to CellRanger4. Utilizes Opal package by Martin Sosic: https://github.com/Martinsos/opal - None … no adapter clipping, all other clip* parameters are disregarded\nstring, example: \"Hamming\"\n\n\n--clip3pNbases\nnumber(s) of bases to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip3pAdapterSeq\nadapter sequences to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates. - polyA … polyA sequence with the length equal to read length\nList of string, multiple_sep: \";\"\n\n\n--clip3pAdapterMMp\nmax proportion of mismatches for 3p adapter clipping for each mate. If one value is given, it will be assumed the same for both mates.\nList of double, example: 0.1, multiple_sep: \";\"\n\n\n--clip3pAfterAdapterNbases\nnumber of bases to clip from 3p of each mate after the adapter clipping. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip5pNbases\nnumber(s) of bases to clip from 5p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n\n\n\nLimits\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--limitGenomeGenerateRAM\nmaximum available RAM (bytes) for genome generation\nlong, example: NA\n\n\n--limitIObufferSize\nmax available buffers size (bytes) for input/output, per thread\nList of long, example: 30000000, 50000000, multiple_sep: \";\"\n\n\n--limitOutSAMoneReadBytes\nmax size of the SAM record (bytes) for one read. Recommended value: &gt;(2(LengthMate1+LengthMate2+100)outFilterMultimapNmax\nlong, example: 100000\n\n\n--limitOutSJoneRead\nmax number of junctions for one read (including all multi-mappers)\ninteger, example: 1000\n\n\n--limitOutSJcollapsed\nmax number of collapsed junctions\ninteger, example: 1000000\n\n\n--limitBAMsortRAM\nmaximum available RAM (bytes) for sorting BAM. If =0, it will be set to the genome index size. 0 value can only be used with –genomeLoad NoSharedMemory option.\nlong, example: 0\n\n\n--limitSjdbInsertNsj\nmaximum number of junctions to be inserted to the genome on the fly at the mapping stage, including those from annotations and those detected in the 1st step of the 2-pass run\ninteger, example: 1000000\n\n\n--limitNreadsSoft\nsoft limit on the number of reads\ninteger, example: -1\n\n\n\n\n\nOutput: general\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outTmpKeep\nwhether to keep the temporary files after STAR runs is finished - None … remove all temporary files - All … keep all files\nstring\n\n\n--outStd\nwhich output will be directed to stdout (standard out) - Log … log messages - SAM … alignments in SAM format (which normally are output to Aligned.out.sam file), normal standard output will go into Log.std.out - BAM_Unsorted … alignments in BAM format, unsorted. Requires –outSAMtype BAM Unsorted - BAM_SortedByCoordinate … alignments in BAM format, sorted by coordinate. Requires –outSAMtype BAM SortedByCoordinate - BAM_Quant … alignments to transcriptome in BAM format, unsorted. Requires –quantMode TranscriptomeSAM\nstring, example: \"Log\"\n\n\n--outReadsUnmapped\noutput of unmapped and partially mapped (i.e. mapped only one mate of a paired end read) reads in separate file(s). - None … no output - Fastx … output in separate fasta/fastq files, Unmapped.out.mate1/2\nstring\n\n\n--outQSconversionAdd\nadd this number to the quality score (e.g. to convert from Illumina to Sanger, use -31)\ninteger, example: 0\n\n\n--outMultimapperOrder\norder of multimapping alignments in the output files - Old_2.4 … quasi-random order used before 2.5.0 - Random … random order of alignments for each multi-mapper. Read mates (pairs) are always adjacent, all alignment for each read stay together. This option will become default in the future releases.\nstring, example: \"Old_2.4\"\n\n\n\n\n\nOutput: SAM and BAM\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSAMtype\ntype of SAM/BAM output 1st word: - BAM … output BAM without sorting - SAM … output SAM without sorting - None … no SAM/BAM output 2nd, 3rd: - Unsorted … standard unsorted - SortedByCoordinate … sorted by coordinate. This option will allocate extra memory for sorting which can be specified by –limitBAMsortRAM.\nList of string, example: \"SAM\", multiple_sep: \";\"\n\n\n--outSAMmode\nmode of SAM output - None … no SAM output - Full … full SAM output - NoQS … full SAM but without quality scores\nstring, example: \"Full\"\n\n\n--outSAMstrandField\nCufflinks-like strand field flag - None … not used - intronMotif … strand derived from the intron motif. This option changes the output alignments: reads with inconsistent and/or non-canonical introns are filtered out.\nstring\n\n\n--outSAMattributes\na string of desired SAM attributes, in the order desired for the output SAM. Tags can be listed in any combination/order. Presets: - None … no attributes - Standard … NH HI AS nM - All … NH HI AS nM NM MD jM jI MC ch Alignment: - NH … number of loci the reads maps to: =1 for unique mappers, &gt;1 for multimappers. Standard SAM tag. - HI … multiple alignment index, starts with –outSAMattrIHstart (=1 by default). Standard SAM tag. - AS … local alignment score, +1/-1 for matches/mismateches, score* penalties for indels and gaps. For PE reads, total score for two mates. Stadnard SAM tag. - nM … number of mismatches. For PE reads, sum over two mates. - NM … edit distance to the reference (number of mismatched + inserted + deleted bases) for each mate. Standard SAM tag. - MD … string encoding mismatched and deleted reference bases (see standard SAM specifications). Standard SAM tag. - jM … intron motifs for all junctions (i.e. N in CIGAR): 0: non-canonical; 1: GT/AG, 2: CT/AC, 3: GC/AG, 4: CT/GC, 5: AT/AC, 6: GT/AT. If splice junctions database is used, and a junction is annotated, 20 is added to its motif value. - jI … start and end of introns for all junctions (1-based). - XS … alignment strand according to –outSAMstrandField. - MC … mate’s CIGAR string. Standard SAM tag. - ch … marks all segment of all chimeric alingments for –chimOutType WithinBAM output. - cN … number of bases clipped from the read ends: 5’ and 3’ Variation: - vA … variant allele - vG … genomic coordinate of the variant overlapped by the read. - vW … 1 - alignment passes WASP filtering; 2,3,4,5,6,7 - alignment does not pass WASP filtering. Requires –waspOutputMode SAMtag. STARsolo: - CR CY UR UY … sequences and quality scores of cell barcodes and UMIs for the solo* demultiplexing. - GX GN … gene ID and gene name for unique-gene reads. - gx gn … gene IDs and gene names for unique- and multi-gene reads. - CB UB … error-corrected cell barcodes and UMIs for solo* demultiplexing. Requires –outSAMtype BAM SortedByCoordinate. - sM … assessment of CB and UMI. - sS … sequence of the entire barcode (CB,UMI,adapter). - sQ … quality of the entire barcode. ***Unsupported/undocumented: - ha … haplotype (1/2) when mapping to the diploid genome. Requires genome generated with –genomeTransformType Diploid . - rB … alignment block read/genomic coordinates. - vR … read coordinate of the variant.\nList of string, example: \"Standard\", multiple_sep: \";\"\n\n\n--outSAMattrIHstart\nstart value for the IH attribute. 0 may be required by some downstream software, such as Cufflinks or StringTie.\ninteger, example: 1\n\n\n--outSAMunmapped\noutput of unmapped reads in the SAM format 1st word: - None … no output - Within … output unmapped reads within the main SAM file (i.e. Aligned.out.sam) 2nd word: - KeepPairs … record unmapped mate for each alignment, and, in case of unsorted output, keep it adjacent to its mapped mate. Only affects multi-mapping reads.\nList of string, multiple_sep: \";\"\n\n\n--outSAMorder\ntype of sorting for the SAM output Paired: one mate after the other for all paired alignments PairedKeepInputOrder: one mate after the other for all paired alignments, the order is kept the same as in the input FASTQ files\nstring, example: \"Paired\"\n\n\n--outSAMprimaryFlag\nwhich alignments are considered primary - all others will be marked with 0x100 bit in the FLAG - OneBestScore … only one alignment with the best score is primary - AllBestScore … all alignments with the best score are primary\nstring, example: \"OneBestScore\"\n\n\n--outSAMreadID\nread ID record type - Standard … first word (until space) from the FASTx read ID line, removing /1,/2 from the end - Number … read number (index) in the FASTx file\nstring, example: \"Standard\"\n\n\n--outSAMmapqUnique\n0 to 255: the MAPQ value for unique mappers\ninteger, example: 255\n\n\n--outSAMflagOR\n0 to 65535: sam FLAG will be bitwise OR’d with this value, i.e. FLAG=FLAG | outSAMflagOR. This is applied after all flags have been set by STAR, and after outSAMflagAND. Can be used to set specific bits that are not set otherwise.\ninteger, example: 0\n\n\n--outSAMflagAND\n0 to 65535: sam FLAG will be bitwise AND’d with this value, i.e. FLAG=FLAG & outSAMflagOR. This is applied after all flags have been set by STAR, but before outSAMflagOR. Can be used to unset specific bits that are not set otherwise.\ninteger, example: 65535\n\n\n--outSAMattrRGline\nSAM/BAM read group line. The first word contains the read group identifier and must start with “ID:”, e.g. –outSAMattrRGline ID:xxx CN:yy “DS:z z z”. xxx will be added as RG tag to each output alignment. Any spaces in the tag values have to be double quoted. Comma separated RG lines correspons to different (comma separated) input files in –readFilesIn. Commas have to be surrounded by spaces, e.g. –outSAMattrRGline ID:xxx , ID:zzz “DS:z z” , ID:yyy DS:yyyy\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderHD\n@HD (header) line of the SAM header\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderPG\nextra @PG (software) line of the SAM header (in addition to STAR)\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderCommentFile\npath to the file with @CO (comment) lines of the SAM header\nstring\n\n\n--outSAMfilter\nfilter the output into main SAM/BAM files - KeepOnlyAddedReferences … only keep the reads for which all alignments are to the extra reference sequences added with –genomeFastaFiles at the mapping stage. - KeepAllAddedReferences … keep all alignments to the extra reference sequences added with –genomeFastaFiles at the mapping stage.\nList of string, multiple_sep: \";\"\n\n\n--outSAMmultNmax\nmax number of multiple alignments for a read that will be output to the SAM/BAM files. Note that if this value is not equal to -1, the top scoring alignment will be output first - -1 … all alignments (up to –outFilterMultimapNmax) will be output\ninteger, example: -1\n\n\n--outSAMtlen\ncalculation method for the TLEN field in the SAM/BAM files - 1 … leftmost base of the (+)strand mate to rightmost base of the (-)mate. (+)sign for the (+)strand mate - 2 … leftmost base of any mate to rightmost base of any mate. (+)sign for the mate with the leftmost base. This is different from 1 for overlapping mates with protruding ends\ninteger, example: 1\n\n\n--outBAMcompression\n-1 to 10 BAM compression level, -1=default compression (6?), 0=no compression, 10=maximum compression\ninteger, example: 1\n\n\n--outBAMsortingThreadN\n&gt;=0: number of threads for BAM sorting. 0 will default to min(6,–runThreadN).\ninteger, example: 0\n\n\n--outBAMsortingBinsN\n&gt;0: number of genome bins for coordinate-sorting\ninteger, example: 50\n\n\n\n\n\nBAM processing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bamRemoveDuplicatesType\nmark duplicates in the BAM file, for now only works with (i) sorted BAM fed with inputBAMfile, and (ii) for paired-end alignments only - - … no duplicate removal/marking - UniqueIdentical … mark all multimappers, and duplicate unique mappers. The coordinates, FLAG, CIGAR must be identical - UniqueIdenticalNotMulti … mark duplicate unique mappers but not multimappers.\nstring\n\n\n--bamRemoveDuplicatesMate2basesN\nnumber of bases from the 5’ of mate 2 to use in collapsing (e.g. for RAMPAGE)\ninteger, example: 0\n\n\n\n\n\nOutput Wiggle\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outWigType\ntype of signal output, e.g. “bedGraph” OR “bedGraph read1_5p”. Requires sorted BAM: –outSAMtype BAM SortedByCoordinate . 1st word: - None … no signal output - bedGraph … bedGraph format - wiggle … wiggle format 2nd word: - read1_5p … signal from only 5’ of the 1st read, useful for CAGE/RAMPAGE etc - read2 … signal from only 2nd read\nList of string, multiple_sep: \";\"\n\n\n--outWigStrand\nstrandedness of wiggle/bedGraph output - Stranded … separate strands, str1 and str2 - Unstranded … collapsed strands\nstring, example: \"Stranded\"\n\n\n--outWigReferencesPrefix\nprefix matching reference names to include in the output wiggle file, e.g. “chr”, default “-” - include all references\nstring\n\n\n--outWigNorm\ntype of normalization for the signal - RPM … reads per million of mapped reads - None … no normalization, “raw” counts\nstring, example: \"RPM\"\n\n\n\n\n\nOutput Filtering\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outFilterType\ntype of filtering - Normal … standard filtering using only current alignment - BySJout … keep only those reads that contain junctions that passed filtering into SJ.out.tab\nstring, example: \"Normal\"\n\n\n--outFilterMultimapScoreRange\nthe score range below the maximum score for multimapping alignments\ninteger, example: 1\n\n\n--outFilterMultimapNmax\nmaximum number of loci the read is allowed to map to. Alignments (all of them) will be output only if the read maps to no more loci than this value. Otherwise no alignments will be output, and the read will be counted as “mapped to too many loci” in the Log.final.out .\ninteger, example: 10\n\n\n--outFilterMismatchNmax\nalignment will be output only if it has no more mismatches than this value.\ninteger, example: 10\n\n\n--outFilterMismatchNoverLmax\nalignment will be output only if its ratio of mismatches to mapped length is less than or equal to this value.\ndouble, example: 0.3\n\n\n--outFilterMismatchNoverReadLmax\nalignment will be output only if its ratio of mismatches to read length is less than or equal to this value.\ndouble, example: 1\n\n\n--outFilterScoreMin\nalignment will be output only if its score is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterScoreMinOverLread\nsame as outFilterScoreMin, but normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 0.66\n\n\n--outFilterMatchNmin\nalignment will be output only if the number of matched bases is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterMatchNminOverLread\nsam as outFilterMatchNmin, but normalized to the read length (sum of mates’ lengths for paired-end reads).\ndouble, example: 0.66\n\n\n--outFilterIntronMotifs\nfilter alignment using their motifs - None … no filtering - RemoveNoncanonical … filter out alignments that contain non-canonical junctions - RemoveNoncanonicalUnannotated … filter out alignments that contain non-canonical unannotated junctions when using annotated splice junctions database. The annotated non-canonical junctions will be kept.\nstring\n\n\n--outFilterIntronStrands\nfilter alignments - RemoveInconsistentStrands … remove alignments that have junctions with inconsistent strands - None … no filtering\nstring, example: \"RemoveInconsistentStrands\"\n\n\n\n\n\nOutput splice junctions (SJ.out.tab)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJtype\ntype of splice junction output - Standard … standard SJ.out.tab output - None … no splice junction output\nstring, example: \"Standard\"\n\n\n\n\n\nOutput Filtering: Splice Junctions\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJfilterReads\nwhich reads to consider for collapsed splice junctions output - All … all reads, unique- and multi-mappers - Unique … uniquely mapping reads only\nstring, example: \"All\"\n\n\n--outSJfilterOverhangMin\nminimum overhang length for splice junctions on both sides for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif does not apply to annotated junctions\nList of integer, example: 30, 12, 12, 12, multiple_sep: \";\"\n\n\n--outSJfilterCountUniqueMin\nminimum uniquely mapping read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterCountTotalMin\nminimum total (multi-mapping+unique) read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterDistToOtherSJmin\nminimum allowed distance to other junctions’ donor/acceptor does not apply to annotated junctions\nList of integer, example: 10, 0, 5, 10, multiple_sep: \";\"\n\n\n--outSJfilterIntronMaxVsReadN\nmaximum gap allowed for junctions supported by 1,2,3,,,N reads i.e. by default junctions supported by 1 read can have gaps &lt;=50000b, by 2 reads: &lt;=100000b, by 3 reads: &lt;=200000. by &gt;=4 reads any gap &lt;=alignIntronMax does not apply to annotated junctions\nList of integer, example: 50000, 100000, 200000, multiple_sep: \";\"\n\n\n\n\n\nScoring\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scoreGap\nsplice junction penalty (independent on intron motif)\ninteger, example: 0\n\n\n--scoreGapNoncan\nnon-canonical junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGapGCAG\nGC/AG and CT/GC junction penalty (in addition to scoreGap)\ninteger, example: -4\n\n\n--scoreGapATAC\nAT/AC and GT/AT junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGenomicLengthLog2scale\nextra score logarithmically scaled with genomic length of the alignment: scoreGenomicLengthLog2scale*log2(genomicLength)\ninteger, example: 0\n\n\n--scoreDelOpen\ndeletion open penalty\ninteger, example: -2\n\n\n--scoreDelBase\ndeletion extension penalty per base (in addition to scoreDelOpen)\ninteger, example: -2\n\n\n--scoreInsOpen\ninsertion open penalty\ninteger, example: -2\n\n\n--scoreInsBase\ninsertion extension penalty per base (in addition to scoreInsOpen)\ninteger, example: -2\n\n\n--scoreStitchSJshift\nmaximum score reduction while searching for SJ boundaries in the stitching step\ninteger, example: 1\n\n\n\n\n\nAlignments and Seeding\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--seedSearchStartLmax\ndefines the search start point through the read - the read is split into pieces no longer than this value\ninteger, example: 50\n\n\n--seedSearchStartLmaxOverLread\nseedSearchStartLmax normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 1\n\n\n--seedSearchLmax\ndefines the maximum length of the seeds, if =0 seed length is not limited\ninteger, example: 0\n\n\n--seedMultimapNmax\nonly pieces that map fewer than this value are utilized in the stitching procedure\ninteger, example: 10000\n\n\n--seedPerReadNmax\nmax number of seeds per read\ninteger, example: 1000\n\n\n--seedPerWindowNmax\nmax number of seeds per window\ninteger, example: 50\n\n\n--seedNoneLociPerWindow\nmax number of one seed loci per window\ninteger, example: 10\n\n\n--seedSplitMin\nmin length of the seed sequences split by Ns or mate gap\ninteger, example: 12\n\n\n--seedMapMin\nmin length of seeds to be mapped\ninteger, example: 5\n\n\n--alignIntronMin\nminimum intron size, genomic gap is considered intron if its length&gt;=alignIntronMin, otherwise it is considered Deletion\ninteger, example: 21\n\n\n--alignIntronMax\nmaximum intron size, if 0, max intron size will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignMatesGapMax\nmaximum gap between two mates, if 0, max intron gap will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignSJoverhangMin\nminimum overhang (i.e. block size) for spliced alignments\ninteger, example: 5\n\n\n--alignSJstitchMismatchNmax\nmaximum number of mismatches for stitching of the splice junctions (-1: no limit). (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif.\nList of integer, example: 0, -1, 0, 0, multiple_sep: \";\"\n\n\n--alignSJDBoverhangMin\nminimum overhang (i.e. block size) for annotated (sjdb) spliced alignments\ninteger, example: 3\n\n\n--alignSplicedMateMapLmin\nminimum mapped length for a read mate that is spliced\ninteger, example: 0\n\n\n--alignSplicedMateMapLminOverLmate\nalignSplicedMateMapLmin normalized to mate length\ndouble, example: 0.66\n\n\n--alignWindowsPerReadNmax\nmax number of windows per read\ninteger, example: 10000\n\n\n--alignTranscriptsPerWindowNmax\nmax number of transcripts per window\ninteger, example: 100\n\n\n--alignTranscriptsPerReadNmax\nmax number of different alignments per read to consider\ninteger, example: 10000\n\n\n--alignEndsType\ntype of read ends alignment - Local … standard local alignment with soft-clipping allowed - EndToEnd … force end-to-end read alignment, do not soft-clip - Extend5pOfRead1 … fully extend only the 5p of the read1, all other ends: local alignment - Extend5pOfReads12 … fully extend only the 5p of the both read1 and read2, all other ends: local alignment\nstring, example: \"Local\"\n\n\n--alignEndsProtrude\nallow protrusion of alignment ends, i.e. start (end) of the +strand mate downstream of the start (end) of the -strand mate 1st word: int: maximum number of protrusion bases allowed 2nd word: string: - ConcordantPair … report alignments with non-zero protrusion as concordant pairs - DiscordantPair … report alignments with non-zero protrusion as discordant pairs\nstring, example: \"0    ConcordantPair\"\n\n\n--alignSoftClipAtReferenceEnds\nallow the soft-clipping of the alignments past the end of the chromosomes - Yes … allow - No … prohibit, useful for compatibility with Cufflinks\nstring, example: \"Yes\"\n\n\n--alignInsertionFlush\nhow to flush ambiguous insertion positions - None … insertions are not flushed - Right … insertions are flushed to the right\nstring\n\n\n\n\n\nPaired-End reads\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--peOverlapNbasesMin\nminimum number of overlapping bases to trigger mates merging and realignment. Specify &gt;0 value to switch on the “merginf of overlapping mates” algorithm.\ninteger, example: 0\n\n\n--peOverlapMMp\nmaximum proportion of mismatched bases in the overlap area\ndouble, example: 0.01\n\n\n\n\n\nWindows, Anchors, Binning\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--winAnchorMultimapNmax\nmax number of loci anchors are allowed to map to\ninteger, example: 50\n\n\n--winBinNbits\n=log2(winBin), where winBin is the size of the bin for the windows/clustering, each window will occupy an integer number of bins.\ninteger, example: 16\n\n\n--winAnchorDistNbins\nmax number of bins between two anchors that allows aggregation of anchors into one window\ninteger, example: 9\n\n\n--winFlankNbins\nlog2(winFlank), where win Flank is the size of the left and right flanking regions for each window\ninteger, example: 4\n\n\n--winReadCoverageRelativeMin\nminimum relative coverage of the read sequence by the seeds in a window, for STARlong algorithm only.\ndouble, example: 0.5\n\n\n--winReadCoverageBasesMin\nminimum number of bases covered by the seeds in a window , for STARlong algorithm only.\ninteger, example: 0\n\n\n\n\n\nChimeric Alignments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--chimOutType\ntype of chimeric output - Junctions … Chimeric.out.junction - SeparateSAMold … output old SAM into separate Chimeric.out.sam file - WithinBAM … output into main aligned BAM files (Aligned.*.bam) - WithinBAM HardClip … (default) hard-clipping in the CIGAR for supplemental chimeric alignments (default if no 2nd word is present) - WithinBAM SoftClip … soft-clipping in the CIGAR for supplemental chimeric alignments\nList of string, example: \"Junctions\", multiple_sep: \";\"\n\n\n--chimSegmentMin\nminimum length of chimeric segment length, if ==0, no chimeric output\ninteger, example: 0\n\n\n--chimScoreMin\nminimum total (summed) score of the chimeric segments\ninteger, example: 0\n\n\n--chimScoreDropMax\nmax drop (difference) of chimeric score (the sum of scores of all chimeric segments) from the read length\ninteger, example: 20\n\n\n--chimScoreSeparation\nminimum difference (separation) between the best chimeric score and the next one\ninteger, example: 10\n\n\n--chimScoreJunctionNonGTAG\npenalty for a non-GT/AG chimeric junction\ninteger, example: -1\n\n\n--chimJunctionOverhangMin\nminimum overhang for a chimeric junction\ninteger, example: 20\n\n\n--chimSegmentReadGapMax\nmaximum gap in the read sequence between chimeric segments\ninteger, example: 0\n\n\n--chimFilter\ndifferent filters for chimeric alignments - None … no filtering - banGenomicN … Ns are not allowed in the genome sequence around the chimeric junction\nList of string, example: \"banGenomicN\", multiple_sep: \";\"\n\n\n--chimMainSegmentMultNmax\nmaximum number of multi-alignments for the main chimeric segment. =1 will prohibit multimapping main segments.\ninteger, example: 10\n\n\n--chimMultimapNmax\nmaximum number of chimeric multi-alignments - 0 … use the old scheme for chimeric detection which only considered unique alignments\ninteger, example: 0\n\n\n--chimMultimapScoreRange\nthe score range for multi-mapping chimeras below the best chimeric score. Only works with –chimMultimapNmax &gt; 1\ninteger, example: 1\n\n\n--chimNonchimScoreDropMin\nto trigger chimeric detection, the drop in the best non-chimeric alignment score with respect to the read length has to be greater than this value\ninteger, example: 20\n\n\n--chimOutJunctionFormat\nformatting type for the Chimeric.out.junction file - 0 … no comment lines/headers - 1 … comment lines at the end of the file: command line and Nreads: total, unique/multi-mapping\ninteger, example: 0\n\n\n\n\n\nQuantification of Annotations\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--quantMode\ntypes of quantification requested - - … none - TranscriptomeSAM … output SAM/BAM alignments to transcriptome into a separate file - GeneCounts … count reads per gene\nList of string, multiple_sep: \";\"\n\n\n--quantTranscriptomeBAMcompression\n-2 to 10 transcriptome BAM compression level - -2 … no BAM output - -1 … default compression (6?) - 0 … no compression - 10 … maximum compression\ninteger, example: 1\n\n\n--quantTranscriptomeBan\nprohibit various alignment type - IndelSoftclipSingleend … prohibit indels, soft clipping and single-end alignments - compatible with RSEM - Singleend … prohibit single-end alignments\nstring, example: \"IndelSoftclipSingleend\"\n\n\n\n\n\n2-pass Mapping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--twopassMode\n2-pass mapping mode. - None … 1-pass mapping - Basic … basic 2-pass mapping, with all 1st pass junctions inserted into the genome indices on the fly\nstring\n\n\n--twopass1readsN\nnumber of reads to process for the 1st step. Use very large number (or default -1) to map all reads in the first step.\ninteger, example: -1\n\n\n\n\n\nWASP parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--waspOutputMode\nWASP allele-specific output type. This is re-implementation of the original WASP mappability filtering by Bryce van de Geijn, Graham McVicker, Yoav Gilad & Jonathan K Pritchard. Please cite the original WASP paper: Nature Methods 12, 1061-1063 (2015), https://www.nature.com/articles/nmeth.3582 . - SAMtag … add WASP tags to the alignments that pass WASP filtering\nstring\n\n\n\n\n\nSTARsolo (single cell RNA-seq) parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--soloType\ntype of single-cell RNA-seq - CB_UMI_Simple … (a.k.a. Droplet) one UMI and one Cell Barcode of fixed length in read2, e.g. Drop-seq and 10X Chromium. - CB_UMI_Complex … multiple Cell Barcodes of varying length, one UMI of fixed length and one adapter sequence of fixed length are allowed in read2 only (e.g. inDrop, ddSeq). - CB_samTagOut … output Cell Barcode as CR and/or CB SAm tag. No UMI counting. –readFilesIn cDNA_read1 [cDNA_read2 if paired-end] CellBarcode_read . Requires –outSAMtype BAM Unsorted [and/or SortedByCoordinate] - SmartSeq … Smart-seq: each cell in a separate FASTQ (paired- or single-end), barcodes are corresponding read-groups, no UMI sequences, alignments deduplicated according to alignment start and end (after extending soft-clipped bases)\nList of string, multiple_sep: \";\"\n\n\n--soloCBwhitelist\nfile(s) with whitelist(s) of cell barcodes. Only –soloType CB_UMI_Complex allows more than one whitelist file. - None … no whitelist: all cell barcodes are allowed\nList of string, multiple_sep: \";\"\n\n\n--soloCBstart\ncell barcode start base\ninteger, example: 1\n\n\n--soloCBlen\ncell barcode length\ninteger, example: 16\n\n\n--soloUMIstart\nUMI start base\ninteger, example: 17\n\n\n--soloUMIlen\nUMI length\ninteger, example: 10\n\n\n--soloBarcodeReadLength\nlength of the barcode read - 1 … equal to sum of soloCBlen+soloUMIlen - 0 … not defined, do not check\ninteger, example: 1\n\n\n--soloBarcodeMate\nidentifies which read mate contains the barcode (CB+UMI) sequence - 0 … barcode sequence is on separate read, which should always be the last file in the –readFilesIn listed - 1 … barcode sequence is a part of mate 1 - 2 … barcode sequence is a part of mate 2\ninteger, example: 0\n\n\n--soloCBposition\nposition of Cell Barcode(s) on the barcode read. Presently only works with –soloType CB_UMI_Complex, and barcodes are assumed to be on Read2. Format for each barcode: startAnchor_startPosition_endAnchor_endPosition start(end)Anchor defines the Anchor Base for the CB: 0: read start; 1: read end; 2: adapter start; 3: adapter end start(end)Position is the 0-based position with of the CB start(end) with respect to the Anchor Base String for different barcodes are separated by space. Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 0_0_2_-1 3_1_3_8\nList of string, multiple_sep: \";\"\n\n\n--soloUMIposition\nposition of the UMI on the barcode read, same as soloCBposition Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 3_9_3_14\nstring\n\n\n--soloAdapterSequence\nadapter sequence to anchor barcodes. Only one adapter sequence is allowed.\nstring\n\n\n--soloAdapterMismatchesNmax\nmaximum number of mismatches allowed in adapter sequence.\ninteger, example: 1\n\n\n--soloCBmatchWLtype\nmatching the Cell Barcodes to the WhiteList - Exact … only exact matches allowed - 1MM … only one match in whitelist with 1 mismatched base allowed. Allowed CBs have to have at least one read with exact match. - 1MM_multi … multiple matches in whitelist with 1 mismatched base allowed, posterior probability calculation is used choose one of the matches. Allowed CBs have to have at least one read with exact match. This option matches best with CellRanger 2.2.0 - 1MM_multi_pseudocounts … same as 1MM_Multi, but pseudocounts of 1 are added to all whitelist barcodes. - 1MM_multi_Nbase_pseudocounts … same as 1MM_multi_pseudocounts, multimatching to WL is allowed for CBs with N-bases. This option matches best with CellRanger &gt;= 3.0.0 - EditDist_2 … allow up to edit distance of 3 fpr each of the barcodes. May include one deletion + one insertion. Only works with –soloType CB_UMI_Complex. Matches to multiple passlist barcdoes are not allowed. Similar to ParseBio Split-seq pipeline.\nstring, example: \"1MM_multi\"\n\n\n--soloInputSAMattrBarcodeSeq\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode sequence (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeSeq CR UR . This parameter is required when running STARsolo with input from SAM.\nList of string, multiple_sep: \";\"\n\n\n--soloInputSAMattrBarcodeQual\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode qualities (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeQual CY UY . If this parameter is ‘-’ (default), the quality ‘H’ will be assigned to all bases.\nList of string, multiple_sep: \";\"\n\n\n--soloStrand\nstrandedness of the solo libraries: - Unstranded … no strand information - Forward … read strand same as the original RNA molecule - Reverse … read strand opposite to the original RNA molecule\nstring, example: \"Forward\"\n\n\n--soloFeatures\ngenomic features for which the UMI counts per Cell Barcode are collected - Gene … genes: reads match the gene transcript - SJ … splice junctions: reported in SJ.out.tab - GeneFull … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns - GeneFull_ExonOverIntron … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns: prioritize 100% overlap with exons - GeneFull_Ex50pAS … full gene (pre-RNA): count all reads overlapping genes’ exons and introns: prioritize &gt;50% overlap with exons. Do not count reads with 100% exonic overlap in the antisense direction.\nList of string, example: \"Gene\", multiple_sep: \";\"\n\n\n--soloMultiMappers\ncounting method for reads mapping to multiple genes - Unique … count only reads that map to unique genes - Uniform … uniformly distribute multi-genic UMIs to all genes - Rescue … distribute UMIs proportionally to unique+uniform counts (~ first iteration of EM) - PropUnique … distribute UMIs proportionally to unique mappers, if present, and uniformly if not. - EM … multi-gene UMIs are distributed using Expectation Maximization algorithm\nList of string, example: \"Unique\", multiple_sep: \";\"\n\n\n--soloUMIdedup\ntype of UMI deduplication (collapsing) algorithm - 1MM_All … all UMIs with 1 mismatch distance to each other are collapsed (i.e. counted once). - 1MM_Directional_UMItools … follows the “directional” method from the UMI-tools by Smith, Heger and Sudbery (Genome Research 2017). - 1MM_Directional … same as 1MM_Directional_UMItools, but with more stringent criteria for duplicate UMIs - Exact … only exactly matching UMIs are collapsed. - NoDedup … no deduplication of UMIs, count all reads. - 1MM_CR … CellRanger2-4 algorithm for 1MM UMI collapsing.\nList of string, example: \"1MM_All\", multiple_sep: \";\"\n\n\n--soloUMIfiltering\ntype of UMI filtering (for reads uniquely mapping to genes) - - … basic filtering: remove UMIs with N and homopolymers (similar to CellRanger 2.2.0). - MultiGeneUMI … basic + remove lower-count UMIs that map to more than one gene. - MultiGeneUMI_All … basic + remove all UMIs that map to more than one gene. - MultiGeneUMI_CR … basic + remove lower-count UMIs that map to more than one gene, matching CellRanger &gt; 3.0.0 . Only works with –soloUMIdedup 1MM_CR\nList of string, multiple_sep: \";\"\n\n\n--soloOutFileNames\nfile names for STARsolo output: file_name_prefix gene_names barcode_sequences cell_feature_count_matrix\nList of string, example: \"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\", multiple_sep: \";\"\n\n\n--soloCellFilter\ncell filtering type and parameters - None … do not output filtered cells - TopCells … only report top cells by UMI count, followed by the exact number of cells - CellRanger2.2 … simple filtering of CellRanger 2.2. Can be followed by numbers: number of expected cells, robust maximum percentile for UMI count, maximum to minimum ratio for UMI count The harcoded values are from CellRanger: nExpectedCells=3000; maxPercentile=0.99; maxMinRatio=10 - EmptyDrops_CR … EmptyDrops filtering in CellRanger flavor. Please cite the original EmptyDrops paper: A.T.L Lun et al, Genome Biology, 20, 63 (2019): https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1662-y Can be followed by 10 numeric parameters: nExpectedCells maxPercentile maxMinRatio indMin indMax umiMin umiMinFracMedian candMaxN FDR simN The harcoded values are from CellRanger: 3000 0.99 10 45000 90000 500 0.01 20000 0.01 10000\nList of string, example: \"CellRanger2.2\", \"3000\", \"0.99\", \"10\", multiple_sep: \";\"\n\n\n--soloOutFormatFeaturesGeneField3\nfield 3 in the Gene features.tsv file. If “-”, then no 3rd field is output.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--soloCellReadStats\nOutput reads statistics for each CB - Standard … standard output\nstring",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Star align"
    ]
  },
  {
    "objectID": "components/modules/mapping/star_align.html#authors",
    "href": "components/modules/mapping/star_align.html#authors",
    "title": "Star align",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Star align"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html",
    "href": "components/modules/mapping/cellranger_multi.html",
    "title": "Cellranger multi",
    "section": "",
    "text": "ID: cellranger_multi\nNamespace: mapping\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger multi"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html#example-commands",
    "href": "components/modules/mapping/cellranger_multi.html#example-commands",
    "title": "Cellranger multi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/cellranger_multi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input files\n# input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n\n# Feature type-specific input files\n# gex_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# abc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# cgc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# mux_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_t_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_t_gd_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_b_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# agc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n\n# Library arguments\n# library_id: [\"mysample1\"]\n# library_type: [\"Gene Expression\"]\n# library_subsample: [\"0.5\"]\n# library_lanes: [\"1-4\"]\n# library_chemistry: \"foo\"\n\n# Sample parameters\n# sample_ids: [\"foo\"]\n# sample_description: [\"foo\"]\n# sample_expect_cells: [3000]\n# sample_force_cells: [3000]\n\n# Feature Barcode library specific arguments\n# feature_reference: \"feature_reference.csv\"\n# feature_r1_length: 123\n# feature_r2_length: 123\n# min_crispr_umi: 123\n\n# Gene expression arguments\ngex_reference: # please fill in - example: \"reference_genome.tar.gz\"\ngex_secondary_analysis: false\ngex_generate_bam: false\n# gex_expect_cells: 3000\n# gex_force_cells: 3000\ngex_include_introns: true\n# gex_r1_length: 123\n# gex_r2_length: 123\ngex_chemistry: \"auto\"\n\n# VDJ related parameters\n# vdj_reference: \"reference_vdj.tar.gz\"\n# vdj_inner_enrichment_primers: \"enrichment_primers.txt\"\n# vdj_r1_length: 123\n# vdj_r2_length: 123\n\n# Cell multiplexing parameters\n# cell_multiplex_oligo_ids: [\"foo\"]\n# min_assignment_confidence: 123.0\n# cmo_set: \"path/to/file\"\n# barcode_sample_assignment: \"path/to/file\"\n\n# Fixed RNA profiling paramaters\n# probe_set: \"path/to/file\"\n# filter_probes: true\n# probe_barcode_ids: [\"foo\"]\n\n# Antigen Capture (BEAM) libary arguments\n# control_id: [\"foo\"]\n# mhc_allele: [\"foo\"]\n\n# General arguments\ncheck_library_compatibility: true\n\n# Outputs\n# output: \"$id.$key.output\"\n\n# Executor arguments\ndryrun: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/cellranger_multi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger multi"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html#argument-groups",
    "href": "components/modules/mapping/cellranger_multi.html#argument-groups",
    "title": "Cellranger multi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput files\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe FASTQ files to be analyzed. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n\n\n\nFeature type-specific input files\nHelper functionality to allow feature type-specific input files, without the need to specify library_type or library_id. The library_id will be inferred from the input paths.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_input\nThe FASTQ files to be analyzed for Gene Expression. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--abc_input\nThe FASTQ files to be analyzed for Antibody Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--cgc_input\nThe FASTQ files to be analyzed for CRISPR Guide Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--mux_input\nThe FASTQ files to be analyzed for Multiplexing Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_input\nThe FASTQ files to be analyzed for VDJ. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_t_input\nThe FASTQ files to be analyzed for VDJ-T. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_t_gd_input\nThe FASTQ files to be analyzed for VDJ-T-GD. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_b_input\nThe FASTQ files to be analyzed for VDJ-B. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--agc_input\nThe FASTQ files to be analyzed for Antigen Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n\n\n\nLibrary arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--library_id\nThe Illumina sample name to analyze. This must exactly match the ’Sample Name’part of the FASTQ files specified in the --input argument.\nList of string, example: \"mysample1\", multiple_sep: \";\"\n\n\n--library_type\nThe underlying feature type of the library.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--library_subsample\nThe rate at which reads from the provided FASTQ files are sampled. Must be strictly greater than 0 and less than or equal to 1.\nList of string, example: \"0.5\", multiple_sep: \";\"\n\n\n--library_lanes\nLanes associated with this sample. Defaults to using all lanes.\nList of string, example: \"1-4\", multiple_sep: \";\"\n\n\n--library_chemistry\nOnly applicable to FRP. Library-specific assay configuration. By default, the assay configuration is detected automatically. Typically, users will not need to specify a chemistry.\nstring\n\n\n\n\n\nSample parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sample_ids\nA name to identify a multiplexed sample. Must be alphanumeric with hyphens and/or underscores, and less than 64 characters. Required for Cell Multiplexing libraries.\nList of string, multiple_sep: \";\"\n\n\n--sample_description\nA description for the sample.\nList of string, multiple_sep: \";\"\n\n\n--sample_expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\nList of integer, example: 3000, multiple_sep: \";\"\n\n\n--sample_force_cells\nForce pipeline to use this number of cells, bypassing cell detection.\nList of integer, example: 3000, multiple_sep: \";\"\n\n\n\n\n\nFeature Barcode library specific arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--feature_reference\nPath to the Feature reference CSV file, declaring Feature Barcode constructs and associated barcodes. Required only for Antibody Capture or CRISPR Guide Capture libraries. See https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/feature-bc-analysis#feature-ref for more information.”\nfile, example: \"feature_reference.csv\"\n\n\n--feature_r1_length\nLimit the length of the input Read 1 sequence of V(D)J libraries to the first N bases, where N is the user-supplied value. Note that the length includes the Barcode and UMI sequences so do not set this below 26.\ninteger\n\n\n--feature_r2_length\nLimit the length of the input Read 2 sequence of V(D)J libraries to the first N bases, where N is a user-supplied value. Trimming occurs before sequencing metrics are computed and therefore, limiting the length of Read 2 may affect Q30 scores.\ninteger\n\n\n--min_crispr_umi\nSet the minimum number of CRISPR guide RNA UMIs required for protospacer detection. If a lower or higher sensitivity is desired for detection, this value can be customized according to specific experimental needs. Applicable only to datasets that include a CRISPR Guide Capture library.\ninteger\n\n\n\n\n\nGene expression arguments\nArguments relevant to the analysis of gene expression data.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_reference\nGenome refence index built by Cell Ranger mkref.\nfile, required, example: \"reference_genome.tar.gz\"\n\n\n--gex_secondary_analysis\nWhether or not to run the secondary analysis e.g. clustering.\nboolean, default: FALSE\n\n\n--gex_generate_bam\nWhether to generate a BAM file.\nboolean, default: FALSE\n\n\n--gex_expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--gex_force_cells\nForce pipeline to use this number of cells, bypassing cell detection.\ninteger, example: 3000\n\n\n--gex_include_introns\nWhether or not to include intronic reads in counts. This option does not apply to Fixed RNA Profiling analysis.\nboolean, default: TRUE\n\n\n--gex_r1_length\nLimit the length of the input Read 1 sequence of V(D)J libraries to the first N bases, where N is the user-supplied value. Note that the length includes the Barcode and UMI sequences so do not set this below 26.\ninteger\n\n\n--gex_r2_length\nLimit the length of the input Read 2 sequence of V(D)J libraries to the first N bases, where N is a user-supplied value. Trimming occurs before sequencing metrics are computed and therefore, limiting the length of Read 2 may affect Q30 scores.\ninteger\n\n\n--gex_chemistry\nAssay configuration. Either specify a single value which will be applied to all libraries, or a number of values that is equal to the number of libararies. The latter is only applicable to only applicable to Fixed RNA Profiling. - auto: Chemistry autodetection (default) - threeprime: Single Cell 3’ - SC3Pv1, SC3Pv2, SC3Pv3, SC3Pv4: Single Cell 3’ v1, v2, v3, or v4 - SC3Pv3HT: Single Cell 3’ v3.1 HT - SC-FB: Single Cell Antibody-only 3’ v2 or 5’ - fiveprime: Single Cell 5’ - SC5P-PE: Paired-end Single Cell 5’ - SC5P-R2: R2-only Single Cell 5’ - SC5P-R2-v3: R2-only Single Cell 5’ v3 - SCP5-PE-v3: Single Cell 5’ paired-end v3 (GEM-X) - SC5PHT : Single Cell 5’ v2 HT - SFRP: Fixed RNA Profiling (Singleplex) - MFRP: Fixed RNA Profiling (Multiplex, Probe Barcode on R2) - MFRP-R1: Fixed RNA Profiling (Multiplex, Probe Barcode on R1) - MFRP-RNA: Fixed RNA Profiling (Multiplex, RNA, Probe Barcode on R2) - MFRP-Ab: Fixed RNA Profiling (Multiplex, Antibody, Probe Barcode at R2:69) - MFRP-Ab-R2pos50: Fixed RNA Profiling (Multiplex, Antibody, Probe Barcode at R2:50) - MFRP-RNA-R1: Fixed RNA Profiling (Multiplex, RNA, Probe Barcode on R1) - MFRP-Ab-R1: Fixed RNA Profiling (Multiplex, Antibody, Probe Barcode on R1) - ARC-v1 for analyzing the Gene Expression portion of Multiome data. If Cell Ranger auto-detects ARC-v1 chemistry, an error is triggered. See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n\n\n\nVDJ related parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vdj_reference\nVDJ refence index built by Cell Ranger mkref.\nfile, example: \"reference_vdj.tar.gz\"\n\n\n--vdj_inner_enrichment_primers\nV(D)J Immune Profiling libraries: if inner enrichment primers other than those provided in the 10x Genomics kits are used, they need to be specified here as a text file with one primer per line.\nfile, example: \"enrichment_primers.txt\"\n\n\n--vdj_r1_length\nLimit the length of the input Read 1 sequence of V(D)J libraries to the first N bases, where N is the user-supplied value. Note that the length includes the Barcode and UMI sequences so do not set this below 26.\ninteger\n\n\n--vdj_r2_length\nLimit the length of the input Read 2 sequence of V(D)J libraries to the first N bases, where N is a user-supplied value. Trimming occurs before sequencing metrics are computed and therefore, limiting the length of Read 2 may affect Q30 scores\ninteger\n\n\n\n\n\nCell multiplexing parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_multiplex_oligo_ids\nThe Cell Multiplexing oligo IDs used to multiplex this sample. If multiple CMOs were used for a sample, separate IDs with a pipe (e.g., CMO301|CMO302). Required for Cell Multiplexing libraries.\nList of string, multiple_sep: \";\"\n\n\n--min_assignment_confidence\nThe minimum estimated likelihood to call a sample as tagged with a Cell Multiplexing Oligo (CMO) instead of “Unassigned”. Users may wish to tolerate a higher rate of mis-assignment in order to obtain more singlets to include in their analysis, or a lower rate of mis-assignment at the cost of obtaining fewer singlets.\ndouble\n\n\n--cmo_set\nPath to a custom CMO set CSV file, declaring CMO constructs and associated barcodes. If the default CMO reference IDs that are built into the Cell Ranger software are required, this option does not need to be used.\nfile\n\n\n--barcode_sample_assignment\nPath to a barcode-sample assignment CSV file that specifies the barcodes that belong to each sample.\nfile\n\n\n\n\n\nFixed RNA profiling paramaters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--probe_set\nA probe set reference CSV file. It specifies the sequences used as a reference for probe alignment and the gene ID associated with each probe. It must include 4 columns (probe file format 1.0.0): gene_id,probe_seq,probe_id,included,region and an optional 5th column (probe file format 1.0.1). - gene_id: The Ensembl gene identifier targeted by the probe. - probe_seq: The nucleotide sequence of the probe, which is complementary to the transcript sequence. - probe_id: The probe identifier, whose format is described in Probe identifiers. - included: A TRUE or FALSE flag specifying whether the probe is included in the filtered counts matrix output or excluded by the probe filter. See filter-probes option of cellranger multi. All probes of a gene must be marked TRUE in the included column for that gene to be included. - region: Present only in v1.0.1 probe set reference CSV. The gene boundary targeted by the probe. Accepted values are spliced or unspliced. The file also contains a number of required metadata fields in the header in the format #key=value: - panel_name: The name of the probe set. - panel_type: Always predesigned for predesigned probe sets. - reference_genome: The reference genome build used for probe design. - reference_version: The version of the Cell Ranger reference transcriptome used for probe design. - probe_set_file_format: The version of the probe set file format specification that this file conforms to.\nfile\n\n\n--filter_probes\nIf ‘false’, include all non-deprecated probes listed in the probe set reference CSV file. If ‘true’ or not set, probes that are predicted to have off-target activity to homologous genes are excluded from analysis. Not filtering will result in UMI counts from all non-deprecated probes, including those with predicted off-target activity, to be used in the analysis. Probes whose ID is prefixed with DEPRECATED are always excluded from the analysis.\nboolean\n\n\n--probe_barcode_ids\nThe Fixed RNA Probe Barcode ID used for this sample, and for multiplex GEX + Antibody Capture libraries, the corresponding Antibody Multiplexing Barcode IDs. 10x recommends specifying both barcodes (e.g., BC001+AB001) when an Antibody Capture library is present. The barcode pair order is BC+AB and they are separated with a “+” (no spaces). Alternatively, you can specify the Probe Barcode ID alone and Cell Ranger’s barcode pairing auto-detection algorithm will automatically match to the corresponding Antibody Multiplexing Barcode.\nList of string, multiple_sep: \";\"\n\n\n\n\n\nAntigen Capture (BEAM) libary arguments\nThese arguments are recommended if an Antigen Capture (BEAM) library is present. It is needed to calculate the antigen specificity score.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--control_id\nA user-defined ID for any negative controls used in the T/BCR Antigen Capture assay. Must match id specified in the feature reference CSV. May only include ASCII characters and must not use whitespace, slash, quote, or comma characters. Each ID must be unique and must not collide with a gene identifier from the transcriptome.\nList of string, multiple_sep: \";\"\n\n\n--mhc_allele\nThe MHC allele for TCR Antigen Capture libraries. Must match mhc_allele name specified in the Feature Reference CSV.\nList of string, multiple_sep: \";\"\n\n\n\n\n\nGeneral arguments\nThese arguments are applicable to all library types.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--check_library_compatibility\nOptional. This option allows users to disable the check that evaluates 10x Barcode overlap between ibraries when multiple libraries are specified (e.g., Gene Expression + Antibody Capture). Setting this option to false will disable the check across all library combinations. We recommend running this check (default), however if the pipeline errors out, users can bypass the check to generate outputs for troubleshooting.\nboolean, default: TRUE\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe folder to store the alignment results.\nfile, required, example: \"/path/to/output\"\n\n\n\n\n\nExecutor arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--dryrun\nIf true, the output directory will only contain the CWL input files, but the pipeline itself will not be executed.\nboolean_true",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger multi"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html#authors",
    "href": "components/modules/mapping/cellranger_multi.html#authors",
    "title": "Cellranger multi",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)\nDries De Maeyer   (author)\nWeiwei Schultz (contributor)\nDorien Roosen   (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger multi"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html",
    "href": "components/modules/mapping/cellranger_count_split.html",
    "title": "Cellranger count split",
    "section": "",
    "text": "ID: cellranger_count_split\nNamespace: mapping\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger count split"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html#example-commands",
    "href": "components/modules/mapping/cellranger_count_split.html#example-commands",
    "title": "Cellranger count split",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/cellranger_count_split/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input_dir\"\n# filtered_h5: \"$id.$key.filtered_h5.h5\"\n# metrics_summary: \"$id.$key.metrics_summary.csv\"\n# molecule_info: \"$id.$key.molecule_info.h5\"\n# bam: \"$id.$key.bam.bam\"\n# bai: \"$id.$key.bai.bai\"\n# raw_h5: \"$id.$key.raw_h5.h5\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/cellranger_count_split/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger count split"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html#argument-group",
    "href": "components/modules/mapping/cellranger_count_split.html#argument-group",
    "title": "Cellranger count split",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nOutput directory from a Cell Ranger count run.\nfile, required, example: \"input_dir\"\n\n\n--filtered_h5\n\nfile, example: \"filtered_feature_bc_matrix.h5\"\n\n\n--metrics_summary\n\nfile, example: \"metrics_summary.csv\"\n\n\n--molecule_info\n\nfile, example: \"molecule_info.h5\"\n\n\n--bam\n\nfile, example: \"possorted_genome_bam.bam\"\n\n\n--bai\n\nfile, example: \"possorted_genome_bam.bam.bai\"\n\n\n--raw_h5\n\nfile, example: \"raw_feature_bc_matrix.h5\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger count split"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html#authors",
    "href": "components/modules/mapping/cellranger_count_split.html#authors",
    "title": "Cellranger count split",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nSamuel D’Souza   (author)\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger count split"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_atac_count.html",
    "href": "components/modules/mapping/cellranger_atac_count.html",
    "title": "Cellranger atac count",
    "section": "",
    "text": "ID: cellranger_atac_count\nNamespace: mapping\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger atac count"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_atac_count.html#example-commands",
    "href": "components/modules/mapping/cellranger_atac_count.html#example-commands",
    "title": "Cellranger atac count",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/cellranger_atac_count/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"reference.tar.gz\"\n\n# Outputs\n# output: \"$id.$key.output\"\n\n# Arguments\ndescription: \"\"\n# force_cells: 123\n# peaks: \"path/to/file\"\ndim_reduce: \"lsa\"\n# subsample_rate: 0.1\n# lanes: [\"1,3\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/cellranger_atac_count/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger atac count"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_atac_count.html#argument-groups",
    "href": "components/modules/mapping/cellranger_atac_count.html#argument-groups",
    "title": "Cellranger atac count",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, required, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nThe path to Cell Ranger reference tar.gz file. Can also be a directory.\nfile, required, example: \"reference.tar.gz\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe folder to store the alignment results.\nfile, required, example: \"/path/to/output\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--description\nSample description to embed in output files\nstring, default: \"\"\n\n\n--force_cells\nDefine the top N barcodes with the most fragments overlapping peaks as cells and override the cell calling algorithm. N must be a positive integer &lt;= 20,000. Use this option if the number of cells estimated by Cell Ranger ATAC is not consistent with the barcode rank plot\ninteger\n\n\n--peaks\nOverride peak caller: specify peaks to use in downstream analyses from supplied 3-column BED file. The supplied peaks file must be sorted by position and not contain overlapping peaks; comment lines beginning with # are allowed\nfile\n\n\n--dim_reduce\nDimensionality reduction mode for clustering\nstring, default: \"lsa\"\n\n\n--subsample_rate\nDownsample to preserve this fraction of reads\ndouble, example: 0.1\n\n\n--lanes\nbcl2fastq option. Semicolon-delimited series of lanes to demultiplex. Use this if you have a sample sheet for an entire flow cell but only want to generate a few lanes for further 10x Genomics analysis.\nList of string, example: \"1,3\", multiple_sep: \";\"",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger atac count"
    ]
  },
  {
    "objectID": "components/modules/mapping/cellranger_atac_count.html#authors",
    "href": "components/modules/mapping/cellranger_atac_count.html#authors",
    "title": "Cellranger atac count",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (author)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Cellranger atac count"
    ]
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html",
    "href": "components/modules/mapping/star_align_v273a.html",
    "title": "Star align v273a",
    "section": "",
    "text": "ID: star_align_v273a\nNamespace: mapping\n\n\n\nSource",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Star align v273a"
    ]
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html#example-commands",
    "href": "components/modules/mapping/star_align_v273a.html#example-commands",
    "title": "Star align v273a",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -main-script target/nextflow/mapping/star_align_v273a/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ninput: # please fill in - example: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"/path/to/reference\"\n# output: \"$id.$key.output\"\n\n# Run Parameters\n# runRNGseed: 777\n\n# Genome Parameters\n# genomeLoad: \"NoSharedMemory\"\n# genomeFastaFiles: [\"path/to/file\"]\n# genomeFileSizes: [0]\n# genomeTransformOutput: [\"foo\"]\n# genomeChrSetMitochondrial: [\"chrM\", \"M\", \"MT\"]\n\n# Splice Junctions Database\n# sjdbFileChrStartEnd: [\"foo\"]\n# sjdbGTFfile: \"path/to/file\"\n# sjdbGTFchrPrefix: \"foo\"\n# sjdbGTFfeatureExon: \"exon\"\n# sjdbGTFtagExonParentTranscript: \"transcript_id\"\n# sjdbGTFtagExonParentGene: \"gene_id\"\n# sjdbGTFtagExonParentGeneName: [\"gene_name\"]\n# sjdbGTFtagExonParentGeneType: [\"gene_type\", \"gene_biotype\"]\n# sjdbOverhang: 100\n# sjdbScore: 2\n# sjdbInsertSave: \"Basic\"\n\n# Variation parameters\n# varVCFfile: \"foo\"\n\n# Read Parameters\n# readFilesType: \"Fastx\"\n# readFilesSAMattrKeep: [\"All\"]\n# readFilesManifest: \"path/to/file\"\n# readFilesPrefix: \"foo\"\n# readFilesCommand: [\"foo\"]\n# readMapNumber: -1\n# readMatesLengthsIn: \"NotEqual\"\n# readNameSeparator: [\"/\"]\n# readQualityScoreBase: 33\n\n# Read Clipping\n# clipAdapterType: \"Hamming\"\n# clip3pNbases: [0]\n# clip3pAdapterSeq: [\"foo\"]\n# clip3pAdapterMMp: [0.1]\n# clip3pAfterAdapterNbases: [0]\n# clip5pNbases: [0]\n\n# Limits\n# limitGenomeGenerateRAM: 31000000000\n# limitIObufferSize: [30000000, 50000000]\n# limitOutSAMoneReadBytes: 100000\n# limitOutSJoneRead: 1000\n# limitOutSJcollapsed: 1000000\n# limitBAMsortRAM: 0\n# limitSjdbInsertNsj: 1000000\n# limitNreadsSoft: -1\n\n# Output: general\n# outTmpKeep: \"foo\"\n# outStd: \"Log\"\n# outReadsUnmapped: \"foo\"\n# outQSconversionAdd: 0\n# outMultimapperOrder: \"Old_2.4\"\n\n# Output: SAM and BAM\n# outSAMtype: [\"SAM\"]\n# outSAMmode: \"Full\"\n# outSAMstrandField: \"foo\"\n# outSAMattributes: [\"Standard\"]\n# outSAMattrIHstart: 1\n# outSAMunmapped: [\"foo\"]\n# outSAMorder: \"Paired\"\n# outSAMprimaryFlag: \"OneBestScore\"\n# outSAMreadID: \"Standard\"\n# outSAMmapqUnique: 255\n# outSAMflagOR: 0\n# outSAMflagAND: 65535\n# outSAMattrRGline: [\"foo\"]\n# outSAMheaderHD: [\"foo\"]\n# outSAMheaderPG: [\"foo\"]\n# outSAMheaderCommentFile: \"foo\"\n# outSAMfilter: [\"foo\"]\n# outSAMmultNmax: -1\n# outSAMtlen: 1\n# outBAMcompression: 1\n# outBAMsortingThreadN: 0\n# outBAMsortingBinsN: 50\n\n# BAM processing\n# bamRemoveDuplicatesType: \"foo\"\n# bamRemoveDuplicatesMate2basesN: 0\n\n# Output Wiggle\n# outWigType: [\"foo\"]\n# outWigStrand: \"Stranded\"\n# outWigReferencesPrefix: \"foo\"\n# outWigNorm: \"RPM\"\n\n# Output Filtering\n# outFilterType: \"Normal\"\n# outFilterMultimapScoreRange: 1\n# outFilterMultimapNmax: 10\n# outFilterMismatchNmax: 10\n# outFilterMismatchNoverLmax: 0.3\n# outFilterMismatchNoverReadLmax: 1.0\n# outFilterScoreMin: 0\n# outFilterScoreMinOverLread: 0.66\n# outFilterMatchNmin: 0\n# outFilterMatchNminOverLread: 0.66\n# outFilterIntronMotifs: \"foo\"\n# outFilterIntronStrands: \"RemoveInconsistentStrands\"\n\n# Output splice junctions (SJ.out.tab)\n# outSJtype: \"Standard\"\n\n# Output Filtering: Splice Junctions\n# outSJfilterReads: \"All\"\n# outSJfilterOverhangMin: [30, 12, 12, 12]\n# outSJfilterCountUniqueMin: [3, 1, 1, 1]\n# outSJfilterCountTotalMin: [3, 1, 1, 1]\n# outSJfilterDistToOtherSJmin: [10, 0, 5, 10]\n# outSJfilterIntronMaxVsReadN: [50000, 100000, 200000]\n\n# Scoring\n# scoreGap: 0\n# scoreGapNoncan: -8\n# scoreGapGCAG: -4\n# scoreGapATAC: -8\n# scoreGenomicLengthLog2scale: 0\n# scoreDelOpen: -2\n# scoreDelBase: -2\n# scoreInsOpen: -2\n# scoreInsBase: -2\n# scoreStitchSJshift: 1\n\n# Alignments and Seeding\n# seedSearchStartLmax: 50\n# seedSearchStartLmaxOverLread: 1.0\n# seedSearchLmax: 0\n# seedMultimapNmax: 10000\n# seedPerReadNmax: 1000\n# seedPerWindowNmax: 50\n# seedNoneLociPerWindow: 10\n# seedSplitMin: 12\n# seedMapMin: 5\n# alignIntronMin: 21\n# alignIntronMax: 0\n# alignMatesGapMax: 0\n# alignSJoverhangMin: 5\n# alignSJstitchMismatchNmax: [0, -1, 0, 0]\n# alignSJDBoverhangMin: 3\n# alignSplicedMateMapLmin: 0\n# alignSplicedMateMapLminOverLmate: 0.66\n# alignWindowsPerReadNmax: 10000\n# alignTranscriptsPerWindowNmax: 100\n# alignTranscriptsPerReadNmax: 10000\n# alignEndsType: \"Local\"\n# alignEndsProtrude: \"0    ConcordantPair\"\n# alignSoftClipAtReferenceEnds: \"Yes\"\n# alignInsertionFlush: \"foo\"\n\n# Paired-End reads\n# peOverlapNbasesMin: 0\n# peOverlapMMp: 0.01\n\n# Windows, Anchors, Binning\n# winAnchorMultimapNmax: 50\n# winBinNbits: 16\n# winAnchorDistNbins: 9\n# winFlankNbins: 4\n# winReadCoverageRelativeMin: 0.5\n# winReadCoverageBasesMin: 0\n\n# Chimeric Alignments\n# chimOutType: [\"Junctions\"]\n# chimSegmentMin: 0\n# chimScoreMin: 0\n# chimScoreDropMax: 20\n# chimScoreSeparation: 10\n# chimScoreJunctionNonGTAG: -1\n# chimJunctionOverhangMin: 20\n# chimSegmentReadGapMax: 0\n# chimFilter: [\"banGenomicN\"]\n# chimMainSegmentMultNmax: 10\n# chimMultimapNmax: 0\n# chimMultimapScoreRange: 1\n# chimNonchimScoreDropMin: 20\n# chimOutJunctionFormat: 0\n\n# Quantification of Annotations\n# quantMode: [\"foo\"]\n# quantTranscriptomeBAMcompression: 1\n# quantTranscriptomeBan: \"IndelSoftclipSingleend\"\n\n# 2-pass Mapping\n# twopassMode: \"foo\"\n# twopass1readsN: -1\n\n# WASP parameters\n# waspOutputMode: \"foo\"\n\n# STARsolo (single cell RNA-seq) parameters\n# soloType: [\"foo\"]\n# soloCBwhitelist: [\"foo\"]\n# soloCBstart: 1\n# soloCBlen: 16\n# soloUMIstart: 17\n# soloUMIlen: 10\n# soloBarcodeReadLength: 1\n# soloBarcodeMate: 0\n# soloCBposition: [\"foo\"]\n# soloUMIposition: \"foo\"\n# soloAdapterSequence: \"foo\"\n# soloAdapterMismatchesNmax: 1\n# soloCBmatchWLtype: \"1MM_multi\"\n# soloInputSAMattrBarcodeSeq: [\"foo\"]\n# soloInputSAMattrBarcodeQual: [\"foo\"]\n# soloStrand: \"Forward\"\n# soloFeatures: [\"Gene\"]\n# soloMultiMappers: [\"Unique\"]\n# soloUMIdedup: [\"1MM_All\"]\n# soloUMIfiltering: [\"foo\"]\n# soloOutFileNames: [\"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\"]\n# soloCellFilter: [\"CellRanger2.2\", \"3000\", \"0.99\", \"10\"]\n# soloOutFormatFeaturesGeneField3: [\"Gene Expression\"]\n# soloCellReadStats: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\n# Arguments\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 2.1.0 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/star_align_v273a/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend.",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Star align v273a"
    ]
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html#argument-groups",
    "href": "components/modules/mapping/star_align_v273a.html#argument-groups",
    "title": "Star align v273a",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe FASTQ files to be analyzed. Corresponds to the –readFilesIn in the STAR command.\nList of file, required, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nPath to the reference built by star_build_reference. Corresponds to the –genomeDir in the STAR command.\nfile, required, example: \"/path/to/reference\"\n\n\n--output\nPath to output directory. Corresponds to the –outFileNamePrefix in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nRun Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--runRNGseed\nrandom number generator seed.\ninteger, example: 777\n\n\n\n\n\nGenome Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeLoad\nmode of shared memory usage for the genome files. Only used with –runMode alignReads. - LoadAndKeep … load genome into shared and keep it in memory after run - LoadAndRemove … load genome into shared but remove it after run - LoadAndExit … load genome into shared memory and exit, keeping the genome in memory for future runs - Remove … do not map anything, just remove loaded genome from memory - NoSharedMemory … do not use shared memory, each job will have its own private copy of the genome\nstring, example: \"NoSharedMemory\"\n\n\n--genomeFastaFiles\npath(s) to the fasta files with the genome sequences, separated by spaces. These files should be plain text FASTA files, they cannot be zipped. Required for the genome generation (–runMode genomeGenerate). Can also be used in the mapping (–runMode alignReads) to add extra (new) sequences to the genome (e.g. spike-ins).\nList of file, multiple_sep: \";\"\n\n\n--genomeFileSizes\ngenome files exact sizes in bytes. Typically, this should not be defined by the user.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--genomeTransformOutput\nwhich output to transform back to original genome - SAM … SAM/BAM alignments - SJ … splice junctions (SJ.out.tab) - None … no transformation of the output\nList of string, multiple_sep: \";\"\n\n\n--genomeChrSetMitochondrial\nnames of the mitochondrial chromosomes. Presently only used for STARsolo statistics output/\nList of string, example: \"chrM\", \"M\", \"MT\", multiple_sep: \";\"\n\n\n\n\n\nSplice Junctions Database\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sjdbFileChrStartEnd\npath to the files with genomic coordinates (chr  start  end  strand) for the splice junction introns. Multiple files can be supplied and will be concatenated.\nList of string, multiple_sep: \";\"\n\n\n--sjdbGTFfile\npath to the GTF file with annotations\nfile\n\n\n--sjdbGTFchrPrefix\nprefix for chromosome names in a GTF file (e.g. ‘chr’ for using ENSMEBL annotations with UCSC genomes)\nstring\n\n\n--sjdbGTFfeatureExon\nfeature type in GTF file to be used as exons for building transcripts\nstring, example: \"exon\"\n\n\n--sjdbGTFtagExonParentTranscript\nGTF attribute name for parent transcript ID (default “transcript_id” works for GTF files)\nstring, example: \"transcript_id\"\n\n\n--sjdbGTFtagExonParentGene\nGTF attribute name for parent gene ID (default “gene_id” works for GTF files)\nstring, example: \"gene_id\"\n\n\n--sjdbGTFtagExonParentGeneName\nGTF attribute name for parent gene name\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--sjdbGTFtagExonParentGeneType\nGTF attribute name for parent gene type\nList of string, example: \"gene_type\", \"gene_biotype\", multiple_sep: \";\"\n\n\n--sjdbOverhang\nlength of the donor/acceptor sequence on each side of the junctions, ideally = (mate_length - 1)\ninteger, example: 100\n\n\n--sjdbScore\nextra alignment score for alignments that cross database junctions\ninteger, example: 2\n\n\n--sjdbInsertSave\nwhich files to save when sjdb junctions are inserted on the fly at the mapping step - Basic … only small junction / transcript files - All … all files including big Genome, SA and SAindex - this will create a complete genome directory\nstring, example: \"Basic\"\n\n\n\n\n\nVariation parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--varVCFfile\npath to the VCF file that contains variation data. The 10th column should contain the genotype information, e.g. 0/1\nstring\n\n\n\n\n\nRead Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--readFilesType\nformat of input read files - Fastx … FASTA or FASTQ - SAM SE … SAM or BAM single-end reads; for BAM use –readFilesCommand samtools view - SAM PE … SAM or BAM paired-end reads; for BAM use –readFilesCommand samtools view\nstring, example: \"Fastx\"\n\n\n--readFilesSAMattrKeep\nfor –readFilesType SAM SE/PE, which SAM tags to keep in the output BAM, e.g.: –readFilesSAMtagsKeep RG PL - All … keep all tags - None … do not keep any tags\nList of string, example: \"All\", multiple_sep: \";\"\n\n\n--readFilesManifest\npath to the “manifest” file with the names of read files. The manifest file should contain 3 tab-separated columns: paired-end reads: read1_file_name \\(tab\\) read2_file_name \\(tab\\) read_group_line. single-end reads: read1_file_name \\(tab\\) - \\(tab\\) read_group_line. Spaces, but not tabs are allowed in file names. If read_group_line does not start with ID:, it can only contain one ID field, and ID: will be added to it. If read_group_line starts with ID:, it can contain several fields separated by \\(tab\\), and all fields will be be copied verbatim into SAM @RG header line.\nfile\n\n\n--readFilesPrefix\nprefix for the read files names, i.e. it will be added in front of the strings in –readFilesIn\nstring\n\n\n--readFilesCommand\ncommand line to execute for each of the input file. This command should generate FASTA or FASTQ text and send it to stdout For example: zcat - to uncompress .gz files, bzcat - to uncompress .bz2 files, etc.\nList of string, multiple_sep: \";\"\n\n\n--readMapNumber\nnumber of reads to map from the beginning of the file -1: map all reads\ninteger, example: -1\n\n\n--readMatesLengthsIn\nEqual/NotEqual - lengths of names,sequences,qualities for both mates are the same / not the same. NotEqual is safe in all situations.\nstring, example: \"NotEqual\"\n\n\n--readNameSeparator\ncharacter(s) separating the part of the read names that will be trimmed in output (read name after space is always trimmed)\nList of string, example: \"/\", multiple_sep: \";\"\n\n\n--readQualityScoreBase\nnumber to be subtracted from the ASCII code to get Phred quality score\ninteger, example: 33\n\n\n\n\n\nRead Clipping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clipAdapterType\nadapter clipping type - Hamming … adapter clipping based on Hamming distance, with the number of mismatches controlled by –clip5pAdapterMMp - CellRanger4 … 5p and 3p adapter clipping similar to CellRanger4. Utilizes Opal package by Martin Sosic: https://github.com/Martinsos/opal - None … no adapter clipping, all other clip* parameters are disregarded\nstring, example: \"Hamming\"\n\n\n--clip3pNbases\nnumber(s) of bases to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip3pAdapterSeq\nadapter sequences to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates. - polyA … polyA sequence with the length equal to read length\nList of string, multiple_sep: \";\"\n\n\n--clip3pAdapterMMp\nmax proportion of mismatches for 3p adapter clipping for each mate. If one value is given, it will be assumed the same for both mates.\nList of double, example: 0.1, multiple_sep: \";\"\n\n\n--clip3pAfterAdapterNbases\nnumber of bases to clip from 3p of each mate after the adapter clipping. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip5pNbases\nnumber(s) of bases to clip from 5p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n\n\n\nLimits\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--limitGenomeGenerateRAM\nmaximum available RAM (bytes) for genome generation\nlong, example: NA\n\n\n--limitIObufferSize\nmax available buffers size (bytes) for input/output, per thread\nList of long, example: 30000000, 50000000, multiple_sep: \";\"\n\n\n--limitOutSAMoneReadBytes\nmax size of the SAM record (bytes) for one read. Recommended value: &gt;(2(LengthMate1+LengthMate2+100)outFilterMultimapNmax\nlong, example: 100000\n\n\n--limitOutSJoneRead\nmax number of junctions for one read (including all multi-mappers)\ninteger, example: 1000\n\n\n--limitOutSJcollapsed\nmax number of collapsed junctions\ninteger, example: 1000000\n\n\n--limitBAMsortRAM\nmaximum available RAM (bytes) for sorting BAM. If =0, it will be set to the genome index size. 0 value can only be used with –genomeLoad NoSharedMemory option.\nlong, example: 0\n\n\n--limitSjdbInsertNsj\nmaximum number of junctions to be inserted to the genome on the fly at the mapping stage, including those from annotations and those detected in the 1st step of the 2-pass run\ninteger, example: 1000000\n\n\n--limitNreadsSoft\nsoft limit on the number of reads\ninteger, example: -1\n\n\n\n\n\nOutput: general\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outTmpKeep\nwhether to keep the temporary files after STAR runs is finished - None … remove all temporary files - All … keep all files\nstring\n\n\n--outStd\nwhich output will be directed to stdout (standard out) - Log … log messages - SAM … alignments in SAM format (which normally are output to Aligned.out.sam file), normal standard output will go into Log.std.out - BAM_Unsorted … alignments in BAM format, unsorted. Requires –outSAMtype BAM Unsorted - BAM_SortedByCoordinate … alignments in BAM format, sorted by coordinate. Requires –outSAMtype BAM SortedByCoordinate - BAM_Quant … alignments to transcriptome in BAM format, unsorted. Requires –quantMode TranscriptomeSAM\nstring, example: \"Log\"\n\n\n--outReadsUnmapped\noutput of unmapped and partially mapped (i.e. mapped only one mate of a paired end read) reads in separate file(s). - None … no output - Fastx … output in separate fasta/fastq files, Unmapped.out.mate1/2\nstring\n\n\n--outQSconversionAdd\nadd this number to the quality score (e.g. to convert from Illumina to Sanger, use -31)\ninteger, example: 0\n\n\n--outMultimapperOrder\norder of multimapping alignments in the output files - Old_2.4 … quasi-random order used before 2.5.0 - Random … random order of alignments for each multi-mapper. Read mates (pairs) are always adjacent, all alignment for each read stay together. This option will become default in the future releases.\nstring, example: \"Old_2.4\"\n\n\n\n\n\nOutput: SAM and BAM\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSAMtype\ntype of SAM/BAM output 1st word: - BAM … output BAM without sorting - SAM … output SAM without sorting - None … no SAM/BAM output 2nd, 3rd: - Unsorted … standard unsorted - SortedByCoordinate … sorted by coordinate. This option will allocate extra memory for sorting which can be specified by –limitBAMsortRAM.\nList of string, example: \"SAM\", multiple_sep: \";\"\n\n\n--outSAMmode\nmode of SAM output - None … no SAM output - Full … full SAM output - NoQS … full SAM but without quality scores\nstring, example: \"Full\"\n\n\n--outSAMstrandField\nCufflinks-like strand field flag - None … not used - intronMotif … strand derived from the intron motif. This option changes the output alignments: reads with inconsistent and/or non-canonical introns are filtered out.\nstring\n\n\n--outSAMattributes\na string of desired SAM attributes, in the order desired for the output SAM. Tags can be listed in any combination/order. Presets: - None … no attributes - Standard … NH HI AS nM - All … NH HI AS nM NM MD jM jI MC ch Alignment: - NH … number of loci the reads maps to: =1 for unique mappers, &gt;1 for multimappers. Standard SAM tag. - HI … multiple alignment index, starts with –outSAMattrIHstart (=1 by default). Standard SAM tag. - AS … local alignment score, +1/-1 for matches/mismateches, score* penalties for indels and gaps. For PE reads, total score for two mates. Stadnard SAM tag. - nM … number of mismatches. For PE reads, sum over two mates. - NM … edit distance to the reference (number of mismatched + inserted + deleted bases) for each mate. Standard SAM tag. - MD … string encoding mismatched and deleted reference bases (see standard SAM specifications). Standard SAM tag. - jM … intron motifs for all junctions (i.e. N in CIGAR): 0: non-canonical; 1: GT/AG, 2: CT/AC, 3: GC/AG, 4: CT/GC, 5: AT/AC, 6: GT/AT. If splice junctions database is used, and a junction is annotated, 20 is added to its motif value. - jI … start and end of introns for all junctions (1-based). - XS … alignment strand according to –outSAMstrandField. - MC … mate’s CIGAR string. Standard SAM tag. - ch … marks all segment of all chimeric alingments for –chimOutType WithinBAM output. - cN … number of bases clipped from the read ends: 5’ and 3’ Variation: - vA … variant allele - vG … genomic coordinate of the variant overlapped by the read. - vW … 1 - alignment passes WASP filtering; 2,3,4,5,6,7 - alignment does not pass WASP filtering. Requires –waspOutputMode SAMtag. STARsolo: - CR CY UR UY … sequences and quality scores of cell barcodes and UMIs for the solo* demultiplexing. - GX GN … gene ID and gene name for unique-gene reads. - gx gn … gene IDs and gene names for unique- and multi-gene reads. - CB UB … error-corrected cell barcodes and UMIs for solo* demultiplexing. Requires –outSAMtype BAM SortedByCoordinate. - sM … assessment of CB and UMI. - sS … sequence of the entire barcode (CB,UMI,adapter). - sQ … quality of the entire barcode. ***Unsupported/undocumented: - ha … haplotype (1/2) when mapping to the diploid genome. Requires genome generated with –genomeTransformType Diploid . - rB … alignment block read/genomic coordinates. - vR … read coordinate of the variant.\nList of string, example: \"Standard\", multiple_sep: \";\"\n\n\n--outSAMattrIHstart\nstart value for the IH attribute. 0 may be required by some downstream software, such as Cufflinks or StringTie.\ninteger, example: 1\n\n\n--outSAMunmapped\noutput of unmapped reads in the SAM format 1st word: - None … no output - Within … output unmapped reads within the main SAM file (i.e. Aligned.out.sam) 2nd word: - KeepPairs … record unmapped mate for each alignment, and, in case of unsorted output, keep it adjacent to its mapped mate. Only affects multi-mapping reads.\nList of string, multiple_sep: \";\"\n\n\n--outSAMorder\ntype of sorting for the SAM output Paired: one mate after the other for all paired alignments PairedKeepInputOrder: one mate after the other for all paired alignments, the order is kept the same as in the input FASTQ files\nstring, example: \"Paired\"\n\n\n--outSAMprimaryFlag\nwhich alignments are considered primary - all others will be marked with 0x100 bit in the FLAG - OneBestScore … only one alignment with the best score is primary - AllBestScore … all alignments with the best score are primary\nstring, example: \"OneBestScore\"\n\n\n--outSAMreadID\nread ID record type - Standard … first word (until space) from the FASTx read ID line, removing /1,/2 from the end - Number … read number (index) in the FASTx file\nstring, example: \"Standard\"\n\n\n--outSAMmapqUnique\n0 to 255: the MAPQ value for unique mappers\ninteger, example: 255\n\n\n--outSAMflagOR\n0 to 65535: sam FLAG will be bitwise OR’d with this value, i.e. FLAG=FLAG | outSAMflagOR. This is applied after all flags have been set by STAR, and after outSAMflagAND. Can be used to set specific bits that are not set otherwise.\ninteger, example: 0\n\n\n--outSAMflagAND\n0 to 65535: sam FLAG will be bitwise AND’d with this value, i.e. FLAG=FLAG & outSAMflagOR. This is applied after all flags have been set by STAR, but before outSAMflagOR. Can be used to unset specific bits that are not set otherwise.\ninteger, example: 65535\n\n\n--outSAMattrRGline\nSAM/BAM read group line. The first word contains the read group identifier and must start with “ID:”, e.g. –outSAMattrRGline ID:xxx CN:yy “DS:z z z”. xxx will be added as RG tag to each output alignment. Any spaces in the tag values have to be double quoted. Comma separated RG lines correspons to different (comma separated) input files in –readFilesIn. Commas have to be surrounded by spaces, e.g. –outSAMattrRGline ID:xxx , ID:zzz “DS:z z” , ID:yyy DS:yyyy\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderHD\n@HD (header) line of the SAM header\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderPG\nextra @PG (software) line of the SAM header (in addition to STAR)\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderCommentFile\npath to the file with @CO (comment) lines of the SAM header\nstring\n\n\n--outSAMfilter\nfilter the output into main SAM/BAM files - KeepOnlyAddedReferences … only keep the reads for which all alignments are to the extra reference sequences added with –genomeFastaFiles at the mapping stage. - KeepAllAddedReferences … keep all alignments to the extra reference sequences added with –genomeFastaFiles at the mapping stage.\nList of string, multiple_sep: \";\"\n\n\n--outSAMmultNmax\nmax number of multiple alignments for a read that will be output to the SAM/BAM files. Note that if this value is not equal to -1, the top scoring alignment will be output first - -1 … all alignments (up to –outFilterMultimapNmax) will be output\ninteger, example: -1\n\n\n--outSAMtlen\ncalculation method for the TLEN field in the SAM/BAM files - 1 … leftmost base of the (+)strand mate to rightmost base of the (-)mate. (+)sign for the (+)strand mate - 2 … leftmost base of any mate to rightmost base of any mate. (+)sign for the mate with the leftmost base. This is different from 1 for overlapping mates with protruding ends\ninteger, example: 1\n\n\n--outBAMcompression\n-1 to 10 BAM compression level, -1=default compression (6?), 0=no compression, 10=maximum compression\ninteger, example: 1\n\n\n--outBAMsortingThreadN\n&gt;=0: number of threads for BAM sorting. 0 will default to min(6,–runThreadN).\ninteger, example: 0\n\n\n--outBAMsortingBinsN\n&gt;0: number of genome bins for coordinate-sorting\ninteger, example: 50\n\n\n\n\n\nBAM processing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bamRemoveDuplicatesType\nmark duplicates in the BAM file, for now only works with (i) sorted BAM fed with inputBAMfile, and (ii) for paired-end alignments only - - … no duplicate removal/marking - UniqueIdentical … mark all multimappers, and duplicate unique mappers. The coordinates, FLAG, CIGAR must be identical - UniqueIdenticalNotMulti … mark duplicate unique mappers but not multimappers.\nstring\n\n\n--bamRemoveDuplicatesMate2basesN\nnumber of bases from the 5’ of mate 2 to use in collapsing (e.g. for RAMPAGE)\ninteger, example: 0\n\n\n\n\n\nOutput Wiggle\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outWigType\ntype of signal output, e.g. “bedGraph” OR “bedGraph read1_5p”. Requires sorted BAM: –outSAMtype BAM SortedByCoordinate . 1st word: - None … no signal output - bedGraph … bedGraph format - wiggle … wiggle format 2nd word: - read1_5p … signal from only 5’ of the 1st read, useful for CAGE/RAMPAGE etc - read2 … signal from only 2nd read\nList of string, multiple_sep: \";\"\n\n\n--outWigStrand\nstrandedness of wiggle/bedGraph output - Stranded … separate strands, str1 and str2 - Unstranded … collapsed strands\nstring, example: \"Stranded\"\n\n\n--outWigReferencesPrefix\nprefix matching reference names to include in the output wiggle file, e.g. “chr”, default “-” - include all references\nstring\n\n\n--outWigNorm\ntype of normalization for the signal - RPM … reads per million of mapped reads - None … no normalization, “raw” counts\nstring, example: \"RPM\"\n\n\n\n\n\nOutput Filtering\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outFilterType\ntype of filtering - Normal … standard filtering using only current alignment - BySJout … keep only those reads that contain junctions that passed filtering into SJ.out.tab\nstring, example: \"Normal\"\n\n\n--outFilterMultimapScoreRange\nthe score range below the maximum score for multimapping alignments\ninteger, example: 1\n\n\n--outFilterMultimapNmax\nmaximum number of loci the read is allowed to map to. Alignments (all of them) will be output only if the read maps to no more loci than this value. Otherwise no alignments will be output, and the read will be counted as “mapped to too many loci” in the Log.final.out .\ninteger, example: 10\n\n\n--outFilterMismatchNmax\nalignment will be output only if it has no more mismatches than this value.\ninteger, example: 10\n\n\n--outFilterMismatchNoverLmax\nalignment will be output only if its ratio of mismatches to mapped length is less than or equal to this value.\ndouble, example: 0.3\n\n\n--outFilterMismatchNoverReadLmax\nalignment will be output only if its ratio of mismatches to read length is less than or equal to this value.\ndouble, example: 1\n\n\n--outFilterScoreMin\nalignment will be output only if its score is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterScoreMinOverLread\nsame as outFilterScoreMin, but normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 0.66\n\n\n--outFilterMatchNmin\nalignment will be output only if the number of matched bases is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterMatchNminOverLread\nsam as outFilterMatchNmin, but normalized to the read length (sum of mates’ lengths for paired-end reads).\ndouble, example: 0.66\n\n\n--outFilterIntronMotifs\nfilter alignment using their motifs - None … no filtering - RemoveNoncanonical … filter out alignments that contain non-canonical junctions - RemoveNoncanonicalUnannotated … filter out alignments that contain non-canonical unannotated junctions when using annotated splice junctions database. The annotated non-canonical junctions will be kept.\nstring\n\n\n--outFilterIntronStrands\nfilter alignments - RemoveInconsistentStrands … remove alignments that have junctions with inconsistent strands - None … no filtering\nstring, example: \"RemoveInconsistentStrands\"\n\n\n\n\n\nOutput splice junctions (SJ.out.tab)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJtype\ntype of splice junction output - Standard … standard SJ.out.tab output - None … no splice junction output\nstring, example: \"Standard\"\n\n\n\n\n\nOutput Filtering: Splice Junctions\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJfilterReads\nwhich reads to consider for collapsed splice junctions output - All … all reads, unique- and multi-mappers - Unique … uniquely mapping reads only\nstring, example: \"All\"\n\n\n--outSJfilterOverhangMin\nminimum overhang length for splice junctions on both sides for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif does not apply to annotated junctions\nList of integer, example: 30, 12, 12, 12, multiple_sep: \";\"\n\n\n--outSJfilterCountUniqueMin\nminimum uniquely mapping read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterCountTotalMin\nminimum total (multi-mapping+unique) read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterDistToOtherSJmin\nminimum allowed distance to other junctions’ donor/acceptor does not apply to annotated junctions\nList of integer, example: 10, 0, 5, 10, multiple_sep: \";\"\n\n\n--outSJfilterIntronMaxVsReadN\nmaximum gap allowed for junctions supported by 1,2,3,,,N reads i.e. by default junctions supported by 1 read can have gaps &lt;=50000b, by 2 reads: &lt;=100000b, by 3 reads: &lt;=200000. by &gt;=4 reads any gap &lt;=alignIntronMax does not apply to annotated junctions\nList of integer, example: 50000, 100000, 200000, multiple_sep: \";\"\n\n\n\n\n\nScoring\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scoreGap\nsplice junction penalty (independent on intron motif)\ninteger, example: 0\n\n\n--scoreGapNoncan\nnon-canonical junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGapGCAG\nGC/AG and CT/GC junction penalty (in addition to scoreGap)\ninteger, example: -4\n\n\n--scoreGapATAC\nAT/AC and GT/AT junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGenomicLengthLog2scale\nextra score logarithmically scaled with genomic length of the alignment: scoreGenomicLengthLog2scale*log2(genomicLength)\ninteger, example: 0\n\n\n--scoreDelOpen\ndeletion open penalty\ninteger, example: -2\n\n\n--scoreDelBase\ndeletion extension penalty per base (in addition to scoreDelOpen)\ninteger, example: -2\n\n\n--scoreInsOpen\ninsertion open penalty\ninteger, example: -2\n\n\n--scoreInsBase\ninsertion extension penalty per base (in addition to scoreInsOpen)\ninteger, example: -2\n\n\n--scoreStitchSJshift\nmaximum score reduction while searching for SJ boundaries in the stitching step\ninteger, example: 1\n\n\n\n\n\nAlignments and Seeding\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--seedSearchStartLmax\ndefines the search start point through the read - the read is split into pieces no longer than this value\ninteger, example: 50\n\n\n--seedSearchStartLmaxOverLread\nseedSearchStartLmax normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 1\n\n\n--seedSearchLmax\ndefines the maximum length of the seeds, if =0 seed length is not limited\ninteger, example: 0\n\n\n--seedMultimapNmax\nonly pieces that map fewer than this value are utilized in the stitching procedure\ninteger, example: 10000\n\n\n--seedPerReadNmax\nmax number of seeds per read\ninteger, example: 1000\n\n\n--seedPerWindowNmax\nmax number of seeds per window\ninteger, example: 50\n\n\n--seedNoneLociPerWindow\nmax number of one seed loci per window\ninteger, example: 10\n\n\n--seedSplitMin\nmin length of the seed sequences split by Ns or mate gap\ninteger, example: 12\n\n\n--seedMapMin\nmin length of seeds to be mapped\ninteger, example: 5\n\n\n--alignIntronMin\nminimum intron size, genomic gap is considered intron if its length&gt;=alignIntronMin, otherwise it is considered Deletion\ninteger, example: 21\n\n\n--alignIntronMax\nmaximum intron size, if 0, max intron size will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignMatesGapMax\nmaximum gap between two mates, if 0, max intron gap will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignSJoverhangMin\nminimum overhang (i.e. block size) for spliced alignments\ninteger, example: 5\n\n\n--alignSJstitchMismatchNmax\nmaximum number of mismatches for stitching of the splice junctions (-1: no limit). (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif.\nList of integer, example: 0, -1, 0, 0, multiple_sep: \";\"\n\n\n--alignSJDBoverhangMin\nminimum overhang (i.e. block size) for annotated (sjdb) spliced alignments\ninteger, example: 3\n\n\n--alignSplicedMateMapLmin\nminimum mapped length for a read mate that is spliced\ninteger, example: 0\n\n\n--alignSplicedMateMapLminOverLmate\nalignSplicedMateMapLmin normalized to mate length\ndouble, example: 0.66\n\n\n--alignWindowsPerReadNmax\nmax number of windows per read\ninteger, example: 10000\n\n\n--alignTranscriptsPerWindowNmax\nmax number of transcripts per window\ninteger, example: 100\n\n\n--alignTranscriptsPerReadNmax\nmax number of different alignments per read to consider\ninteger, example: 10000\n\n\n--alignEndsType\ntype of read ends alignment - Local … standard local alignment with soft-clipping allowed - EndToEnd … force end-to-end read alignment, do not soft-clip - Extend5pOfRead1 … fully extend only the 5p of the read1, all other ends: local alignment - Extend5pOfReads12 … fully extend only the 5p of the both read1 and read2, all other ends: local alignment\nstring, example: \"Local\"\n\n\n--alignEndsProtrude\nallow protrusion of alignment ends, i.e. start (end) of the +strand mate downstream of the start (end) of the -strand mate 1st word: int: maximum number of protrusion bases allowed 2nd word: string: - ConcordantPair … report alignments with non-zero protrusion as concordant pairs - DiscordantPair … report alignments with non-zero protrusion as discordant pairs\nstring, example: \"0    ConcordantPair\"\n\n\n--alignSoftClipAtReferenceEnds\nallow the soft-clipping of the alignments past the end of the chromosomes - Yes … allow - No … prohibit, useful for compatibility with Cufflinks\nstring, example: \"Yes\"\n\n\n--alignInsertionFlush\nhow to flush ambiguous insertion positions - None … insertions are not flushed - Right … insertions are flushed to the right\nstring\n\n\n\n\n\nPaired-End reads\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--peOverlapNbasesMin\nminimum number of overlapping bases to trigger mates merging and realignment. Specify &gt;0 value to switch on the “merginf of overlapping mates” algorithm.\ninteger, example: 0\n\n\n--peOverlapMMp\nmaximum proportion of mismatched bases in the overlap area\ndouble, example: 0.01\n\n\n\n\n\nWindows, Anchors, Binning\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--winAnchorMultimapNmax\nmax number of loci anchors are allowed to map to\ninteger, example: 50\n\n\n--winBinNbits\n=log2(winBin), where winBin is the size of the bin for the windows/clustering, each window will occupy an integer number of bins.\ninteger, example: 16\n\n\n--winAnchorDistNbins\nmax number of bins between two anchors that allows aggregation of anchors into one window\ninteger, example: 9\n\n\n--winFlankNbins\nlog2(winFlank), where win Flank is the size of the left and right flanking regions for each window\ninteger, example: 4\n\n\n--winReadCoverageRelativeMin\nminimum relative coverage of the read sequence by the seeds in a window, for STARlong algorithm only.\ndouble, example: 0.5\n\n\n--winReadCoverageBasesMin\nminimum number of bases covered by the seeds in a window , for STARlong algorithm only.\ninteger, example: 0\n\n\n\n\n\nChimeric Alignments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--chimOutType\ntype of chimeric output - Junctions … Chimeric.out.junction - SeparateSAMold … output old SAM into separate Chimeric.out.sam file - WithinBAM … output into main aligned BAM files (Aligned.*.bam) - WithinBAM HardClip … (default) hard-clipping in the CIGAR for supplemental chimeric alignments (default if no 2nd word is present) - WithinBAM SoftClip … soft-clipping in the CIGAR for supplemental chimeric alignments\nList of string, example: \"Junctions\", multiple_sep: \";\"\n\n\n--chimSegmentMin\nminimum length of chimeric segment length, if ==0, no chimeric output\ninteger, example: 0\n\n\n--chimScoreMin\nminimum total (summed) score of the chimeric segments\ninteger, example: 0\n\n\n--chimScoreDropMax\nmax drop (difference) of chimeric score (the sum of scores of all chimeric segments) from the read length\ninteger, example: 20\n\n\n--chimScoreSeparation\nminimum difference (separation) between the best chimeric score and the next one\ninteger, example: 10\n\n\n--chimScoreJunctionNonGTAG\npenalty for a non-GT/AG chimeric junction\ninteger, example: -1\n\n\n--chimJunctionOverhangMin\nminimum overhang for a chimeric junction\ninteger, example: 20\n\n\n--chimSegmentReadGapMax\nmaximum gap in the read sequence between chimeric segments\ninteger, example: 0\n\n\n--chimFilter\ndifferent filters for chimeric alignments - None … no filtering - banGenomicN … Ns are not allowed in the genome sequence around the chimeric junction\nList of string, example: \"banGenomicN\", multiple_sep: \";\"\n\n\n--chimMainSegmentMultNmax\nmaximum number of multi-alignments for the main chimeric segment. =1 will prohibit multimapping main segments.\ninteger, example: 10\n\n\n--chimMultimapNmax\nmaximum number of chimeric multi-alignments - 0 … use the old scheme for chimeric detection which only considered unique alignments\ninteger, example: 0\n\n\n--chimMultimapScoreRange\nthe score range for multi-mapping chimeras below the best chimeric score. Only works with –chimMultimapNmax &gt; 1\ninteger, example: 1\n\n\n--chimNonchimScoreDropMin\nto trigger chimeric detection, the drop in the best non-chimeric alignment score with respect to the read length has to be greater than this value\ninteger, example: 20\n\n\n--chimOutJunctionFormat\nformatting type for the Chimeric.out.junction file - 0 … no comment lines/headers - 1 … comment lines at the end of the file: command line and Nreads: total, unique/multi-mapping\ninteger, example: 0\n\n\n\n\n\nQuantification of Annotations\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--quantMode\ntypes of quantification requested - - … none - TranscriptomeSAM … output SAM/BAM alignments to transcriptome into a separate file - GeneCounts … count reads per gene\nList of string, multiple_sep: \";\"\n\n\n--quantTranscriptomeBAMcompression\n-2 to 10 transcriptome BAM compression level - -2 … no BAM output - -1 … default compression (6?) - 0 … no compression - 10 … maximum compression\ninteger, example: 1\n\n\n--quantTranscriptomeBan\nprohibit various alignment type - IndelSoftclipSingleend … prohibit indels, soft clipping and single-end alignments - compatible with RSEM - Singleend … prohibit single-end alignments\nstring, example: \"IndelSoftclipSingleend\"\n\n\n\n\n\n2-pass Mapping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--twopassMode\n2-pass mapping mode. - None … 1-pass mapping - Basic … basic 2-pass mapping, with all 1st pass junctions inserted into the genome indices on the fly\nstring\n\n\n--twopass1readsN\nnumber of reads to process for the 1st step. Use very large number (or default -1) to map all reads in the first step.\ninteger, example: -1\n\n\n\n\n\nWASP parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--waspOutputMode\nWASP allele-specific output type. This is re-implementation of the original WASP mappability filtering by Bryce van de Geijn, Graham McVicker, Yoav Gilad & Jonathan K Pritchard. Please cite the original WASP paper: Nature Methods 12, 1061-1063 (2015), https://www.nature.com/articles/nmeth.3582 . - SAMtag … add WASP tags to the alignments that pass WASP filtering\nstring\n\n\n\n\n\nSTARsolo (single cell RNA-seq) parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--soloType\ntype of single-cell RNA-seq - CB_UMI_Simple … (a.k.a. Droplet) one UMI and one Cell Barcode of fixed length in read2, e.g. Drop-seq and 10X Chromium. - CB_UMI_Complex … multiple Cell Barcodes of varying length, one UMI of fixed length and one adapter sequence of fixed length are allowed in read2 only (e.g. inDrop, ddSeq). - CB_samTagOut … output Cell Barcode as CR and/or CB SAm tag. No UMI counting. –readFilesIn cDNA_read1 [cDNA_read2 if paired-end] CellBarcode_read . Requires –outSAMtype BAM Unsorted [and/or SortedByCoordinate] - SmartSeq … Smart-seq: each cell in a separate FASTQ (paired- or single-end), barcodes are corresponding read-groups, no UMI sequences, alignments deduplicated according to alignment start and end (after extending soft-clipped bases)\nList of string, multiple_sep: \";\"\n\n\n--soloCBwhitelist\nfile(s) with whitelist(s) of cell barcodes. Only –soloType CB_UMI_Complex allows more than one whitelist file. - None … no whitelist: all cell barcodes are allowed\nList of string, multiple_sep: \";\"\n\n\n--soloCBstart\ncell barcode start base\ninteger, example: 1\n\n\n--soloCBlen\ncell barcode length\ninteger, example: 16\n\n\n--soloUMIstart\nUMI start base\ninteger, example: 17\n\n\n--soloUMIlen\nUMI length\ninteger, example: 10\n\n\n--soloBarcodeReadLength\nlength of the barcode read - 1 … equal to sum of soloCBlen+soloUMIlen - 0 … not defined, do not check\ninteger, example: 1\n\n\n--soloBarcodeMate\nidentifies which read mate contains the barcode (CB+UMI) sequence - 0 … barcode sequence is on separate read, which should always be the last file in the –readFilesIn listed - 1 … barcode sequence is a part of mate 1 - 2 … barcode sequence is a part of mate 2\ninteger, example: 0\n\n\n--soloCBposition\nposition of Cell Barcode(s) on the barcode read. Presently only works with –soloType CB_UMI_Complex, and barcodes are assumed to be on Read2. Format for each barcode: startAnchor_startPosition_endAnchor_endPosition start(end)Anchor defines the Anchor Base for the CB: 0: read start; 1: read end; 2: adapter start; 3: adapter end start(end)Position is the 0-based position with of the CB start(end) with respect to the Anchor Base String for different barcodes are separated by space. Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 0_0_2_-1 3_1_3_8\nList of string, multiple_sep: \";\"\n\n\n--soloUMIposition\nposition of the UMI on the barcode read, same as soloCBposition Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 3_9_3_14\nstring\n\n\n--soloAdapterSequence\nadapter sequence to anchor barcodes. Only one adapter sequence is allowed.\nstring\n\n\n--soloAdapterMismatchesNmax\nmaximum number of mismatches allowed in adapter sequence.\ninteger, example: 1\n\n\n--soloCBmatchWLtype\nmatching the Cell Barcodes to the WhiteList - Exact … only exact matches allowed - 1MM … only one match in whitelist with 1 mismatched base allowed. Allowed CBs have to have at least one read with exact match. - 1MM_multi … multiple matches in whitelist with 1 mismatched base allowed, posterior probability calculation is used choose one of the matches. Allowed CBs have to have at least one read with exact match. This option matches best with CellRanger 2.2.0 - 1MM_multi_pseudocounts … same as 1MM_Multi, but pseudocounts of 1 are added to all whitelist barcodes. - 1MM_multi_Nbase_pseudocounts … same as 1MM_multi_pseudocounts, multimatching to WL is allowed for CBs with N-bases. This option matches best with CellRanger &gt;= 3.0.0 - EditDist_2 … allow up to edit distance of 3 fpr each of the barcodes. May include one deletion + one insertion. Only works with –soloType CB_UMI_Complex. Matches to multiple passlist barcdoes are not allowed. Similar to ParseBio Split-seq pipeline.\nstring, example: \"1MM_multi\"\n\n\n--soloInputSAMattrBarcodeSeq\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode sequence (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeSeq CR UR . This parameter is required when running STARsolo with input from SAM.\nList of string, multiple_sep: \";\"\n\n\n--soloInputSAMattrBarcodeQual\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode qualities (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeQual CY UY . If this parameter is ‘-’ (default), the quality ‘H’ will be assigned to all bases.\nList of string, multiple_sep: \";\"\n\n\n--soloStrand\nstrandedness of the solo libraries: - Unstranded … no strand information - Forward … read strand same as the original RNA molecule - Reverse … read strand opposite to the original RNA molecule\nstring, example: \"Forward\"\n\n\n--soloFeatures\ngenomic features for which the UMI counts per Cell Barcode are collected - Gene … genes: reads match the gene transcript - SJ … splice junctions: reported in SJ.out.tab - GeneFull … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns - GeneFull_ExonOverIntron … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns: prioritize 100% overlap with exons - GeneFull_Ex50pAS … full gene (pre-RNA): count all reads overlapping genes’ exons and introns: prioritize &gt;50% overlap with exons. Do not count reads with 100% exonic overlap in the antisense direction.\nList of string, example: \"Gene\", multiple_sep: \";\"\n\n\n--soloMultiMappers\ncounting method for reads mapping to multiple genes - Unique … count only reads that map to unique genes - Uniform … uniformly distribute multi-genic UMIs to all genes - Rescue … distribute UMIs proportionally to unique+uniform counts (~ first iteration of EM) - PropUnique … distribute UMIs proportionally to unique mappers, if present, and uniformly if not. - EM … multi-gene UMIs are distributed using Expectation Maximization algorithm\nList of string, example: \"Unique\", multiple_sep: \";\"\n\n\n--soloUMIdedup\ntype of UMI deduplication (collapsing) algorithm - 1MM_All … all UMIs with 1 mismatch distance to each other are collapsed (i.e. counted once). - 1MM_Directional_UMItools … follows the “directional” method from the UMI-tools by Smith, Heger and Sudbery (Genome Research 2017). - 1MM_Directional … same as 1MM_Directional_UMItools, but with more stringent criteria for duplicate UMIs - Exact … only exactly matching UMIs are collapsed. - NoDedup … no deduplication of UMIs, count all reads. - 1MM_CR … CellRanger2-4 algorithm for 1MM UMI collapsing.\nList of string, example: \"1MM_All\", multiple_sep: \";\"\n\n\n--soloUMIfiltering\ntype of UMI filtering (for reads uniquely mapping to genes) - - … basic filtering: remove UMIs with N and homopolymers (similar to CellRanger 2.2.0). - MultiGeneUMI … basic + remove lower-count UMIs that map to more than one gene. - MultiGeneUMI_All … basic + remove all UMIs that map to more than one gene. - MultiGeneUMI_CR … basic + remove lower-count UMIs that map to more than one gene, matching CellRanger &gt; 3.0.0 . Only works with –soloUMIdedup 1MM_CR\nList of string, multiple_sep: \";\"\n\n\n--soloOutFileNames\nfile names for STARsolo output: file_name_prefix gene_names barcode_sequences cell_feature_count_matrix\nList of string, example: \"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\", multiple_sep: \";\"\n\n\n--soloCellFilter\ncell filtering type and parameters - None … do not output filtered cells - TopCells … only report top cells by UMI count, followed by the exact number of cells - CellRanger2.2 … simple filtering of CellRanger 2.2. Can be followed by numbers: number of expected cells, robust maximum percentile for UMI count, maximum to minimum ratio for UMI count The harcoded values are from CellRanger: nExpectedCells=3000; maxPercentile=0.99; maxMinRatio=10 - EmptyDrops_CR … EmptyDrops filtering in CellRanger flavor. Please cite the original EmptyDrops paper: A.T.L Lun et al, Genome Biology, 20, 63 (2019): https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1662-y Can be followed by 10 numeric parameters: nExpectedCells maxPercentile maxMinRatio indMin indMax umiMin umiMinFracMedian candMaxN FDR simN The harcoded values are from CellRanger: 3000 0.99 10 45000 90000 500 0.01 20000 0.01 10000\nList of string, example: \"CellRanger2.2\", \"3000\", \"0.99\", \"10\", multiple_sep: \";\"\n\n\n--soloOutFormatFeaturesGeneField3\nfield 3 in the Gene features.tsv file. If “-”, then no 3rd field is output.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--soloCellReadStats\nOutput reads statistics for each CB - Standard … standard output\nstring",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Star align v273a"
    ]
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html#authors",
    "href": "components/modules/mapping/star_align_v273a.html#authors",
    "title": "Star align v273a",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)",
    "crumbs": [
      "Reference",
      "Modules",
      "Mapping",
      "Star align v273a"
    ]
  },
  {
    "objectID": "user_guide/parameter_lists.html",
    "href": "user_guide/parameter_lists.html",
    "title": "Parameter lists",
    "section": "",
    "text": "Using the Viash VDSL3 Nextflow platform, an optional --param_list argument can be passed to OpenPipelines workflows. The --param_list argument enables passing multiple inputs to a workflow, resulting in a multi-event nextflow channel.",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Parameter lists"
    ]
  },
  {
    "objectID": "user_guide/parameter_lists.html#json-file",
    "href": "user_guide/parameter_lists.html#json-file",
    "title": "Parameter lists",
    "section": "JSON file",
    "text": "JSON file\nThe following example shows how to use a json file as a parameter list.\n$ cat param_list.json\n[\n    {\n        \"id\": \"foo\",\n        \"input\": \"foo.txt\",\n        \"event_param\": \"lorem\"\n    },\n    {\n        \"id\": \"bar\",\n        \"input\": \"bar.txt\",\n        \"event_param\": \"ipsum\"\n    }\n]\nnextflow run ... --param_list param_list.json",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Parameter lists"
    ]
  },
  {
    "objectID": "user_guide/parameter_lists.html#csv-file",
    "href": "user_guide/parameter_lists.html#csv-file",
    "title": "Parameter lists",
    "section": "CSV file",
    "text": "CSV file\nThe following example shows how to use a csv file as a parameter list.\n$ cat param_list.csv\nid,input,event_param\nfoo,foo.txt,lorem\nbar,bar.txt,ipsum\nnextflow run ... --param_list param_list.csv",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Parameter lists"
    ]
  },
  {
    "objectID": "user_guide/index.html",
    "href": "user_guide/index.html",
    "title": "User guide",
    "section": "",
    "text": "Getting started: Setting up infrastructure\n  \n  \n  \n    Running pipelines: Run a pipeline from CLI or Nextflow Tower\n  \n  \n  \n    Parameter lists: Passing multiple inputs to a workflow\n  \n  \n  \n    Ingestion: From sequencing to count tables\n  \n  \n  \n    Processing: From count tables to integrated data\n  \n  \n  \n    Downstream: Celltyping and cell-cell communication\n  \n  \n  \n    Bug reports: How to report bugs\n  \n  \n\n\nNo matching items",
    "crumbs": [
      "Fundamentals",
      "User guide"
    ]
  },
  {
    "objectID": "user_guide/bug_reports.html",
    "href": "user_guide/bug_reports.html",
    "title": "Bug reports",
    "section": "",
    "text": "Issues with Openpipelines are being tracked on Github. In order for an issue to be fixed in a timely manner, creating a complete and reproducable is essential.",
    "crumbs": [
      "Fundamentals",
      "User guide",
      "Bug reports"
    ]
  }
]